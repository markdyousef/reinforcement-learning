{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Q-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import gym\n",
    "from gym.wrappers import Monitor\n",
    "import itertools\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from collections import deque, namedtuple\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import EpisodeStats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 16:42:30,135] Making new env: Breakout-v0\n"
     ]
    }
   ],
   "source": [
    "env = gym.envs.make('Breakout-v0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NOOP', 'FIRE', 'RIGHT', 'LEFT']\n"
     ]
    }
   ],
   "source": [
    "print(env.env.get_action_meanings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "VALID_ACTIONS = [0,1,2,3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Environment State"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "raw Atari 2600 frames: 210x160 pixel images with a 128-colour palette\n",
    "\n",
    "\n",
    "**basic preprocessing step:**\n",
    "* 4 last screen images\n",
    "* resize to 84x84\n",
    "* convert to grayscale (256 gray levels)\n",
    "\n",
    "$256^{84x84x4} \\approx 10^{67970}$ possible game states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class StateProcessor():\n",
    "    def __init__(self):\n",
    "        # build TF graph\n",
    "        with tf.variable_scope('state_processor'):\n",
    "            self.input_state = tf.placeholder(shape=[210, 160, 3], dtype=tf.uint8)\n",
    "            self.output = tf.image.rgb_to_grayscale(self.input_state)\n",
    "            self.output = tf.image.crop_to_bounding_box(\n",
    "                self.output, 34, 0, 160, 160)\n",
    "            self.output = tf.image.resize_images(\n",
    "                self.output, [84, 84], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "            self.output = tf.squeeze(self.output)\n",
    "    \n",
    "    def process(self, sess, state):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            sess: TF session object\n",
    "            state: [210, 160, 3] Atari RGB State\n",
    "        Returns:\n",
    "            processed [84,84,1] state\n",
    "        \"\"\"\n",
    "        return sess.run(self.output, { self.input_state: state})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Network Architecture:**\n",
    "\n",
    "|Layer|Input   |Filter size|Stride|Num filters|Activation|Output  |\n",
    "|-----|--------|-----------|------|-----------|----------|--------|\n",
    "|conv1|84x84x4 |8x8        |4     |32         |ReLU      |20x20x32|\n",
    "|conv2|20x20x32|4x4        |3     |64         |ReLU      |9x9x64  |\n",
    "|conv3|9x9x64  |3x3        |1     |64         |ReLU      |7x7x64  |\n",
    "|fc4  |7x7x64  |           |      |512        |ReLU      |512     |\n",
    "|fc5  |512     |           |      |18         |Linear    |18*     |\n",
    "\n",
    "\\* number of valid actions\n",
    "\n",
    "**Optimizer RMSProp:**\n",
    "* lr = 0.00025\n",
    "* decay = 0.99\n",
    "* no momentum\n",
    "* epsilon = 1e-6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Estimator is used for both Q-Network and the Target Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Estimator():\n",
    "    def __init__(self, scope='estimator', summaries_dir=None):\n",
    "        self.scope = scope\n",
    "        # write Tensorboard summaries to disk\n",
    "        self.summary_writer = None\n",
    "        with tf.variable_scope(scope):\n",
    "            self._build_model()\n",
    "            if summaries_dir:\n",
    "                summary_dir = os.path.join(summaries_dir, 'summaries_{}'.format(scope))\n",
    "                if not os.path.exists(summary_dir):\n",
    "                    os.makedirs(summary_dir)\n",
    "                self.summary_writer = tf.summary.FileWriter(summary_dir)\n",
    "    \n",
    "    def _build_model(self):\n",
    "        # input are 4 RGB frames w/ shape 160x160\n",
    "        self.X = tf.placeholder(shape=[None, 84, 84, 4], dtype=tf.uint8, name='X')\n",
    "        # TD-target value\n",
    "        self.y = tf.placeholder(shape=[None], dtype=tf.float32, name='y')\n",
    "        # int id for selected actions\n",
    "        self.actions = tf.placeholder(shape=[None], dtype=tf.int32, name='actions')\n",
    "        X = tf.to_float(self.X)/255.0\n",
    "        batch_size = tf.shape(self.X)[0]\n",
    "        # Network\n",
    "        conv1 = tf.contrib.layers.conv2d(X, 32, 8, 4, activation_fn=tf.nn.relu)\n",
    "        conv2 = tf.contrib.layers.conv2d(conv1, 64, 4, 3, activation_fn=tf.nn.relu)\n",
    "        conv3 = tf.contrib.layers.conv2d(conv2, 64, 3, 1, activation_fn=tf.nn.relu)\n",
    "        fc4 = tf.contrib.layers.fully_connected(\n",
    "            tf.contrib.layers.flatten(conv3), 512)\n",
    "        self.preds = tf.contrib.layers.fully_connected(fc4, len(VALID_ACTIONS))\n",
    "        # predictions for chosen actions only\n",
    "        gather_indices = tf.range(batch_size)*tf.shape(self.preds)[1]+self.actions\n",
    "        self.action_preds = tf.gather(tf.reshape(self.preds, [-1]), gather_indices)\n",
    "        # calculate the loss\n",
    "        self.losses = tf.squared_difference(self.y, self.action_preds)\n",
    "        self.loss = tf.reduce_mean(self.losses)\n",
    "        # Optimizer\n",
    "        self.optimizer = tf.train.RMSPropOptimizer(0.00025, decay=0.99, epsilon=1e-6)\n",
    "        self.train_op = self.optimizer.minimize(\n",
    "            self.loss, global_step=tf.contrib.framework.get_global_step())\n",
    "        # summaries for Tensorboard\n",
    "        self.summaries = tf.summary.merge([\n",
    "            tf.summary.scalar('loss', self.loss),\n",
    "            tf.summary.histogram('loss_hist', self.losses),\n",
    "            tf.summary.histogram('q_values_hist', self.preds),\n",
    "            tf.summary.scalar('max_q_value', tf.reduce_max(self.preds))\n",
    "        ])\n",
    "    \n",
    "    def predict(self, sess, s):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            sess: TF session object\n",
    "            s: state input of shape [batch_size, 4, 160, 160, 3]\n",
    "        \n",
    "        Returns:\n",
    "            tensor of shape [batch_size, NUM_VALID_ACTIONS] containing estimated action values\n",
    "        \"\"\"\n",
    "        return sess.run(self.preds, {self.X: s})\n",
    "    \n",
    "    def update(self, sess, s, a, y):\n",
    "        \"\"\"\n",
    "        Updates estimator towards given targets (y)\n",
    "        Args:\n",
    "            sess: TF session object\n",
    "            s: state input of shape [batch_size, 4, 160, 160, 3]\n",
    "            a: chosen action of shape [batch_size]\n",
    "            y: targets of shape [batch_size]\n",
    "        Returns:\n",
    "            calculated loss on the batch\n",
    "        \"\"\"\n",
    "        feed_dict = {self.X: s, self.y: y, self.actions: a}\n",
    "        summaries, global_step, _, loss = sess.run([\n",
    "            self.summaries,\n",
    "            tf.contrib.framework.get_global_step(),\n",
    "            self.train_op,\n",
    "            self.loss\n",
    "        ], feed_dict)\n",
    "        if self.summary_writer:\n",
    "            self.summary_writer.add_summary(summaries, global_step)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark/.conda/envs/dl/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          0.04459491  0.0059645   0.00791901]\n",
      " [ 0.          0.04459491  0.0059645   0.00791901]]\n",
      "99.4759\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "\n",
    "e = Estimator(scope='test')\n",
    "sp = StateProcessor()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    # example observation batch\n",
    "    observation = env.reset()\n",
    "    \n",
    "    observation_p = sp.process(sess, observation)\n",
    "    observation = np.stack([observation_p]*4, axis=2)\n",
    "    observations = np.array([observation]*2)\n",
    "    # test prediction\n",
    "    print(e.predict(sess, observations))\n",
    "    # test training step\n",
    "    y = np.array([10.0, 10.0])\n",
    "    a = np.array([1, 3])\n",
    "    print(e.update(sess, observations, a, y))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def copy_model_parameters(sess, estimator1, estimator2):\n",
    "    \"\"\"\n",
    "    Copies model parameters from one estimator to another.\n",
    "    Args:\n",
    "        sess: TF session instance\n",
    "        estimator1: Estimator to copy parameters from\n",
    "        estimator2: Estimator to copy parameters to\n",
    "    \"\"\"\n",
    "    e1_params = [t for t in tf.trainable_variables() if t.name.startswith(estimator1.scope)]\n",
    "    e1_params = sorted(e1_params, key=lambda v: v.name)\n",
    "    e2_params = [t for t in tf.trainable_variables() if t.name.startswith(estimator2.scope)]\n",
    "    e2_params = sorted(e2_params, key=lambda v: v.name)\n",
    "    \n",
    "    update_ops = []\n",
    "    for e1_v, e2_v in zip(e1_params, e2_params):\n",
    "        op = e2_v.assign(e1_v)\n",
    "        update_ops.append(op)\n",
    "    \n",
    "    sess.run(update_ops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\epsilon$-greedy policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def epsilon_greedy(estimator, nA):\n",
    "    \"\"\"\n",
    "    Creates an epsilon-greedy policy based on a given Q-function approximator and epsilon.\n",
    "    Args:\n",
    "        estimator: An estimator that returns q values for a given state\n",
    "        nA: Number of actions in the environment.\n",
    "    Returns:\n",
    "        A function that takes the (sess, observation, epsilon) as an argument and returns\n",
    "        the probabilities for each action in the form of a numpy array of length nA.\n",
    "\n",
    "    \"\"\"\n",
    "    def policy_fn(sess, observation, epsilon):\n",
    "        A = np.ones(nA, dtype=float) * epsilon / nA\n",
    "        q_values = estimator.predict(sess, np.expand_dims(observation, 0))[0]\n",
    "        best_action = np.argmax(q_values)\n",
    "        A[best_action] += (1.0 - epsilon)\n",
    "        return A\n",
    "    return policy_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def deep_q_learning(sess,\n",
    "                    env,\n",
    "                    q_estimator,\n",
    "                    target_estimator,\n",
    "                    state_processor,\n",
    "                    n_episodes,\n",
    "                    experiments_dir,\n",
    "                    replay_mem_size=500000,\n",
    "                    replay_mem_init_size=10000,\n",
    "                    estimator_update_steps=10000,\n",
    "                    discount_factor=0.99,\n",
    "                    epsilon_start=1.0,\n",
    "                    epsilon_end=0.1,\n",
    "                    epsilon_decay_steps=500000,\n",
    "                    batch_size=32,\n",
    "                    record_video=50):\n",
    "    \"\"\"\n",
    "    Q-Learning algorithm for TD control using Function Approximation\n",
    "    Finds optimal greedy policy while following epsilon-greedy policy\n",
    "    Args:\n",
    "        sess: TF session object\n",
    "        env: OpenAI env\n",
    "        q_estimator: Estimator object used for the q values\n",
    "        target_estimator: Estimator object used for targets\n",
    "        state_processor: StateProcessor object\n",
    "        n_episodes: Number of episodes to run\n",
    "        experiments_dir: Dir to save TF summaries in\n",
    "        replay_mem_size: Size of replay memory\n",
    "        replay_mem_init_size: Number of random experiences to sample\n",
    "                            when initializing the replay memory\n",
    "        estimator_update_steps: Copy params from q_estimator to target_estimator every N steps\n",
    "        discount_factor: Lambda time discount factor\n",
    "        epsilon_start: Chance to sample a random action when taking action (decayed over time)\n",
    "        epsilon_end: Final minimum value of epsilon after decay\n",
    "        batch_size: Size of batches to sample from replay memory\n",
    "        record_video: Record a video every N steps\n",
    "    Returns:\n",
    "        EpisodeStats object\n",
    "    \"\"\"\n",
    "    Transition = namedtuple('Transition', ['state', 'action', 'reward', 'next_state', 'done'])\n",
    "    \n",
    "    # the replay memory\n",
    "    replay_memory = []\n",
    "    \n",
    "    # keep track of useful stats\n",
    "    stats = EpisodeStats(\n",
    "        episode_lengths=np.zeros(n_episodes),\n",
    "        episode_rewards=np.zeros(n_episodes))\n",
    "    \n",
    "    # create dirs for checkpoints and summaries\n",
    "    checkpoint_dir = os.path.join(experiments_dir, 'checkpoints')\n",
    "    checkpoint_path = os.path.join(checkpoint_dir, 'model')\n",
    "    monitor_path = os.path.join(experiments_dir, 'monitor')\n",
    "    \n",
    "    if not os.path.exists(checkpoint_dir):\n",
    "        os.makedirs(checkpoint_dir)\n",
    "    if not os.path.exists(monitor_path):\n",
    "        os.makedirs(monitor_path)\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    # load previous checkpoint if it exists\n",
    "    latest_checkpoint = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "    if latest_checkpoint:\n",
    "        print('Loading model checkpoint {}...\\n'.format(latest_checkpoint))\n",
    "        saver.restore(sess, latest_checkpoint)\n",
    "    \n",
    "    # get current time step\n",
    "    total_t = sess.run(tf.contrib.framework.get_global_step())\n",
    "    \n",
    "    # epsilon decay schedule\n",
    "    epsilons = np.linspace(epsilon_start, epsilon_end, epsilon_decay_steps)\n",
    "    \n",
    "    policy = epsilon_greedy(q_estimator, len(VALID_ACTIONS))\n",
    "    \n",
    "    # populate replay memory with initial experience\n",
    "    print('Populating replay memory...')\n",
    "    state = env.reset()\n",
    "    state = state_processor.process(sess, state)\n",
    "    state = np.stack([state]*4, axis=2)\n",
    "    for i in range(replay_mem_init_size):\n",
    "        a_probs = policy(sess, state, epsilons[min(total_t, epsilon_decay_steps-1)])\n",
    "        action = np.random.choice(np.arange(len(a_probs)), p=a_probs)\n",
    "        next_state, reward, done, _ = env.step(VALID_ACTIONS[action])\n",
    "        next_state = state_processor.process(sess, next_state)\n",
    "        next_state = np.append(state[:,:,1:], np.expand_dims(next_state, 2), axis=2)\n",
    "        replay_memory.append(Transition(state, action, reward, next_state, done))\n",
    "        if done:\n",
    "            state = env.reset()\n",
    "            state = state_processor.process(sess, state)\n",
    "            state = np.stack([state]*4, axis=2)\n",
    "        else:\n",
    "            state = next_state\n",
    "    \n",
    "    # record videos\n",
    "    env = Monitor(env, directory=monitor_path,\n",
    "                  resume=True, video_callable=lambda count: count%record_video == 0)\n",
    "    \n",
    "    for i_episode in range(n_episodes):\n",
    "        # save current checkpoint\n",
    "        saver.save(tf.get_default_session(), checkpoint_path)\n",
    "        \n",
    "        # reset the environment\n",
    "        state = env.reset()\n",
    "        state = state_processor.process(sess, state)\n",
    "        state = np.stack([state]*4, axis=2)\n",
    "        loss = None\n",
    "        \n",
    "        for t in itertools.count():\n",
    "            # epsilon for this time step\n",
    "            epsilon = epsilons[min(total_t, epsilon_decay_steps-1)]\n",
    "            \n",
    "            # add epsilon to Tensorboard\n",
    "            episode_summary = tf.Summary()\n",
    "            episode_summary.value.add(simple_value=epsilon, tag='epsilon')\n",
    "            q_estimator.summary_writer.add_summary(episode_summary, total_t)\n",
    "            \n",
    "            # update target estimator\n",
    "            if total_t%estimator_update_steps == 0:\n",
    "                copy_model_parameters(sess, q_estimator, target_estimator)\n",
    "                print('\\n Copied model parameters to target network')\n",
    "            \n",
    "            # print step information\n",
    "            print('\\rStep {} ({}) @ Episode {}/{}, loss: {}'.format(\n",
    "                t, total_t, i_episode+1, n_episodes, loss), end='')\n",
    "            sys.stdout.flush()\n",
    "            \n",
    "            # take step in environment\n",
    "            a_probs = policy(sess, state, epsilon)\n",
    "            action = np.random.choice(np.arange(len(a_probs)), p=a_probs)\n",
    "            next_state, reward, done, _ = env.step(VALID_ACTIONS[action])\n",
    "            next_state = state_processor.process(sess, next_state)\n",
    "            next_state = np.append(state[:,:,1:], np.expand_dims(next_state, 2), axis=2)\n",
    "            \n",
    "            # if replay memory is full, pop first element\n",
    "            if len(replay_memory) == replay_mem_size:\n",
    "                replay_memory.pop(0)\n",
    "            \n",
    "            # save transition to replay memory\n",
    "            replay_memory.append(Transition(state, action, reward, next_state, done))\n",
    "            \n",
    "            # update stats\n",
    "            stats.episode_lengths[i_episode] = t\n",
    "            stats.episode_rewards[i_episode] += reward\n",
    "            \n",
    "            # sample minibatch from the replay memory\n",
    "            samples = random.sample(replay_memory, batch_size)\n",
    "            s_batch, a_batch, r_batch, next_s_batch, done_batch = map(np.array, zip(*samples))\n",
    "            # calc q values and targets (Double DQN)\n",
    "            q_values_next = q_estimator.predict(sess, next_s_batch)\n",
    "            best_actions = np.argmax(q_values_next, axis=1)\n",
    "            q_values_next_target = target_estimator.predict(sess, next_s_batch)\n",
    "            targets_batch = r_batch+np.invert(done_batch).astype(np.float32)*\\\n",
    "                discount_factor*q_values_next_target[np.arange(batch_size), best_actions]\n",
    "            # perform GD update\n",
    "            s_batch = np.array(s_batch)\n",
    "            loss = q_estimator.update(sess, s_batch, a_batch, targets_batch)\n",
    "            \n",
    "            if done:\n",
    "                break\n",
    "            \n",
    "            state = next_state\n",
    "            total_t += 1\n",
    "            \n",
    "        # add summaries to Tensorboard\n",
    "        episode_summary = tf.Summary()\n",
    "        episode_summary.value.add(\n",
    "            simple_value=stats.episode_rewards[i_episode],\n",
    "            node_name='episode_reward',\n",
    "            tag='episode_reward')\n",
    "        episode_summary.value.add(\n",
    "            simple_value=stats.episode_lengths[i_episode],\n",
    "            node_name='episode_length',\n",
    "            tag='episode_length')\n",
    "        q_estimator.summary_writer.add_summary(episode_summary, total_t)\n",
    "        q_estimator.summary_writer.flush()\n",
    "\n",
    "        yield total_t, EpisodeStats(\n",
    "            episode_lengths=stats.episode_lengths[:i_episode+1],\n",
    "            episode_rewards=stats.episode_rewards[:i_episode+1])\n",
    "        \n",
    "    env.monitor.close()\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mark/.conda/envs/dl/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating replay memory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 16:47:00,222] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video000000.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Copied model parameters to target network\n",
      "Step 176 (176) @ Episode 1/10000, loss: 0.0013382609467953444\n",
      "Episode Reward: 0.0\n",
      "Step 187 (363) @ Episode 2/10000, loss: 0.0006927750655449927\n",
      "Episode Reward: 0.0\n",
      "Step 164 (527) @ Episode 3/10000, loss: 0.0008092967327684164\n",
      "Episode Reward: 0.0\n",
      "Step 181 (708) @ Episode 4/10000, loss: 0.00071764533640816814\n",
      "Episode Reward: 0.0\n",
      "Step 172 (880) @ Episode 5/10000, loss: 0.00031979102641344076\n",
      "Episode Reward: 0.0\n",
      "Step 236 (1116) @ Episode 6/10000, loss: 0.00078760675387457017\n",
      "Episode Reward: 1.0\n",
      "Step 225 (1341) @ Episode 7/10000, loss: 0.00231808237731456766\n",
      "Episode Reward: 1.0\n",
      "Step 251 (1592) @ Episode 8/10000, loss: 6.0259255405981094e-05\n",
      "Episode Reward: 1.0\n",
      "Step 193 (1785) @ Episode 9/10000, loss: 0.00027064629830420017\n",
      "Episode Reward: 0.0\n",
      "Step 232 (2017) @ Episode 10/10000, loss: 0.03076225891709327737\n",
      "Episode Reward: 1.0\n",
      "Step 279 (2296) @ Episode 11/10000, loss: 0.00016380517627112567\n",
      "Episode Reward: 2.0\n",
      "Step 332 (2628) @ Episode 12/10000, loss: 0.03044376149773597763\n",
      "Episode Reward: 3.0\n",
      "Step 221 (2849) @ Episode 13/10000, loss: 0.03219145908951759314\n",
      "Episode Reward: 1.0\n",
      "Step 171 (3020) @ Episode 14/10000, loss: 0.00064451439538970593\n",
      "Episode Reward: 0.0\n",
      "Step 310 (3330) @ Episode 15/10000, loss: 0.03115624003112316-05\n",
      "Episode Reward: 2.0\n",
      "Step 178 (3508) @ Episode 16/10000, loss: 6.398957339115441e-053\n",
      "Episode Reward: 0.0\n",
      "Step 204 (3712) @ Episode 17/10000, loss: 0.00027164386119693524\n",
      "Episode Reward: 1.0\n",
      "Step 253 (3965) @ Episode 18/10000, loss: 0.03031598031520843575\n",
      "Episode Reward: 1.0\n",
      "Step 286 (4251) @ Episode 19/10000, loss: 0.00123859790619462732\n",
      "Episode Reward: 2.0\n",
      "Step 226 (4477) @ Episode 20/10000, loss: 0.03100019693374633854\n",
      "Episode Reward: 1.0\n",
      "Step 170 (4647) @ Episode 21/10000, loss: 1.0159817975363694e-05\n",
      "Episode Reward: 0.0\n",
      "Step 281 (4928) @ Episode 22/10000, loss: 0.00021515155094675726\n",
      "Episode Reward: 2.0\n",
      "Step 196 (5124) @ Episode 23/10000, loss: 0.00033249071566388013\n",
      "Episode Reward: 0.0\n",
      "Step 283 (5407) @ Episode 24/10000, loss: 0.00120069831609725955\n",
      "Episode Reward: 2.0\n",
      "Step 186 (5593) @ Episode 25/10000, loss: 0.03034342825412750256\n",
      "Episode Reward: 0.0\n",
      "Step 177 (5770) @ Episode 26/10000, loss: 0.00125865964218974114\n",
      "Episode Reward: 0.0\n",
      "Step 371 (6141) @ Episode 27/10000, loss: 0.00097481580451130876\n",
      "Episode Reward: 3.0\n",
      "Step 202 (6343) @ Episode 28/10000, loss: 0.00033672823337838054\n",
      "Episode Reward: 1.0\n",
      "Step 226 (6569) @ Episode 29/10000, loss: 2.377035707468167e-055\n",
      "Episode Reward: 1.0\n",
      "Step 427 (6996) @ Episode 30/10000, loss: 4.4798143790103495e-05\n",
      "Episode Reward: 5.0\n",
      "Step 160 (7156) @ Episode 31/10000, loss: 0.00114168389700353155\n",
      "Episode Reward: 0.0\n",
      "Step 174 (7330) @ Episode 32/10000, loss: 6.0417405620682985e-05\n",
      "Episode Reward: 0.0\n",
      "Step 303 (7633) @ Episode 33/10000, loss: 0.00073425314621999863\n",
      "Episode Reward: 2.0\n",
      "Step 175 (7808) @ Episode 34/10000, loss: 7.764133624732494e-055\n",
      "Episode Reward: 0.0\n",
      "Step 345 (8153) @ Episode 35/10000, loss: 0.03306629508733749463\n",
      "Episode Reward: 3.0\n",
      "Step 218 (8371) @ Episode 36/10000, loss: 0.00012627264368347824\n",
      "Episode Reward: 1.0\n",
      "Step 279 (8650) @ Episode 37/10000, loss: 0.00014696306607220322\n",
      "Episode Reward: 2.0\n",
      "Step 274 (8924) @ Episode 38/10000, loss: 0.00116826186422258627\n",
      "Episode Reward: 2.0\n",
      "Step 164 (9088) @ Episode 39/10000, loss: 0.00020134636724833433\n",
      "Episode Reward: 0.0\n",
      "Step 288 (9376) @ Episode 40/10000, loss: 0.00078184640733525165\n",
      "Episode Reward: 2.0\n",
      "Step 247 (9623) @ Episode 41/10000, loss: 0.03031851537525654373\n",
      "Episode Reward: 2.0\n",
      "Step 169 (9792) @ Episode 42/10000, loss: 0.00016458614845760167\n",
      "Episode Reward: 0.0\n",
      "Step 207 (9999) @ Episode 43/10000, loss: 8.627214992884547e-053\n",
      " Copied model parameters to target network\n",
      "Step 223 (10015) @ Episode 43/10000, loss: 1.2345000868663192e-05\n",
      "Episode Reward: 1.0\n",
      "Step 229 (10244) @ Episode 44/10000, loss: 5.974880696157925e-055\n",
      "Episode Reward: 1.0\n",
      "Step 231 (10475) @ Episode 45/10000, loss: 4.698946941061877e-055\n",
      "Episode Reward: 1.0\n",
      "Step 221 (10696) @ Episode 46/10000, loss: 9.52116897678934e-0665\n",
      "Episode Reward: 1.0\n",
      "Step 285 (10981) @ Episode 47/10000, loss: 8.844579861033708e-054\n",
      "Episode Reward: 2.0\n",
      "Step 214 (11195) @ Episode 48/10000, loss: 2.297059108968824e-055\n",
      "Episode Reward: 1.0\n",
      "Step 174 (11369) @ Episode 49/10000, loss: 3.105565701844171e-055\n",
      "Episode Reward: 0.0\n",
      "Step 285 (11654) @ Episode 50/10000, loss: 0.03122204914689064315\n",
      "Episode Reward: 2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 16:48:49,194] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video000050.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 249 (11903) @ Episode 51/10000, loss: 0.00013567335554398596\n",
      "Episode Reward: 1.0\n",
      "Step 350 (12253) @ Episode 52/10000, loss: 6.96593924658373e-0556\n",
      "Episode Reward: 3.0\n",
      "Step 307 (12560) @ Episode 53/10000, loss: 0.03114337474107742399\n",
      "Episode Reward: 2.0\n",
      "Step 239 (12799) @ Episode 54/10000, loss: 6.866150943096727e-053\n",
      "Episode Reward: 1.0\n",
      "Step 166 (12965) @ Episode 55/10000, loss: 0.03075840696692466755\n",
      "Episode Reward: 0.0\n",
      "Step 179 (13144) @ Episode 56/10000, loss: 3.109467070316896e-055\n",
      "Episode Reward: 0.0\n",
      "Step 167 (13311) @ Episode 57/10000, loss: 7.009273394942284e-055\n",
      "Episode Reward: 0.0\n",
      "Step 391 (13702) @ Episode 58/10000, loss: 1.961134148587007e-055\n",
      "Episode Reward: 4.0\n",
      "Step 179 (13881) @ Episode 59/10000, loss: 5.750271157012321e-055\n",
      "Episode Reward: 0.0\n",
      "Step 189 (14070) @ Episode 60/10000, loss: 9.60688921622932e-0555\n",
      "Episode Reward: 0.0\n",
      "Step 267 (14337) @ Episode 61/10000, loss: 1.5190262274700217e-05\n",
      "Episode Reward: 2.0\n",
      "Step 270 (14607) @ Episode 62/10000, loss: 0.00013267729082144797\n",
      "Episode Reward: 2.0\n",
      "Step 260 (14867) @ Episode 63/10000, loss: 6.233023304957896e-053\n",
      "Episode Reward: 2.0\n",
      "Step 302 (15169) @ Episode 64/10000, loss: 5.820828300784342e-055\n",
      "Episode Reward: 2.0\n",
      "Step 305 (15474) @ Episode 65/10000, loss: 5.4295207519317046e-05\n",
      "Episode Reward: 3.0\n",
      "Step 175 (15649) @ Episode 66/10000, loss: 1.4244526028051041e-05\n",
      "Episode Reward: 0.0\n",
      "Step 155 (15804) @ Episode 67/10000, loss: 1.819694989535492e-055\n",
      "Episode Reward: 0.0\n",
      "Step 203 (16007) @ Episode 68/10000, loss: 2.332051190023776e-055\n",
      "Episode Reward: 1.0\n",
      "Step 323 (16330) @ Episode 69/10000, loss: 0.03079450130462646506\n",
      "Episode Reward: 3.0\n",
      "Step 269 (16599) @ Episode 70/10000, loss: 8.197923307307065e-065\n",
      "Episode Reward: 2.0\n",
      "Step 418 (17017) @ Episode 71/10000, loss: 3.890052539645694e-055\n",
      "Episode Reward: 4.0\n",
      "Step 237 (17254) @ Episode 72/10000, loss: 3.572831701603718e-055\n",
      "Episode Reward: 1.0\n",
      "Step 176 (17430) @ Episode 73/10000, loss: 1.4016042769071646e-05\n",
      "Episode Reward: 0.0\n",
      "Step 171 (17601) @ Episode 74/10000, loss: 2.462331030983478e-055\n",
      "Episode Reward: 0.0\n",
      "Step 211 (17812) @ Episode 75/10000, loss: 8.155674731824547e-056\n",
      "Episode Reward: 1.0\n",
      "Step 231 (18043) @ Episode 76/10000, loss: 2.8238107915967703e-05\n",
      "Episode Reward: 1.0\n",
      "Step 169 (18212) @ Episode 77/10000, loss: 6.254765139601659e-065\n",
      "Episode Reward: 0.0\n",
      "Step 258 (18470) @ Episode 78/10000, loss: 3.1382158340420574e-05\n",
      "Episode Reward: 1.0\n",
      "Step 286 (18756) @ Episode 79/10000, loss: 6.34631360298954e-0505\n",
      "Episode Reward: 2.0\n",
      "Step 201 (18957) @ Episode 80/10000, loss: 6.82178870192729e-0505\n",
      "Episode Reward: 1.0\n",
      "Step 206 (19163) @ Episode 81/10000, loss: 0.03107152692973613755\n",
      "Episode Reward: 1.0\n",
      "Step 309 (19472) @ Episode 82/10000, loss: 2.128084634023253e-055\n",
      "Episode Reward: 2.0\n",
      "Step 179 (19651) @ Episode 83/10000, loss: 8.675616118125618e-055\n",
      "Episode Reward: 0.0\n",
      "Step 179 (19830) @ Episode 84/10000, loss: 4.201106639811769e-055\n",
      "Episode Reward: 0.0\n",
      "Step 169 (19999) @ Episode 85/10000, loss: 2.70254486167687e-0666\n",
      " Copied model parameters to target network\n",
      "Step 247 (20077) @ Episode 85/10000, loss: 7.4272243182349484e-06\n",
      "Episode Reward: 1.0\n",
      "Step 315 (20392) @ Episode 86/10000, loss: 3.5368066164664924e-05\n",
      "Episode Reward: 3.0\n",
      "Step 161 (20553) @ Episode 87/10000, loss: 1.1661721146083437e-05\n",
      "Episode Reward: 0.0\n",
      "Step 252 (20805) @ Episode 88/10000, loss: 0.03093485161662101755\n",
      "Episode Reward: 2.0\n",
      "Step 243 (21048) @ Episode 89/10000, loss: 0.03075600787997245855\n",
      "Episode Reward: 1.0\n",
      "Step 174 (21222) @ Episode 90/10000, loss: 6.373293217620812e-065\n",
      "Episode Reward: 0.0\n",
      "Step 202 (21424) @ Episode 91/10000, loss: 5.372070063458523e-065\n",
      "Episode Reward: 1.0\n",
      "Step 225 (21649) @ Episode 92/10000, loss: 1.2048706594214309e-05\n",
      "Episode Reward: 1.0\n",
      "Step 182 (21831) @ Episode 93/10000, loss: 8.366652764379978e-065\n",
      "Episode Reward: 0.0\n",
      "Step 234 (22065) @ Episode 94/10000, loss: 9.573873830959201e-055\n",
      "Episode Reward: 1.0\n",
      "Step 272 (22337) @ Episode 95/10000, loss: 6.734472117386758e-055\n",
      "Episode Reward: 2.0\n",
      "Step 270 (22607) @ Episode 96/10000, loss: 3.9227743400260806e-05\n",
      "Episode Reward: 2.0\n",
      "Step 170 (22777) @ Episode 97/10000, loss: 1.1546730092959478e-05\n",
      "Episode Reward: 0.0\n",
      "Step 183 (22960) @ Episode 98/10000, loss: 7.073579035932198e-055\n",
      "Episode Reward: 0.0\n",
      "Step 168 (23128) @ Episode 99/10000, loss: 0.06165373325347900455\n",
      "Episode Reward: 0.0\n",
      "Step 355 (23483) @ Episode 100/10000, loss: 8.048648851399776e-065\n",
      "Episode Reward: 3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 16:50:37,849] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video000100.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 226 (23709) @ Episode 101/10000, loss: 2.5970868591684848e-05\n",
      "Episode Reward: 1.0\n",
      "Step 279 (23988) @ Episode 102/10000, loss: 4.6133493015076965e-05\n",
      "Episode Reward: 2.0\n",
      "Step 175 (24163) @ Episode 103/10000, loss: 0.00015031133079901338\n",
      "Episode Reward: 0.0\n",
      "Step 253 (24416) @ Episode 104/10000, loss: 1.0927294169960078e-05\n",
      "Episode Reward: 2.0\n",
      "Step 167 (24583) @ Episode 105/10000, loss: 2.9229169740574434e-05\n",
      "Episode Reward: 0.0\n",
      "Step 232 (24815) @ Episode 106/10000, loss: 4.669652844313532e-055\n",
      "Episode Reward: 1.0\n",
      "Step 181 (24996) @ Episode 107/10000, loss: 3.370702688698657e-055\n",
      "Episode Reward: 0.0\n",
      "Step 178 (25174) @ Episode 108/10000, loss: 2.5639035811764188e-05\n",
      "Episode Reward: 0.0\n",
      "Step 230 (25404) @ Episode 109/10000, loss: 0.03082400187849998505\n",
      "Episode Reward: 1.0\n",
      "Step 212 (25616) @ Episode 110/10000, loss: 0.03090857714414596605\n",
      "Episode Reward: 1.0\n",
      "Step 214 (25830) @ Episode 111/10000, loss: 0.02998815104365348855\n",
      "Episode Reward: 1.0\n",
      "Step 333 (26163) @ Episode 112/10000, loss: 0.03110174275934696255\n",
      "Episode Reward: 3.0\n",
      "Step 298 (26461) @ Episode 113/10000, loss: 4.552036625682376e-055\n",
      "Episode Reward: 3.0\n",
      "Step 233 (26694) @ Episode 114/10000, loss: 6.059855422790861e-065\n",
      "Episode Reward: 1.0\n",
      "Step 383 (27077) @ Episode 115/10000, loss: 5.564880120800808e-055\n",
      "Episode Reward: 4.0\n",
      "Step 179 (27256) @ Episode 116/10000, loss: 2.2605816411669366e-05\n",
      "Episode Reward: 0.0\n",
      "Step 236 (27492) @ Episode 117/10000, loss: 1.1949096005992033e-05\n",
      "Episode Reward: 1.0\n",
      "Step 173 (27665) @ Episode 118/10000, loss: 4.603024990501581e-065\n",
      "Episode Reward: 0.0\n",
      "Step 177 (27842) @ Episode 119/10000, loss: 0.00012067361967638135\n",
      "Episode Reward: 0.0\n",
      "Step 178 (28020) @ Episode 120/10000, loss: 7.339620788116008e-053\n",
      "Episode Reward: 0.0\n",
      "Step 279 (28299) @ Episode 121/10000, loss: 1.7668451619101688e-05\n",
      "Episode Reward: 2.0\n",
      "Step 300 (28599) @ Episode 122/10000, loss: 0.06114218011498451-05\n",
      "Episode Reward: 2.0\n",
      "Step 404 (29003) @ Episode 123/10000, loss: 4.401872865855694e-052\n",
      "Episode Reward: 4.0\n",
      "Step 180 (29183) @ Episode 124/10000, loss: 0.00012169590627308935\n",
      "Episode Reward: 0.0\n",
      "Step 172 (29355) @ Episode 125/10000, loss: 2.3231728846440092e-05\n",
      "Episode Reward: 0.0\n",
      "Step 165 (29520) @ Episode 126/10000, loss: 5.8971476391889155e-05\n",
      "Episode Reward: 0.0\n",
      "Step 177 (29697) @ Episode 127/10000, loss: 0.03066809847950935455\n",
      "Episode Reward: 0.0\n",
      "Step 302 (29999) @ Episode 128/10000, loss: 6.573427526745945e-055\n",
      " Copied model parameters to target network\n",
      "Step 303 (30000) @ Episode 128/10000, loss: 3.246218693675473e-05\n",
      "Episode Reward: 2.0\n",
      "\n",
      " Copied model parameters to target network\n",
      "Step 301 (30301) @ Episode 129/10000, loss: 2.8222242690389976e-05\n",
      "Episode Reward: 2.0\n",
      "Step 423 (30724) @ Episode 130/10000, loss: 0.03063281066715717355\n",
      "Episode Reward: 4.0\n",
      "Step 171 (30895) @ Episode 131/10000, loss: 1.4311739505501464e-05\n",
      "Episode Reward: 0.0\n",
      "Step 176 (31071) @ Episode 132/10000, loss: 0.03124357759952545559\n",
      "Episode Reward: 0.0\n",
      "Step 217 (31288) @ Episode 133/10000, loss: 4.475464083952829e-053\n",
      "Episode Reward: 1.0\n",
      "Step 171 (31459) @ Episode 134/10000, loss: 0.03096261434257030505\n",
      "Episode Reward: 0.0\n",
      "Step 182 (31641) @ Episode 135/10000, loss: 8.250115206465125e-055\n",
      "Episode Reward: 0.0\n",
      "Step 347 (31988) @ Episode 136/10000, loss: 0.00011077981616836041\n",
      "Episode Reward: 3.0\n",
      "Step 170 (32158) @ Episode 137/10000, loss: 0.03056828491389751405\n",
      "Episode Reward: 0.0\n",
      "Step 328 (32486) @ Episode 138/10000, loss: 0.00018096229177899668\n",
      "Episode Reward: 2.0\n",
      "Step 169 (32655) @ Episode 139/10000, loss: 1.8786060536513105e-05\n",
      "Episode Reward: 0.0\n",
      "Step 163 (32818) @ Episode 140/10000, loss: 1.1426438504713587e-05\n",
      "Episode Reward: 0.0\n",
      "Step 289 (33107) @ Episode 141/10000, loss: 0.03095112182199955-05\n",
      "Episode Reward: 2.0\n",
      "Step 360 (33467) @ Episode 142/10000, loss: 2.1067462512291968e-05\n",
      "Episode Reward: 3.0\n",
      "Step 404 (33871) @ Episode 143/10000, loss: 7.721341717115138e-065\n",
      "Episode Reward: 4.0\n",
      "Step 234 (34105) @ Episode 144/10000, loss: 1.1900362551386934e-05\n",
      "Episode Reward: 1.0\n",
      "Step 237 (34342) @ Episode 145/10000, loss: 1.4241945791582111e-05\n",
      "Episode Reward: 1.0\n",
      "Step 171 (34513) @ Episode 146/10000, loss: 4.54532346338965e-0555\n",
      "Episode Reward: 0.0\n",
      "Step 221 (34734) @ Episode 147/10000, loss: 2.9309103410923854e-05\n",
      "Episode Reward: 1.0\n",
      "Step 237 (34971) @ Episode 148/10000, loss: 2.4024915546760894e-05\n",
      "Episode Reward: 1.0\n",
      "Step 338 (35309) @ Episode 149/10000, loss: 0.03015685081481933605\n",
      "Episode Reward: 3.0\n",
      "Step 338 (35647) @ Episode 150/10000, loss: 3.914009721484035e-055\n",
      "Episode Reward: 3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 16:52:30,872] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video000150.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 243 (35890) @ Episode 151/10000, loss: 0.00016578909708186984\n",
      "Episode Reward: 1.0\n",
      "Step 305 (36195) @ Episode 152/10000, loss: 0.00011105967860203236\n",
      "Episode Reward: 2.0\n",
      "Step 307 (36502) @ Episode 153/10000, loss: 1.701402106846217e-055\n",
      "Episode Reward: 2.0\n",
      "Step 225 (36727) @ Episode 154/10000, loss: 8.883620466804132e-065\n",
      "Episode Reward: 1.0\n",
      "Step 276 (37003) @ Episode 155/10000, loss: 7.011285924818367e-055\n",
      "Episode Reward: 2.0\n",
      "Step 279 (37282) @ Episode 156/10000, loss: 9.618548210710287e-057\n",
      "Episode Reward: 2.0\n",
      "Step 232 (37514) @ Episode 157/10000, loss: 0.00011187343625351787\n",
      "Episode Reward: 1.0\n",
      "Step 164 (37678) @ Episode 158/10000, loss: 6.19989586994052e-0552\n",
      "Episode Reward: 0.0\n",
      "Step 280 (37958) @ Episode 159/10000, loss: 4.726889528683387e-055\n",
      "Episode Reward: 2.0\n",
      "Step 226 (38184) @ Episode 160/10000, loss: 7.698403351241723e-055\n",
      "Episode Reward: 1.0\n",
      "Step 165 (38349) @ Episode 161/10000, loss: 3.3534844988025725e-05\n",
      "Episode Reward: 0.0\n",
      "Step 169 (38518) @ Episode 162/10000, loss: 0.02638152986764908058\n",
      "Episode Reward: 0.0\n",
      "Step 230 (38748) @ Episode 163/10000, loss: 5.22332702530548e-0577\n",
      "Episode Reward: 1.0\n",
      "Step 403 (39151) @ Episode 164/10000, loss: 6.216701149241999e-054\n",
      "Episode Reward: 4.0\n",
      "Step 235 (39386) @ Episode 165/10000, loss: 7.63465286581777e-0585\n",
      "Episode Reward: 1.0\n",
      "Step 192 (39578) @ Episode 166/10000, loss: 0.00025641493266448385\n",
      "Episode Reward: 0.0\n",
      "Step 263 (39841) @ Episode 167/10000, loss: 0.00020208900969009846\n",
      "Episode Reward: 2.0\n",
      "Step 158 (39999) @ Episode 168/10000, loss: 6.367921741912141e-056\n",
      " Copied model parameters to target network\n",
      "Step 347 (40188) @ Episode 168/10000, loss: 3.108549572061747e-056\n",
      "Episode Reward: 4.0\n",
      "Step 265 (40453) @ Episode 169/10000, loss: 9.541990584693849e-055\n",
      "Episode Reward: 2.0\n",
      "Step 315 (40768) @ Episode 170/10000, loss: 8.866094867698848e-054\n",
      "Episode Reward: 2.0\n",
      "Step 163 (40931) @ Episode 171/10000, loss: 0.00018131962860934436\n",
      "Episode Reward: 0.0\n",
      "Step 438 (41369) @ Episode 172/10000, loss: 0.02971590869128704968\n",
      "Episode Reward: 4.0\n",
      "Step 239 (41608) @ Episode 173/10000, loss: 0.00035160541301593184\n",
      "Episode Reward: 1.0\n",
      "Step 282 (41890) @ Episode 174/10000, loss: 0.00030390621395781636\n",
      "Episode Reward: 2.0\n",
      "Step 371 (42261) @ Episode 175/10000, loss: 0.00211194902658462523\n",
      "Episode Reward: 4.0\n",
      "Step 310 (42571) @ Episode 176/10000, loss: 0.00032177704269997776\n",
      "Episode Reward: 2.0\n",
      "Step 302 (42873) @ Episode 177/10000, loss: 0.00016898605099413544\n",
      "Episode Reward: 3.0\n",
      "Step 473 (43346) @ Episode 178/10000, loss: 0.00107107858639210465\n",
      "Episode Reward: 5.0\n",
      "Step 342 (43688) @ Episode 179/10000, loss: 0.00015313655603677034\n",
      "Episode Reward: 3.0\n",
      "Step 166 (43854) @ Episode 180/10000, loss: 0.00032340074540115893\n",
      "Episode Reward: 0.0\n",
      "Step 314 (44168) @ Episode 181/10000, loss: 0.00055098807206377398\n",
      "Episode Reward: 3.0\n",
      "Step 253 (44421) @ Episode 182/10000, loss: 0.01535119768232107276\n",
      "Episode Reward: 2.0\n",
      "Step 300 (44721) @ Episode 183/10000, loss: 0.00053168745944276454\n",
      "Episode Reward: 2.0\n",
      "Step 235 (44956) @ Episode 184/10000, loss: 0.00016873929416760802\n",
      "Episode Reward: 1.0\n",
      "Step 244 (45200) @ Episode 185/10000, loss: 0.00026350180269218983\n",
      "Episode Reward: 1.0\n",
      "Step 301 (45501) @ Episode 186/10000, loss: 0.00066354079172015194\n",
      "Episode Reward: 2.0\n",
      "Step 366 (45867) @ Episode 187/10000, loss: 0.00037582532968372107\n",
      "Episode Reward: 3.0\n",
      "Step 235 (46102) @ Episode 188/10000, loss: 0.02916238084435463171\n",
      "Episode Reward: 1.0\n",
      "Step 250 (46352) @ Episode 189/10000, loss: 0.00024992739781737334\n",
      "Episode Reward: 1.0\n",
      "Step 226 (46578) @ Episode 190/10000, loss: 0.00015648857515770942\n",
      "Episode Reward: 1.0\n",
      "Step 190 (46768) @ Episode 191/10000, loss: 0.00573705090209841762\n",
      "Episode Reward: 0.0\n",
      "Step 329 (47097) @ Episode 192/10000, loss: 8.565227471990511e-052\n",
      "Episode Reward: 3.0\n",
      "Step 244 (47341) @ Episode 193/10000, loss: 0.00050530058797448872\n",
      "Episode Reward: 1.0\n",
      "Step 171 (47512) @ Episode 194/10000, loss: 0.00097064318833872683\n",
      "Episode Reward: 0.0\n",
      "Step 209 (47721) @ Episode 195/10000, loss: 0.00011861033999593928\n",
      "Episode Reward: 1.0\n",
      "Step 161 (47882) @ Episode 196/10000, loss: 0.01373041700571775483\n",
      "Episode Reward: 0.0\n",
      "Step 213 (48095) @ Episode 197/10000, loss: 0.00012472659000195563\n",
      "Episode Reward: 1.0\n",
      "Step 163 (48258) @ Episode 198/10000, loss: 0.00151439884211868056\n",
      "Episode Reward: 0.0\n",
      "Step 234 (48492) @ Episode 199/10000, loss: 0.00024718049098737545\n",
      "Episode Reward: 1.0\n",
      "Step 271 (48763) @ Episode 200/10000, loss: 0.02977868355810642232\n",
      "Episode Reward: 2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 16:54:30,718] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video000200.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 322 (49085) @ Episode 201/10000, loss: 0.00013777610729448497\n",
      "Episode Reward: 3.0\n",
      "Step 251 (49336) @ Episode 202/10000, loss: 0.00030435196822509179\n",
      "Episode Reward: 2.0\n",
      "Step 239 (49575) @ Episode 203/10000, loss: 0.00016286681056953967\n",
      "Episode Reward: 1.0\n",
      "Step 282 (49857) @ Episode 204/10000, loss: 2.8821254090871662e-05\n",
      "Episode Reward: 2.0\n",
      "Step 142 (49999) @ Episode 205/10000, loss: 0.00320332497358322145\n",
      " Copied model parameters to target network\n",
      "Step 234 (50091) @ Episode 205/10000, loss: 0.00073502992745488883\n",
      "Episode Reward: 1.0\n",
      "Step 192 (50283) @ Episode 206/10000, loss: 0.00145963439717888833\n",
      "Episode Reward: 0.0\n",
      "Step 344 (50627) @ Episode 207/10000, loss: 0.00235614110715687273\n",
      "Episode Reward: 3.0\n",
      "Step 443 (51070) @ Episode 208/10000, loss: 0.00141975376754999163\n",
      "Episode Reward: 5.0\n",
      "Step 180 (51250) @ Episode 209/10000, loss: 0.00018924841424450278\n",
      "Episode Reward: 0.0\n",
      "Step 177 (51427) @ Episode 210/10000, loss: 0.00354386423714458946\n",
      "Episode Reward: 0.0\n",
      "Step 180 (51607) @ Episode 211/10000, loss: 0.00098269490990787746\n",
      "Episode Reward: 0.0\n",
      "Step 235 (51842) @ Episode 212/10000, loss: 0.00022704320144839585\n",
      "Episode Reward: 1.0\n",
      "Step 283 (52125) @ Episode 213/10000, loss: 0.00820076186209917385\n",
      "Episode Reward: 2.0\n",
      "Step 342 (52467) @ Episode 214/10000, loss: 0.00045507075265049934\n",
      "Episode Reward: 3.0\n",
      "Step 176 (52643) @ Episode 215/10000, loss: 0.00508102681487798755\n",
      "Episode Reward: 0.0\n",
      "Step 245 (52888) @ Episode 216/10000, loss: 0.00164114974904805422\n",
      "Episode Reward: 1.0\n",
      "Step 209 (53097) @ Episode 217/10000, loss: 0.00296991621144115921\n",
      "Episode Reward: 1.0\n",
      "Step 169 (53266) @ Episode 218/10000, loss: 0.00031742348801344633\n",
      "Episode Reward: 0.0\n",
      "Step 359 (53625) @ Episode 219/10000, loss: 0.00029510862077586353\n",
      "Episode Reward: 3.0\n",
      "Step 220 (53845) @ Episode 220/10000, loss: 0.00089726445730775648\n",
      "Episode Reward: 1.0\n",
      "Step 475 (54320) @ Episode 221/10000, loss: 6.149229011498392e-053\n",
      "Episode Reward: 5.0\n",
      "Step 353 (54673) @ Episode 222/10000, loss: 0.00528002483770251356\n",
      "Episode Reward: 3.0\n",
      "Step 334 (55007) @ Episode 223/10000, loss: 0.00018948540673591197\n",
      "Episode Reward: 3.0\n",
      "Step 228 (55235) @ Episode 224/10000, loss: 0.00048412522301077843\n",
      "Episode Reward: 1.0\n",
      "Step 171 (55406) @ Episode 225/10000, loss: 8.729919500183314e-055\n",
      "Episode Reward: 0.0\n",
      "Step 175 (55581) @ Episode 226/10000, loss: 0.00269172340631485095\n",
      "Episode Reward: 0.0\n",
      "Step 300 (55881) @ Episode 227/10000, loss: 0.00014016299974173307\n",
      "Episode Reward: 2.0\n",
      "Step 235 (56116) @ Episode 228/10000, loss: 0.00098749855533242233\n",
      "Episode Reward: 1.0\n",
      "Step 273 (56389) @ Episode 229/10000, loss: 0.00010366058995714411\n",
      "Episode Reward: 2.0\n",
      "Step 169 (56558) @ Episode 230/10000, loss: 0.00025535852182656527\n",
      "Episode Reward: 0.0\n",
      "Step 177 (56735) @ Episode 231/10000, loss: 0.00046469763037748635\n",
      "Episode Reward: 0.0\n",
      "Step 291 (57026) @ Episode 232/10000, loss: 0.00257670413702726365\n",
      "Episode Reward: 2.0\n",
      "Step 186 (57212) @ Episode 233/10000, loss: 0.00011654905392788354\n",
      "Episode Reward: 0.0\n",
      "Step 265 (57477) @ Episode 234/10000, loss: 0.00035849557025358088\n",
      "Episode Reward: 2.0\n",
      "Step 177 (57654) @ Episode 235/10000, loss: 0.00830530561506748236\n",
      "Episode Reward: 0.0\n",
      "Step 346 (58000) @ Episode 236/10000, loss: 0.00071103079244494446\n",
      "Episode Reward: 3.0\n",
      "Step 233 (58233) @ Episode 237/10000, loss: 8.462031837552786e-054\n",
      "Episode Reward: 1.0\n",
      "Step 184 (58417) @ Episode 238/10000, loss: 0.00042122352169826627\n",
      "Episode Reward: 0.0\n",
      "Step 338 (58755) @ Episode 239/10000, loss: 7.911458669696003e-053\n",
      "Episode Reward: 3.0\n",
      "Step 184 (58939) @ Episode 240/10000, loss: 0.00496818404644727796\n",
      "Episode Reward: 0.0\n",
      "Step 233 (59172) @ Episode 241/10000, loss: 0.00014310506230685866\n",
      "Episode Reward: 1.0\n",
      "Step 184 (59356) @ Episode 242/10000, loss: 0.00130986329168081286\n",
      "Episode Reward: 0.0\n",
      "Step 236 (59592) @ Episode 243/10000, loss: 0.00042339877109043311\n",
      "Episode Reward: 2.0\n",
      "Step 247 (59839) @ Episode 244/10000, loss: 0.00145691016223281622\n",
      "Episode Reward: 2.0\n",
      "Step 160 (59999) @ Episode 245/10000, loss: 8.596020052209496e-052\n",
      " Copied model parameters to target network\n",
      "Step 274 (60113) @ Episode 245/10000, loss: 4.580446329782717e-055\n",
      "Episode Reward: 2.0\n",
      "Step 186 (60299) @ Episode 246/10000, loss: 0.00052160653285682263\n",
      "Episode Reward: 0.0\n",
      "Step 251 (60550) @ Episode 247/10000, loss: 0.00032833288423717025\n",
      "Episode Reward: 1.0\n",
      "Step 477 (61027) @ Episode 248/10000, loss: 0.00110824336297810083\n",
      "Episode Reward: 5.0\n",
      "Step 191 (61218) @ Episode 249/10000, loss: 0.00044583325507119386\n",
      "Episode Reward: 0.0\n",
      "Step 168 (61386) @ Episode 250/10000, loss: 3.3342592359986156e-05\n",
      "Episode Reward: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 16:56:27,679] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video000250.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 191 (61577) @ Episode 251/10000, loss: 0.00012438654084689915\n",
      "Episode Reward: 0.0\n",
      "Step 235 (61812) @ Episode 252/10000, loss: 0.00012234260793775325\n",
      "Episode Reward: 1.0\n",
      "Step 241 (62053) @ Episode 253/10000, loss: 0.00011586687469389295\n",
      "Episode Reward: 2.0\n",
      "Step 205 (62258) @ Episode 254/10000, loss: 0.00051947083557024642\n",
      "Episode Reward: 1.0\n",
      "Step 263 (62521) @ Episode 255/10000, loss: 0.00067020795540884144\n",
      "Episode Reward: 2.0\n",
      "Step 198 (62719) @ Episode 256/10000, loss: 0.00040016139973886315\n",
      "Episode Reward: 0.0\n",
      "Step 236 (62955) @ Episode 257/10000, loss: 5.8716155763249844e-05\n",
      "Episode Reward: 1.0\n",
      "Step 235 (63190) @ Episode 258/10000, loss: 0.00012927592615596954\n",
      "Episode Reward: 1.0\n",
      "Step 232 (63422) @ Episode 259/10000, loss: 0.00021012077922932804\n",
      "Episode Reward: 1.0\n",
      "Step 159 (63581) @ Episode 260/10000, loss: 0.00011865461419802159\n",
      "Episode Reward: 0.0\n",
      "Step 207 (63788) @ Episode 261/10000, loss: 7.542640378233045e-053\n",
      "Episode Reward: 1.0\n",
      "Step 167 (63955) @ Episode 262/10000, loss: 6.639297498622909e-057\n",
      "Episode Reward: 0.0\n",
      "Step 177 (64132) @ Episode 263/10000, loss: 0.00041504329419694843\n",
      "Episode Reward: 0.0\n",
      "Step 435 (64567) @ Episode 264/10000, loss: 9.943016630131751e-053\n",
      "Episode Reward: 5.0\n",
      "Step 204 (64771) @ Episode 265/10000, loss: 6.81380697642453e-0555\n",
      "Episode Reward: 1.0\n",
      "Step 373 (65144) @ Episode 266/10000, loss: 0.00206234748475253695\n",
      "Episode Reward: 3.0\n",
      "Step 206 (65350) @ Episode 267/10000, loss: 0.00121468398720026023\n",
      "Episode Reward: 1.0\n",
      "Step 243 (65593) @ Episode 268/10000, loss: 0.00035253632813692093\n",
      "Episode Reward: 1.0\n",
      "Step 362 (65955) @ Episode 269/10000, loss: 0.00072311813710257416\n",
      "Episode Reward: 3.0\n",
      "Step 214 (66169) @ Episode 270/10000, loss: 0.00038017623592168093\n",
      "Episode Reward: 1.0\n",
      "Step 408 (66577) @ Episode 271/10000, loss: 0.00052478688303381205\n",
      "Episode Reward: 4.0\n",
      "Step 345 (66922) @ Episode 272/10000, loss: 0.00428994791582226756\n",
      "Episode Reward: 4.0\n",
      "Step 167 (67089) @ Episode 273/10000, loss: 0.00067088229116052395\n",
      "Episode Reward: 0.0\n",
      "Step 229 (67318) @ Episode 274/10000, loss: 0.00092593790031969556\n",
      "Episode Reward: 1.0\n",
      "Step 292 (67610) @ Episode 275/10000, loss: 6.0724512877641246e-05\n",
      "Episode Reward: 2.0\n",
      "Step 305 (67915) @ Episode 276/10000, loss: 0.00045554735697805882\n",
      "Episode Reward: 3.0\n",
      "Step 193 (68108) @ Episode 277/10000, loss: 0.00032979971729218963\n",
      "Episode Reward: 0.0\n",
      "Step 224 (68332) @ Episode 278/10000, loss: 0.00269662193022668364\n",
      "Episode Reward: 1.0\n",
      "Step 172 (68504) @ Episode 279/10000, loss: 0.00057540688430890443\n",
      "Episode Reward: 0.0\n",
      "Step 267 (68771) @ Episode 280/10000, loss: 0.00163177645299583674\n",
      "Episode Reward: 2.0\n",
      "Step 195 (68966) @ Episode 281/10000, loss: 0.00172493304125964645\n",
      "Episode Reward: 0.0\n",
      "Step 208 (69174) @ Episode 282/10000, loss: 0.00040422589518129826\n",
      "Episode Reward: 1.0\n",
      "Step 286 (69460) @ Episode 283/10000, loss: 6.831236532889307e-052\n",
      "Episode Reward: 2.0\n",
      "Step 169 (69629) @ Episode 284/10000, loss: 0.00257909111678600369\n",
      "Episode Reward: 0.0\n",
      "Step 243 (69872) @ Episode 285/10000, loss: 9.804860019357875e-057\n",
      "Episode Reward: 1.0\n",
      "Step 127 (69999) @ Episode 286/10000, loss: 0.00031196023337543015\n",
      " Copied model parameters to target network\n",
      "Step 289 (70161) @ Episode 286/10000, loss: 0.00079918623669072998\n",
      "Episode Reward: 2.0\n",
      "Step 237 (70398) @ Episode 287/10000, loss: 0.00258933682925999164\n",
      "Episode Reward: 1.0\n",
      "Step 270 (70668) @ Episode 288/10000, loss: 0.00052447093185037371\n",
      "Episode Reward: 2.0\n",
      "Step 278 (70946) @ Episode 289/10000, loss: 0.00043346270103938887\n",
      "Episode Reward: 2.0\n",
      "Step 248 (71194) @ Episode 290/10000, loss: 0.00058641697978600867\n",
      "Episode Reward: 1.0\n",
      "Step 251 (71445) @ Episode 291/10000, loss: 8.66101254359819e-0538\n",
      "Episode Reward: 1.0\n",
      "Step 232 (71677) @ Episode 292/10000, loss: 0.00016564660472795367\n",
      "Episode Reward: 1.0\n",
      "Step 180 (71857) @ Episode 293/10000, loss: 0.00012747153232339773\n",
      "Episode Reward: 0.0\n",
      "Step 174 (72031) @ Episode 294/10000, loss: 0.00015086533676367253\n",
      "Episode Reward: 0.0\n",
      "Step 173 (72204) @ Episode 295/10000, loss: 7.995899068191648e-054\n",
      "Episode Reward: 0.0\n",
      "Step 218 (72422) @ Episode 296/10000, loss: 0.00546811148524284414\n",
      "Episode Reward: 1.0\n",
      "Step 306 (72728) @ Episode 297/10000, loss: 0.00015079075819812715\n",
      "Episode Reward: 3.0\n",
      "Step 182 (72910) @ Episode 298/10000, loss: 0.00010595133062452078\n",
      "Episode Reward: 0.0\n",
      "Step 278 (73188) @ Episode 299/10000, loss: 0.00187480752356350424\n",
      "Episode Reward: 2.0\n",
      "Step 310 (73498) @ Episode 300/10000, loss: 0.00588160287588834856\n",
      "Episode Reward: 2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 16:58:19,320] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video000300.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 185 (73683) @ Episode 301/10000, loss: 0.02394571900367736887\n",
      "Episode Reward: 0.0\n",
      "Step 307 (73990) @ Episode 302/10000, loss: 6.006577314110473e-055\n",
      "Episode Reward: 2.0\n",
      "Step 167 (74157) @ Episode 303/10000, loss: 0.00020039545779582113\n",
      "Episode Reward: 0.0\n",
      "Step 194 (74351) @ Episode 304/10000, loss: 0.00018524186452850747\n",
      "Episode Reward: 0.0\n",
      "Step 166 (74517) @ Episode 305/10000, loss: 0.00046851555816829205\n",
      "Episode Reward: 0.0\n",
      "Step 184 (74701) @ Episode 306/10000, loss: 0.00028571000439114875\n",
      "Episode Reward: 0.0\n",
      "Step 176 (74877) @ Episode 307/10000, loss: 0.00011463381815701723\n",
      "Episode Reward: 0.0\n",
      "Step 279 (75156) @ Episode 308/10000, loss: 0.00044758760486729443\n",
      "Episode Reward: 2.0\n",
      "Step 357 (75513) @ Episode 309/10000, loss: 0.00348509638570249143\n",
      "Episode Reward: 4.0\n",
      "Step 214 (75727) @ Episode 310/10000, loss: 0.00026709609664976597\n",
      "Episode Reward: 1.0\n",
      "Step 170 (75897) @ Episode 311/10000, loss: 0.00013115261390339583\n",
      "Episode Reward: 0.0\n",
      "Step 228 (76125) @ Episode 312/10000, loss: 0.00192955322563648225\n",
      "Episode Reward: 1.0\n",
      "Step 231 (76356) @ Episode 313/10000, loss: 0.00042357365600764756\n",
      "Episode Reward: 1.0\n",
      "Step 386 (76742) @ Episode 314/10000, loss: 0.00012366000737529248\n",
      "Episode Reward: 4.0\n",
      "Step 241 (76983) @ Episode 315/10000, loss: 5.5625430832151324e-05\n",
      "Episode Reward: 1.0\n",
      "Step 234 (77217) @ Episode 316/10000, loss: 0.00030057464027777314\n",
      "Episode Reward: 1.0\n",
      "Step 331 (77548) @ Episode 317/10000, loss: 0.00011270843970123678\n",
      "Episode Reward: 2.0\n",
      "Step 248 (77796) @ Episode 318/10000, loss: 9.272871830035001e-055\n",
      "Episode Reward: 1.0\n",
      "Step 305 (78101) @ Episode 319/10000, loss: 0.00042288954136893153\n",
      "Episode Reward: 2.0\n",
      "Step 167 (78268) @ Episode 320/10000, loss: 0.00170974980574101204\n",
      "Episode Reward: 0.0\n",
      "Step 175 (78443) @ Episode 321/10000, loss: 0.00010790111991809681\n",
      "Episode Reward: 0.0\n",
      "Step 296 (78739) @ Episode 322/10000, loss: 0.00138127047102898363\n",
      "Episode Reward: 2.0\n",
      "Step 177 (78916) @ Episode 323/10000, loss: 0.00010925445531029254\n",
      "Episode Reward: 0.0\n",
      "Step 213 (79129) @ Episode 324/10000, loss: 7.19580493750982e-0564\n",
      "Episode Reward: 1.0\n",
      "Step 269 (79398) @ Episode 325/10000, loss: 0.00043539894977584484\n",
      "Episode Reward: 2.0\n",
      "Step 376 (79774) @ Episode 326/10000, loss: 0.00089170580031350261\n",
      "Episode Reward: 4.0\n",
      "Step 225 (79999) @ Episode 327/10000, loss: 8.054592035477981e-056\n",
      " Copied model parameters to target network\n",
      "Step 356 (80130) @ Episode 327/10000, loss: 0.00026323649217374623\n",
      "Episode Reward: 3.0\n",
      "Step 250 (80380) @ Episode 328/10000, loss: 0.00045427557779476047\n",
      "Episode Reward: 1.0\n",
      "Step 177 (80557) @ Episode 329/10000, loss: 0.00011205202463315829\n",
      "Episode Reward: 0.0\n",
      "Step 179 (80736) @ Episode 330/10000, loss: 0.00010039700282504782\n",
      "Episode Reward: 0.0\n",
      "Step 177 (80913) @ Episode 331/10000, loss: 0.00581536814570426954\n",
      "Episode Reward: 0.0\n",
      "Step 317 (81230) @ Episode 332/10000, loss: 0.00065123848617076873\n",
      "Episode Reward: 2.0\n",
      "Step 193 (81423) @ Episode 333/10000, loss: 0.00214661308564245743\n",
      "Episode Reward: 0.0\n",
      "Step 167 (81590) @ Episode 334/10000, loss: 0.00012406296445988124\n",
      "Episode Reward: 0.0\n",
      "Step 169 (81759) @ Episode 335/10000, loss: 0.00020424075773917139\n",
      "Episode Reward: 0.0\n",
      "Step 250 (82009) @ Episode 336/10000, loss: 8.376834011869505e-058\n",
      "Episode Reward: 1.0\n",
      "Step 285 (82294) @ Episode 337/10000, loss: 3.935489439754747e-054\n",
      "Episode Reward: 2.0\n",
      "Step 275 (82569) @ Episode 338/10000, loss: 0.00256984960287809374\n",
      "Episode Reward: 2.0\n",
      "Step 162 (82731) @ Episode 339/10000, loss: 0.00317686935886740701\n",
      "Episode Reward: 0.0\n",
      "Step 214 (82945) @ Episode 340/10000, loss: 0.00043306755833327777\n",
      "Episode Reward: 1.0\n",
      "Step 165 (83110) @ Episode 341/10000, loss: 4.764676486956887e-058\n",
      "Episode Reward: 0.0\n",
      "Step 213 (83323) @ Episode 342/10000, loss: 0.00049390015192329886\n",
      "Episode Reward: 1.0\n",
      "Step 226 (83549) @ Episode 343/10000, loss: 0.00419868761673569716\n",
      "Episode Reward: 1.0\n",
      "Step 227 (83776) @ Episode 344/10000, loss: 7.498337072320282e-053\n",
      "Episode Reward: 1.0\n",
      "Step 334 (84110) @ Episode 345/10000, loss: 7.273539085872471e-054\n",
      "Episode Reward: 3.0\n",
      "Step 339 (84449) @ Episode 346/10000, loss: 0.00113028031773865223\n",
      "Episode Reward: 3.0\n",
      "Step 188 (84637) @ Episode 347/10000, loss: 6.0177921113790944e-05\n",
      "Episode Reward: 0.0\n",
      "Step 286 (84923) @ Episode 348/10000, loss: 0.00014497278607450426\n",
      "Episode Reward: 2.0\n",
      "Step 247 (85170) @ Episode 349/10000, loss: 0.00148176681250333793\n",
      "Episode Reward: 1.0\n",
      "Step 208 (85378) @ Episode 350/10000, loss: 0.00338544696569442754\n",
      "Episode Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 17:00:07,638] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video000350.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 178 (85556) @ Episode 351/10000, loss: 0.00013161716924514621\n",
      "Episode Reward: 0.0\n",
      "Step 238 (85794) @ Episode 352/10000, loss: 0.00076188641833141457\n",
      "Episode Reward: 1.0\n",
      "Step 332 (86126) @ Episode 353/10000, loss: 0.00052852317458018662\n",
      "Episode Reward: 3.0\n",
      "Step 230 (86356) @ Episode 354/10000, loss: 0.00223943335004150875\n",
      "Episode Reward: 1.0\n",
      "Step 504 (86860) @ Episode 355/10000, loss: 0.00011955306399613619\n",
      "Episode Reward: 5.0\n",
      "Step 234 (87094) @ Episode 356/10000, loss: 8.570092904847115e-056\n",
      "Episode Reward: 1.0\n",
      "Step 171 (87265) @ Episode 357/10000, loss: 0.00032880617072805766\n",
      "Episode Reward: 0.0\n",
      "Step 249 (87514) @ Episode 358/10000, loss: 0.00290116947144269945\n",
      "Episode Reward: 1.0\n",
      "Step 325 (87839) @ Episode 359/10000, loss: 0.00095845269970595846\n",
      "Episode Reward: 3.0\n",
      "Step 190 (88029) @ Episode 360/10000, loss: 0.00093172461492940782\n",
      "Episode Reward: 0.0\n",
      "Step 210 (88239) @ Episode 361/10000, loss: 0.00179942732211202383\n",
      "Episode Reward: 1.0\n",
      "Step 349 (88588) @ Episode 362/10000, loss: 0.00154483376536518346\n",
      "Episode Reward: 3.0\n",
      "Step 171 (88759) @ Episode 363/10000, loss: 0.00125257787294685843\n",
      "Episode Reward: 0.0\n",
      "Step 210 (88969) @ Episode 364/10000, loss: 0.00052923796465620466\n",
      "Episode Reward: 0.0\n",
      "Step 162 (89131) @ Episode 365/10000, loss: 0.00122816720977425585\n",
      "Episode Reward: 0.0\n",
      "Step 262 (89393) @ Episode 366/10000, loss: 0.00090551679022610193\n",
      "Episode Reward: 2.0\n",
      "Step 300 (89693) @ Episode 367/10000, loss: 7.00688106007874e-0535\n",
      "Episode Reward: 2.0\n",
      "Step 220 (89913) @ Episode 368/10000, loss: 0.00080202455865219244\n",
      "Episode Reward: 1.0\n",
      "Step 86 (89999) @ Episode 369/10000, loss: 0.00012023084855172783\n",
      " Copied model parameters to target network\n",
      "Step 176 (90089) @ Episode 369/10000, loss: 0.00247065606527030474\n",
      "Episode Reward: 0.0\n",
      "Step 182 (90271) @ Episode 370/10000, loss: 0.00200223131105303766\n",
      "Episode Reward: 0.0\n",
      "Step 310 (90581) @ Episode 371/10000, loss: 0.00203007808886468413\n",
      "Episode Reward: 2.0\n",
      "Step 327 (90908) @ Episode 372/10000, loss: 0.00222847983241081246\n",
      "Episode Reward: 3.0\n",
      "Step 208 (91116) @ Episode 373/10000, loss: 0.00534282997250556953\n",
      "Episode Reward: 0.0\n",
      "Step 304 (91420) @ Episode 374/10000, loss: 0.00014289468526840213\n",
      "Episode Reward: 2.0\n",
      "Step 211 (91631) @ Episode 375/10000, loss: 0.00032701945747248835\n",
      "Episode Reward: 1.0\n",
      "Step 351 (91982) @ Episode 376/10000, loss: 0.00066786073148250583\n",
      "Episode Reward: 3.0\n",
      "Step 181 (92163) @ Episode 377/10000, loss: 0.00168347079306840943\n",
      "Episode Reward: 0.0\n",
      "Step 178 (92341) @ Episode 378/10000, loss: 0.00134227669332176452\n",
      "Episode Reward: 0.0\n",
      "Step 228 (92569) @ Episode 379/10000, loss: 0.00075228791683912285\n",
      "Episode Reward: 1.0\n",
      "Step 177 (92746) @ Episode 380/10000, loss: 0.00031677691731601954\n",
      "Episode Reward: 0.0\n",
      "Step 170 (92916) @ Episode 381/10000, loss: 0.00212255655787885294\n",
      "Episode Reward: 0.0\n",
      "Step 177 (93093) @ Episode 382/10000, loss: 0.00412569753825664554\n",
      "Episode Reward: 0.0\n",
      "Step 205 (93298) @ Episode 383/10000, loss: 0.00088375352788716551\n",
      "Episode Reward: 1.0\n",
      "Step 251 (93549) @ Episode 384/10000, loss: 0.00160086411051452166\n",
      "Episode Reward: 1.0\n",
      "Step 217 (93766) @ Episode 385/10000, loss: 0.00040757135138846934\n",
      "Episode Reward: 1.0\n",
      "Step 179 (93945) @ Episode 386/10000, loss: 0.00019727020116988578\n",
      "Episode Reward: 0.0\n",
      "Step 215 (94160) @ Episode 387/10000, loss: 0.00096341781318187715\n",
      "Episode Reward: 1.0\n",
      "Step 356 (94516) @ Episode 388/10000, loss: 0.00050735502736642966\n",
      "Episode Reward: 3.0\n",
      "Step 171 (94687) @ Episode 389/10000, loss: 0.00076104444451630126\n",
      "Episode Reward: 0.0\n",
      "Step 190 (94877) @ Episode 390/10000, loss: 0.00208888063207268786\n",
      "Episode Reward: 0.0\n",
      "Step 238 (95115) @ Episode 391/10000, loss: 0.00069478643126785762\n",
      "Episode Reward: 1.0\n",
      "Step 297 (95412) @ Episode 392/10000, loss: 0.00694334786385297877\n",
      "Episode Reward: 2.0\n",
      "Step 341 (95753) @ Episode 393/10000, loss: 0.00429918710142374052\n",
      "Episode Reward: 3.0\n",
      "Step 166 (95919) @ Episode 394/10000, loss: 0.00065542175434529785\n",
      "Episode Reward: 0.0\n",
      "Step 170 (96089) @ Episode 395/10000, loss: 7.46145160519518e-0506\n",
      "Episode Reward: 0.0\n",
      "Step 165 (96254) @ Episode 396/10000, loss: 0.00037203263491392136\n",
      "Episode Reward: 0.0\n",
      "Step 282 (96536) @ Episode 397/10000, loss: 0.00010972753807436675\n",
      "Episode Reward: 2.0\n",
      "Step 268 (96804) @ Episode 398/10000, loss: 0.00053849088726565245\n",
      "Episode Reward: 2.0\n",
      "Step 172 (96976) @ Episode 399/10000, loss: 9.439831046620384e-055\n",
      "Episode Reward: 0.0\n",
      "Step 320 (97296) @ Episode 400/10000, loss: 0.00100502558052539834\n",
      "Episode Reward: 3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 17:01:57,313] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video000400.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 182 (97478) @ Episode 401/10000, loss: 0.00230901525355875525\n",
      "Episode Reward: 0.0\n",
      "Step 225 (97703) @ Episode 402/10000, loss: 0.00019027441157959402\n",
      "Episode Reward: 1.0\n",
      "Step 250 (97953) @ Episode 403/10000, loss: 0.00197931914590299137\n",
      "Episode Reward: 1.0\n",
      "Step 212 (98165) @ Episode 404/10000, loss: 0.00086792249931022521\n",
      "Episode Reward: 1.0\n",
      "Step 240 (98405) @ Episode 405/10000, loss: 0.00066849787253886463\n",
      "Episode Reward: 1.0\n",
      "Step 172 (98577) @ Episode 406/10000, loss: 0.00048637503641657537\n",
      "Episode Reward: 0.0\n",
      "Step 277 (98854) @ Episode 407/10000, loss: 0.00069855630863457924\n",
      "Episode Reward: 2.0\n",
      "Step 253 (99107) @ Episode 408/10000, loss: 0.00062006391817703844\n",
      "Episode Reward: 1.0\n",
      "Step 168 (99275) @ Episode 409/10000, loss: 0.00045058407704345884\n",
      "Episode Reward: 0.0\n",
      "Step 355 (99630) @ Episode 410/10000, loss: 0.00025065016234293586\n",
      "Episode Reward: 3.0\n",
      "Step 369 (99999) @ Episode 411/10000, loss: 0.00080551445716992028\n",
      " Copied model parameters to target network\n",
      "Step 422 (100052) @ Episode 411/10000, loss: 0.00085863098502159128\n",
      "Episode Reward: 4.0\n",
      "Step 173 (100225) @ Episode 412/10000, loss: 0.00046420647413469857\n",
      "Episode Reward: 0.0\n",
      "Step 176 (100401) @ Episode 413/10000, loss: 0.00029446941334754236\n",
      "Episode Reward: 0.0\n",
      "Step 310 (100711) @ Episode 414/10000, loss: 0.00296838860958814677\n",
      "Episode Reward: 3.0\n",
      "Step 165 (100876) @ Episode 415/10000, loss: 0.00191012141294777463\n",
      "Episode Reward: 0.0\n",
      "Step 363 (101239) @ Episode 416/10000, loss: 0.00046098319580778483\n",
      "Episode Reward: 3.0\n",
      "Step 214 (101453) @ Episode 417/10000, loss: 0.00182371190749108879\n",
      "Episode Reward: 1.0\n",
      "Step 177 (101630) @ Episode 418/10000, loss: 0.00065273232758045267\n",
      "Episode Reward: 0.0\n",
      "Step 176 (101806) @ Episode 419/10000, loss: 0.00034289949689991776\n",
      "Episode Reward: 0.0\n",
      "Step 299 (102105) @ Episode 420/10000, loss: 0.00078420271165668965\n",
      "Episode Reward: 2.0\n",
      "Step 319 (102424) @ Episode 421/10000, loss: 0.00010406176443211734\n",
      "Episode Reward: 3.0\n",
      "Step 361 (102785) @ Episode 422/10000, loss: 0.00889291614294052116\n",
      "Episode Reward: 3.0\n",
      "Step 180 (102965) @ Episode 423/10000, loss: 0.00070746341953054073\n",
      "Episode Reward: 0.0\n",
      "Step 220 (103185) @ Episode 424/10000, loss: 8.719424658920616e-054\n",
      "Episode Reward: 1.0\n",
      "Step 279 (103464) @ Episode 425/10000, loss: 0.00018823136633727756\n",
      "Episode Reward: 2.0\n",
      "Step 261 (103725) @ Episode 426/10000, loss: 0.00052837713155895478\n",
      "Episode Reward: 2.0\n",
      "Step 293 (104018) @ Episode 427/10000, loss: 9.538729500491172e-055\n",
      "Episode Reward: 2.0\n",
      "Step 326 (104344) @ Episode 428/10000, loss: 0.00087537884246557955\n",
      "Episode Reward: 3.0\n",
      "Step 178 (104522) @ Episode 429/10000, loss: 7.638264651177451e-056\n",
      "Episode Reward: 0.0\n",
      "Step 309 (104831) @ Episode 430/10000, loss: 7.936551264720038e-055\n",
      "Episode Reward: 2.0\n",
      "Step 312 (105143) @ Episode 431/10000, loss: 0.00229115854017436579\n",
      "Episode Reward: 2.0\n",
      "Step 187 (105330) @ Episode 432/10000, loss: 0.00889972131699323735\n",
      "Episode Reward: 0.0\n",
      "Step 226 (105556) @ Episode 433/10000, loss: 0.00050297618145123129\n",
      "Episode Reward: 1.0\n",
      "Step 231 (105787) @ Episode 434/10000, loss: 0.00165101920720189863\n",
      "Episode Reward: 1.0\n",
      "Step 393 (106180) @ Episode 435/10000, loss: 0.00052378588588908313\n",
      "Episode Reward: 4.0\n",
      "Step 357 (106537) @ Episode 436/10000, loss: 0.00515547720715403648\n",
      "Episode Reward: 3.0\n",
      "Step 167 (106704) @ Episode 437/10000, loss: 0.00029309053206816316\n",
      "Episode Reward: 0.0\n",
      "Step 165 (106869) @ Episode 438/10000, loss: 0.00096473022131249315\n",
      "Episode Reward: 0.0\n",
      "Step 353 (107222) @ Episode 439/10000, loss: 0.00018908811034634716\n",
      "Episode Reward: 3.0\n",
      "Step 233 (107455) @ Episode 440/10000, loss: 0.00017756517627276484\n",
      "Episode Reward: 1.0\n",
      "Step 229 (107684) @ Episode 441/10000, loss: 0.00078480469528585672\n",
      "Episode Reward: 1.0\n",
      "Step 338 (108022) @ Episode 442/10000, loss: 0.00168371212203055623\n",
      "Episode Reward: 3.0\n",
      "Step 180 (108202) @ Episode 443/10000, loss: 0.00026336760492995385\n",
      "Episode Reward: 0.0\n",
      "Step 173 (108375) @ Episode 444/10000, loss: 0.00072909449227154254\n",
      "Episode Reward: 0.0\n",
      "Step 183 (108558) @ Episode 445/10000, loss: 0.00084360537584871055\n",
      "Episode Reward: 0.0\n",
      "Step 225 (108783) @ Episode 446/10000, loss: 0.00174772785976529126\n",
      "Episode Reward: 1.0\n",
      "Step 231 (109014) @ Episode 447/10000, loss: 0.00177150941453874118\n",
      "Episode Reward: 1.0\n",
      "Step 386 (109400) @ Episode 448/10000, loss: 7.216638914542273e-056\n",
      "Episode Reward: 3.0\n",
      "Step 164 (109564) @ Episode 449/10000, loss: 0.00027275583124719563\n",
      "Episode Reward: 0.0\n",
      "Step 242 (109806) @ Episode 450/10000, loss: 0.00016186108405236155\n",
      "Episode Reward: 2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 17:03:52,703] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video000450.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 176 (109982) @ Episode 451/10000, loss: 0.00033036217791959643\n",
      "Episode Reward: 0.0\n",
      "Step 17 (109999) @ Episode 452/10000, loss: 7.928442937554792e-05\n",
      " Copied model parameters to target network\n",
      "Step 183 (110165) @ Episode 452/10000, loss: 0.00175402476452291018\n",
      "Episode Reward: 0.0\n",
      "Step 229 (110394) @ Episode 453/10000, loss: 0.00185433519072830683\n",
      "Episode Reward: 1.0\n",
      "Step 277 (110671) @ Episode 454/10000, loss: 0.00036634848220273857\n",
      "Episode Reward: 2.0\n",
      "Step 344 (111015) @ Episode 455/10000, loss: 0.00196659052744507815\n",
      "Episode Reward: 3.0\n",
      "Step 183 (111198) @ Episode 456/10000, loss: 0.00071119295898824936\n",
      "Episode Reward: 0.0\n",
      "Step 172 (111370) @ Episode 457/10000, loss: 0.00287052523344755173\n",
      "Episode Reward: 0.0\n",
      "Step 244 (111614) @ Episode 458/10000, loss: 0.00744606787338852944\n",
      "Episode Reward: 1.0\n",
      "Step 209 (111823) @ Episode 459/10000, loss: 0.00195423024706542597\n",
      "Episode Reward: 1.0\n",
      "Step 275 (112098) @ Episode 460/10000, loss: 0.00059237744426354772\n",
      "Episode Reward: 2.0\n",
      "Step 561 (112659) @ Episode 461/10000, loss: 0.00145563320256769663\n",
      "Episode Reward: 6.0\n",
      "Step 249 (112908) @ Episode 462/10000, loss: 0.00059580086963251234\n",
      "Episode Reward: 2.0\n",
      "Step 231 (113139) @ Episode 463/10000, loss: 0.00028491919510997834\n",
      "Episode Reward: 1.0\n",
      "Step 236 (113375) @ Episode 464/10000, loss: 0.00069566274760290987\n",
      "Episode Reward: 1.0\n",
      "Step 283 (113658) @ Episode 465/10000, loss: 0.00080606469418853528\n",
      "Episode Reward: 2.0\n",
      "Step 178 (113836) @ Episode 466/10000, loss: 0.00089753465726971635\n",
      "Episode Reward: 0.0\n",
      "Step 238 (114074) @ Episode 467/10000, loss: 0.00038093017064966262\n",
      "Episode Reward: 1.0\n",
      "Step 179 (114253) @ Episode 468/10000, loss: 0.00026155158411711454\n",
      "Episode Reward: 0.0\n",
      "Step 172 (114425) @ Episode 469/10000, loss: 0.00161121052224189044\n",
      "Episode Reward: 0.0\n",
      "Step 175 (114600) @ Episode 470/10000, loss: 0.00021708183339796965\n",
      "Episode Reward: 0.0\n",
      "Step 203 (114803) @ Episode 471/10000, loss: 0.00028383068274706625\n",
      "Episode Reward: 1.0\n",
      "Step 378 (115181) @ Episode 472/10000, loss: 0.00054335664026439194\n",
      "Episode Reward: 4.0\n",
      "Step 238 (115419) @ Episode 473/10000, loss: 0.00040004795300774276\n",
      "Episode Reward: 1.0\n",
      "Step 173 (115592) @ Episode 474/10000, loss: 0.00162395776715129614\n",
      "Episode Reward: 0.0\n",
      "Step 239 (115831) @ Episode 475/10000, loss: 0.00036800644011236727\n",
      "Episode Reward: 1.0\n",
      "Step 310 (116141) @ Episode 476/10000, loss: 0.00272824196144938473\n",
      "Episode Reward: 3.0\n",
      "Step 236 (116377) @ Episode 477/10000, loss: 0.00127138395328074724\n",
      "Episode Reward: 1.0\n",
      "Step 186 (116563) @ Episode 478/10000, loss: 0.00225014099851250655\n",
      "Episode Reward: 0.0\n",
      "Step 194 (116757) @ Episode 479/10000, loss: 0.00039685054798610513\n",
      "Episode Reward: 0.0\n",
      "Step 180 (116937) @ Episode 480/10000, loss: 0.00029315974097698927\n",
      "Episode Reward: 0.0\n",
      "Step 220 (117157) @ Episode 481/10000, loss: 0.00049549207324162136\n",
      "Episode Reward: 1.0\n",
      "Step 169 (117326) @ Episode 482/10000, loss: 0.00443571805953979557\n",
      "Episode Reward: 0.0\n",
      "Step 359 (117685) @ Episode 483/10000, loss: 0.00191210268530994654\n",
      "Episode Reward: 3.0\n",
      "Step 176 (117861) @ Episode 484/10000, loss: 0.00182393717113882376\n",
      "Episode Reward: 0.0\n",
      "Step 216 (118077) @ Episode 485/10000, loss: 0.00014497026859316975\n",
      "Episode Reward: 1.0\n",
      "Step 306 (118383) @ Episode 486/10000, loss: 0.00048818855429999532\n",
      "Episode Reward: 2.0\n",
      "Step 233 (118616) @ Episode 487/10000, loss: 0.00058783416170626889\n",
      "Episode Reward: 1.0\n",
      "Step 171 (118787) @ Episode 488/10000, loss: 0.00013220396067481488\n",
      "Episode Reward: 0.0\n",
      "Step 288 (119075) @ Episode 489/10000, loss: 0.00066843634704127913\n",
      "Episode Reward: 2.0\n",
      "Step 229 (119304) @ Episode 490/10000, loss: 0.00025364739121869206\n",
      "Episode Reward: 1.0\n",
      "Step 232 (119536) @ Episode 491/10000, loss: 0.00066339108161628257\n",
      "Episode Reward: 1.0\n",
      "Step 167 (119703) @ Episode 492/10000, loss: 0.00060458091320469982\n",
      "Episode Reward: 0.0\n",
      "Step 175 (119878) @ Episode 493/10000, loss: 0.00264669326134026052\n",
      "Episode Reward: 0.0\n",
      "Step 121 (119999) @ Episode 494/10000, loss: 0.00063733948627486821\n",
      " Copied model parameters to target network\n",
      "Step 303 (120181) @ Episode 494/10000, loss: 0.00036496622487902644\n",
      "Episode Reward: 2.0\n",
      "Step 232 (120413) @ Episode 495/10000, loss: 0.00048954435624182222\n",
      "Episode Reward: 1.0\n",
      "Step 276 (120689) @ Episode 496/10000, loss: 0.00106401368975639346\n",
      "Episode Reward: 2.0\n",
      "Step 357 (121046) @ Episode 497/10000, loss: 0.00035022490192204714\n",
      "Episode Reward: 4.0\n",
      "Step 173 (121219) @ Episode 498/10000, loss: 0.00038380653131753206\n",
      "Episode Reward: 0.0\n",
      "Step 183 (121402) @ Episode 499/10000, loss: 0.00050127529539167883\n",
      "Episode Reward: 0.0\n",
      "Step 170 (121572) @ Episode 500/10000, loss: 0.00227380730211734773\n",
      "Episode Reward: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 17:05:41,572] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video000500.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 186 (121758) @ Episode 501/10000, loss: 0.00098320585675537598\n",
      "Episode Reward: 0.0\n",
      "Step 245 (122003) @ Episode 502/10000, loss: 0.00085095490794628864\n",
      "Episode Reward: 1.0\n",
      "Step 210 (122213) @ Episode 503/10000, loss: 0.00079279462806880474\n",
      "Episode Reward: 1.0\n",
      "Step 243 (122456) @ Episode 504/10000, loss: 0.00047976727364584804\n",
      "Episode Reward: 2.0\n",
      "Step 226 (122682) @ Episode 505/10000, loss: 0.00051688606617972257\n",
      "Episode Reward: 1.0\n",
      "Step 239 (122921) @ Episode 506/10000, loss: 0.00149187573697417974\n",
      "Episode Reward: 1.0\n",
      "Step 250 (123171) @ Episode 507/10000, loss: 0.00021232402650639415\n",
      "Episode Reward: 1.0\n",
      "Step 267 (123438) @ Episode 508/10000, loss: 0.00296107586473226553\n",
      "Episode Reward: 2.0\n",
      "Step 163 (123601) @ Episode 509/10000, loss: 0.00072440132498741156\n",
      "Episode Reward: 0.0\n",
      "Step 367 (123968) @ Episode 510/10000, loss: 0.00050437636673450475\n",
      "Episode Reward: 3.0\n",
      "Step 388 (124356) @ Episode 511/10000, loss: 0.00059635844081640245\n",
      "Episode Reward: 4.0\n",
      "Step 236 (124592) @ Episode 512/10000, loss: 0.00187111448030918848\n",
      "Episode Reward: 1.0\n",
      "Step 211 (124803) @ Episode 513/10000, loss: 0.00017902324907481675\n",
      "Episode Reward: 1.0\n",
      "Step 264 (125067) @ Episode 514/10000, loss: 0.00013931735884398222\n",
      "Episode Reward: 2.0\n",
      "Step 169 (125236) @ Episode 515/10000, loss: 0.00179044122342020273\n",
      "Episode Reward: 0.0\n",
      "Step 260 (125496) @ Episode 516/10000, loss: 0.00124020176008343747\n",
      "Episode Reward: 1.0\n",
      "Step 171 (125667) @ Episode 517/10000, loss: 8.793843153398484e-054\n",
      "Episode Reward: 0.0\n",
      "Step 296 (125963) @ Episode 518/10000, loss: 0.00037740357220172885\n",
      "Episode Reward: 2.0\n",
      "Step 173 (126136) @ Episode 519/10000, loss: 0.00041742497705854475\n",
      "Episode Reward: 0.0\n",
      "Step 181 (126317) @ Episode 520/10000, loss: 8.002339745871723e-056\n",
      "Episode Reward: 0.0\n",
      "Step 168 (126485) @ Episode 521/10000, loss: 0.00042037633829750123\n",
      "Episode Reward: 0.0\n",
      "Step 210 (126695) @ Episode 522/10000, loss: 0.00025924964575096965\n",
      "Episode Reward: 1.0\n",
      "Step 240 (126935) @ Episode 523/10000, loss: 0.00014947957242839038\n",
      "Episode Reward: 1.0\n",
      "Step 475 (127410) @ Episode 524/10000, loss: 0.00235968129709363664\n",
      "Episode Reward: 5.0\n",
      "Step 277 (127687) @ Episode 525/10000, loss: 8.101639105007052e-054\n",
      "Episode Reward: 2.0\n",
      "Step 182 (127869) @ Episode 526/10000, loss: 0.00784776452928781534\n",
      "Episode Reward: 0.0\n",
      "Step 212 (128081) @ Episode 527/10000, loss: 0.00014816180919297047\n",
      "Episode Reward: 1.0\n",
      "Step 223 (128304) @ Episode 528/10000, loss: 6.702573591610417e-056\n",
      "Episode Reward: 1.0\n",
      "Step 177 (128481) @ Episode 529/10000, loss: 0.00436895992606878358\n",
      "Episode Reward: 0.0\n",
      "Step 187 (128668) @ Episode 530/10000, loss: 0.00110487733036279683\n",
      "Episode Reward: 0.0\n",
      "Step 183 (128851) @ Episode 531/10000, loss: 0.00018335491768084466\n",
      "Episode Reward: 0.0\n",
      "Step 210 (129061) @ Episode 532/10000, loss: 0.00054739892948418864\n",
      "Episode Reward: 1.0\n",
      "Step 198 (129259) @ Episode 533/10000, loss: 0.00043868401553481817\n",
      "Episode Reward: 1.0\n",
      "Step 215 (129474) @ Episode 534/10000, loss: 0.00012150303518865258\n",
      "Episode Reward: 1.0\n",
      "Step 238 (129712) @ Episode 535/10000, loss: 0.00213903421536088394\n",
      "Episode Reward: 1.0\n",
      "Step 287 (129999) @ Episode 536/10000, loss: 0.00031882329494692385\n",
      " Copied model parameters to target network\n",
      "Step 369 (130081) @ Episode 536/10000, loss: 0.00288427388295531273\n",
      "Episode Reward: 3.0\n",
      "Step 283 (130364) @ Episode 537/10000, loss: 0.00058706849813461315\n",
      "Episode Reward: 2.0\n",
      "Step 271 (130635) @ Episode 538/10000, loss: 0.00180967117194086317\n",
      "Episode Reward: 2.0\n",
      "Step 163 (130798) @ Episode 539/10000, loss: 0.00132302707061171537\n",
      "Episode Reward: 0.0\n",
      "Step 246 (131044) @ Episode 540/10000, loss: 0.00043467205250635743\n",
      "Episode Reward: 1.0\n",
      "Step 357 (131401) @ Episode 541/10000, loss: 0.00043405208270996815\n",
      "Episode Reward: 3.0\n",
      "Step 288 (131689) @ Episode 542/10000, loss: 0.00045539403799921274\n",
      "Episode Reward: 2.0\n",
      "Step 431 (132120) @ Episode 543/10000, loss: 0.00063822686206549415\n",
      "Episode Reward: 4.0\n",
      "Step 286 (132406) @ Episode 544/10000, loss: 0.00017739708709996194\n",
      "Episode Reward: 2.0\n",
      "Step 184 (132590) @ Episode 545/10000, loss: 0.00059325410984456544\n",
      "Episode Reward: 0.0\n",
      "Step 242 (132832) @ Episode 546/10000, loss: 0.00153694255277514463\n",
      "Episode Reward: 1.0\n",
      "Step 368 (133200) @ Episode 547/10000, loss: 7.052622822811827e-054\n",
      "Episode Reward: 3.0\n",
      "Step 323 (133523) @ Episode 548/10000, loss: 0.00044154439819976696\n",
      "Episode Reward: 3.0\n",
      "Step 183 (133706) @ Episode 549/10000, loss: 0.00011692649422911927\n",
      "Episode Reward: 0.0\n",
      "Step 287 (133993) @ Episode 550/10000, loss: 0.00133586674928665166\n",
      "Episode Reward: 2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 17:07:36,736] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video000550.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 518 (134511) @ Episode 551/10000, loss: 0.00043025446939282126\n",
      "Episode Reward: 5.0\n",
      "Step 177 (134688) @ Episode 552/10000, loss: 0.00047966698184609413\n",
      "Episode Reward: 0.0\n",
      "Step 252 (134940) @ Episode 553/10000, loss: 0.00611695367842912755\n",
      "Episode Reward: 1.0\n",
      "Step 209 (135149) @ Episode 554/10000, loss: 0.00090447289403527987\n",
      "Episode Reward: 1.0\n",
      "Step 343 (135492) @ Episode 555/10000, loss: 9.462649177294225e-056\n",
      "Episode Reward: 3.0\n",
      "Step 197 (135689) @ Episode 556/10000, loss: 0.00036697639734484255\n",
      "Episode Reward: 0.0\n",
      "Step 210 (135899) @ Episode 557/10000, loss: 0.00022550973517354578\n",
      "Episode Reward: 1.0\n",
      "Step 274 (136173) @ Episode 558/10000, loss: 4.278805135982111e-052\n",
      "Episode Reward: 2.0\n",
      "Step 226 (136399) @ Episode 559/10000, loss: 9.29120578803122e-0573\n",
      "Episode Reward: 1.0\n",
      "Step 237 (136636) @ Episode 560/10000, loss: 0.00095384009182453166\n",
      "Episode Reward: 1.0\n",
      "Step 178 (136814) @ Episode 561/10000, loss: 0.00067162630148231983\n",
      "Episode Reward: 0.0\n",
      "Step 262 (137076) @ Episode 562/10000, loss: 0.00056401151232421477\n",
      "Episode Reward: 2.0\n",
      "Step 277 (137353) @ Episode 563/10000, loss: 0.00050169567111879598\n",
      "Episode Reward: 2.0\n",
      "Step 407 (137760) @ Episode 564/10000, loss: 0.00030536943813785914\n",
      "Episode Reward: 4.0\n",
      "Step 260 (138020) @ Episode 565/10000, loss: 0.00173627550248056657\n",
      "Episode Reward: 1.0\n",
      "Step 272 (138292) @ Episode 566/10000, loss: 0.00200635497458279133\n",
      "Episode Reward: 2.0\n",
      "Step 350 (138642) @ Episode 567/10000, loss: 0.00023512131883762777\n",
      "Episode Reward: 4.0\n",
      "Step 168 (138810) @ Episode 568/10000, loss: 0.00079741311492398384\n",
      "Episode Reward: 0.0\n",
      "Step 167 (138977) @ Episode 569/10000, loss: 6.994586146902293e-056\n",
      "Episode Reward: 0.0\n",
      "Step 216 (139193) @ Episode 570/10000, loss: 8.167299529304728e-053\n",
      "Episode Reward: 1.0\n",
      "Step 184 (139377) @ Episode 571/10000, loss: 0.00014169589849188924\n",
      "Episode Reward: 0.0\n",
      "Step 226 (139603) @ Episode 572/10000, loss: 0.00241359462961554533\n",
      "Episode Reward: 1.0\n",
      "Step 167 (139770) @ Episode 573/10000, loss: 0.00089085783110931527\n",
      "Episode Reward: 0.0\n",
      "Step 229 (139999) @ Episode 574/10000, loss: 0.00013382719771470875\n",
      " Copied model parameters to target network\n",
      "Step 271 (140041) @ Episode 574/10000, loss: 0.00064374192152172338\n",
      "Episode Reward: 2.0\n",
      "Step 320 (140361) @ Episode 575/10000, loss: 0.00033466349123045834\n",
      "Episode Reward: 3.0\n",
      "Step 176 (140537) @ Episode 576/10000, loss: 0.00108137587085366257\n",
      "Episode Reward: 0.0\n",
      "Step 274 (140811) @ Episode 577/10000, loss: 0.00039924250449985266\n",
      "Episode Reward: 2.0\n",
      "Step 205 (141016) @ Episode 578/10000, loss: 0.00058109255041927133\n",
      "Episode Reward: 1.0\n",
      "Step 260 (141276) @ Episode 579/10000, loss: 0.00048202605103142565\n",
      "Episode Reward: 1.0\n",
      "Step 323 (141599) @ Episode 580/10000, loss: 0.00023022529785521328\n",
      "Episode Reward: 2.0\n",
      "Step 244 (141843) @ Episode 581/10000, loss: 0.00033326522679999478\n",
      "Episode Reward: 1.0\n",
      "Step 287 (142130) @ Episode 582/10000, loss: 0.00056802196195349159\n",
      "Episode Reward: 2.0\n",
      "Step 305 (142435) @ Episode 583/10000, loss: 0.00015883130254223943\n",
      "Episode Reward: 3.0\n",
      "Step 188 (142623) @ Episode 584/10000, loss: 0.00052859139395877723\n",
      "Episode Reward: 0.0\n",
      "Step 175 (142798) @ Episode 585/10000, loss: 0.00086859613656997685\n",
      "Episode Reward: 0.0\n",
      "Step 169 (142967) @ Episode 586/10000, loss: 0.00011119974078610544\n",
      "Episode Reward: 0.0\n",
      "Step 187 (143154) @ Episode 587/10000, loss: 3.2983909477479756e-05\n",
      "Episode Reward: 0.0\n",
      "Step 237 (143391) @ Episode 588/10000, loss: 0.00015830583288334314\n",
      "Episode Reward: 1.0\n",
      "Step 257 (143648) @ Episode 589/10000, loss: 0.00038773936103098094\n",
      "Episode Reward: 1.0\n",
      "Step 274 (143922) @ Episode 590/10000, loss: 0.00068410916719585667\n",
      "Episode Reward: 2.0\n",
      "Step 209 (144131) @ Episode 591/10000, loss: 0.00082957046106457716\n",
      "Episode Reward: 1.0\n",
      "Step 264 (144395) @ Episode 592/10000, loss: 0.00375424511730670935\n",
      "Episode Reward: 2.0\n",
      "Step 172 (144567) @ Episode 593/10000, loss: 0.00031699298415333032\n",
      "Episode Reward: 0.0\n",
      "Step 174 (144741) @ Episode 594/10000, loss: 0.00028045504586771138\n",
      "Episode Reward: 0.0\n",
      "Step 247 (144988) @ Episode 595/10000, loss: 0.00124780298210680482\n",
      "Episode Reward: 1.0\n",
      "Step 167 (145155) @ Episode 596/10000, loss: 0.00124334287829697135\n",
      "Episode Reward: 0.0\n",
      "Step 448 (145603) @ Episode 597/10000, loss: 0.00065022613853216179\n",
      "Episode Reward: 5.0\n",
      "Step 205 (145808) @ Episode 598/10000, loss: 0.00063945678994059565\n",
      "Episode Reward: 0.0\n",
      "Step 203 (146011) @ Episode 599/10000, loss: 0.00013023211795371026\n",
      "Episode Reward: 1.0\n",
      "Step 242 (146253) @ Episode 600/10000, loss: 0.00159123877529054881\n",
      "Episode Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 17:09:29,821] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video000600.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 175 (146428) @ Episode 601/10000, loss: 0.00070066790794953727\n",
      "Episode Reward: 0.0\n",
      "Step 443 (146871) @ Episode 602/10000, loss: 0.00057326769456267368\n",
      "Episode Reward: 5.0\n",
      "Step 181 (147052) @ Episode 603/10000, loss: 0.00057493452914059167\n",
      "Episode Reward: 0.0\n",
      "Step 311 (147363) @ Episode 604/10000, loss: 0.00201682560145854954\n",
      "Episode Reward: 2.0\n",
      "Step 279 (147642) @ Episode 605/10000, loss: 0.00033299170900136234\n",
      "Episode Reward: 2.0\n",
      "Step 167 (147809) @ Episode 606/10000, loss: 0.00108478334732353692\n",
      "Episode Reward: 0.0\n",
      "Step 243 (148052) @ Episode 607/10000, loss: 0.01078216917812824253\n",
      "Episode Reward: 2.0\n",
      "Step 178 (148230) @ Episode 608/10000, loss: 0.00223748292773962355\n",
      "Episode Reward: 0.0\n",
      "Step 245 (148475) @ Episode 609/10000, loss: 0.00035347117227502167\n",
      "Episode Reward: 1.0\n",
      "Step 170 (148645) @ Episode 610/10000, loss: 0.00135524407960474574\n",
      "Episode Reward: 0.0\n",
      "Step 319 (148964) @ Episode 611/10000, loss: 0.00073563703335821634\n",
      "Episode Reward: 3.0\n",
      "Step 185 (149149) @ Episode 612/10000, loss: 0.00020900845993310213\n",
      "Episode Reward: 0.0\n",
      "Step 232 (149381) @ Episode 613/10000, loss: 0.00051388877909630544\n",
      "Episode Reward: 1.0\n",
      "Step 227 (149608) @ Episode 614/10000, loss: 0.00038185811717994516\n",
      "Episode Reward: 1.0\n",
      "Step 189 (149797) @ Episode 615/10000, loss: 0.00013528492127079517\n",
      "Episode Reward: 0.0\n",
      "Step 202 (149999) @ Episode 616/10000, loss: 0.00177206052467226986\n",
      " Copied model parameters to target network\n",
      "Step 377 (150174) @ Episode 616/10000, loss: 0.00049914751434698793\n",
      "Episode Reward: 4.0\n",
      "Step 227 (150401) @ Episode 617/10000, loss: 0.00058533134870231155\n",
      "Episode Reward: 1.0\n",
      "Step 214 (150615) @ Episode 618/10000, loss: 0.00049459090223535904\n",
      "Episode Reward: 1.0\n",
      "Step 243 (150858) @ Episode 619/10000, loss: 0.00110801181290298747\n",
      "Episode Reward: 1.0\n",
      "Step 334 (151192) @ Episode 620/10000, loss: 0.00027790461899712688\n",
      "Episode Reward: 3.0\n",
      "Step 187 (151379) @ Episode 621/10000, loss: 0.00309810740873217608\n",
      "Episode Reward: 0.0\n",
      "Step 175 (151554) @ Episode 622/10000, loss: 0.00015874978271313012\n",
      "Episode Reward: 0.0\n",
      "Step 224 (151778) @ Episode 623/10000, loss: 0.00017386705440003425\n",
      "Episode Reward: 1.0\n",
      "Step 227 (152005) @ Episode 624/10000, loss: 0.00142954289913177543\n",
      "Episode Reward: 1.0\n",
      "Step 257 (152262) @ Episode 625/10000, loss: 0.00177334935870021586\n",
      "Episode Reward: 2.0\n",
      "Step 179 (152441) @ Episode 626/10000, loss: 0.00040582608198747042\n",
      "Episode Reward: 0.0\n",
      "Step 169 (152610) @ Episode 627/10000, loss: 0.00035986336297355595\n",
      "Episode Reward: 0.0\n",
      "Step 245 (152855) @ Episode 628/10000, loss: 7.38117378205061e-0516\n",
      "Episode Reward: 1.0\n",
      "Step 294 (153149) @ Episode 629/10000, loss: 0.00038290931843221196\n",
      "Episode Reward: 2.0\n",
      "Step 252 (153401) @ Episode 630/10000, loss: 0.00037992355646565557\n",
      "Episode Reward: 1.0\n",
      "Step 338 (153739) @ Episode 631/10000, loss: 0.00016657332889735706\n",
      "Episode Reward: 3.0\n",
      "Step 233 (153972) @ Episode 632/10000, loss: 0.00162751099560409787\n",
      "Episode Reward: 1.0\n",
      "Step 312 (154284) @ Episode 633/10000, loss: 0.00067605182994157087\n",
      "Episode Reward: 2.0\n",
      "Step 175 (154459) @ Episode 634/10000, loss: 0.00044499768409878016\n",
      "Episode Reward: 0.0\n",
      "Step 326 (154785) @ Episode 635/10000, loss: 0.00054531689966097473\n",
      "Episode Reward: 3.0\n",
      "Step 274 (155059) @ Episode 636/10000, loss: 0.00034366737236268824\n",
      "Episode Reward: 2.0\n",
      "Step 316 (155375) @ Episode 637/10000, loss: 0.00101176346652209763\n",
      "Episode Reward: 2.0\n",
      "Step 172 (155547) @ Episode 638/10000, loss: 0.00011794175952672958\n",
      "Episode Reward: 0.0\n",
      "Step 251 (155798) @ Episode 639/10000, loss: 0.00036542126326821744\n",
      "Episode Reward: 1.0\n",
      "Step 211 (156009) @ Episode 640/10000, loss: 0.00063121953280642635\n",
      "Episode Reward: 1.0\n",
      "Step 189 (156198) @ Episode 641/10000, loss: 0.00030551839154213667\n",
      "Episode Reward: 0.0\n",
      "Step 301 (156499) @ Episode 642/10000, loss: 0.00037377787521108985\n",
      "Episode Reward: 3.0\n",
      "Step 176 (156675) @ Episode 643/10000, loss: 0.00097101938445121054\n",
      "Episode Reward: 0.0\n",
      "Step 318 (156993) @ Episode 644/10000, loss: 0.00101309025194495927\n",
      "Episode Reward: 3.0\n",
      "Step 246 (157239) @ Episode 645/10000, loss: 0.00024099850270431495\n",
      "Episode Reward: 1.0\n",
      "Step 223 (157462) @ Episode 646/10000, loss: 0.00037770363269373775\n",
      "Episode Reward: 1.0\n",
      "Step 185 (157647) @ Episode 647/10000, loss: 0.00059895188314840254\n",
      "Episode Reward: 0.0\n",
      "Step 361 (158008) @ Episode 648/10000, loss: 0.00023774884175509214\n",
      "Episode Reward: 3.0\n",
      "Step 182 (158190) @ Episode 649/10000, loss: 0.00228967843577265747\n",
      "Episode Reward: 0.0\n",
      "Step 178 (158368) @ Episode 650/10000, loss: 6.168868276290596e-054\n",
      "Episode Reward: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 17:11:23,253] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video000650.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 166 (158534) @ Episode 651/10000, loss: 0.00083070702385157355\n",
      "Episode Reward: 0.0\n",
      "Step 286 (158820) @ Episode 652/10000, loss: 0.00022302397701423615\n",
      "Episode Reward: 2.0\n",
      "Step 194 (159014) @ Episode 653/10000, loss: 0.00013710325583815575\n",
      "Episode Reward: 0.0\n",
      "Step 173 (159187) @ Episode 654/10000, loss: 0.00027728971326723695\n",
      "Episode Reward: 0.0\n",
      "Step 362 (159549) @ Episode 655/10000, loss: 0.00236578867770731455\n",
      "Episode Reward: 4.0\n",
      "Step 263 (159812) @ Episode 656/10000, loss: 0.00083409360377117996\n",
      "Episode Reward: 1.0\n",
      "Step 187 (159999) @ Episode 657/10000, loss: 0.00048449329915456474\n",
      " Copied model parameters to target network\n",
      "Step 387 (160199) @ Episode 657/10000, loss: 0.00082042271969839934\n",
      "Episode Reward: 3.0\n",
      "Step 201 (160400) @ Episode 658/10000, loss: 0.00063262390904128555\n",
      "Episode Reward: 0.0\n",
      "Step 273 (160673) @ Episode 659/10000, loss: 8.426474232692271e-054\n",
      "Episode Reward: 2.0\n",
      "Step 185 (160858) @ Episode 660/10000, loss: 0.00108398951124399959\n",
      "Episode Reward: 0.0\n",
      "Step 169 (161027) @ Episode 661/10000, loss: 0.00335009349510073665\n",
      "Episode Reward: 0.0\n",
      "Step 350 (161377) @ Episode 662/10000, loss: 0.00017158078844659035\n",
      "Episode Reward: 3.0\n",
      "Step 363 (161740) @ Episode 663/10000, loss: 0.00026737531879916787\n",
      "Episode Reward: 3.0\n",
      "Step 193 (161933) @ Episode 664/10000, loss: 0.00013228187162894756\n",
      "Episode Reward: 0.0\n",
      "Step 269 (162202) @ Episode 665/10000, loss: 0.00162888457998633385\n",
      "Episode Reward: 2.0\n",
      "Step 308 (162510) @ Episode 666/10000, loss: 0.00146609218791127262\n",
      "Episode Reward: 2.0\n",
      "Step 172 (162682) @ Episode 667/10000, loss: 0.00043719960376620294\n",
      "Episode Reward: 0.0\n",
      "Step 287 (162969) @ Episode 668/10000, loss: 0.00087033607997000225\n",
      "Episode Reward: 2.0\n",
      "Step 230 (163199) @ Episode 669/10000, loss: 0.00334930140525102614\n",
      "Episode Reward: 1.0\n",
      "Step 168 (163367) @ Episode 670/10000, loss: 0.00090158241800963885\n",
      "Episode Reward: 0.0\n",
      "Step 256 (163623) @ Episode 671/10000, loss: 0.00087859557243064054\n",
      "Episode Reward: 1.0\n",
      "Step 315 (163938) @ Episode 672/10000, loss: 0.00095592148136347537\n",
      "Episode Reward: 3.0\n",
      "Step 213 (164151) @ Episode 673/10000, loss: 0.00022802824969403446\n",
      "Episode Reward: 1.0\n",
      "Step 296 (164447) @ Episode 674/10000, loss: 0.00133002083748579035\n",
      "Episode Reward: 2.0\n",
      "Step 180 (164627) @ Episode 675/10000, loss: 0.00141053076367825278\n",
      "Episode Reward: 0.0\n",
      "Step 208 (164835) @ Episode 676/10000, loss: 0.00015865915338508785\n",
      "Episode Reward: 1.0\n",
      "Step 270 (165105) @ Episode 677/10000, loss: 0.00384715199470522885\n",
      "Episode Reward: 2.0\n",
      "Step 300 (165405) @ Episode 678/10000, loss: 0.00044989376328885555\n",
      "Episode Reward: 2.0\n",
      "Step 178 (165583) @ Episode 679/10000, loss: 0.00015166465891525153\n",
      "Episode Reward: 0.0\n",
      "Step 231 (165814) @ Episode 680/10000, loss: 0.00091548770433291796\n",
      "Episode Reward: 1.0\n",
      "Step 313 (166127) @ Episode 681/10000, loss: 0.00101219001226127156\n",
      "Episode Reward: 2.0\n",
      "Step 338 (166465) @ Episode 682/10000, loss: 0.00031895749270915985\n",
      "Episode Reward: 3.0\n",
      "Step 181 (166646) @ Episode 683/10000, loss: 0.00147852778900414755\n",
      "Episode Reward: 0.0\n",
      "Step 251 (166897) @ Episode 684/10000, loss: 0.00018176811863668263\n",
      "Episode Reward: 2.0\n",
      "Step 242 (167139) @ Episode 685/10000, loss: 0.00239226222038269043\n",
      "Episode Reward: 1.0\n",
      "Step 169 (167308) @ Episode 686/10000, loss: 0.00035875421599484987\n",
      "Episode Reward: 0.0\n",
      "Step 192 (167500) @ Episode 687/10000, loss: 0.00096010998822748668\n",
      "Episode Reward: 0.0\n",
      "Step 238 (167738) @ Episode 688/10000, loss: 0.00120205793064087636\n",
      "Episode Reward: 1.0\n",
      "Step 179 (167917) @ Episode 689/10000, loss: 0.00036344004911370575\n",
      "Episode Reward: 0.0\n",
      "Step 186 (168103) @ Episode 690/10000, loss: 0.00022269887267611926\n",
      "Episode Reward: 0.0\n",
      "Step 321 (168424) @ Episode 691/10000, loss: 0.00031496473820880055\n",
      "Episode Reward: 2.0\n",
      "Step 332 (168756) @ Episode 692/10000, loss: 0.00058375619119033226\n",
      "Episode Reward: 3.0\n",
      "Step 228 (168984) @ Episode 693/10000, loss: 0.00012215207971166824\n",
      "Episode Reward: 1.0\n",
      "Step 302 (169286) @ Episode 694/10000, loss: 0.00014631243539042775\n",
      "Episode Reward: 2.0\n",
      "Step 292 (169578) @ Episode 695/10000, loss: 0.00134556926786899572\n",
      "Episode Reward: 2.0\n",
      "Step 182 (169760) @ Episode 696/10000, loss: 0.00011438279761932796\n",
      "Episode Reward: 0.0\n",
      "Step 227 (169987) @ Episode 697/10000, loss: 0.00012857993715442717\n",
      "Episode Reward: 1.0\n",
      "Step 12 (169999) @ Episode 698/10000, loss: 0.00041485868860036135\n",
      " Copied model parameters to target network\n",
      "Step 190 (170177) @ Episode 698/10000, loss: 0.00056701287394389515\n",
      "Episode Reward: 0.0\n",
      "Step 340 (170517) @ Episode 699/10000, loss: 0.00044753446127288043\n",
      "Episode Reward: 3.0\n",
      "Step 348 (170865) @ Episode 700/10000, loss: 0.00114810490049421798\n",
      "Episode Reward: 3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 17:13:19,126] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video000700.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 307 (171172) @ Episode 701/10000, loss: 0.00092659093206748374\n",
      "Episode Reward: 2.0\n",
      "Step 183 (171355) @ Episode 702/10000, loss: 0.00036426621954888105\n",
      "Episode Reward: 0.0\n",
      "Step 168 (171523) @ Episode 703/10000, loss: 0.00028095167363062567\n",
      "Episode Reward: 0.0\n",
      "Step 237 (171760) @ Episode 704/10000, loss: 0.00027671884163282812\n",
      "Episode Reward: 1.0\n",
      "Step 172 (171932) @ Episode 705/10000, loss: 0.00042223138734698296\n",
      "Episode Reward: 0.0\n",
      "Step 471 (172403) @ Episode 706/10000, loss: 0.00353525392711162573\n",
      "Episode Reward: 5.0\n",
      "Step 171 (172574) @ Episode 707/10000, loss: 0.00082910357741639024\n",
      "Episode Reward: 0.0\n",
      "Step 238 (172812) @ Episode 708/10000, loss: 0.00096531974850222477\n",
      "Episode Reward: 1.0\n",
      "Step 416 (173228) @ Episode 709/10000, loss: 0.00569185195490717934\n",
      "Episode Reward: 4.0\n",
      "Step 345 (173573) @ Episode 710/10000, loss: 0.00062545685796067124\n",
      "Episode Reward: 3.0\n",
      "Step 241 (173814) @ Episode 711/10000, loss: 0.00128412863705307254\n",
      "Episode Reward: 1.0\n",
      "Step 202 (174016) @ Episode 712/10000, loss: 0.00028411069069989026\n",
      "Episode Reward: 1.0\n",
      "Step 251 (174267) @ Episode 713/10000, loss: 0.00133374496363103438\n",
      "Episode Reward: 1.0\n",
      "Step 180 (174447) @ Episode 714/10000, loss: 0.00026894151233136654\n",
      "Episode Reward: 0.0\n",
      "Step 402 (174849) @ Episode 715/10000, loss: 0.00975076388567686268\n",
      "Episode Reward: 4.0\n",
      "Step 213 (175062) @ Episode 716/10000, loss: 0.00031743367435410622\n",
      "Episode Reward: 1.0\n",
      "Step 239 (175301) @ Episode 717/10000, loss: 0.00016210190369747584\n",
      "Episode Reward: 1.0\n",
      "Step 294 (175595) @ Episode 718/10000, loss: 0.00045367309940047568\n",
      "Episode Reward: 2.0\n",
      "Step 377 (175972) @ Episode 719/10000, loss: 0.00041439727647230035\n",
      "Episode Reward: 4.0\n",
      "Step 202 (176174) @ Episode 720/10000, loss: 0.00013288561603985727\n",
      "Episode Reward: 1.0\n",
      "Step 345 (176519) @ Episode 721/10000, loss: 0.00024790654424577952\n",
      "Episode Reward: 3.0\n",
      "Step 368 (176887) @ Episode 722/10000, loss: 7.191865734057501e-053\n",
      "Episode Reward: 4.0\n",
      "Step 317 (177204) @ Episode 723/10000, loss: 0.00070087210042402153\n",
      "Episode Reward: 2.0\n",
      "Step 268 (177472) @ Episode 724/10000, loss: 0.00013357437273953112\n",
      "Episode Reward: 2.0\n",
      "Step 231 (177703) @ Episode 725/10000, loss: 0.00047045815153978765\n",
      "Episode Reward: 1.0\n",
      "Step 356 (178059) @ Episode 726/10000, loss: 0.00583983911201357812\n",
      "Episode Reward: 3.0\n",
      "Step 384 (178443) @ Episode 727/10000, loss: 0.00058704242110252386\n",
      "Episode Reward: 4.0\n",
      "Step 403 (178846) @ Episode 728/10000, loss: 0.00164975388906896116\n",
      "Episode Reward: 4.0\n",
      "Step 220 (179066) @ Episode 729/10000, loss: 0.00184648134745657442\n",
      "Episode Reward: 1.0\n",
      "Step 183 (179249) @ Episode 730/10000, loss: 6.543595372932032e-056\n",
      "Episode Reward: 0.0\n",
      "Step 202 (179451) @ Episode 731/10000, loss: 0.00018932644161395729\n",
      "Episode Reward: 1.0\n",
      "Step 186 (179637) @ Episode 732/10000, loss: 0.00047925399849191318\n",
      "Episode Reward: 0.0\n",
      "Step 192 (179829) @ Episode 733/10000, loss: 0.00033339264336973437\n",
      "Episode Reward: 0.0\n",
      "Step 170 (179999) @ Episode 734/10000, loss: 0.00149076001252979041\n",
      " Copied model parameters to target network\n",
      "Step 271 (180100) @ Episode 734/10000, loss: 0.00044190848711878068\n",
      "Episode Reward: 2.0\n",
      "Step 239 (180339) @ Episode 735/10000, loss: 0.00024184264475479722\n",
      "Episode Reward: 1.0\n",
      "Step 281 (180620) @ Episode 736/10000, loss: 0.00076698703924193982\n",
      "Episode Reward: 2.0\n",
      "Step 311 (180931) @ Episode 737/10000, loss: 0.00209904462099075355\n",
      "Episode Reward: 3.0\n",
      "Step 194 (181125) @ Episode 738/10000, loss: 0.00082292465958744293\n",
      "Episode Reward: 0.0\n",
      "Step 203 (181328) @ Episode 739/10000, loss: 0.00066711654653772717\n",
      "Episode Reward: 1.0\n",
      "Step 270 (181598) @ Episode 740/10000, loss: 0.00047515879850834615\n",
      "Episode Reward: 2.0\n",
      "Step 173 (181771) @ Episode 741/10000, loss: 0.00016518888878636062\n",
      "Episode Reward: 0.0\n",
      "Step 210 (181981) @ Episode 742/10000, loss: 0.00010477171599632129\n",
      "Episode Reward: 1.0\n",
      "Step 399 (182380) @ Episode 743/10000, loss: 7.669495971640572e-052\n",
      "Episode Reward: 4.0\n",
      "Step 336 (182716) @ Episode 744/10000, loss: 0.00044343667104840282\n",
      "Episode Reward: 3.0\n",
      "Step 316 (183032) @ Episode 745/10000, loss: 0.00654534390196204243\n",
      "Episode Reward: 2.0\n",
      "Step 266 (183298) @ Episode 746/10000, loss: 0.00079437717795372016\n",
      "Episode Reward: 2.0\n",
      "Step 172 (183470) @ Episode 747/10000, loss: 0.00479255616664886587\n",
      "Episode Reward: 0.0\n",
      "Step 274 (183744) @ Episode 748/10000, loss: 0.00111736287362873556\n",
      "Episode Reward: 2.0\n",
      "Step 168 (183912) @ Episode 749/10000, loss: 0.00077154248720034966\n",
      "Episode Reward: 0.0\n",
      "Step 449 (184361) @ Episode 750/10000, loss: 0.00120128120761364753\n",
      "Episode Reward: 4.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 17:15:24,008] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video000750.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 282 (184643) @ Episode 751/10000, loss: 0.00018807135347742587\n",
      "Episode Reward: 2.0\n",
      "Step 264 (184907) @ Episode 752/10000, loss: 0.00040583114605396986\n",
      "Episode Reward: 2.0\n",
      "Step 174 (185081) @ Episode 753/10000, loss: 0.00414607254788279565\n",
      "Episode Reward: 0.0\n",
      "Step 193 (185274) @ Episode 754/10000, loss: 0.00402726139873266273\n",
      "Episode Reward: 0.0\n",
      "Step 232 (185506) @ Episode 755/10000, loss: 0.00294055650010705494\n",
      "Episode Reward: 1.0\n",
      "Step 247 (185753) @ Episode 756/10000, loss: 0.00042608834337443113\n",
      "Episode Reward: 1.0\n",
      "Step 175 (185928) @ Episode 757/10000, loss: 0.00034242655965499583\n",
      "Episode Reward: 0.0\n",
      "Step 177 (186105) @ Episode 758/10000, loss: 0.00031987659167498355\n",
      "Episode Reward: 0.0\n",
      "Step 227 (186332) @ Episode 759/10000, loss: 0.00020812210277654233\n",
      "Episode Reward: 1.0\n",
      "Step 178 (186510) @ Episode 760/10000, loss: 0.00015124569472391158\n",
      "Episode Reward: 0.0\n",
      "Step 321 (186831) @ Episode 761/10000, loss: 0.00051307334797456864\n",
      "Episode Reward: 3.0\n",
      "Step 360 (187191) @ Episode 762/10000, loss: 0.00042034999933093786\n",
      "Episode Reward: 3.0\n",
      "Step 174 (187365) @ Episode 763/10000, loss: 0.00024268733977805823\n",
      "Episode Reward: 0.0\n",
      "Step 355 (187720) @ Episode 764/10000, loss: 0.00127965665888041263\n",
      "Episode Reward: 3.0\n",
      "Step 170 (187890) @ Episode 765/10000, loss: 0.00019077844626735896\n",
      "Episode Reward: 0.0\n",
      "Step 421 (188311) @ Episode 766/10000, loss: 0.00031642406247556215\n",
      "Episode Reward: 4.0\n",
      "Step 216 (188527) @ Episode 767/10000, loss: 0.00443499116227030755\n",
      "Episode Reward: 1.0\n",
      "Step 170 (188697) @ Episode 768/10000, loss: 0.00073071487713605177\n",
      "Episode Reward: 0.0\n",
      "Step 228 (188925) @ Episode 769/10000, loss: 0.00089245272101834424\n",
      "Episode Reward: 1.0\n",
      "Step 173 (189098) @ Episode 770/10000, loss: 0.00065514555899426343\n",
      "Episode Reward: 0.0\n",
      "Step 322 (189420) @ Episode 771/10000, loss: 0.00043294727220223215\n",
      "Episode Reward: 2.0\n",
      "Step 276 (189696) @ Episode 772/10000, loss: 0.00021369569003582078\n",
      "Episode Reward: 1.0\n",
      "Step 232 (189928) @ Episode 773/10000, loss: 0.00028187318821437657\n",
      "Episode Reward: 1.0\n",
      "Step 71 (189999) @ Episode 774/10000, loss: 0.00052201421931385995\n",
      " Copied model parameters to target network\n",
      "Step 165 (190093) @ Episode 774/10000, loss: 0.00165729061700403775\n",
      "Episode Reward: 0.0\n",
      "Step 328 (190421) @ Episode 775/10000, loss: 0.00071390497032552966\n",
      "Episode Reward: 3.0\n",
      "Step 256 (190677) @ Episode 776/10000, loss: 0.00012345178402028978\n",
      "Episode Reward: 1.0\n",
      "Step 185 (190862) @ Episode 777/10000, loss: 0.00102799234446138145\n",
      "Episode Reward: 0.0\n",
      "Step 271 (191133) @ Episode 778/10000, loss: 0.00017967121675610542\n",
      "Episode Reward: 2.0\n",
      "Step 177 (191310) @ Episode 779/10000, loss: 0.00045104522723704576\n",
      "Episode Reward: 0.0\n",
      "Step 240 (191550) @ Episode 780/10000, loss: 0.00459703011438250535\n",
      "Episode Reward: 1.0\n",
      "Step 215 (191765) @ Episode 781/10000, loss: 0.00070667947875335815\n",
      "Episode Reward: 1.0\n",
      "Step 185 (191950) @ Episode 782/10000, loss: 0.00048668304225429896\n",
      "Episode Reward: 0.0\n",
      "Step 301 (192251) @ Episode 783/10000, loss: 0.00025732006179168827\n",
      "Episode Reward: 2.0\n",
      "Step 170 (192421) @ Episode 784/10000, loss: 0.00160017656162381175\n",
      "Episode Reward: 0.0\n",
      "Step 186 (192607) @ Episode 785/10000, loss: 0.00127209397032856947\n",
      "Episode Reward: 0.0\n",
      "Step 303 (192910) @ Episode 786/10000, loss: 0.00027064088499173524\n",
      "Episode Reward: 2.0\n",
      "Step 242 (193152) @ Episode 787/10000, loss: 0.00056214939104393125\n",
      "Episode Reward: 1.0\n",
      "Step 196 (193348) @ Episode 788/10000, loss: 0.00054570345673710112\n",
      "Episode Reward: 0.0\n",
      "Step 275 (193623) @ Episode 789/10000, loss: 0.00066268624505028138\n",
      "Episode Reward: 2.0\n",
      "Step 212 (193835) @ Episode 790/10000, loss: 0.00021600417676381767\n",
      "Episode Reward: 1.0\n",
      "Step 250 (194085) @ Episode 791/10000, loss: 0.00014571771316695958\n",
      "Episode Reward: 1.0\n",
      "Step 168 (194253) @ Episode 792/10000, loss: 0.00043109722901135683\n",
      "Episode Reward: 0.0\n",
      "Step 249 (194502) @ Episode 793/10000, loss: 0.00195123290177434686\n",
      "Episode Reward: 1.0\n",
      "Step 182 (194684) @ Episode 794/10000, loss: 8.904300921130925e-058\n",
      "Episode Reward: 0.0\n",
      "Step 277 (194961) @ Episode 795/10000, loss: 0.00132913922425359493\n",
      "Episode Reward: 2.0\n",
      "Step 189 (195150) @ Episode 796/10000, loss: 0.00060767121613025675\n",
      "Episode Reward: 0.0\n",
      "Step 165 (195315) @ Episode 797/10000, loss: 0.00055079400772228843\n",
      "Episode Reward: 0.0\n",
      "Step 340 (195655) @ Episode 798/10000, loss: 0.00230176164768636233\n",
      "Episode Reward: 3.0\n",
      "Step 165 (195820) @ Episode 799/10000, loss: 0.00065947091206908233\n",
      "Episode Reward: 0.0\n",
      "Step 411 (196231) @ Episode 800/10000, loss: 0.00120267900638282307\n",
      "Episode Reward: 4.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 17:17:13,625] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video000800.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 297 (196528) @ Episode 801/10000, loss: 0.00021608901442959905\n",
      "Episode Reward: 2.0\n",
      "Step 227 (196755) @ Episode 802/10000, loss: 0.00015236574108712375\n",
      "Episode Reward: 1.0\n",
      "Step 193 (196948) @ Episode 803/10000, loss: 0.00062990887090563773\n",
      "Episode Reward: 0.0\n",
      "Step 160 (197108) @ Episode 804/10000, loss: 4.634944343706593e-055\n",
      "Episode Reward: 0.0\n",
      "Step 184 (197292) @ Episode 805/10000, loss: 0.00044270334183238447\n",
      "Episode Reward: 0.0\n",
      "Step 258 (197550) @ Episode 806/10000, loss: 0.00427728937938809433\n",
      "Episode Reward: 1.0\n",
      "Step 296 (197846) @ Episode 807/10000, loss: 0.00194705941248685122\n",
      "Episode Reward: 2.0\n",
      "Step 397 (198243) @ Episode 808/10000, loss: 0.00031899104942567647\n",
      "Episode Reward: 4.0\n",
      "Step 168 (198411) @ Episode 809/10000, loss: 0.00148686091415584094\n",
      "Episode Reward: 0.0\n",
      "Step 172 (198583) @ Episode 810/10000, loss: 0.00075528281740844253\n",
      "Episode Reward: 0.0\n",
      "Step 277 (198860) @ Episode 811/10000, loss: 0.00025037003797478974\n",
      "Episode Reward: 2.0\n",
      "Step 325 (199185) @ Episode 812/10000, loss: 0.00033769165747798983\n",
      "Episode Reward: 3.0\n",
      "Step 311 (199496) @ Episode 813/10000, loss: 0.00058239244390279056\n",
      "Episode Reward: 2.0\n",
      "Step 195 (199691) @ Episode 814/10000, loss: 0.00031202909303829074\n",
      "Episode Reward: 0.0\n",
      "Step 162 (199853) @ Episode 815/10000, loss: 0.00064918992575258024\n",
      "Episode Reward: 0.0\n",
      "Step 146 (199999) @ Episode 816/10000, loss: 0.00144904246553778653\n",
      " Copied model parameters to target network\n",
      "Step 177 (200030) @ Episode 816/10000, loss: 0.00348286563530564327\n",
      "Episode Reward: 0.0\n",
      "Step 173 (200203) @ Episode 817/10000, loss: 0.00090303737670183185\n",
      "Episode Reward: 0.0\n",
      "Step 352 (200555) @ Episode 818/10000, loss: 0.00022936187451705337\n",
      "Episode Reward: 3.0\n",
      "Step 468 (201023) @ Episode 819/10000, loss: 0.00019684922881424427\n",
      "Episode Reward: 5.0\n",
      "Step 346 (201369) @ Episode 820/10000, loss: 0.00020984371076337993\n",
      "Episode Reward: 3.0\n",
      "Step 403 (201772) @ Episode 821/10000, loss: 0.00095275649800896646\n",
      "Episode Reward: 4.0\n",
      "Step 396 (202168) @ Episode 822/10000, loss: 0.00085069547640159736\n",
      "Episode Reward: 4.0\n",
      "Step 178 (202346) @ Episode 823/10000, loss: 0.00039196040597744286\n",
      "Episode Reward: 0.0\n",
      "Step 265 (202611) @ Episode 824/10000, loss: 0.00050988537259399897\n",
      "Episode Reward: 2.0\n",
      "Step 294 (202905) @ Episode 825/10000, loss: 0.00304191932082176264\n",
      "Episode Reward: 2.0\n",
      "Step 314 (203219) @ Episode 826/10000, loss: 0.00087318214355036626\n",
      "Episode Reward: 2.0\n",
      "Step 235 (203454) @ Episode 827/10000, loss: 0.00190429273061454322\n",
      "Episode Reward: 1.0\n",
      "Step 275 (203729) @ Episode 828/10000, loss: 0.00036612531403079633\n",
      "Episode Reward: 2.0\n",
      "Step 179 (203908) @ Episode 829/10000, loss: 0.00016282446449622512\n",
      "Episode Reward: 0.0\n",
      "Step 238 (204146) @ Episode 830/10000, loss: 0.00072490464663133036\n",
      "Episode Reward: 1.0\n",
      "Step 261 (204407) @ Episode 831/10000, loss: 0.00113116286229342227\n",
      "Episode Reward: 2.0\n",
      "Step 235 (204642) @ Episode 832/10000, loss: 0.00020728261733893305\n",
      "Episode Reward: 1.0\n",
      "Step 468 (205110) @ Episode 833/10000, loss: 0.00068814086262136783\n",
      "Episode Reward: 5.0\n",
      "Step 210 (205320) @ Episode 834/10000, loss: 0.00021539980662055314\n",
      "Episode Reward: 1.0\n",
      "Step 175 (205495) @ Episode 835/10000, loss: 0.00015120170428417623\n",
      "Episode Reward: 0.0\n",
      "Step 244 (205739) @ Episode 836/10000, loss: 0.00058880681172013283\n",
      "Episode Reward: 1.0\n",
      "Step 289 (206028) @ Episode 837/10000, loss: 0.00026584713486954574\n",
      "Episode Reward: 2.0\n",
      "Step 165 (206193) @ Episode 838/10000, loss: 0.00016322461306117475\n",
      "Episode Reward: 0.0\n",
      "Step 174 (206367) @ Episode 839/10000, loss: 0.00015136631554923952\n",
      "Episode Reward: 0.0\n",
      "Step 261 (206628) @ Episode 840/10000, loss: 0.00312161655165255078\n",
      "Episode Reward: 2.0\n",
      "Step 289 (206917) @ Episode 841/10000, loss: 0.00101599248591810466\n",
      "Episode Reward: 2.0\n",
      "Step 397 (207314) @ Episode 842/10000, loss: 0.00012436744873411953\n",
      "Episode Reward: 4.0\n",
      "Step 259 (207573) @ Episode 843/10000, loss: 0.00015739529044367373\n",
      "Episode Reward: 2.0\n",
      "Step 295 (207868) @ Episode 844/10000, loss: 0.00041213899385184054\n",
      "Episode Reward: 2.0\n",
      "Step 231 (208099) @ Episode 845/10000, loss: 0.00010707616456784308\n",
      "Episode Reward: 1.0\n",
      "Step 330 (208429) @ Episode 846/10000, loss: 0.00031792369554750627\n",
      "Episode Reward: 3.0\n",
      "Step 239 (208668) @ Episode 847/10000, loss: 0.00016831653192639355\n",
      "Episode Reward: 1.0\n",
      "Step 268 (208936) @ Episode 848/10000, loss: 0.00032008218113332987\n",
      "Episode Reward: 2.0\n",
      "Step 242 (209178) @ Episode 849/10000, loss: 0.00019382266327738762\n",
      "Episode Reward: 1.0\n",
      "Step 181 (209359) @ Episode 850/10000, loss: 0.00116152258124202553\n",
      "Episode Reward: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 17:19:15,439] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video000850.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 220 (209579) @ Episode 851/10000, loss: 0.00076294247992336752\n",
      "Episode Reward: 1.0\n",
      "Step 175 (209754) @ Episode 852/10000, loss: 0.00039756472688168287\n",
      "Episode Reward: 0.0\n",
      "Step 242 (209996) @ Episode 853/10000, loss: 0.00022263766732066873\n",
      "Episode Reward: 1.0\n",
      "Step 3 (209999) @ Episode 854/10000, loss: 8.930838521337137e-05\n",
      " Copied model parameters to target network\n",
      "Step 216 (210212) @ Episode 854/10000, loss: 0.00058767921291291715\n",
      "Episode Reward: 1.0\n",
      "Step 204 (210416) @ Episode 855/10000, loss: 0.00161744072102010254\n",
      "Episode Reward: 0.0\n",
      "Step 180 (210596) @ Episode 856/10000, loss: 0.00058398250257596376\n",
      "Episode Reward: 0.0\n",
      "Step 164 (210760) @ Episode 857/10000, loss: 9.09668451640755e-0534\n",
      "Episode Reward: 0.0\n",
      "Step 393 (211153) @ Episode 858/10000, loss: 0.00111379683949053296\n",
      "Episode Reward: 4.0\n",
      "Step 242 (211395) @ Episode 859/10000, loss: 0.00046947621740400794\n",
      "Episode Reward: 1.0\n",
      "Step 167 (211562) @ Episode 860/10000, loss: 0.00042423751438036565\n",
      "Episode Reward: 0.0\n",
      "Step 199 (211761) @ Episode 861/10000, loss: 0.00136898295022547254\n",
      "Episode Reward: 0.0\n",
      "Step 168 (211929) @ Episode 862/10000, loss: 0.00036734633613377816\n",
      "Episode Reward: 0.0\n",
      "Step 172 (212101) @ Episode 863/10000, loss: 0.00060592999216169122\n",
      "Episode Reward: 0.0\n",
      "Step 191 (212292) @ Episode 864/10000, loss: 0.00055671698646619923\n",
      "Episode Reward: 0.0\n",
      "Step 194 (212486) @ Episode 865/10000, loss: 0.00035423535155132413\n",
      "Episode Reward: 0.0\n",
      "Step 179 (212665) @ Episode 866/10000, loss: 0.00023780568153597414\n",
      "Episode Reward: 0.0\n",
      "Step 235 (212900) @ Episode 867/10000, loss: 0.00038349625538103283\n",
      "Episode Reward: 1.0\n",
      "Step 178 (213078) @ Episode 868/10000, loss: 0.00064163468778133394\n",
      "Episode Reward: 0.0\n",
      "Step 338 (213416) @ Episode 869/10000, loss: 0.00071915949229151016\n",
      "Episode Reward: 3.0\n",
      "Step 304 (213720) @ Episode 870/10000, loss: 0.00042316169128753245\n",
      "Episode Reward: 2.0\n",
      "Step 347 (214067) @ Episode 871/10000, loss: 0.00047327953507192433\n",
      "Episode Reward: 3.0\n",
      "Step 254 (214321) @ Episode 872/10000, loss: 0.00126863154582679276\n",
      "Episode Reward: 1.0\n",
      "Step 319 (214640) @ Episode 873/10000, loss: 0.00014500544057227671\n",
      "Episode Reward: 2.0\n",
      "Step 261 (214901) @ Episode 874/10000, loss: 0.00014303643547464162\n",
      "Episode Reward: 2.0\n",
      "Step 199 (215100) @ Episode 875/10000, loss: 0.00014316246961243458\n",
      "Episode Reward: 1.0\n",
      "Step 180 (215280) @ Episode 876/10000, loss: 0.00036892422940582037\n",
      "Episode Reward: 0.0\n",
      "Step 386 (215666) @ Episode 877/10000, loss: 0.00052669248543679714\n",
      "Episode Reward: 4.0\n",
      "Step 170 (215836) @ Episode 878/10000, loss: 0.00092136132298037415\n",
      "Episode Reward: 0.0\n",
      "Step 173 (216009) @ Episode 879/10000, loss: 0.00015034707030281425\n",
      "Episode Reward: 0.0\n",
      "Step 173 (216182) @ Episode 880/10000, loss: 0.00105188903398811824\n",
      "Episode Reward: 0.0\n",
      "Step 311 (216493) @ Episode 881/10000, loss: 0.00021673997980542481\n",
      "Episode Reward: 3.0\n",
      "Step 238 (216731) @ Episode 882/10000, loss: 0.00032278720755130053\n",
      "Episode Reward: 1.0\n",
      "Step 176 (216907) @ Episode 883/10000, loss: 0.00011988308688160032\n",
      "Episode Reward: 0.0\n",
      "Step 245 (217152) @ Episode 884/10000, loss: 0.00037417304702103148\n",
      "Episode Reward: 1.0\n",
      "Step 292 (217444) @ Episode 885/10000, loss: 0.00056081690127030014\n",
      "Episode Reward: 2.0\n",
      "Step 245 (217689) @ Episode 886/10000, loss: 0.00135437399148941043\n",
      "Episode Reward: 1.0\n",
      "Step 172 (217861) @ Episode 887/10000, loss: 0.00018374639330431823\n",
      "Episode Reward: 0.0\n",
      "Step 205 (218066) @ Episode 888/10000, loss: 0.00030193751445040107\n",
      "Episode Reward: 1.0\n",
      "Step 209 (218275) @ Episode 889/10000, loss: 0.00017464179836679255\n",
      "Episode Reward: 1.0\n",
      "Step 235 (218510) @ Episode 890/10000, loss: 0.00040584485395811525\n",
      "Episode Reward: 1.0\n",
      "Step 172 (218682) @ Episode 891/10000, loss: 0.00033214548602700233\n",
      "Episode Reward: 0.0\n",
      "Step 230 (218912) @ Episode 892/10000, loss: 0.00016351666999980807\n",
      "Episode Reward: 1.0\n",
      "Step 280 (219192) @ Episode 893/10000, loss: 7.916300819488242e-055\n",
      "Episode Reward: 2.0\n",
      "Step 334 (219526) @ Episode 894/10000, loss: 0.00024469610070809727\n",
      "Episode Reward: 3.0\n",
      "Step 281 (219807) @ Episode 895/10000, loss: 9.764997230377048e-054\n",
      "Episode Reward: 2.0\n",
      "Step 192 (219999) @ Episode 896/10000, loss: 0.00010723141167545691\n",
      " Copied model parameters to target network\n",
      "Step 280 (220087) @ Episode 896/10000, loss: 0.00201637484133243563\n",
      "Episode Reward: 2.0\n",
      "Step 180 (220267) @ Episode 897/10000, loss: 0.00063621019944548615\n",
      "Episode Reward: 0.0\n",
      "Step 167 (220434) @ Episode 898/10000, loss: 0.00060024287085980185\n",
      "Episode Reward: 0.0\n",
      "Step 268 (220702) @ Episode 899/10000, loss: 0.00051126244943588973\n",
      "Episode Reward: 2.0\n",
      "Step 237 (220939) @ Episode 900/10000, loss: 0.00029974576318636537\n",
      "Episode Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 17:21:01,978] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video000900.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 164 (221103) @ Episode 901/10000, loss: 0.00017733842832967647\n",
      "Episode Reward: 0.0\n",
      "Step 169 (221272) @ Episode 902/10000, loss: 0.00054257432930171496\n",
      "Episode Reward: 0.0\n",
      "Step 169 (221441) @ Episode 903/10000, loss: 0.00021995211136527364\n",
      "Episode Reward: 0.0\n",
      "Step 174 (221615) @ Episode 904/10000, loss: 0.00036758324131369599\n",
      "Episode Reward: 0.0\n",
      "Step 270 (221885) @ Episode 905/10000, loss: 0.00093306700000539425\n",
      "Episode Reward: 2.0\n",
      "Step 236 (222121) @ Episode 906/10000, loss: 0.00085005251457914718\n",
      "Episode Reward: 1.0\n",
      "Step 240 (222361) @ Episode 907/10000, loss: 0.00039464957080781466\n",
      "Episode Reward: 1.0\n",
      "Step 165 (222526) @ Episode 908/10000, loss: 0.00020242558093741536\n",
      "Episode Reward: 0.0\n",
      "Step 294 (222820) @ Episode 909/10000, loss: 0.00043897141586057846\n",
      "Episode Reward: 2.0\n",
      "Step 177 (222997) @ Episode 910/10000, loss: 0.00050686392933130266\n",
      "Episode Reward: 0.0\n",
      "Step 401 (223398) @ Episode 911/10000, loss: 0.00013595377095043662\n",
      "Episode Reward: 4.0\n",
      "Step 170 (223568) @ Episode 912/10000, loss: 0.00087857450125738986\n",
      "Episode Reward: 0.0\n",
      "Step 167 (223735) @ Episode 913/10000, loss: 0.00091413466725498448\n",
      "Episode Reward: 0.0\n",
      "Step 243 (223978) @ Episode 914/10000, loss: 0.00016056577442213893\n",
      "Episode Reward: 2.0\n",
      "Step 175 (224153) @ Episode 915/10000, loss: 7.131751044653356e-053\n",
      "Episode Reward: 0.0\n",
      "Step 176 (224329) @ Episode 916/10000, loss: 0.00109211169183254248\n",
      "Episode Reward: 0.0\n",
      "Step 427 (224756) @ Episode 917/10000, loss: 0.00042345657129772013\n",
      "Episode Reward: 5.0\n",
      "Step 168 (224924) @ Episode 918/10000, loss: 8.974730735644698e-057\n",
      "Episode Reward: 0.0\n",
      "Step 166 (225090) @ Episode 919/10000, loss: 0.00037902424810454253\n",
      "Episode Reward: 0.0\n",
      "Step 229 (225319) @ Episode 920/10000, loss: 0.00022302674187812954\n",
      "Episode Reward: 1.0\n",
      "Step 225 (225544) @ Episode 921/10000, loss: 0.00017989237676374614\n",
      "Episode Reward: 1.0\n",
      "Step 186 (225730) @ Episode 922/10000, loss: 0.00023604210582561795\n",
      "Episode Reward: 0.0\n",
      "Step 376 (226106) @ Episode 923/10000, loss: 0.00011222887405892834\n",
      "Episode Reward: 4.0\n",
      "Step 210 (226316) @ Episode 924/10000, loss: 0.00041874946327880025\n",
      "Episode Reward: 1.0\n",
      "Step 215 (226531) @ Episode 925/10000, loss: 0.00161402765661478045\n",
      "Episode Reward: 1.0\n",
      "Step 235 (226766) @ Episode 926/10000, loss: 0.00023641521693207324\n",
      "Episode Reward: 1.0\n",
      "Step 281 (227047) @ Episode 927/10000, loss: 0.00011685372010106221\n",
      "Episode Reward: 2.0\n",
      "Step 236 (227283) @ Episode 928/10000, loss: 0.00268978718668222433\n",
      "Episode Reward: 1.0\n",
      "Step 265 (227548) @ Episode 929/10000, loss: 0.00114646065048873425\n",
      "Episode Reward: 2.0\n",
      "Step 164 (227712) @ Episode 930/10000, loss: 0.00029132602503523234\n",
      "Episode Reward: 0.0\n",
      "Step 543 (228255) @ Episode 931/10000, loss: 5.519147089216858e-055\n",
      "Episode Reward: 7.0\n",
      "Step 161 (228416) @ Episode 932/10000, loss: 0.00014431905583478516\n",
      "Episode Reward: 0.0\n",
      "Step 234 (228650) @ Episode 933/10000, loss: 5.1701914344448596e-05\n",
      "Episode Reward: 1.0\n",
      "Step 183 (228833) @ Episode 934/10000, loss: 0.00049989123363047846\n",
      "Episode Reward: 0.0\n",
      "Step 217 (229050) @ Episode 935/10000, loss: 0.00016384955961257221\n",
      "Episode Reward: 1.0\n",
      "Step 183 (229233) @ Episode 936/10000, loss: 0.00018888540216721594\n",
      "Episode Reward: 0.0\n",
      "Step 521 (229754) @ Episode 937/10000, loss: 0.00109155406244099144\n",
      "Episode Reward: 6.0\n",
      "Step 163 (229917) @ Episode 938/10000, loss: 0.00178890174720436335\n",
      "Episode Reward: 0.0\n",
      "Step 82 (229999) @ Episode 939/10000, loss: 0.00056170974858105186\n",
      " Copied model parameters to target network\n",
      "Step 314 (230231) @ Episode 939/10000, loss: 0.00203990773297846376\n",
      "Episode Reward: 3.0\n",
      "Step 351 (230582) @ Episode 940/10000, loss: 0.00038931949529796846\n",
      "Episode Reward: 3.0\n",
      "Step 216 (230798) @ Episode 941/10000, loss: 0.00073094363324344165\n",
      "Episode Reward: 1.0\n",
      "Step 277 (231075) @ Episode 942/10000, loss: 0.00015673742746002972\n",
      "Episode Reward: 2.0\n",
      "Step 334 (231409) @ Episode 943/10000, loss: 0.00024440602282993495\n",
      "Episode Reward: 3.0\n",
      "Step 236 (231645) @ Episode 944/10000, loss: 0.00019097684707958257\n",
      "Episode Reward: 1.0\n",
      "Step 242 (231887) @ Episode 945/10000, loss: 0.00013822903565596794\n",
      "Episode Reward: 1.0\n",
      "Step 206 (232093) @ Episode 946/10000, loss: 0.00116494484245777134\n",
      "Episode Reward: 1.0\n",
      "Step 296 (232389) @ Episode 947/10000, loss: 0.00045575806871056557\n",
      "Episode Reward: 2.0\n",
      "Step 169 (232558) @ Episode 948/10000, loss: 0.00021494715474545956\n",
      "Episode Reward: 0.0\n",
      "Step 305 (232863) @ Episode 949/10000, loss: 0.00042912337812595078\n",
      "Episode Reward: 2.0\n",
      "Step 161 (233024) @ Episode 950/10000, loss: 0.00013183035480324185\n",
      "Episode Reward: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 17:22:55,160] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video000950.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 184 (233208) @ Episode 951/10000, loss: 0.00090099556837230927\n",
      "Episode Reward: 0.0\n",
      "Step 335 (233543) @ Episode 952/10000, loss: 0.00142958050128072532\n",
      "Episode Reward: 3.0\n",
      "Step 186 (233729) @ Episode 953/10000, loss: 0.00333799910731613645\n",
      "Episode Reward: 0.0\n",
      "Step 181 (233910) @ Episode 954/10000, loss: 0.00086406164336949594\n",
      "Episode Reward: 0.0\n",
      "Step 186 (234096) @ Episode 955/10000, loss: 0.00050535169430077087\n",
      "Episode Reward: 0.0\n",
      "Step 179 (234275) @ Episode 956/10000, loss: 0.00053766561904922134\n",
      "Episode Reward: 0.0\n",
      "Step 303 (234578) @ Episode 957/10000, loss: 0.00023939243692439054\n",
      "Episode Reward: 2.0\n",
      "Step 220 (234798) @ Episode 958/10000, loss: 0.00013519011554308236\n",
      "Episode Reward: 1.0\n",
      "Step 169 (234967) @ Episode 959/10000, loss: 0.00084991287440061574\n",
      "Episode Reward: 0.0\n",
      "Step 276 (235243) @ Episode 960/10000, loss: 0.00056871859123930344\n",
      "Episode Reward: 2.0\n",
      "Step 193 (235436) @ Episode 961/10000, loss: 0.00073785689892247325\n",
      "Episode Reward: 0.0\n",
      "Step 161 (235597) @ Episode 962/10000, loss: 0.00012822510325349867\n",
      "Episode Reward: 0.0\n",
      "Step 275 (235872) @ Episode 963/10000, loss: 0.00032476166961714625\n",
      "Episode Reward: 2.0\n",
      "Step 236 (236108) @ Episode 964/10000, loss: 4.056744000990875e-053\n",
      "Episode Reward: 1.0\n",
      "Step 180 (236288) @ Episode 965/10000, loss: 0.00107435346581041814\n",
      "Episode Reward: 0.0\n",
      "Step 242 (236530) @ Episode 966/10000, loss: 0.00040397551492787915\n",
      "Episode Reward: 1.0\n",
      "Step 188 (236718) @ Episode 967/10000, loss: 0.00085120793664827948\n",
      "Episode Reward: 0.0\n",
      "Step 235 (236953) @ Episode 968/10000, loss: 0.00075310812098905444\n",
      "Episode Reward: 1.0\n",
      "Step 226 (237179) @ Episode 969/10000, loss: 0.00017893491894938052\n",
      "Episode Reward: 1.0\n",
      "Step 290 (237469) @ Episode 970/10000, loss: 0.00047472896403633064\n",
      "Episode Reward: 2.0\n",
      "Step 172 (237641) @ Episode 971/10000, loss: 0.00154812773689627658\n",
      "Episode Reward: 0.0\n",
      "Step 262 (237903) @ Episode 972/10000, loss: 0.00034634332405403256\n",
      "Episode Reward: 2.0\n",
      "Step 174 (238077) @ Episode 973/10000, loss: 7.835947326384485e-053\n",
      "Episode Reward: 0.0\n",
      "Step 173 (238250) @ Episode 974/10000, loss: 0.00102905905805528166\n",
      "Episode Reward: 0.0\n",
      "Step 186 (238436) @ Episode 975/10000, loss: 0.00317105324938893305\n",
      "Episode Reward: 0.0\n",
      "Step 200 (238636) @ Episode 976/10000, loss: 0.00015659081691410393\n",
      "Episode Reward: 1.0\n",
      "Step 220 (238856) @ Episode 977/10000, loss: 0.00077933340799063442\n",
      "Episode Reward: 1.0\n",
      "Step 171 (239027) @ Episode 978/10000, loss: 0.00173637340776622327\n",
      "Episode Reward: 0.0\n",
      "Step 165 (239192) @ Episode 979/10000, loss: 0.00030565250199288137\n",
      "Episode Reward: 0.0\n",
      "Step 230 (239422) @ Episode 980/10000, loss: 0.00019522405636962503\n",
      "Episode Reward: 1.0\n",
      "Step 170 (239592) @ Episode 981/10000, loss: 0.00020481858518905938\n",
      "Episode Reward: 0.0\n",
      "Step 356 (239948) @ Episode 982/10000, loss: 0.00120283639989793376\n",
      "Episode Reward: 3.0\n",
      "Step 51 (239999) @ Episode 983/10000, loss: 0.00059635483194142583\n",
      " Copied model parameters to target network\n",
      "Step 303 (240251) @ Episode 983/10000, loss: 0.00063711486291140328\n",
      "Episode Reward: 2.0\n",
      "Step 253 (240504) @ Episode 984/10000, loss: 0.00158317107707262045\n",
      "Episode Reward: 1.0\n",
      "Step 411 (240915) @ Episode 985/10000, loss: 0.00184844632167369137\n",
      "Episode Reward: 4.0\n",
      "Step 283 (241198) @ Episode 986/10000, loss: 0.00138857855927199137\n",
      "Episode Reward: 2.0\n",
      "Step 388 (241586) @ Episode 987/10000, loss: 0.00148716231342405088\n",
      "Episode Reward: 4.0\n",
      "Step 319 (241905) @ Episode 988/10000, loss: 0.00043720923713408414\n",
      "Episode Reward: 3.0\n",
      "Step 235 (242140) @ Episode 989/10000, loss: 0.00014589684724342078\n",
      "Episode Reward: 1.0\n",
      "Step 411 (242551) @ Episode 990/10000, loss: 0.00021158350864425302\n",
      "Episode Reward: 4.0\n",
      "Step 220 (242771) @ Episode 991/10000, loss: 0.00131568196229636674\n",
      "Episode Reward: 1.0\n",
      "Step 269 (243040) @ Episode 992/10000, loss: 6.985418440308422e-053\n",
      "Episode Reward: 2.0\n",
      "Step 309 (243349) @ Episode 993/10000, loss: 0.00119153189007192858\n",
      "Episode Reward: 2.0\n",
      "Step 159 (243508) @ Episode 994/10000, loss: 0.00035295364796184003\n",
      "Episode Reward: 0.0\n",
      "Step 189 (243697) @ Episode 995/10000, loss: 0.00031827937345951796\n",
      "Episode Reward: 0.0\n",
      "Step 400 (244097) @ Episode 996/10000, loss: 0.00014832335000392056\n",
      "Episode Reward: 4.0\n",
      "Step 164 (244261) @ Episode 997/10000, loss: 9.725473501021042e-056\n",
      "Episode Reward: 0.0\n",
      "Step 470 (244731) @ Episode 998/10000, loss: 0.00036127847852185374\n",
      "Episode Reward: 5.0\n",
      "Step 305 (245036) @ Episode 999/10000, loss: 0.00067028659395873556\n",
      "Episode Reward: 3.0\n",
      "Step 264 (245300) @ Episode 1000/10000, loss: 0.00176057522185146806\n",
      "Episode Reward: 2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 17:24:48,255] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video001000.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 213 (245513) @ Episode 1001/10000, loss: 0.00012105189671274275\n",
      "Episode Reward: 0.0\n",
      "Step 242 (245755) @ Episode 1002/10000, loss: 0.00071939080953598023\n",
      "Episode Reward: 1.0\n",
      "Step 317 (246072) @ Episode 1003/10000, loss: 0.00010782494791783392\n",
      "Episode Reward: 2.0\n",
      "Step 177 (246249) @ Episode 1004/10000, loss: 0.00085658911848440771\n",
      "Episode Reward: 0.0\n",
      "Step 254 (246503) @ Episode 1005/10000, loss: 0.00031361222499981525\n",
      "Episode Reward: 2.0\n",
      "Step 175 (246678) @ Episode 1006/10000, loss: 0.00018233961600344628\n",
      "Episode Reward: 0.0\n",
      "Step 266 (246944) @ Episode 1007/10000, loss: 0.00012048200005665421\n",
      "Episode Reward: 1.0\n",
      "Step 335 (247279) @ Episode 1008/10000, loss: 0.00202202051877975464\n",
      "Episode Reward: 3.0\n",
      "Step 281 (247560) @ Episode 1009/10000, loss: 0.00025720882695168257\n",
      "Episode Reward: 2.0\n",
      "Step 193 (247753) @ Episode 1010/10000, loss: 0.00087110779713839295\n",
      "Episode Reward: 0.0\n",
      "Step 356 (248109) @ Episode 1011/10000, loss: 0.00010800758900586516\n",
      "Episode Reward: 3.0\n",
      "Step 235 (248344) @ Episode 1012/10000, loss: 0.00016304627934005111\n",
      "Episode Reward: 1.0\n",
      "Step 161 (248505) @ Episode 1013/10000, loss: 0.00021122378529980787\n",
      "Episode Reward: 0.0\n",
      "Step 163 (248668) @ Episode 1014/10000, loss: 0.00018117268336936831\n",
      "Episode Reward: 0.0\n",
      "Step 298 (248966) @ Episode 1015/10000, loss: 0.00026871752925217157\n",
      "Episode Reward: 2.0\n",
      "Step 178 (249144) @ Episode 1016/10000, loss: 0.00019033436547033496\n",
      "Episode Reward: 0.0\n",
      "Step 239 (249383) @ Episode 1017/10000, loss: 0.00024008880427572876\n",
      "Episode Reward: 1.0\n",
      "Step 413 (249796) @ Episode 1018/10000, loss: 0.00016492570284754038\n",
      "Episode Reward: 4.0\n",
      "Step 203 (249999) @ Episode 1019/10000, loss: 0.00020434320322237913\n",
      " Copied model parameters to target network\n",
      "Step 335 (250131) @ Episode 1019/10000, loss: 0.00035573102650232613\n",
      "Episode Reward: 3.0\n",
      "Step 327 (250458) @ Episode 1020/10000, loss: 0.00052174174925312455\n",
      "Episode Reward: 3.0\n",
      "Step 167 (250625) @ Episode 1021/10000, loss: 0.00097085628658533146\n",
      "Episode Reward: 0.0\n",
      "Step 172 (250797) @ Episode 1022/10000, loss: 0.00024790957104414703\n",
      "Episode Reward: 0.0\n",
      "Step 390 (251187) @ Episode 1023/10000, loss: 0.00011237878788961098\n",
      "Episode Reward: 4.0\n",
      "Step 186 (251373) @ Episode 1024/10000, loss: 0.00071399478474631914\n",
      "Episode Reward: 0.0\n",
      "Step 249 (251622) @ Episode 1025/10000, loss: 0.00061165506485849626\n",
      "Episode Reward: 1.0\n",
      "Step 239 (251861) @ Episode 1026/10000, loss: 0.00040735193761065667\n",
      "Episode Reward: 1.0\n",
      "Step 181 (252042) @ Episode 1027/10000, loss: 0.00020905521523673087\n",
      "Episode Reward: 0.0\n",
      "Step 274 (252316) @ Episode 1028/10000, loss: 0.00427926983684301457\n",
      "Episode Reward: 2.0\n",
      "Step 232 (252548) @ Episode 1029/10000, loss: 0.00038012591539882123\n",
      "Episode Reward: 1.0\n",
      "Step 175 (252723) @ Episode 1030/10000, loss: 0.00057137355906888844\n",
      "Episode Reward: 0.0\n",
      "Step 170 (252893) @ Episode 1031/10000, loss: 6.084733104216866e-058\n",
      "Episode Reward: 0.0\n",
      "Step 189 (253082) @ Episode 1032/10000, loss: 0.00096304540056735283\n",
      "Episode Reward: 0.0\n",
      "Step 303 (253385) @ Episode 1033/10000, loss: 0.00029093088232912123\n",
      "Episode Reward: 2.0\n",
      "Step 427 (253812) @ Episode 1034/10000, loss: 0.00014995547826401897\n",
      "Episode Reward: 4.0\n",
      "Step 172 (253984) @ Episode 1035/10000, loss: 0.00035746951471082866\n",
      "Episode Reward: 0.0\n",
      "Step 164 (254148) @ Episode 1036/10000, loss: 0.00046136276796460156\n",
      "Episode Reward: 0.0\n",
      "Step 203 (254351) @ Episode 1037/10000, loss: 0.00013802704052068293\n",
      "Episode Reward: 1.0\n",
      "Step 303 (254654) @ Episode 1038/10000, loss: 0.00025473241112194955\n",
      "Episode Reward: 2.0\n",
      "Step 351 (255005) @ Episode 1039/10000, loss: 0.00029820518102496865\n",
      "Episode Reward: 4.0\n",
      "Step 243 (255248) @ Episode 1040/10000, loss: 0.00024345651036128402\n",
      "Episode Reward: 1.0\n",
      "Step 286 (255534) @ Episode 1041/10000, loss: 0.00012036569387419149\n",
      "Episode Reward: 2.0\n",
      "Step 265 (255799) @ Episode 1042/10000, loss: 0.00197423645295202735\n",
      "Episode Reward: 2.0\n",
      "Step 296 (256095) @ Episode 1043/10000, loss: 0.00017610375653021038\n",
      "Episode Reward: 2.0\n",
      "Step 273 (256368) @ Episode 1044/10000, loss: 0.00010096054029418156\n",
      "Episode Reward: 2.0\n",
      "Step 225 (256593) @ Episode 1045/10000, loss: 0.00148475985042750848\n",
      "Episode Reward: 1.0\n",
      "Step 318 (256911) @ Episode 1046/10000, loss: 0.00032396285678260038\n",
      "Episode Reward: 3.0\n",
      "Step 261 (257172) @ Episode 1047/10000, loss: 0.00363939674571156555\n",
      "Episode Reward: 2.0\n",
      "Step 243 (257415) @ Episode 1048/10000, loss: 0.00158123392611742023\n",
      "Episode Reward: 1.0\n",
      "Step 196 (257611) @ Episode 1049/10000, loss: 0.00017092711641453207\n",
      "Episode Reward: 0.0\n",
      "Step 292 (257903) @ Episode 1050/10000, loss: 0.00062361365417018536\n",
      "Episode Reward: 2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 17:26:44,304] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video001050.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 185 (258088) @ Episode 1051/10000, loss: 8.123601583065465e-056\n",
      "Episode Reward: 0.0\n",
      "Step 307 (258395) @ Episode 1052/10000, loss: 0.00060886412393301734\n",
      "Episode Reward: 3.0\n",
      "Step 403 (258798) @ Episode 1053/10000, loss: 0.00042382060200907293\n",
      "Episode Reward: 4.0\n",
      "Step 191 (258989) @ Episode 1054/10000, loss: 0.00019397535652387887\n",
      "Episode Reward: 0.0\n",
      "Step 338 (259327) @ Episode 1055/10000, loss: 0.00047299210564233364\n",
      "Episode Reward: 3.0\n",
      "Step 192 (259519) @ Episode 1056/10000, loss: 0.00011806437396444384\n",
      "Episode Reward: 0.0\n",
      "Step 194 (259713) @ Episode 1057/10000, loss: 0.00025073249707929791\n",
      "Episode Reward: 0.0\n",
      "Step 215 (259928) @ Episode 1058/10000, loss: 0.00028362561715766796\n",
      "Episode Reward: 1.0\n",
      "Step 71 (259999) @ Episode 1059/10000, loss: 0.00296598603017628245\n",
      " Copied model parameters to target network\n",
      "Step 308 (260236) @ Episode 1059/10000, loss: 0.00098099978640675545\n",
      "Episode Reward: 2.0\n",
      "Step 253 (260489) @ Episode 1060/10000, loss: 0.00017817252955865115\n",
      "Episode Reward: 1.0\n",
      "Step 274 (260763) @ Episode 1061/10000, loss: 0.00124557840172201415\n",
      "Episode Reward: 2.0\n",
      "Step 258 (261021) @ Episode 1062/10000, loss: 0.00027340347878634938\n",
      "Episode Reward: 1.0\n",
      "Step 181 (261202) @ Episode 1063/10000, loss: 0.00020309255341999233\n",
      "Episode Reward: 0.0\n",
      "Step 233 (261435) @ Episode 1064/10000, loss: 0.00056765030603855853\n",
      "Episode Reward: 1.0\n",
      "Step 381 (261816) @ Episode 1065/10000, loss: 0.00028167519485577942\n",
      "Episode Reward: 3.0\n",
      "Step 456 (262272) @ Episode 1066/10000, loss: 0.00141796632669866093\n",
      "Episode Reward: 5.0\n",
      "Step 327 (262599) @ Episode 1067/10000, loss: 0.00019767548656091094\n",
      "Episode Reward: 3.0\n",
      "Step 244 (262843) @ Episode 1068/10000, loss: 0.00021236445172689855\n",
      "Episode Reward: 1.0\n",
      "Step 238 (263081) @ Episode 1069/10000, loss: 0.00038716406561434275\n",
      "Episode Reward: 1.0\n",
      "Step 269 (263350) @ Episode 1070/10000, loss: 0.00036261382047086954\n",
      "Episode Reward: 2.0\n",
      "Step 216 (263566) @ Episode 1071/10000, loss: 0.00115394056774675856\n",
      "Episode Reward: 1.0\n",
      "Step 295 (263861) @ Episode 1072/10000, loss: 0.00010151797323487699\n",
      "Episode Reward: 2.0\n",
      "Step 279 (264140) @ Episode 1073/10000, loss: 0.00542761664837598873\n",
      "Episode Reward: 2.0\n",
      "Step 225 (264365) @ Episode 1074/10000, loss: 0.00087730697123333818\n",
      "Episode Reward: 1.0\n",
      "Step 311 (264676) @ Episode 1075/10000, loss: 0.00505212927237153055\n",
      "Episode Reward: 2.0\n",
      "Step 172 (264848) @ Episode 1076/10000, loss: 0.00051069050095975455\n",
      "Episode Reward: 0.0\n",
      "Step 332 (265180) @ Episode 1077/10000, loss: 0.00016267500177491456\n",
      "Episode Reward: 3.0\n",
      "Step 267 (265447) @ Episode 1078/10000, loss: 0.00011667663056869062\n",
      "Episode Reward: 2.0\n",
      "Step 239 (265686) @ Episode 1079/10000, loss: 0.00017986947204917672\n",
      "Episode Reward: 1.0\n",
      "Step 275 (265961) @ Episode 1080/10000, loss: 6.761692930012941e-055\n",
      "Episode Reward: 2.0\n",
      "Step 222 (266183) @ Episode 1081/10000, loss: 0.00290692504495382386\n",
      "Episode Reward: 1.0\n",
      "Step 170 (266353) @ Episode 1082/10000, loss: 2.7295114705339074e-05\n",
      "Episode Reward: 0.0\n",
      "Step 188 (266541) @ Episode 1083/10000, loss: 0.00050847657257691033\n",
      "Episode Reward: 0.0\n",
      "Step 306 (266847) @ Episode 1084/10000, loss: 0.00066480517853051423\n",
      "Episode Reward: 2.0\n",
      "Step 182 (267029) @ Episode 1085/10000, loss: 0.00042154802940785885\n",
      "Episode Reward: 0.0\n",
      "Step 235 (267264) @ Episode 1086/10000, loss: 0.00894087925553321845\n",
      "Episode Reward: 1.0\n",
      "Step 202 (267466) @ Episode 1087/10000, loss: 8.256103319581598e-054\n",
      "Episode Reward: 0.0\n",
      "Step 256 (267722) @ Episode 1088/10000, loss: 0.00042995496187359095\n",
      "Episode Reward: 1.0\n",
      "Step 264 (267986) @ Episode 1089/10000, loss: 0.00033118599094450474\n",
      "Episode Reward: 1.0\n",
      "Step 247 (268233) @ Episode 1090/10000, loss: 0.00044194512884132564\n",
      "Episode Reward: 1.0\n",
      "Step 244 (268477) @ Episode 1091/10000, loss: 0.00014496259973384446\n",
      "Episode Reward: 1.0\n",
      "Step 178 (268655) @ Episode 1092/10000, loss: 0.00032727097277529547\n",
      "Episode Reward: 0.0\n",
      "Step 171 (268826) @ Episode 1093/10000, loss: 0.00025583847309462726\n",
      "Episode Reward: 0.0\n",
      "Step 322 (269148) @ Episode 1094/10000, loss: 0.00654323911294341152\n",
      "Episode Reward: 3.0\n",
      "Step 274 (269422) @ Episode 1095/10000, loss: 0.00023346472880803049\n",
      "Episode Reward: 2.0\n",
      "Step 243 (269665) @ Episode 1096/10000, loss: 0.00018462358275428414\n",
      "Episode Reward: 1.0\n",
      "Step 231 (269896) @ Episode 1097/10000, loss: 0.00029363745125010615\n",
      "Episode Reward: 1.0\n",
      "Step 103 (269999) @ Episode 1098/10000, loss: 0.00140387797728180897\n",
      " Copied model parameters to target network\n",
      "Step 202 (270098) @ Episode 1098/10000, loss: 0.00065668730530887846\n",
      "Episode Reward: 0.0\n",
      "Step 211 (270309) @ Episode 1099/10000, loss: 0.00015637013711966574\n",
      "Episode Reward: 1.0\n",
      "Step 174 (270483) @ Episode 1100/10000, loss: 4.467788676265627e-055\n",
      "Episode Reward: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 17:28:40,551] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video001100.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 231 (270714) @ Episode 1101/10000, loss: 0.00048899766989052354\n",
      "Episode Reward: 1.0\n",
      "Step 309 (271023) @ Episode 1102/10000, loss: 9.107861842494458e-057\n",
      "Episode Reward: 2.0\n",
      "Step 181 (271204) @ Episode 1103/10000, loss: 0.00020489323651418093\n",
      "Episode Reward: 0.0\n",
      "Step 428 (271632) @ Episode 1104/10000, loss: 0.00032761821057647467\n",
      "Episode Reward: 4.0\n",
      "Step 223 (271855) @ Episode 1105/10000, loss: 0.00127341691404581071\n",
      "Episode Reward: 1.0\n",
      "Step 207 (272062) @ Episode 1106/10000, loss: 0.00159010000061243776\n",
      "Episode Reward: 1.0\n",
      "Step 364 (272426) @ Episode 1107/10000, loss: 5.909327228437178e-052\n",
      "Episode Reward: 4.0\n",
      "Step 323 (272749) @ Episode 1108/10000, loss: 0.00026532268384471536\n",
      "Episode Reward: 2.0\n",
      "Step 195 (272944) @ Episode 1109/10000, loss: 0.00221257796511054046\n",
      "Episode Reward: 0.0\n",
      "Step 224 (273168) @ Episode 1110/10000, loss: 0.00041145147406496115\n",
      "Episode Reward: 1.0\n",
      "Step 282 (273450) @ Episode 1111/10000, loss: 0.00461653154343366683\n",
      "Episode Reward: 2.0\n",
      "Step 281 (273731) @ Episode 1112/10000, loss: 0.00037859979784116154\n",
      "Episode Reward: 2.0\n",
      "Step 180 (273911) @ Episode 1113/10000, loss: 0.00010940124775515869\n",
      "Episode Reward: 0.0\n",
      "Step 268 (274179) @ Episode 1114/10000, loss: 0.00927100609987974213\n",
      "Episode Reward: 2.0\n",
      "Step 228 (274407) @ Episode 1115/10000, loss: 0.00014530897897202522\n",
      "Episode Reward: 1.0\n",
      "Step 279 (274686) @ Episode 1116/10000, loss: 0.00050766434287652373\n",
      "Episode Reward: 2.0\n",
      "Step 176 (274862) @ Episode 1117/10000, loss: 0.00024009970366023482\n",
      "Episode Reward: 0.0\n",
      "Step 285 (275147) @ Episode 1118/10000, loss: 0.00312342098914086852\n",
      "Episode Reward: 2.0\n",
      "Step 238 (275385) @ Episode 1119/10000, loss: 0.00019518125918693843\n",
      "Episode Reward: 1.0\n",
      "Step 185 (275570) @ Episode 1120/10000, loss: 0.00034040788887068635\n",
      "Episode Reward: 0.0\n",
      "Step 192 (275762) @ Episode 1121/10000, loss: 5.7100402045762166e-05\n",
      "Episode Reward: 0.0\n",
      "Step 246 (276008) @ Episode 1122/10000, loss: 0.00023946160217747092\n",
      "Episode Reward: 1.0\n",
      "Step 219 (276227) @ Episode 1123/10000, loss: 0.00035684852628037333\n",
      "Episode Reward: 1.0\n",
      "Step 305 (276532) @ Episode 1124/10000, loss: 0.00013497272448148578\n",
      "Episode Reward: 2.0\n",
      "Step 176 (276708) @ Episode 1125/10000, loss: 0.00019956394680775702\n",
      "Episode Reward: 0.0\n",
      "Step 186 (276894) @ Episode 1126/10000, loss: 0.00027635268634185195\n",
      "Episode Reward: 0.0\n",
      "Step 352 (277246) @ Episode 1127/10000, loss: 0.00195924891158938447\n",
      "Episode Reward: 3.0\n",
      "Step 189 (277435) @ Episode 1128/10000, loss: 0.00058968452503904784\n",
      "Episode Reward: 0.0\n",
      "Step 263 (277698) @ Episode 1129/10000, loss: 5.1409617299214005e-05\n",
      "Episode Reward: 2.0\n",
      "Step 250 (277948) @ Episode 1130/10000, loss: 0.00010935871978290379\n",
      "Episode Reward: 1.0\n",
      "Step 292 (278240) @ Episode 1131/10000, loss: 0.00052826758474111567\n",
      "Episode Reward: 2.0\n",
      "Step 223 (278463) @ Episode 1132/10000, loss: 0.00036849066964350647\n",
      "Episode Reward: 1.0\n",
      "Step 192 (278655) @ Episode 1133/10000, loss: 9.743369446368888e-058\n",
      "Episode Reward: 0.0\n",
      "Step 252 (278907) @ Episode 1134/10000, loss: 0.00103452138137072326\n",
      "Episode Reward: 1.0\n",
      "Step 281 (279188) @ Episode 1135/10000, loss: 0.00072725053178146485\n",
      "Episode Reward: 2.0\n",
      "Step 162 (279350) @ Episode 1136/10000, loss: 0.00026734563289210245\n",
      "Episode Reward: 0.0\n",
      "Step 380 (279730) @ Episode 1137/10000, loss: 0.00068830029340460936\n",
      "Episode Reward: 4.0\n",
      "Step 269 (279999) @ Episode 1138/10000, loss: 0.00013026237138547003\n",
      " Copied model parameters to target network\n",
      "Step 326 (280056) @ Episode 1138/10000, loss: 0.00891469139605760626\n",
      "Episode Reward: 3.0\n",
      "Step 314 (280370) @ Episode 1139/10000, loss: 0.00021851672499906272\n",
      "Episode Reward: 3.0\n",
      "Step 332 (280702) @ Episode 1140/10000, loss: 0.00147588597610592843\n",
      "Episode Reward: 3.0\n",
      "Step 300 (281002) @ Episode 1141/10000, loss: 0.00042187035433016727\n",
      "Episode Reward: 2.0\n",
      "Step 327 (281329) @ Episode 1142/10000, loss: 0.00051167607307434086\n",
      "Episode Reward: 3.0\n",
      "Step 262 (281591) @ Episode 1143/10000, loss: 0.00057069433387368926\n",
      "Episode Reward: 1.0\n",
      "Step 261 (281852) @ Episode 1144/10000, loss: 0.00023178683477453887\n",
      "Episode Reward: 2.0\n",
      "Step 336 (282188) @ Episode 1145/10000, loss: 0.00033045731834135952\n",
      "Episode Reward: 3.0\n",
      "Step 281 (282469) @ Episode 1146/10000, loss: 0.00068431976251304154\n",
      "Episode Reward: 2.0\n",
      "Step 227 (282696) @ Episode 1147/10000, loss: 0.00109313987195491824\n",
      "Episode Reward: 1.0\n",
      "Step 252 (282948) @ Episode 1148/10000, loss: 0.00013231276534497738\n",
      "Episode Reward: 1.0\n",
      "Step 242 (283190) @ Episode 1149/10000, loss: 0.00024093007959891114\n",
      "Episode Reward: 1.0\n",
      "Step 247 (283437) @ Episode 1150/10000, loss: 8.288097160402685e-056\n",
      "Episode Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 17:30:39,719] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video001150.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 355 (283792) @ Episode 1151/10000, loss: 0.00063994515221565964\n",
      "Episode Reward: 3.0\n",
      "Step 272 (284064) @ Episode 1152/10000, loss: 0.00113154563587158926\n",
      "Episode Reward: 2.0\n",
      "Step 260 (284324) @ Episode 1153/10000, loss: 0.00041876704199239617\n",
      "Episode Reward: 1.0\n",
      "Step 327 (284651) @ Episode 1154/10000, loss: 0.00074967317050322899\n",
      "Episode Reward: 3.0\n",
      "Step 364 (285015) @ Episode 1155/10000, loss: 0.00169674132484942672\n",
      "Episode Reward: 4.0\n",
      "Step 211 (285226) @ Episode 1156/10000, loss: 0.00108727719634771352\n",
      "Episode Reward: 1.0\n",
      "Step 173 (285399) @ Episode 1157/10000, loss: 0.00020188037888146937\n",
      "Episode Reward: 0.0\n",
      "Step 343 (285742) @ Episode 1158/10000, loss: 0.00014491977344732732\n",
      "Episode Reward: 3.0\n",
      "Step 429 (286171) @ Episode 1159/10000, loss: 0.00025503218057565394\n",
      "Episode Reward: 4.0\n",
      "Step 284 (286455) @ Episode 1160/10000, loss: 0.00194067310076206925\n",
      "Episode Reward: 2.0\n",
      "Step 402 (286857) @ Episode 1161/10000, loss: 0.00016084618982858956\n",
      "Episode Reward: 4.0\n",
      "Step 379 (287236) @ Episode 1162/10000, loss: 0.00016419407620560378\n",
      "Episode Reward: 4.0\n",
      "Step 241 (287477) @ Episode 1163/10000, loss: 0.00026364577934145934\n",
      "Episode Reward: 1.0\n",
      "Step 306 (287783) @ Episode 1164/10000, loss: 0.00062626396538689734\n",
      "Episode Reward: 2.0\n",
      "Step 355 (288138) @ Episode 1165/10000, loss: 0.00391128472983837132\n",
      "Episode Reward: 3.0\n",
      "Step 318 (288456) @ Episode 1166/10000, loss: 0.00032990585896186538\n",
      "Episode Reward: 2.0\n",
      "Step 398 (288854) @ Episode 1167/10000, loss: 0.00072356138844043026\n",
      "Episode Reward: 4.0\n",
      "Step 187 (289041) @ Episode 1168/10000, loss: 0.00149646727368235592\n",
      "Episode Reward: 0.0\n",
      "Step 221 (289262) @ Episode 1169/10000, loss: 0.00036930839996784925\n",
      "Episode Reward: 1.0\n",
      "Step 165 (289427) @ Episode 1170/10000, loss: 0.00014768396795261651\n",
      "Episode Reward: 0.0\n",
      "Step 220 (289647) @ Episode 1171/10000, loss: 0.00035467758425511425\n",
      "Episode Reward: 1.0\n",
      "Step 294 (289941) @ Episode 1172/10000, loss: 0.00029411647119559353\n",
      "Episode Reward: 2.0\n",
      "Step 58 (289999) @ Episode 1173/10000, loss: 0.00210795411840081255\n",
      " Copied model parameters to target network\n",
      "Step 288 (290229) @ Episode 1173/10000, loss: 0.00503080850467085815\n",
      "Episode Reward: 2.0\n",
      "Step 254 (290483) @ Episode 1174/10000, loss: 0.00137434515636414396\n",
      "Episode Reward: 1.0\n",
      "Step 184 (290667) @ Episode 1175/10000, loss: 0.00578936561942100533\n",
      "Episode Reward: 0.0\n",
      "Step 160 (290827) @ Episode 1176/10000, loss: 0.00270385597832500934\n",
      "Episode Reward: 0.0\n",
      "Step 194 (291021) @ Episode 1177/10000, loss: 0.00015987035294529055\n",
      "Episode Reward: 0.0\n",
      "Step 338 (291359) @ Episode 1178/10000, loss: 0.00017275722348131242\n",
      "Episode Reward: 3.0\n",
      "Step 182 (291541) @ Episode 1179/10000, loss: 0.00017286231741309166\n",
      "Episode Reward: 0.0\n",
      "Step 190 (291731) @ Episode 1180/10000, loss: 0.00175245082937181019\n",
      "Episode Reward: 0.0\n",
      "Step 198 (291929) @ Episode 1181/10000, loss: 0.00252525229007005765\n",
      "Episode Reward: 0.0\n",
      "Step 249 (292178) @ Episode 1182/10000, loss: 9.865603351499885e-053\n",
      "Episode Reward: 1.0\n",
      "Step 250 (292428) @ Episode 1183/10000, loss: 0.00443034851923584966\n",
      "Episode Reward: 1.0\n",
      "Step 367 (292795) @ Episode 1184/10000, loss: 0.00027429472538642585\n",
      "Episode Reward: 4.0\n",
      "Step 187 (292982) @ Episode 1185/10000, loss: 6.740437675034627e-057\n",
      "Episode Reward: 0.0\n",
      "Step 206 (293188) @ Episode 1186/10000, loss: 0.00077697087544947864\n",
      "Episode Reward: 1.0\n",
      "Step 226 (293414) @ Episode 1187/10000, loss: 0.00039508272311650217\n",
      "Episode Reward: 1.0\n",
      "Step 292 (293706) @ Episode 1188/10000, loss: 0.00046607409603893757\n",
      "Episode Reward: 2.0\n",
      "Step 291 (293997) @ Episode 1189/10000, loss: 0.00025906364317052066\n",
      "Episode Reward: 2.0\n",
      "Step 281 (294278) @ Episode 1190/10000, loss: 0.00375561439432203775\n",
      "Episode Reward: 2.0\n",
      "Step 293 (294571) @ Episode 1191/10000, loss: 0.00016520617646165192\n",
      "Episode Reward: 2.0\n",
      "Step 278 (294849) @ Episode 1192/10000, loss: 0.00046603468945249915\n",
      "Episode Reward: 2.0\n",
      "Step 254 (295103) @ Episode 1193/10000, loss: 0.00053178332746028973\n",
      "Episode Reward: 1.0\n",
      "Step 377 (295480) @ Episode 1194/10000, loss: 0.00070117088034749036\n",
      "Episode Reward: 4.0\n",
      "Step 583 (296063) @ Episode 1195/10000, loss: 0.00031333736842498183\n",
      "Episode Reward: 9.0\n",
      "Step 237 (296300) @ Episode 1196/10000, loss: 0.00273810466751456265\n",
      "Episode Reward: 1.0\n",
      "Step 268 (296568) @ Episode 1197/10000, loss: 0.00420848280191421556\n",
      "Episode Reward: 2.0\n",
      "Step 302 (296870) @ Episode 1198/10000, loss: 6.973514246055856e-058\n",
      "Episode Reward: 3.0\n",
      "Step 341 (297211) @ Episode 1199/10000, loss: 0.00032796297455206513\n",
      "Episode Reward: 3.0\n",
      "Step 210 (297421) @ Episode 1200/10000, loss: 0.00021433254005387425\n",
      "Episode Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 17:32:49,340] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video001200.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 235 (297656) @ Episode 1201/10000, loss: 0.00031521407072432346\n",
      "Episode Reward: 1.0\n",
      "Step 225 (297881) @ Episode 1202/10000, loss: 0.00044732572860084474\n",
      "Episode Reward: 1.0\n",
      "Step 222 (298103) @ Episode 1203/10000, loss: 0.00022781889128964394\n",
      "Episode Reward: 0.0\n",
      "Step 243 (298346) @ Episode 1204/10000, loss: 0.00211378559470176722\n",
      "Episode Reward: 1.0\n",
      "Step 237 (298583) @ Episode 1205/10000, loss: 0.00021093280520290136\n",
      "Episode Reward: 1.0\n",
      "Step 298 (298881) @ Episode 1206/10000, loss: 9.318927914137021e-053\n",
      "Episode Reward: 2.0\n",
      "Step 223 (299104) @ Episode 1207/10000, loss: 0.00068958057090640076\n",
      "Episode Reward: 1.0\n",
      "Step 340 (299444) @ Episode 1208/10000, loss: 0.00187641347292810686\n",
      "Episode Reward: 3.0\n",
      "Step 244 (299688) @ Episode 1209/10000, loss: 0.00046034634578973055\n",
      "Episode Reward: 1.0\n",
      "Step 309 (299997) @ Episode 1210/10000, loss: 0.00038762562326155603\n",
      "Episode Reward: 2.0\n",
      "Step 2 (299999) @ Episode 1211/10000, loss: 0.0003385043819434941\n",
      " Copied model parameters to target network\n",
      "Step 280 (300277) @ Episode 1211/10000, loss: 0.00058628310216590768\n",
      "Episode Reward: 2.0\n",
      "Step 311 (300588) @ Episode 1212/10000, loss: 0.00017392827430741327\n",
      "Episode Reward: 2.0\n",
      "Step 282 (300870) @ Episode 1213/10000, loss: 0.00046517353621311486\n",
      "Episode Reward: 2.0\n",
      "Step 322 (301192) @ Episode 1214/10000, loss: 0.00030221443739719698\n",
      "Episode Reward: 2.0\n",
      "Step 174 (301366) @ Episode 1215/10000, loss: 0.00015625107334926724\n",
      "Episode Reward: 0.0\n",
      "Step 286 (301652) @ Episode 1216/10000, loss: 0.00067252333974465738\n",
      "Episode Reward: 2.0\n",
      "Step 348 (302000) @ Episode 1217/10000, loss: 0.00482086185365915355\n",
      "Episode Reward: 3.0\n",
      "Step 263 (302263) @ Episode 1218/10000, loss: 0.00026762741617858417\n",
      "Episode Reward: 1.0\n",
      "Step 171 (302434) @ Episode 1219/10000, loss: 0.00284862075932323934\n",
      "Episode Reward: 0.0\n",
      "Step 353 (302787) @ Episode 1220/10000, loss: 0.00707107735797762948\n",
      "Episode Reward: 3.0\n",
      "Step 287 (303074) @ Episode 1221/10000, loss: 6.403469888027757e-057\n",
      "Episode Reward: 2.0\n",
      "Step 316 (303390) @ Episode 1222/10000, loss: 0.00134328764397650968\n",
      "Episode Reward: 2.0\n",
      "Step 243 (303633) @ Episode 1223/10000, loss: 0.00215257680974900723\n",
      "Episode Reward: 2.0\n",
      "Step 423 (304056) @ Episode 1224/10000, loss: 0.00650880346074700362\n",
      "Episode Reward: 4.0\n",
      "Step 223 (304279) @ Episode 1225/10000, loss: 0.00085644738283008348\n",
      "Episode Reward: 1.0\n",
      "Step 401 (304680) @ Episode 1226/10000, loss: 0.00021532313257921487\n",
      "Episode Reward: 3.0\n",
      "Step 291 (304971) @ Episode 1227/10000, loss: 0.00012822530698031187\n",
      "Episode Reward: 2.0\n",
      "Step 449 (305420) @ Episode 1228/10000, loss: 0.00102657254319638012\n",
      "Episode Reward: 5.0\n",
      "Step 228 (305648) @ Episode 1229/10000, loss: 0.00022298120893537998\n",
      "Episode Reward: 1.0\n",
      "Step 180 (305828) @ Episode 1230/10000, loss: 0.00023281201720237732\n",
      "Episode Reward: 0.0\n",
      "Step 315 (306143) @ Episode 1231/10000, loss: 0.00121012178715318442\n",
      "Episode Reward: 3.0\n",
      "Step 177 (306320) @ Episode 1232/10000, loss: 0.00027970850351266563\n",
      "Episode Reward: 0.0\n",
      "Step 278 (306598) @ Episode 1233/10000, loss: 0.00056494167074561123\n",
      "Episode Reward: 2.0\n",
      "Step 291 (306889) @ Episode 1234/10000, loss: 0.00021493734675459564\n",
      "Episode Reward: 2.0\n",
      "Step 267 (307156) @ Episode 1235/10000, loss: 0.00102527905255556174\n",
      "Episode Reward: 2.0\n",
      "Step 190 (307346) @ Episode 1236/10000, loss: 0.00101914908736944287\n",
      "Episode Reward: 0.0\n",
      "Step 388 (307734) @ Episode 1237/10000, loss: 0.00031488461536355317\n",
      "Episode Reward: 4.0\n",
      "Step 237 (307971) @ Episode 1238/10000, loss: 0.00011300167534500361\n",
      "Episode Reward: 2.0\n",
      "Step 234 (308205) @ Episode 1239/10000, loss: 0.00011216226266697049\n",
      "Episode Reward: 1.0\n",
      "Step 244 (308449) @ Episode 1240/10000, loss: 0.00111432292032986885\n",
      "Episode Reward: 1.0\n",
      "Step 309 (308758) @ Episode 1241/10000, loss: 0.00192656309809535747\n",
      "Episode Reward: 2.0\n",
      "Step 209 (308967) @ Episode 1242/10000, loss: 0.00031710829352959995\n",
      "Episode Reward: 1.0\n",
      "Step 215 (309182) @ Episode 1243/10000, loss: 0.00106210296507924815\n",
      "Episode Reward: 1.0\n",
      "Step 270 (309452) @ Episode 1244/10000, loss: 0.00086876889690756853\n",
      "Episode Reward: 2.0\n",
      "Step 206 (309658) @ Episode 1245/10000, loss: 0.00026306704967282716\n",
      "Episode Reward: 0.0\n",
      "Step 334 (309992) @ Episode 1246/10000, loss: 6.4149106037803e-05171\n",
      "Episode Reward: 3.0\n",
      "Step 7 (309999) @ Episode 1247/10000, loss: 0.00119569688104093074\n",
      " Copied model parameters to target network\n",
      "Step 174 (310166) @ Episode 1247/10000, loss: 0.00092782848514616495\n",
      "Episode Reward: 0.0\n",
      "Step 286 (310452) @ Episode 1248/10000, loss: 0.00181210169102996598\n",
      "Episode Reward: 2.0\n",
      "Step 172 (310624) @ Episode 1249/10000, loss: 0.00304471282288432166\n",
      "Episode Reward: 0.0\n",
      "Step 315 (310939) @ Episode 1250/10000, loss: 0.01382336858659982763\n",
      "Episode Reward: 2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 17:34:53,757] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video001250.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 183 (311122) @ Episode 1251/10000, loss: 0.00100531789939850577\n",
      "Episode Reward: 0.0\n",
      "Step 272 (311394) @ Episode 1252/10000, loss: 0.00193608645349740987\n",
      "Episode Reward: 2.0\n",
      "Step 221 (311615) @ Episode 1253/10000, loss: 0.00039821868995204574\n",
      "Episode Reward: 1.0\n",
      "Step 319 (311934) @ Episode 1254/10000, loss: 0.00140383373945951462\n",
      "Episode Reward: 2.0\n",
      "Step 388 (312322) @ Episode 1255/10000, loss: 0.00215642852708697326\n",
      "Episode Reward: 4.0\n",
      "Step 430 (312752) @ Episode 1256/10000, loss: 0.00055556511506438265\n",
      "Episode Reward: 5.0\n",
      "Step 502 (313254) @ Episode 1257/10000, loss: 0.00058506045024842023\n",
      "Episode Reward: 5.0\n",
      "Step 348 (313602) @ Episode 1258/10000, loss: 0.00136604614090174444\n",
      "Episode Reward: 3.0\n",
      "Step 258 (313860) @ Episode 1259/10000, loss: 0.00024880334967747335\n",
      "Episode Reward: 1.0\n",
      "Step 212 (314072) @ Episode 1260/10000, loss: 0.00025177441420964897\n",
      "Episode Reward: 0.0\n",
      "Step 161 (314233) @ Episode 1261/10000, loss: 0.00023726522340439262\n",
      "Episode Reward: 0.0\n",
      "Step 298 (314531) @ Episode 1262/10000, loss: 0.00144321261905133727\n",
      "Episode Reward: 2.0\n",
      "Step 411 (314942) @ Episode 1263/10000, loss: 0.00053679780103266244\n",
      "Episode Reward: 4.0\n",
      "Step 240 (315182) @ Episode 1264/10000, loss: 0.00163464271463453776\n",
      "Episode Reward: 1.0\n",
      "Step 165 (315347) @ Episode 1265/10000, loss: 0.00049609935376793157\n",
      "Episode Reward: 0.0\n",
      "Step 210 (315557) @ Episode 1266/10000, loss: 0.00042145431507378817\n",
      "Episode Reward: 1.0\n",
      "Step 299 (315856) @ Episode 1267/10000, loss: 0.00149163010064512567\n",
      "Episode Reward: 2.0\n",
      "Step 427 (316283) @ Episode 1268/10000, loss: 0.00060793390730395918\n",
      "Episode Reward: 5.0\n",
      "Step 191 (316474) @ Episode 1269/10000, loss: 0.00012440093269106051\n",
      "Episode Reward: 0.0\n",
      "Step 455 (316929) @ Episode 1270/10000, loss: 0.00064115028362721263\n",
      "Episode Reward: 5.0\n",
      "Step 275 (317204) @ Episode 1271/10000, loss: 0.00019842402252834294\n",
      "Episode Reward: 2.0\n",
      "Step 392 (317596) @ Episode 1272/10000, loss: 9.476720151724294e-054\n",
      "Episode Reward: 4.0\n",
      "Step 236 (317832) @ Episode 1273/10000, loss: 0.00019130806322209537\n",
      "Episode Reward: 1.0\n",
      "Step 310 (318142) @ Episode 1274/10000, loss: 0.00280734547413885674\n",
      "Episode Reward: 3.0\n",
      "Step 182 (318324) @ Episode 1275/10000, loss: 0.00152074068319052463\n",
      "Episode Reward: 0.0\n",
      "Step 299 (318623) @ Episode 1276/10000, loss: 0.00089810317149385814\n",
      "Episode Reward: 2.0\n",
      "Step 322 (318945) @ Episode 1277/10000, loss: 0.00025441867182962596\n",
      "Episode Reward: 2.0\n",
      "Step 171 (319116) @ Episode 1278/10000, loss: 0.00299372104927897457\n",
      "Episode Reward: 0.0\n",
      "Step 337 (319453) @ Episode 1279/10000, loss: 0.00360313849523663554\n",
      "Episode Reward: 3.0\n",
      "Step 277 (319730) @ Episode 1280/10000, loss: 0.00027101134764961955\n",
      "Episode Reward: 2.0\n",
      "Step 269 (319999) @ Episode 1281/10000, loss: 0.00014855620975140482\n",
      " Copied model parameters to target network\n",
      "Step 354 (320084) @ Episode 1281/10000, loss: 0.00037207844434306026\n",
      "Episode Reward: 3.0\n",
      "Step 230 (320314) @ Episode 1282/10000, loss: 0.00251524685882031922\n",
      "Episode Reward: 1.0\n",
      "Step 275 (320589) @ Episode 1283/10000, loss: 0.00032946220017038286\n",
      "Episode Reward: 1.0\n",
      "Step 297 (320886) @ Episode 1284/10000, loss: 0.00018635604646988213\n",
      "Episode Reward: 2.0\n",
      "Step 316 (321202) @ Episode 1285/10000, loss: 0.00055926782079041306\n",
      "Episode Reward: 3.0\n",
      "Step 265 (321467) @ Episode 1286/10000, loss: 0.00014325637312140316\n",
      "Episode Reward: 2.0\n",
      "Step 339 (321806) @ Episode 1287/10000, loss: 0.01337656099349260314\n",
      "Episode Reward: 3.0\n",
      "Step 277 (322083) @ Episode 1288/10000, loss: 9.434740786673501e-054\n",
      "Episode Reward: 2.0\n",
      "Step 388 (322471) @ Episode 1289/10000, loss: 0.00049879634752869615\n",
      "Episode Reward: 4.0\n",
      "Step 215 (322686) @ Episode 1290/10000, loss: 0.00036138843279331927\n",
      "Episode Reward: 0.0\n",
      "Step 246 (322932) @ Episode 1291/10000, loss: 0.00238972599618136984\n",
      "Episode Reward: 2.0\n",
      "Step 281 (323213) @ Episode 1292/10000, loss: 0.00090778223238885415\n",
      "Episode Reward: 2.0\n",
      "Step 235 (323448) @ Episode 1293/10000, loss: 0.00051858241204172375\n",
      "Episode Reward: 1.0\n",
      "Step 245 (323693) @ Episode 1294/10000, loss: 0.00061695009935647253\n",
      "Episode Reward: 1.0\n",
      "Step 349 (324042) @ Episode 1295/10000, loss: 0.00088554609101265676\n",
      "Episode Reward: 3.0\n",
      "Step 222 (324264) @ Episode 1296/10000, loss: 0.00100407307036221034\n",
      "Episode Reward: 1.0\n",
      "Step 280 (324544) @ Episode 1297/10000, loss: 0.00028041703626513485\n",
      "Episode Reward: 1.0\n",
      "Step 255 (324799) @ Episode 1298/10000, loss: 0.00046344814472831786\n",
      "Episode Reward: 1.0\n",
      "Step 273 (325072) @ Episode 1299/10000, loss: 0.00041259473073296256\n",
      "Episode Reward: 1.0\n",
      "Step 183 (325255) @ Episode 1300/10000, loss: 0.00034035029239021244\n",
      "Episode Reward: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 17:37:05,398] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video001300.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 220 (325475) @ Episode 1301/10000, loss: 0.00111790047958493234\n",
      "Episode Reward: 0.0\n",
      "Step 262 (325737) @ Episode 1302/10000, loss: 0.00020900524395983666\n",
      "Episode Reward: 2.0\n",
      "Step 212 (325949) @ Episode 1303/10000, loss: 0.00114345108158886433\n",
      "Episode Reward: 1.0\n",
      "Step 366 (326315) @ Episode 1304/10000, loss: 0.00076543173054233195\n",
      "Episode Reward: 3.0\n",
      "Step 314 (326629) @ Episode 1305/10000, loss: 0.00064041384030133496\n",
      "Episode Reward: 2.0\n",
      "Step 174 (326803) @ Episode 1306/10000, loss: 0.00110202503856271545\n",
      "Episode Reward: 0.0\n",
      "Step 198 (327001) @ Episode 1307/10000, loss: 0.00042333159944973886\n",
      "Episode Reward: 0.0\n",
      "Step 347 (327348) @ Episode 1308/10000, loss: 0.00092895410489290955\n",
      "Episode Reward: 3.0\n",
      "Step 208 (327556) @ Episode 1309/10000, loss: 0.00025470688706263953\n",
      "Episode Reward: 1.0\n",
      "Step 170 (327726) @ Episode 1310/10000, loss: 0.00045083274017088115\n",
      "Episode Reward: 0.0\n",
      "Step 208 (327934) @ Episode 1311/10000, loss: 0.00029093917692080148\n",
      "Episode Reward: 0.0\n",
      "Step 266 (328200) @ Episode 1312/10000, loss: 0.00084701500600203876\n",
      "Episode Reward: 2.0\n",
      "Step 277 (328477) @ Episode 1313/10000, loss: 0.00095321837579831486\n",
      "Episode Reward: 2.0\n",
      "Step 249 (328726) @ Episode 1314/10000, loss: 0.00030936062103137374\n",
      "Episode Reward: 1.0\n",
      "Step 226 (328952) @ Episode 1315/10000, loss: 0.00097997509874403486\n",
      "Episode Reward: 1.0\n",
      "Step 234 (329186) @ Episode 1316/10000, loss: 0.00117417564615607267\n",
      "Episode Reward: 1.0\n",
      "Step 365 (329551) @ Episode 1317/10000, loss: 0.00174271105788648133\n",
      "Episode Reward: 4.0\n",
      "Step 230 (329781) @ Episode 1318/10000, loss: 0.00064104096964001667\n",
      "Episode Reward: 1.0\n",
      "Step 180 (329961) @ Episode 1319/10000, loss: 0.00025101439678110184\n",
      "Episode Reward: 0.0\n",
      "Step 38 (329999) @ Episode 1320/10000, loss: 0.00244931643828749663\n",
      " Copied model parameters to target network\n",
      "Step 409 (330370) @ Episode 1320/10000, loss: 0.00086825940525159244\n",
      "Episode Reward: 4.0\n",
      "Step 335 (330705) @ Episode 1321/10000, loss: 0.00063864549156278376\n",
      "Episode Reward: 2.0\n",
      "Step 181 (330886) @ Episode 1322/10000, loss: 0.00048938282998278748\n",
      "Episode Reward: 0.0\n",
      "Step 258 (331144) @ Episode 1323/10000, loss: 0.00047442637151107194\n",
      "Episode Reward: 1.0\n",
      "Step 294 (331438) @ Episode 1324/10000, loss: 0.00402029929682612474\n",
      "Episode Reward: 2.0\n",
      "Step 297 (331735) @ Episode 1325/10000, loss: 0.00099567207507789136\n",
      "Episode Reward: 1.0\n",
      "Step 251 (331986) @ Episode 1326/10000, loss: 0.00041496264748275287\n",
      "Episode Reward: 1.0\n",
      "Step 211 (332197) @ Episode 1327/10000, loss: 0.00346544478088617327\n",
      "Episode Reward: 1.0\n",
      "Step 441 (332638) @ Episode 1328/10000, loss: 0.00026850771973840897\n",
      "Episode Reward: 4.0\n",
      "Step 283 (332921) @ Episode 1329/10000, loss: 0.00043479449232108896\n",
      "Episode Reward: 2.0\n",
      "Step 213 (333134) @ Episode 1330/10000, loss: 0.00067520834272727376\n",
      "Episode Reward: 0.0\n",
      "Step 220 (333354) @ Episode 1331/10000, loss: 0.00013504346134141088\n",
      "Episode Reward: 1.0\n",
      "Step 281 (333635) @ Episode 1332/10000, loss: 0.00066048005828633932\n",
      "Episode Reward: 2.0\n",
      "Step 274 (333909) @ Episode 1333/10000, loss: 0.00104486581403762113\n",
      "Episode Reward: 2.0\n",
      "Step 201 (334110) @ Episode 1334/10000, loss: 0.00326345721259713176\n",
      "Episode Reward: 1.0\n",
      "Step 333 (334443) @ Episode 1335/10000, loss: 0.00110059417784214026\n",
      "Episode Reward: 3.0\n",
      "Step 282 (334725) @ Episode 1336/10000, loss: 0.00298322900198403956\n",
      "Episode Reward: 2.0\n",
      "Step 269 (334994) @ Episode 1337/10000, loss: 0.00368047459051013394\n",
      "Episode Reward: 2.0\n",
      "Step 347 (335341) @ Episode 1338/10000, loss: 0.00126459391321986913\n",
      "Episode Reward: 3.0\n",
      "Step 405 (335746) @ Episode 1339/10000, loss: 0.00047041341895237565\n",
      "Episode Reward: 4.0\n",
      "Step 357 (336103) @ Episode 1340/10000, loss: 0.00093466107500717042\n",
      "Episode Reward: 3.0\n",
      "Step 246 (336349) @ Episode 1341/10000, loss: 0.00061713776085525752\n",
      "Episode Reward: 1.0\n",
      "Step 276 (336625) @ Episode 1342/10000, loss: 0.00287059484981000425\n",
      "Episode Reward: 2.0\n",
      "Step 249 (336874) @ Episode 1343/10000, loss: 0.00017847523849923164\n",
      "Episode Reward: 1.0\n",
      "Step 222 (337096) @ Episode 1344/10000, loss: 0.00023712476831860845\n",
      "Episode Reward: 1.0\n",
      "Step 362 (337458) @ Episode 1345/10000, loss: 0.00016384193440899253\n",
      "Episode Reward: 3.0\n",
      "Step 451 (337909) @ Episode 1346/10000, loss: 0.00109433941543102268\n",
      "Episode Reward: 4.0\n",
      "Step 217 (338126) @ Episode 1347/10000, loss: 0.00115310132969170863\n",
      "Episode Reward: 1.0\n",
      "Step 542 (338668) @ Episode 1348/10000, loss: 0.10879918187856674433\n",
      "Episode Reward: 6.0\n",
      "Step 300 (338968) @ Episode 1349/10000, loss: 0.00041881180368363857\n",
      "Episode Reward: 3.0\n",
      "Step 380 (339348) @ Episode 1350/10000, loss: 0.00427759811282157987\n",
      "Episode Reward: 4.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 17:39:13,000] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video001350.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 372 (339720) @ Episode 1351/10000, loss: 0.00062192021869122987\n",
      "Episode Reward: 3.0\n",
      "Step 279 (339999) @ Episode 1352/10000, loss: 0.00435321405529975987\n",
      " Copied model parameters to target network\n",
      "Step 351 (340071) @ Episode 1352/10000, loss: 0.00784769933670759253\n",
      "Episode Reward: 4.0\n",
      "Step 429 (340500) @ Episode 1353/10000, loss: 0.00048759146011434495\n",
      "Episode Reward: 5.0\n",
      "Step 459 (340959) @ Episode 1354/10000, loss: 0.00305023021064698755\n",
      "Episode Reward: 5.0\n",
      "Step 356 (341315) @ Episode 1355/10000, loss: 0.00055770663311704994\n",
      "Episode Reward: 3.0\n",
      "Step 343 (341658) @ Episode 1356/10000, loss: 0.00164159806445240973\n",
      "Episode Reward: 3.0\n",
      "Step 457 (342115) @ Episode 1357/10000, loss: 0.00023026371491141617\n",
      "Episode Reward: 5.0\n",
      "Step 226 (342341) @ Episode 1358/10000, loss: 0.00095352064818143847\n",
      "Episode Reward: 1.0\n",
      "Step 345 (342686) @ Episode 1359/10000, loss: 0.00016612434410490096\n",
      "Episode Reward: 3.0\n",
      "Step 567 (343253) @ Episode 1360/10000, loss: 0.00068097439361736188\n",
      "Episode Reward: 7.0\n",
      "Step 302 (343555) @ Episode 1361/10000, loss: 0.00382590875960886566\n",
      "Episode Reward: 2.0\n",
      "Step 388 (343943) @ Episode 1362/10000, loss: 0.00299870641902089187\n",
      "Episode Reward: 3.0\n",
      "Step 230 (344173) @ Episode 1363/10000, loss: 0.00055773725034669047\n",
      "Episode Reward: 1.0\n",
      "Step 381 (344554) @ Episode 1364/10000, loss: 0.00220333784818649325\n",
      "Episode Reward: 3.0\n",
      "Step 321 (344875) @ Episode 1365/10000, loss: 0.00093603727873414755\n",
      "Episode Reward: 3.0\n",
      "Step 323 (345198) @ Episode 1366/10000, loss: 0.00727099087089300168\n",
      "Episode Reward: 3.0\n",
      "Step 316 (345514) @ Episode 1367/10000, loss: 0.00119773182086646567\n",
      "Episode Reward: 2.0\n",
      "Step 314 (345828) @ Episode 1368/10000, loss: 0.00116447336040437224\n",
      "Episode Reward: 3.0\n",
      "Step 244 (346072) @ Episode 1369/10000, loss: 0.00074399827281013132\n",
      "Episode Reward: 2.0\n",
      "Step 285 (346357) @ Episode 1370/10000, loss: 0.00153918052092194567\n",
      "Episode Reward: 2.0\n",
      "Step 313 (346670) @ Episode 1371/10000, loss: 0.00021904231107328087\n",
      "Episode Reward: 3.0\n",
      "Step 263 (346933) @ Episode 1372/10000, loss: 0.00064574595307931396\n",
      "Episode Reward: 2.0\n",
      "Step 376 (347309) @ Episode 1373/10000, loss: 0.00067472551017999654\n",
      "Episode Reward: 4.0\n",
      "Step 254 (347563) @ Episode 1374/10000, loss: 0.00036051945062354207\n",
      "Episode Reward: 2.0\n",
      "Step 447 (348010) @ Episode 1375/10000, loss: 0.00016068690456449986\n",
      "Episode Reward: 5.0\n",
      "Step 322 (348332) @ Episode 1376/10000, loss: 0.00055407523177564144\n",
      "Episode Reward: 3.0\n",
      "Step 248 (348580) @ Episode 1377/10000, loss: 0.00339470850303769145\n",
      "Episode Reward: 1.0\n",
      "Step 352 (348932) @ Episode 1378/10000, loss: 0.00060077477246522998\n",
      "Episode Reward: 3.0\n",
      "Step 348 (349280) @ Episode 1379/10000, loss: 0.00172355631366372154\n",
      "Episode Reward: 3.0\n",
      "Step 250 (349530) @ Episode 1380/10000, loss: 0.00073783373227342967\n",
      "Episode Reward: 2.0\n",
      "Step 395 (349925) @ Episode 1381/10000, loss: 0.00135419645812362437\n",
      "Episode Reward: 4.0\n",
      "Step 74 (349999) @ Episode 1382/10000, loss: 0.00030600372701883316\n",
      " Copied model parameters to target network\n",
      "Step 277 (350202) @ Episode 1382/10000, loss: 0.00777747947722673427\n",
      "Episode Reward: 2.0\n",
      "Step 355 (350557) @ Episode 1383/10000, loss: 0.00025072251446545124\n",
      "Episode Reward: 3.0\n",
      "Step 216 (350773) @ Episode 1384/10000, loss: 0.00047055413597263396\n",
      "Episode Reward: 1.0\n",
      "Step 471 (351244) @ Episode 1385/10000, loss: 0.00115774886216968315\n",
      "Episode Reward: 5.0\n",
      "Step 354 (351598) @ Episode 1386/10000, loss: 0.00044623640133067966\n",
      "Episode Reward: 3.0\n",
      "Step 287 (351885) @ Episode 1387/10000, loss: 0.00054374401224777148\n",
      "Episode Reward: 2.0\n",
      "Step 287 (352172) @ Episode 1388/10000, loss: 0.00135042727924883377\n",
      "Episode Reward: 2.0\n",
      "Step 225 (352397) @ Episode 1389/10000, loss: 0.00370307592675089847\n",
      "Episode Reward: 1.0\n",
      "Step 350 (352747) @ Episode 1390/10000, loss: 0.00035491661401465535\n",
      "Episode Reward: 3.0\n",
      "Step 472 (353219) @ Episode 1391/10000, loss: 0.00296662305481731986\n",
      "Episode Reward: 5.0\n",
      "Step 372 (353591) @ Episode 1392/10000, loss: 0.00011076994269387797\n",
      "Episode Reward: 4.0\n",
      "Step 406 (353997) @ Episode 1393/10000, loss: 0.00034258860978297895\n",
      "Episode Reward: 5.0\n",
      "Step 249 (354246) @ Episode 1394/10000, loss: 0.00036301053478382536\n",
      "Episode Reward: 2.0\n",
      "Step 385 (354631) @ Episode 1395/10000, loss: 0.00181092030834406616\n",
      "Episode Reward: 4.0\n",
      "Step 452 (355083) @ Episode 1396/10000, loss: 0.00287701701745390964\n",
      "Episode Reward: 5.0\n",
      "Step 602 (355685) @ Episode 1397/10000, loss: 0.00010959927749354392\n",
      "Episode Reward: 7.0\n",
      "Step 379 (356064) @ Episode 1398/10000, loss: 0.00141713023185729986\n",
      "Episode Reward: 3.0\n",
      "Step 435 (356499) @ Episode 1399/10000, loss: 0.00057174894027411946\n",
      "Episode Reward: 5.0\n",
      "Step 517 (357016) @ Episode 1400/10000, loss: 0.00023440990480594337\n",
      "Episode Reward: 6.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 17:41:51,083] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video001400.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 350 (357366) @ Episode 1401/10000, loss: 0.00081971869803965095\n",
      "Episode Reward: 3.0\n",
      "Step 382 (357748) @ Episode 1402/10000, loss: 0.00030419169343076646\n",
      "Episode Reward: 4.0\n",
      "Step 320 (358068) @ Episode 1403/10000, loss: 0.00087926606647670272\n",
      "Episode Reward: 3.0\n",
      "Step 270 (358338) @ Episode 1404/10000, loss: 0.00078485545236617334\n",
      "Episode Reward: 2.0\n",
      "Step 477 (358815) @ Episode 1405/10000, loss: 0.00045872016926296055\n",
      "Episode Reward: 5.0\n",
      "Step 426 (359241) @ Episode 1406/10000, loss: 0.00055410107597708716\n",
      "Episode Reward: 5.0\n",
      "Step 421 (359662) @ Episode 1407/10000, loss: 0.00312338164076209073\n",
      "Episode Reward: 5.0\n",
      "Step 337 (359999) @ Episode 1408/10000, loss: 0.00056761724408715964\n",
      " Copied model parameters to target network\n",
      "Step 412 (360074) @ Episode 1408/10000, loss: 0.00023987462918739766\n",
      "Episode Reward: 4.0\n",
      "Step 593 (360667) @ Episode 1409/10000, loss: 0.00192808744031935933\n",
      "Episode Reward: 7.0\n",
      "Step 500 (361167) @ Episode 1410/10000, loss: 0.00051603972679004074\n",
      "Episode Reward: 6.0\n",
      "Step 342 (361509) @ Episode 1411/10000, loss: 0.00022895200527273118\n",
      "Episode Reward: 3.0\n",
      "Step 299 (361808) @ Episode 1412/10000, loss: 0.00399881601333618204\n",
      "Episode Reward: 3.0\n",
      "Step 541 (362349) @ Episode 1413/10000, loss: 0.00168329139705747373\n",
      "Episode Reward: 8.0\n",
      "Step 312 (362661) @ Episode 1414/10000, loss: 0.00048903125571087452\n",
      "Episode Reward: 3.0\n",
      "Step 299 (362960) @ Episode 1415/10000, loss: 0.00067534786649048333\n",
      "Episode Reward: 3.0\n",
      "Step 512 (363472) @ Episode 1416/10000, loss: 0.00220705429092049647\n",
      "Episode Reward: 7.0\n",
      "Step 245 (363717) @ Episode 1417/10000, loss: 0.00027426681481301785\n",
      "Episode Reward: 2.0\n",
      "Step 396 (364113) @ Episode 1418/10000, loss: 0.00039575833943672484\n",
      "Episode Reward: 5.0\n",
      "Step 465 (364578) @ Episode 1419/10000, loss: 0.00208994233980774936\n",
      "Episode Reward: 5.0\n",
      "Step 457 (365035) @ Episode 1420/10000, loss: 0.00182788888923823834\n",
      "Episode Reward: 6.0\n",
      "Step 528 (365563) @ Episode 1421/10000, loss: 0.00063968112226575613\n",
      "Episode Reward: 7.0\n",
      "Step 416 (365979) @ Episode 1422/10000, loss: 0.00030845520086586475\n",
      "Episode Reward: 4.0\n",
      "Step 421 (366400) @ Episode 1423/10000, loss: 0.00052140455227345233\n",
      "Episode Reward: 4.0\n",
      "Step 336 (366736) @ Episode 1424/10000, loss: 0.00046068633673712616\n",
      "Episode Reward: 2.0\n",
      "Step 402 (367138) @ Episode 1425/10000, loss: 0.00091107829939574847\n",
      "Episode Reward: 4.0\n",
      "Step 389 (367527) @ Episode 1426/10000, loss: 0.00030045001767575744\n",
      "Episode Reward: 4.0\n",
      "Step 437 (367964) @ Episode 1427/10000, loss: 0.00014884606935083866\n",
      "Episode Reward: 5.0\n",
      "Step 359 (368323) @ Episode 1428/10000, loss: 0.00060097977984696637\n",
      "Episode Reward: 4.0\n",
      "Step 355 (368678) @ Episode 1429/10000, loss: 0.00128959002904593944\n",
      "Episode Reward: 3.0\n",
      "Step 632 (369310) @ Episode 1430/10000, loss: 0.00238820794038474564\n",
      "Episode Reward: 7.0\n",
      "Step 597 (369907) @ Episode 1431/10000, loss: 0.00266837398521602152\n",
      "Episode Reward: 9.0\n",
      "Step 92 (369999) @ Episode 1432/10000, loss: 0.00023900155792944133\n",
      " Copied model parameters to target network\n",
      "Step 449 (370356) @ Episode 1432/10000, loss: 0.00667159492149949184\n",
      "Episode Reward: 5.0\n",
      "Step 348 (370704) @ Episode 1433/10000, loss: 0.00090705062029883274\n",
      "Episode Reward: 3.0\n",
      "Step 360 (371064) @ Episode 1434/10000, loss: 0.00353701715357601648\n",
      "Episode Reward: 3.0\n",
      "Step 501 (371565) @ Episode 1435/10000, loss: 0.00021173812274355447\n",
      "Episode Reward: 5.0\n",
      "Step 564 (372129) @ Episode 1436/10000, loss: 0.00040306782466359437\n",
      "Episode Reward: 6.0\n",
      "Step 325 (372454) @ Episode 1437/10000, loss: 0.00098458409775048555\n",
      "Episode Reward: 3.0\n",
      "Step 413 (372867) @ Episode 1438/10000, loss: 0.00186746520921587947\n",
      "Episode Reward: 4.0\n",
      "Step 376 (373243) @ Episode 1439/10000, loss: 0.00106889859307557344\n",
      "Episode Reward: 3.0\n",
      "Step 356 (373599) @ Episode 1440/10000, loss: 0.00013562277308665216\n",
      "Episode Reward: 4.0\n",
      "Step 585 (374184) @ Episode 1441/10000, loss: 0.00191169092431664474\n",
      "Episode Reward: 7.0\n",
      "Step 414 (374598) @ Episode 1442/10000, loss: 0.00260963523760437976\n",
      "Episode Reward: 4.0\n",
      "Step 548 (375146) @ Episode 1443/10000, loss: 0.00179344066418707373\n",
      "Episode Reward: 6.0\n",
      "Step 465 (375611) @ Episode 1444/10000, loss: 0.00077548524131998422\n",
      "Episode Reward: 5.0\n",
      "Step 524 (376135) @ Episode 1445/10000, loss: 0.00145653740037232643\n",
      "Episode Reward: 6.0\n",
      "Step 401 (376536) @ Episode 1446/10000, loss: 0.01018794998526573275\n",
      "Episode Reward: 4.0\n",
      "Step 276 (376812) @ Episode 1447/10000, loss: 0.00136565172579139474\n",
      "Episode Reward: 2.0\n",
      "Step 618 (377430) @ Episode 1448/10000, loss: 0.00083800312131643323\n",
      "Episode Reward: 9.0\n",
      "Step 485 (377915) @ Episode 1449/10000, loss: 0.00086805236060172325\n",
      "Episode Reward: 5.0\n",
      "Step 356 (378271) @ Episode 1450/10000, loss: 0.00279883365146815785\n",
      "Episode Reward: 3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 17:44:57,132] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video001450.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 309 (378580) @ Episode 1451/10000, loss: 0.00037581671494990587\n",
      "Episode Reward: 3.0\n",
      "Step 674 (379254) @ Episode 1452/10000, loss: 0.00056173437042161823\n",
      "Episode Reward: 11.0\n",
      "Step 459 (379713) @ Episode 1453/10000, loss: 0.00523214275017380776\n",
      "Episode Reward: 5.0\n",
      "Step 286 (379999) @ Episode 1454/10000, loss: 0.00261398334987461575\n",
      " Copied model parameters to target network\n",
      "Step 472 (380185) @ Episode 1454/10000, loss: 0.00125898921396583327\n",
      "Episode Reward: 6.0\n",
      "Step 449 (380634) @ Episode 1455/10000, loss: 0.00128634157590568074\n",
      "Episode Reward: 5.0\n",
      "Step 543 (381177) @ Episode 1456/10000, loss: 0.00064326159190386536\n",
      "Episode Reward: 6.0\n",
      "Step 370 (381547) @ Episode 1457/10000, loss: 0.00871228054165840125\n",
      "Episode Reward: 4.0\n",
      "Step 562 (382109) @ Episode 1458/10000, loss: 0.00065698754042387013\n",
      "Episode Reward: 5.0\n",
      "Step 480 (382589) @ Episode 1459/10000, loss: 0.00184887752402573824\n",
      "Episode Reward: 6.0\n",
      "Step 357 (382946) @ Episode 1460/10000, loss: 0.00098010711371898658\n",
      "Episode Reward: 3.0\n",
      "Step 517 (383463) @ Episode 1461/10000, loss: 0.00070321641396731143\n",
      "Episode Reward: 6.0\n",
      "Step 609 (384072) @ Episode 1462/10000, loss: 0.00335610401816666135\n",
      "Episode Reward: 8.0\n",
      "Step 554 (384626) @ Episode 1463/10000, loss: 0.00139163085259497173\n",
      "Episode Reward: 6.0\n",
      "Step 465 (385091) @ Episode 1464/10000, loss: 0.00332737015560269364\n",
      "Episode Reward: 6.0\n",
      "Step 320 (385411) @ Episode 1465/10000, loss: 0.00089875247795134785\n",
      "Episode Reward: 3.0\n",
      "Step 536 (385947) @ Episode 1466/10000, loss: 0.00350832892581820583\n",
      "Episode Reward: 6.0\n",
      "Step 505 (386452) @ Episode 1467/10000, loss: 0.00283913826569914816\n",
      "Episode Reward: 6.0\n",
      "Step 619 (387071) @ Episode 1468/10000, loss: 0.00401897821575403246\n",
      "Episode Reward: 10.0\n",
      "Step 280 (387351) @ Episode 1469/10000, loss: 0.00638510240241885237\n",
      "Episode Reward: 2.0\n",
      "Step 359 (387710) @ Episode 1470/10000, loss: 0.00044123386032879357\n",
      "Episode Reward: 4.0\n",
      "Step 428 (388138) @ Episode 1471/10000, loss: 0.01208658795803785365\n",
      "Episode Reward: 5.0\n",
      "Step 481 (388619) @ Episode 1472/10000, loss: 0.00179305020719766626\n",
      "Episode Reward: 6.0\n",
      "Step 518 (389137) @ Episode 1473/10000, loss: 0.01301158964633941775\n",
      "Episode Reward: 5.0\n",
      "Step 320 (389457) @ Episode 1474/10000, loss: 0.00048712865100242247\n",
      "Episode Reward: 3.0\n",
      "Step 510 (389967) @ Episode 1475/10000, loss: 0.00032198155531659724\n",
      "Episode Reward: 10.0\n",
      "Step 32 (389999) @ Episode 1476/10000, loss: 0.00067693408345803623\n",
      " Copied model parameters to target network\n",
      "Step 377 (390344) @ Episode 1476/10000, loss: 0.00478455098345875785\n",
      "Episode Reward: 4.0\n",
      "Step 680 (391024) @ Episode 1477/10000, loss: 0.00042949465569108725\n",
      "Episode Reward: 8.0\n",
      "Step 484 (391508) @ Episode 1478/10000, loss: 0.00051361363148316743\n",
      "Episode Reward: 4.0\n",
      "Step 506 (392014) @ Episode 1479/10000, loss: 0.01295463927090168716\n",
      "Episode Reward: 6.0\n",
      "Step 435 (392449) @ Episode 1480/10000, loss: 0.00646971166133880677\n",
      "Episode Reward: 5.0\n",
      "Step 392 (392841) @ Episode 1481/10000, loss: 0.00054236344294622544\n",
      "Episode Reward: 4.0\n",
      "Step 431 (393272) @ Episode 1482/10000, loss: 0.00067106774076819424\n",
      "Episode Reward: 4.0\n",
      "Step 503 (393775) @ Episode 1483/10000, loss: 0.00197081267833709744\n",
      "Episode Reward: 6.0\n",
      "Step 477 (394252) @ Episode 1484/10000, loss: 0.00087955535855144264\n",
      "Episode Reward: 9.0\n",
      "Step 409 (394661) @ Episode 1485/10000, loss: 0.00156071409583091748\n",
      "Episode Reward: 5.0\n",
      "Step 597 (395258) @ Episode 1486/10000, loss: 0.00192066165618598466\n",
      "Episode Reward: 7.0\n",
      "Step 520 (395778) @ Episode 1487/10000, loss: 0.00134666729718446734\n",
      "Episode Reward: 6.0\n",
      "Step 411 (396189) @ Episode 1488/10000, loss: 0.00046939309686422353\n",
      "Episode Reward: 4.0\n",
      "Step 552 (396741) @ Episode 1489/10000, loss: 0.00051557249389588837\n",
      "Episode Reward: 6.0\n",
      "Step 417 (397158) @ Episode 1490/10000, loss: 0.00055741250980645426\n",
      "Episode Reward: 4.0\n",
      "Step 439 (397597) @ Episode 1491/10000, loss: 0.00163196003995835783\n",
      "Episode Reward: 5.0\n",
      "Step 564 (398161) @ Episode 1492/10000, loss: 0.00092382065486162997\n",
      "Episode Reward: 7.0\n",
      "Step 296 (398457) @ Episode 1493/10000, loss: 0.00100821978412568575\n",
      "Episode Reward: 3.0\n",
      "Step 442 (398899) @ Episode 1494/10000, loss: 0.00047916028415784246\n",
      "Episode Reward: 5.0\n",
      "Step 715 (399614) @ Episode 1495/10000, loss: 0.00015653879381716251\n",
      "Episode Reward: 9.0\n",
      "Step 330 (399944) @ Episode 1496/10000, loss: 0.00021380968973971903\n",
      "Episode Reward: 3.0\n",
      "Step 55 (399999) @ Episode 1497/10000, loss: 0.00030827207956463144\n",
      " Copied model parameters to target network\n",
      "Step 463 (400407) @ Episode 1497/10000, loss: 0.00060439197113737466\n",
      "Episode Reward: 5.0\n",
      "Step 518 (400925) @ Episode 1498/10000, loss: 0.00531327817589044644\n",
      "Episode Reward: 6.0\n",
      "Step 516 (401441) @ Episode 1499/10000, loss: 0.00147718517109751736\n",
      "Episode Reward: 6.0\n",
      "Step 750 (402191) @ Episode 1500/10000, loss: 0.00145299092400819064\n",
      "Episode Reward: 10.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 17:48:25,730] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video001500.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 454 (402645) @ Episode 1501/10000, loss: 0.00044097995851188916\n",
      "Episode Reward: 6.0\n",
      "Step 545 (403190) @ Episode 1502/10000, loss: 0.00078764604404568677\n",
      "Episode Reward: 6.0\n",
      "Step 416 (403606) @ Episode 1503/10000, loss: 0.00225125811994075784\n",
      "Episode Reward: 6.0\n",
      "Step 664 (404270) @ Episode 1504/10000, loss: 0.00223504239693284034\n",
      "Episode Reward: 8.0\n",
      "Step 411 (404681) @ Episode 1505/10000, loss: 0.00252436846494674747\n",
      "Episode Reward: 5.0\n",
      "Step 508 (405189) @ Episode 1506/10000, loss: 0.00075944117270410066\n",
      "Episode Reward: 6.0\n",
      "Step 543 (405732) @ Episode 1507/10000, loss: 0.00048649945529177785\n",
      "Episode Reward: 6.0\n",
      "Step 612 (406344) @ Episode 1508/10000, loss: 0.00204989337362349036\n",
      "Episode Reward: 8.0\n",
      "Step 645 (406989) @ Episode 1509/10000, loss: 0.00045037042582407594\n",
      "Episode Reward: 8.0\n",
      "Step 607 (407596) @ Episode 1510/10000, loss: 0.00141619204077869654\n",
      "Episode Reward: 8.0\n",
      "Step 622 (408218) @ Episode 1511/10000, loss: 0.00382013013586401946\n",
      "Episode Reward: 8.0\n",
      "Step 389 (408607) @ Episode 1512/10000, loss: 0.00184184347745031126\n",
      "Episode Reward: 4.0\n",
      "Step 693 (409300) @ Episode 1513/10000, loss: 0.00038295541889965534\n",
      "Episode Reward: 9.0\n",
      "Step 305 (409605) @ Episode 1514/10000, loss: 0.00191638036631047734\n",
      "Episode Reward: 3.0\n",
      "Step 394 (409999) @ Episode 1515/10000, loss: 0.00046897621359676126\n",
      " Copied model parameters to target network\n",
      "Step 560 (410165) @ Episode 1515/10000, loss: 0.00374251068569719886\n",
      "Episode Reward: 7.0\n",
      "Step 684 (410849) @ Episode 1516/10000, loss: 0.00106821511872112755\n",
      "Episode Reward: 9.0\n",
      "Step 410 (411259) @ Episode 1517/10000, loss: 0.00446418114006519394\n",
      "Episode Reward: 4.0\n",
      "Step 594 (411853) @ Episode 1518/10000, loss: 0.00202208384871482853\n",
      "Episode Reward: 8.0\n",
      "Step 554 (412407) @ Episode 1519/10000, loss: 0.00101684185210615447\n",
      "Episode Reward: 5.0\n",
      "Step 411 (412818) @ Episode 1520/10000, loss: 0.00390669191256165594\n",
      "Episode Reward: 4.0\n",
      "Step 447 (413265) @ Episode 1521/10000, loss: 0.00173748773522675047\n",
      "Episode Reward: 5.0\n",
      "Step 708 (413973) @ Episode 1522/10000, loss: 0.00155709276441484785\n",
      "Episode Reward: 9.0\n",
      "Step 344 (414317) @ Episode 1523/10000, loss: 0.00170583685394376523\n",
      "Episode Reward: 3.0\n",
      "Step 453 (414770) @ Episode 1524/10000, loss: 0.00099983601830899723\n",
      "Episode Reward: 5.0\n",
      "Step 511 (415281) @ Episode 1525/10000, loss: 0.00142574287019670746\n",
      "Episode Reward: 5.0\n",
      "Step 383 (415664) @ Episode 1526/10000, loss: 0.00264013581909239337\n",
      "Episode Reward: 4.0\n",
      "Step 601 (416265) @ Episode 1527/10000, loss: 0.00053469248814508326\n",
      "Episode Reward: 8.0\n",
      "Step 689 (416954) @ Episode 1528/10000, loss: 0.00060963915893808015\n",
      "Episode Reward: 9.0\n",
      "Step 466 (417420) @ Episode 1529/10000, loss: 0.00146003626286983564\n",
      "Episode Reward: 5.0\n",
      "Step 580 (418000) @ Episode 1530/10000, loss: 0.00063504732679575687\n",
      "Episode Reward: 8.0\n",
      "Step 495 (418495) @ Episode 1531/10000, loss: 0.00051122519653290514\n",
      "Episode Reward: 6.0\n",
      "Step 563 (419058) @ Episode 1532/10000, loss: 0.00384257338009774747\n",
      "Episode Reward: 8.0\n",
      "Step 413 (419471) @ Episode 1533/10000, loss: 0.00119464052841067314\n",
      "Episode Reward: 4.0\n",
      "Step 456 (419927) @ Episode 1534/10000, loss: 0.00056347262579947716\n",
      "Episode Reward: 5.0\n",
      "Step 72 (419999) @ Episode 1535/10000, loss: 0.00256079435348510747\n",
      " Copied model parameters to target network\n",
      "Step 624 (420551) @ Episode 1535/10000, loss: 0.00181048468220978983\n",
      "Episode Reward: 9.0\n",
      "Step 550 (421101) @ Episode 1536/10000, loss: 0.00411875685676932356\n",
      "Episode Reward: 6.0\n",
      "Step 684 (421785) @ Episode 1537/10000, loss: 0.00046135525917634377\n",
      "Episode Reward: 13.0\n",
      "Step 514 (422299) @ Episode 1538/10000, loss: 0.00067106063943356284\n",
      "Episode Reward: 9.0\n",
      "Step 551 (422850) @ Episode 1539/10000, loss: 0.00117841712199151527\n",
      "Episode Reward: 7.0\n",
      "Step 387 (423237) @ Episode 1540/10000, loss: 0.00064911734079942114\n",
      "Episode Reward: 5.0\n",
      "Step 825 (424062) @ Episode 1541/10000, loss: 0.00137227808590978382\n",
      "Episode Reward: 11.0\n",
      "Step 661 (424723) @ Episode 1542/10000, loss: 0.00195931573398411276\n",
      "Episode Reward: 9.0\n",
      "Step 559 (425282) @ Episode 1543/10000, loss: 0.00600454816594719966\n",
      "Episode Reward: 7.0\n",
      "Step 610 (425892) @ Episode 1544/10000, loss: 0.00157708732876926662\n",
      "Episode Reward: 8.0\n",
      "Step 772 (426664) @ Episode 1545/10000, loss: 0.00091034575598314415\n",
      "Episode Reward: 11.0\n",
      "Step 481 (427145) @ Episode 1546/10000, loss: 0.00180869095493108035\n",
      "Episode Reward: 13.0\n",
      "Step 683 (427828) @ Episode 1547/10000, loss: 0.00134489941410720356\n",
      "Episode Reward: 9.0\n",
      "Step 640 (428468) @ Episode 1548/10000, loss: 0.00350697524845600135\n",
      "Episode Reward: 12.0\n",
      "Step 617 (429085) @ Episode 1549/10000, loss: 0.00709885871037840863\n",
      "Episode Reward: 12.0\n",
      "Step 601 (429686) @ Episode 1550/10000, loss: 0.00093066896079108127\n",
      "Episode Reward: 8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 17:52:26,627] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video001550.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 313 (429999) @ Episode 1551/10000, loss: 0.00065637892112135894\n",
      " Copied model parameters to target network\n",
      "Step 515 (430201) @ Episode 1551/10000, loss: 0.00785540975630283486\n",
      "Episode Reward: 7.0\n",
      "Step 543 (430744) @ Episode 1552/10000, loss: 0.01108171511441469225\n",
      "Episode Reward: 7.0\n",
      "Step 523 (431267) @ Episode 1553/10000, loss: 0.00101985794026404627\n",
      "Episode Reward: 6.0\n",
      "Step 528 (431795) @ Episode 1554/10000, loss: 0.00227865274064242843\n",
      "Episode Reward: 6.0\n",
      "Step 510 (432305) @ Episode 1555/10000, loss: 0.00083226716378703715\n",
      "Episode Reward: 5.0\n",
      "Step 622 (432927) @ Episode 1556/10000, loss: 0.01059809699654579243\n",
      "Episode Reward: 9.0\n",
      "Step 636 (433563) @ Episode 1557/10000, loss: 0.00259350379928946524\n",
      "Episode Reward: 7.0\n",
      "Step 724 (434287) @ Episode 1558/10000, loss: 0.00244317809119820674\n",
      "Episode Reward: 10.0\n",
      "Step 645 (434932) @ Episode 1559/10000, loss: 0.00096516311168670655\n",
      "Episode Reward: 9.0\n",
      "Step 655 (435587) @ Episode 1560/10000, loss: 0.00130599306430667644\n",
      "Episode Reward: 12.0\n",
      "Step 710 (436297) @ Episode 1561/10000, loss: 0.00457973266020417263\n",
      "Episode Reward: 10.0\n",
      "Step 576 (436873) @ Episode 1562/10000, loss: 0.01545038074254989654\n",
      "Episode Reward: 7.0\n",
      "Step 635 (437508) @ Episode 1563/10000, loss: 0.00119424937292933466\n",
      "Episode Reward: 7.0\n",
      "Step 632 (438140) @ Episode 1564/10000, loss: 0.00282832304947078234\n",
      "Episode Reward: 9.0\n",
      "Step 990 (439130) @ Episode 1565/10000, loss: 0.00054105889284983284\n",
      "Episode Reward: 15.0\n",
      "Step 869 (439999) @ Episode 1566/10000, loss: 0.00224244454875588424\n",
      " Copied model parameters to target network\n",
      "Step 966 (440096) @ Episode 1566/10000, loss: 0.0035800889600068337\n",
      "Episode Reward: 14.0\n",
      "Step 723 (440819) @ Episode 1567/10000, loss: 0.00113551749382168055\n",
      "Episode Reward: 9.0\n",
      "Step 809 (441628) @ Episode 1568/10000, loss: 0.00120413443073630334\n",
      "Episode Reward: 14.0\n",
      "Step 645 (442273) @ Episode 1569/10000, loss: 0.00198426353745162574\n",
      "Episode Reward: 8.0\n",
      "Step 913 (443186) @ Episode 1570/10000, loss: 0.00114299706183373935\n",
      "Episode Reward: 15.0\n",
      "Step 862 (444048) @ Episode 1571/10000, loss: 0.00166655576322227725\n",
      "Episode Reward: 16.0\n",
      "Step 564 (444612) @ Episode 1572/10000, loss: 0.00090660731075331575\n",
      "Episode Reward: 6.0\n",
      "Step 792 (445404) @ Episode 1573/10000, loss: 0.00066945026628673083\n",
      "Episode Reward: 12.0\n",
      "Step 707 (446111) @ Episode 1574/10000, loss: 0.00151520653162151583\n",
      "Episode Reward: 10.0\n",
      "Step 594 (446705) @ Episode 1575/10000, loss: 0.00134114059619605546\n",
      "Episode Reward: 7.0\n",
      "Step 887 (447592) @ Episode 1576/10000, loss: 0.00086662184912711387\n",
      "Episode Reward: 17.0\n",
      "Step 644 (448236) @ Episode 1577/10000, loss: 0.00087797362357378015\n",
      "Episode Reward: 9.0\n",
      "Step 770 (449006) @ Episode 1578/10000, loss: 0.00151905231177806854\n",
      "Episode Reward: 12.0\n",
      "Step 811 (449817) @ Episode 1579/10000, loss: 0.00139899819623678925\n",
      "Episode Reward: 12.0\n",
      "Step 182 (449999) @ Episode 1580/10000, loss: 0.00112856249324977453\n",
      " Copied model parameters to target network\n",
      "Step 763 (450580) @ Episode 1580/10000, loss: 0.00401192856952548797\n",
      "Episode Reward: 11.0\n",
      "Step 1213 (451793) @ Episode 1581/10000, loss: 0.0069389985874295235\n",
      "Episode Reward: 24.0\n",
      "Step 798 (452591) @ Episode 1582/10000, loss: 0.00274237943813204775\n",
      "Episode Reward: 11.0\n",
      "Step 749 (453340) @ Episode 1583/10000, loss: 0.00077005050843581563\n",
      "Episode Reward: 9.0\n",
      "Step 673 (454013) @ Episode 1584/10000, loss: 0.00133408070541918283\n",
      "Episode Reward: 9.0\n",
      "Step 619 (454632) @ Episode 1585/10000, loss: 0.00205697072669863756\n",
      "Episode Reward: 12.0\n",
      "Step 789 (455421) @ Episode 1586/10000, loss: 0.00208560796454548845\n",
      "Episode Reward: 16.0\n",
      "Step 758 (456179) @ Episode 1587/10000, loss: 0.00543078174814581944\n",
      "Episode Reward: 15.0\n",
      "Step 1140 (457319) @ Episode 1588/10000, loss: 0.00234898366034030964\n",
      "Episode Reward: 17.0\n",
      "Step 616 (457935) @ Episode 1589/10000, loss: 0.01399034075438976363\n",
      "Episode Reward: 9.0\n",
      "Step 815 (458750) @ Episode 1590/10000, loss: 0.00084618275286629847\n",
      "Episode Reward: 12.0\n",
      "Step 685 (459435) @ Episode 1591/10000, loss: 0.00203253515064716346\n",
      "Episode Reward: 11.0\n",
      "Step 564 (459999) @ Episode 1592/10000, loss: 0.00271152518689632463\n",
      " Copied model parameters to target network\n",
      "Step 924 (460359) @ Episode 1592/10000, loss: 0.00134167191572487355\n",
      "Episode Reward: 13.0\n",
      "Step 908 (461267) @ Episode 1593/10000, loss: 0.00355008663609623945\n",
      "Episode Reward: 17.0\n",
      "Step 695 (461962) @ Episode 1594/10000, loss: 0.01127339713275432643\n",
      "Episode Reward: 11.0\n",
      "Step 892 (462854) @ Episode 1595/10000, loss: 0.00431034713983535827\n",
      "Episode Reward: 15.0\n",
      "Step 994 (463848) @ Episode 1596/10000, loss: 0.00295058754272758963\n",
      "Episode Reward: 22.0\n",
      "Step 905 (464753) @ Episode 1597/10000, loss: 0.00215395120903849643\n",
      "Episode Reward: 13.0\n",
      "Step 732 (465485) @ Episode 1598/10000, loss: 0.00188074866309762575\n",
      "Episode Reward: 13.0\n",
      "Step 740 (466225) @ Episode 1599/10000, loss: 0.00227376632392406465\n",
      "Episode Reward: 11.0\n",
      "Step 907 (467132) @ Episode 1600/10000, loss: 0.00260534044355154045\n",
      "Episode Reward: 14.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 17:57:58,722] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video001600.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 792 (467924) @ Episode 1601/10000, loss: 0.00264182733371853835\n",
      "Episode Reward: 10.0\n",
      "Step 692 (468616) @ Episode 1602/10000, loss: 0.00290880491957068444\n",
      "Episode Reward: 8.0\n",
      "Step 862 (469478) @ Episode 1603/10000, loss: 0.00474187731742858924\n",
      "Episode Reward: 18.0\n",
      "Step 521 (469999) @ Episode 1604/10000, loss: 0.00317810382694005974\n",
      " Copied model parameters to target network\n",
      "Step 869 (470347) @ Episode 1604/10000, loss: 0.00218910910189151766\n",
      "Episode Reward: 15.0\n",
      "Step 526 (470873) @ Episode 1605/10000, loss: 0.00218551768921315674\n",
      "Episode Reward: 6.0\n",
      "Step 874 (471747) @ Episode 1606/10000, loss: 0.00399695243686437634\n",
      "Episode Reward: 16.0\n",
      "Step 731 (472478) @ Episode 1607/10000, loss: 0.00049311073962599046\n",
      "Episode Reward: 13.0\n",
      "Step 728 (473206) @ Episode 1608/10000, loss: 0.00137550430372357375\n",
      "Episode Reward: 11.0\n",
      "Step 935 (474141) @ Episode 1609/10000, loss: 0.00180404330603778367\n",
      "Episode Reward: 14.0\n",
      "Step 780 (474921) @ Episode 1610/10000, loss: 0.00250393222086131575\n",
      "Episode Reward: 12.0\n",
      "Step 758 (475679) @ Episode 1611/10000, loss: 0.00193097721785306935\n",
      "Episode Reward: 12.0\n",
      "Step 732 (476411) @ Episode 1612/10000, loss: 0.00189302652142941954\n",
      "Episode Reward: 10.0\n",
      "Step 919 (477330) @ Episode 1613/10000, loss: 0.00131904031150043536\n",
      "Episode Reward: 14.0\n",
      "Step 657 (477987) @ Episode 1614/10000, loss: 0.00098893442191183576\n",
      "Episode Reward: 17.0\n",
      "Step 876 (478863) @ Episode 1615/10000, loss: 0.00157065805979073056\n",
      "Episode Reward: 13.0\n",
      "Step 791 (479654) @ Episode 1616/10000, loss: 0.00201486656442284613\n",
      "Episode Reward: 18.0\n",
      "Step 345 (479999) @ Episode 1617/10000, loss: 0.00201815250329673394\n",
      " Copied model parameters to target network\n",
      "Step 614 (480268) @ Episode 1617/10000, loss: 0.0011622449383139615\n",
      "Episode Reward: 13.0\n",
      "Step 798 (481066) @ Episode 1618/10000, loss: 0.00237100804224610336\n",
      "Episode Reward: 14.0\n",
      "Step 819 (481885) @ Episode 1619/10000, loss: 0.00183451955672353585\n",
      "Episode Reward: 13.0\n",
      "Step 650 (482535) @ Episode 1620/10000, loss: 0.0022305117454379797\n",
      "Episode Reward: 13.0\n",
      "Step 721 (483256) @ Episode 1621/10000, loss: 0.00096816674340516334\n",
      "Episode Reward: 10.0\n",
      "Step 758 (484014) @ Episode 1622/10000, loss: 0.0019283172441646457\n",
      "Episode Reward: 13.0\n",
      "Step 841 (484855) @ Episode 1623/10000, loss: 0.00400992017239332217\n",
      "Episode Reward: 15.0\n",
      "Step 672 (485527) @ Episode 1624/10000, loss: 0.00483514741063118543\n",
      "Episode Reward: 13.0\n",
      "Step 923 (486450) @ Episode 1625/10000, loss: 0.00119821808766573674\n",
      "Episode Reward: 22.0\n",
      "Step 926 (487376) @ Episode 1626/10000, loss: 0.00101721764076501134\n",
      "Episode Reward: 18.0\n",
      "Step 766 (488142) @ Episode 1627/10000, loss: 0.00113093852996826177\n",
      "Episode Reward: 12.0\n",
      "Step 924 (489066) @ Episode 1628/10000, loss: 0.00168549141380935947\n",
      "Episode Reward: 24.0\n",
      "Step 877 (489943) @ Episode 1629/10000, loss: 0.00715887872502207766\n",
      "Episode Reward: 13.0\n",
      "Step 56 (489999) @ Episode 1630/10000, loss: 0.0005927807651460171\n",
      " Copied model parameters to target network\n",
      "Step 900 (490843) @ Episode 1630/10000, loss: 0.00104156055022031077\n",
      "Episode Reward: 16.0\n",
      "Step 777 (491620) @ Episode 1631/10000, loss: 0.00128002464771270757\n",
      "Episode Reward: 14.0\n",
      "Step 1277 (492897) @ Episode 1632/10000, loss: 0.0030206535011529922\n",
      "Episode Reward: 30.0\n",
      "Step 941 (493838) @ Episode 1633/10000, loss: 0.00330614158883690836\n",
      "Episode Reward: 18.0\n",
      "Step 922 (494760) @ Episode 1634/10000, loss: 0.00373211642727255845\n",
      "Episode Reward: 22.0\n",
      "Step 692 (495452) @ Episode 1635/10000, loss: 0.00135102029889822556\n",
      "Episode Reward: 14.0\n",
      "Step 879 (496331) @ Episode 1636/10000, loss: 0.00215435517020523554\n",
      "Episode Reward: 13.0\n",
      "Step 635 (496966) @ Episode 1637/10000, loss: 0.0049808202311396604\n",
      "Episode Reward: 10.0\n",
      "Step 830 (497796) @ Episode 1638/10000, loss: 0.00132600637152791025\n",
      "Episode Reward: 13.0\n",
      "Step 838 (498634) @ Episode 1639/10000, loss: 0.00185107509605586534\n",
      "Episode Reward: 12.0\n",
      "Step 728 (499362) @ Episode 1640/10000, loss: 0.00229583121836185467\n",
      "Episode Reward: 13.0\n",
      "Step 637 (499999) @ Episode 1641/10000, loss: 0.00558938086032867445\n",
      " Copied model parameters to target network\n",
      "Step 729 (500091) @ Episode 1641/10000, loss: 0.0012662059161812067\n",
      "Episode Reward: 11.0\n",
      "Step 790 (500881) @ Episode 1642/10000, loss: 0.00114844483323395254\n",
      "Episode Reward: 17.0\n",
      "Step 855 (501736) @ Episode 1643/10000, loss: 0.00172167154960334327\n",
      "Episode Reward: 18.0\n",
      "Step 965 (502701) @ Episode 1644/10000, loss: 0.00127392867580056223\n",
      "Episode Reward: 19.0\n",
      "Step 829 (503530) @ Episode 1645/10000, loss: 0.0030249406117945916\n",
      "Episode Reward: 14.0\n",
      "Step 1092 (504622) @ Episode 1646/10000, loss: 0.0037642209790647038\n",
      "Episode Reward: 18.0\n",
      "Step 792 (505414) @ Episode 1647/10000, loss: 0.00222569936886429853\n",
      "Episode Reward: 15.0\n",
      "Step 778 (506192) @ Episode 1648/10000, loss: 0.00155960069969296463\n",
      "Episode Reward: 13.0\n",
      "Step 1005 (507197) @ Episode 1649/10000, loss: 0.0020062951371073723\n",
      "Episode Reward: 16.0\n",
      "Step 749 (507946) @ Episode 1650/10000, loss: 0.00781546998769044945\n",
      "Episode Reward: 12.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 18:04:04,526] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video001650.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 666 (508612) @ Episode 1651/10000, loss: 0.00326832034625113966\n",
      "Episode Reward: 11.0\n",
      "Step 625 (509237) @ Episode 1652/10000, loss: 0.00124973803758621224\n",
      "Episode Reward: 10.0\n",
      "Step 762 (509999) @ Episode 1653/10000, loss: 0.00124375673476606664\n",
      " Copied model parameters to target network\n",
      "Step 795 (510032) @ Episode 1653/10000, loss: 0.0105529129505157475\n",
      "Episode Reward: 17.0\n",
      "Step 812 (510844) @ Episode 1654/10000, loss: 0.0023215520195662975\n",
      "Episode Reward: 13.0\n",
      "Step 782 (511626) @ Episode 1655/10000, loss: 0.00533791678026318555\n",
      "Episode Reward: 13.0\n",
      "Step 846 (512472) @ Episode 1656/10000, loss: 0.00391224399209022587\n",
      "Episode Reward: 16.0\n",
      "Step 647 (513119) @ Episode 1657/10000, loss: 0.0028300131671130657\n",
      "Episode Reward: 10.0\n",
      "Step 963 (514082) @ Episode 1658/10000, loss: 0.00496996054425835675\n",
      "Episode Reward: 21.0\n",
      "Step 596 (514678) @ Episode 1659/10000, loss: 0.00212489860132336655\n",
      "Episode Reward: 13.0\n",
      "Step 717 (515395) @ Episode 1660/10000, loss: 0.00101002142764627934\n",
      "Episode Reward: 14.0\n",
      "Step 735 (516130) @ Episode 1661/10000, loss: 0.00196085940115153874\n",
      "Episode Reward: 11.0\n",
      "Step 729 (516859) @ Episode 1662/10000, loss: 0.00194557360373437444\n",
      "Episode Reward: 14.0\n",
      "Step 885 (517744) @ Episode 1663/10000, loss: 0.00078337697777897123\n",
      "Episode Reward: 19.0\n",
      "Step 962 (518706) @ Episode 1664/10000, loss: 0.00363422674126923155\n",
      "Episode Reward: 26.0\n",
      "Step 809 (519515) @ Episode 1665/10000, loss: 0.00117512140423059463\n",
      "Episode Reward: 13.0\n",
      "Step 484 (519999) @ Episode 1666/10000, loss: 0.0012898496352136135\n",
      " Copied model parameters to target network\n",
      "Step 743 (520258) @ Episode 1666/10000, loss: 0.0010833218693733215\n",
      "Episode Reward: 12.0\n",
      "Step 731 (520989) @ Episode 1667/10000, loss: 0.0028688679449260235\n",
      "Episode Reward: 11.0\n",
      "Step 812 (521801) @ Episode 1668/10000, loss: 0.00298108858987689153\n",
      "Episode Reward: 12.0\n",
      "Step 606 (522407) @ Episode 1669/10000, loss: 0.0131215248256921771\n",
      "Episode Reward: 12.0\n",
      "Step 952 (523359) @ Episode 1670/10000, loss: 0.00243065319955348973\n",
      "Episode Reward: 19.0\n",
      "Step 802 (524161) @ Episode 1671/10000, loss: 0.00667459145188331654\n",
      "Episode Reward: 24.0\n",
      "Step 693 (524854) @ Episode 1672/10000, loss: 0.0016791945090517402\n",
      "Episode Reward: 12.0\n",
      "Step 1042 (525896) @ Episode 1673/10000, loss: 0.00715445913374424634\n",
      "Episode Reward: 22.0\n",
      "Step 713 (526609) @ Episode 1674/10000, loss: 0.00391465239226818137\n",
      "Episode Reward: 11.0\n",
      "Step 825 (527434) @ Episode 1675/10000, loss: 0.00148502772208303216\n",
      "Episode Reward: 12.0\n",
      "Step 861 (528295) @ Episode 1676/10000, loss: 0.00070667534600943334\n",
      "Episode Reward: 16.0\n",
      "Step 1069 (529364) @ Episode 1677/10000, loss: 0.00184766971506178385\n",
      "Episode Reward: 25.0\n",
      "Step 635 (529999) @ Episode 1678/10000, loss: 0.0008263642666861415\n",
      " Copied model parameters to target network\n",
      "Step 847 (530211) @ Episode 1678/10000, loss: 0.0014521467965096235\n",
      "Episode Reward: 13.0\n",
      "Step 951 (531162) @ Episode 1679/10000, loss: 0.0087862359359860426\n",
      "Episode Reward: 20.0\n",
      "Step 936 (532098) @ Episode 1680/10000, loss: 0.0016279723495244983\n",
      "Episode Reward: 32.0\n",
      "Step 624 (532722) @ Episode 1681/10000, loss: 0.0036376900970935827\n",
      "Episode Reward: 11.0\n",
      "Step 708 (533430) @ Episode 1682/10000, loss: 0.0021701827645301825\n",
      "Episode Reward: 14.0\n",
      "Step 995 (534425) @ Episode 1683/10000, loss: 0.00587286613881588545\n",
      "Episode Reward: 17.0\n",
      "Step 1404 (535829) @ Episode 1684/10000, loss: 0.0028938397299498327\n",
      "Episode Reward: 31.0\n",
      "Step 1094 (536923) @ Episode 1685/10000, loss: 0.0040547819808125563\n",
      "Episode Reward: 19.0\n",
      "Step 885 (537808) @ Episode 1686/10000, loss: 0.00106112705543637285\n",
      "Episode Reward: 15.0\n",
      "Step 519 (538327) @ Episode 1687/10000, loss: 0.0014087057206779718\n",
      "Episode Reward: 8.0\n",
      "Step 755 (539082) @ Episode 1688/10000, loss: 0.0089881038293242457\n",
      "Episode Reward: 13.0\n",
      "Step 917 (539999) @ Episode 1689/10000, loss: 0.0027113715186715126\n",
      " Copied model parameters to target network\n",
      "Step 945 (540027) @ Episode 1689/10000, loss: 0.0050284652970731262\n",
      "Episode Reward: 21.0\n",
      "Step 872 (540899) @ Episode 1690/10000, loss: 0.03057272173464298277\n",
      "Episode Reward: 18.0\n",
      "Step 812 (541711) @ Episode 1691/10000, loss: 0.00298146717250347143\n",
      "Episode Reward: 17.0\n",
      "Step 603 (542314) @ Episode 1692/10000, loss: 0.0033107898198068148\n",
      "Episode Reward: 9.0\n",
      "Step 833 (543147) @ Episode 1693/10000, loss: 0.0123893171548843385\n",
      "Episode Reward: 17.0\n",
      "Step 829 (543976) @ Episode 1694/10000, loss: 0.0027261725626885898\n",
      "Episode Reward: 16.0\n",
      "Step 1036 (545012) @ Episode 1695/10000, loss: 0.0222871899604797366\n",
      "Episode Reward: 22.0\n",
      "Step 754 (545766) @ Episode 1696/10000, loss: 0.00839834101498127466\n",
      "Episode Reward: 20.0\n",
      "Step 794 (546560) @ Episode 1697/10000, loss: 0.0087028108537197113\n",
      "Episode Reward: 13.0\n",
      "Step 912 (547472) @ Episode 1698/10000, loss: 0.00260550063103437425\n",
      "Episode Reward: 22.0\n",
      "Step 951 (548423) @ Episode 1699/10000, loss: 0.0086282007396221168\n",
      "Episode Reward: 17.0\n",
      "Step 888 (549311) @ Episode 1700/10000, loss: 0.01318013947457075137\n",
      "Episode Reward: 19.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 18:10:17,227] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video001700.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 680 (549991) @ Episode 1701/10000, loss: 0.0357096269726753233\n",
      "Episode Reward: 14.0\n",
      "Step 8 (549999) @ Episode 1702/10000, loss: 0.0023735018912702817\n",
      " Copied model parameters to target network\n",
      "Step 868 (550859) @ Episode 1702/10000, loss: 0.0132257081568241124\n",
      "Episode Reward: 21.0\n",
      "Step 967 (551826) @ Episode 1703/10000, loss: 0.0008348650881089274\n",
      "Episode Reward: 20.0\n",
      "Step 751 (552577) @ Episode 1704/10000, loss: 0.01071628369390964556\n",
      "Episode Reward: 15.0\n",
      "Step 968 (553545) @ Episode 1705/10000, loss: 0.00407147733494639447\n",
      "Episode Reward: 17.0\n",
      "Step 715 (554260) @ Episode 1706/10000, loss: 0.0011032656766474247\n",
      "Episode Reward: 11.0\n",
      "Step 890 (555150) @ Episode 1707/10000, loss: 0.00117790489457547666\n",
      "Episode Reward: 14.0\n",
      "Step 773 (555923) @ Episode 1708/10000, loss: 0.00083251821342855696\n",
      "Episode Reward: 12.0\n",
      "Step 769 (556692) @ Episode 1709/10000, loss: 0.00250006257556378847\n",
      "Episode Reward: 13.0\n",
      "Step 872 (557564) @ Episode 1710/10000, loss: 0.0020228973589837553\n",
      "Episode Reward: 19.0\n",
      "Step 1204 (558768) @ Episode 1711/10000, loss: 0.0062554343603551395\n",
      "Episode Reward: 23.0\n",
      "Step 720 (559488) @ Episode 1712/10000, loss: 0.0039757476188242435\n",
      "Episode Reward: 15.0\n",
      "Step 511 (559999) @ Episode 1713/10000, loss: 0.01047858595848083556\n",
      " Copied model parameters to target network\n",
      "Step 641 (560129) @ Episode 1713/10000, loss: 0.0039055065717548132\n",
      "Episode Reward: 10.0\n",
      "Step 901 (561030) @ Episode 1714/10000, loss: 0.00042539869900792837\n",
      "Episode Reward: 17.0\n",
      "Step 783 (561813) @ Episode 1715/10000, loss: 0.00643968209624290597\n",
      "Episode Reward: 15.0\n",
      "Step 900 (562713) @ Episode 1716/10000, loss: 0.0034576538018882275\n",
      "Episode Reward: 15.0\n",
      "Step 1020 (563733) @ Episode 1717/10000, loss: 0.0020227248314768076\n",
      "Episode Reward: 20.0\n",
      "Step 639 (564372) @ Episode 1718/10000, loss: 0.0105632403865456582\n",
      "Episode Reward: 11.0\n",
      "Step 707 (565079) @ Episode 1719/10000, loss: 0.0011764302616938949\n",
      "Episode Reward: 10.0\n",
      "Step 823 (565902) @ Episode 1720/10000, loss: 0.00202665873803198347\n",
      "Episode Reward: 17.0\n",
      "Step 616 (566518) @ Episode 1721/10000, loss: 0.0034931155387312174\n",
      "Episode Reward: 9.0\n",
      "Step 860 (567378) @ Episode 1722/10000, loss: 0.00211831601336598455\n",
      "Episode Reward: 17.0\n",
      "Step 910 (568288) @ Episode 1723/10000, loss: 0.0048377458006143571\n",
      "Episode Reward: 19.0\n",
      "Step 802 (569090) @ Episode 1724/10000, loss: 0.0019344640895724297\n",
      "Episode Reward: 20.0\n",
      "Step 909 (569999) @ Episode 1725/10000, loss: 0.0029942693654447794\n",
      " Copied model parameters to target network\n",
      "Step 1189 (570279) @ Episode 1725/10000, loss: 0.0104488227516412735\n",
      "Episode Reward: 27.0\n",
      "Step 1038 (571317) @ Episode 1726/10000, loss: 0.0044083045795559887\n",
      "Episode Reward: 25.0\n",
      "Step 947 (572264) @ Episode 1727/10000, loss: 0.0043052230030298234\n",
      "Episode Reward: 17.0\n",
      "Step 814 (573078) @ Episode 1728/10000, loss: 0.0054065170697867875\n",
      "Episode Reward: 21.0\n",
      "Step 531 (573609) @ Episode 1729/10000, loss: 0.0016130055300891464\n",
      "Episode Reward: 8.0\n",
      "Step 716 (574325) @ Episode 1730/10000, loss: 0.00115456967614591124\n",
      "Episode Reward: 15.0\n",
      "Step 745 (575070) @ Episode 1731/10000, loss: 0.00103758787736296653\n",
      "Episode Reward: 13.0\n",
      "Step 935 (576005) @ Episode 1732/10000, loss: 0.00205473648384213454\n",
      "Episode Reward: 18.0\n",
      "Step 1278 (577283) @ Episode 1733/10000, loss: 0.0013592503964900973\n",
      "Episode Reward: 25.0\n",
      "Step 845 (578128) @ Episode 1734/10000, loss: 0.0068768635392189032\n",
      "Episode Reward: 21.0\n",
      "Step 905 (579033) @ Episode 1735/10000, loss: 0.0063983635045588025\n",
      "Episode Reward: 18.0\n",
      "Step 652 (579685) @ Episode 1736/10000, loss: 0.00477815698832273515\n",
      "Episode Reward: 11.0\n",
      "Step 314 (579999) @ Episode 1737/10000, loss: 0.0009559878963045776\n",
      " Copied model parameters to target network\n",
      "Step 636 (580321) @ Episode 1737/10000, loss: 0.0023143449798226357\n",
      "Episode Reward: 10.0\n",
      "Step 817 (581138) @ Episode 1738/10000, loss: 0.00198220764286816163\n",
      "Episode Reward: 13.0\n",
      "Step 1097 (582235) @ Episode 1739/10000, loss: 0.0053828279487788687\n",
      "Episode Reward: 25.0\n",
      "Step 974 (583209) @ Episode 1740/10000, loss: 0.00324759096838533937\n",
      "Episode Reward: 22.0\n",
      "Step 878 (584087) @ Episode 1741/10000, loss: 0.00352172646671533667\n",
      "Episode Reward: 15.0\n",
      "Step 804 (584891) @ Episode 1742/10000, loss: 0.0032373550347983837\n",
      "Episode Reward: 15.0\n",
      "Step 806 (585697) @ Episode 1743/10000, loss: 0.0040829461067914965\n",
      "Episode Reward: 15.0\n",
      "Step 982 (586679) @ Episode 1744/10000, loss: 0.00180267053656280047\n",
      "Episode Reward: 21.0\n",
      "Step 959 (587638) @ Episode 1745/10000, loss: 0.00777699798345565894\n",
      "Episode Reward: 18.0\n",
      "Step 759 (588397) @ Episode 1746/10000, loss: 0.00230273138731718064\n",
      "Episode Reward: 18.0\n",
      "Step 951 (589348) @ Episode 1747/10000, loss: 0.0014508065069094387\n",
      "Episode Reward: 20.0\n",
      "Step 651 (589999) @ Episode 1748/10000, loss: 0.00630913209170103157\n",
      " Copied model parameters to target network\n",
      "Step 1154 (590502) @ Episode 1748/10000, loss: 0.0015286492416635156\n",
      "Episode Reward: 24.0\n",
      "Step 809 (591311) @ Episode 1749/10000, loss: 0.00121870858129113914\n",
      "Episode Reward: 13.0\n",
      "Step 851 (592162) @ Episode 1750/10000, loss: 0.00914156809449195986\n",
      "Episode Reward: 33.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 18:16:42,806] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video001750.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 954 (593116) @ Episode 1751/10000, loss: 0.00127430888824164873\n",
      "Episode Reward: 19.0\n",
      "Step 807 (593923) @ Episode 1752/10000, loss: 0.0016359977889806032\n",
      "Episode Reward: 14.0\n",
      "Step 1108 (595031) @ Episode 1753/10000, loss: 0.0014475395437330008\n",
      "Episode Reward: 19.0\n",
      "Step 1442 (596473) @ Episode 1754/10000, loss: 0.0018244474194943905\n",
      "Episode Reward: 33.0\n",
      "Step 1346 (597819) @ Episode 1755/10000, loss: 0.00140199041925370723\n",
      "Episode Reward: 30.0\n",
      "Step 786 (598605) @ Episode 1756/10000, loss: 0.00092482578475028287\n",
      "Episode Reward: 13.0\n",
      "Step 1394 (599999) @ Episode 1757/10000, loss: 0.0010218662209808826\n",
      " Copied model parameters to target network\n",
      "Step 1545 (600150) @ Episode 1757/10000, loss: 0.0115452697500586516\n",
      "Episode Reward: 35.0\n",
      "Step 807 (600957) @ Episode 1758/10000, loss: 0.0025508166290819645\n",
      "Episode Reward: 18.0\n",
      "Step 761 (601718) @ Episode 1759/10000, loss: 0.00144963059574365623\n",
      "Episode Reward: 13.0\n",
      "Step 1324 (603042) @ Episode 1760/10000, loss: 0.00115101970732212077\n",
      "Episode Reward: 30.0\n",
      "Step 838 (603880) @ Episode 1761/10000, loss: 0.00133480271324515345\n",
      "Episode Reward: 18.0\n",
      "Step 786 (604666) @ Episode 1762/10000, loss: 0.0008948248578235507\n",
      "Episode Reward: 24.0\n",
      "Step 1199 (605865) @ Episode 1763/10000, loss: 0.0015621538041159514\n",
      "Episode Reward: 26.0\n",
      "Step 757 (606622) @ Episode 1764/10000, loss: 0.00119133898988366137\n",
      "Episode Reward: 19.0\n",
      "Step 1303 (607925) @ Episode 1765/10000, loss: 0.0029164089355617764\n",
      "Episode Reward: 33.0\n",
      "Step 1037 (608962) @ Episode 1766/10000, loss: 0.0023469177540391684\n",
      "Episode Reward: 16.0\n",
      "Step 1037 (609999) @ Episode 1767/10000, loss: 0.0045485645532608036\n",
      " Copied model parameters to target network\n",
      "Step 1047 (610009) @ Episode 1767/10000, loss: 0.0035198475234210496\n",
      "Episode Reward: 17.0\n",
      "Step 851 (610860) @ Episode 1768/10000, loss: 0.0011461945250630379\n",
      "Episode Reward: 17.0\n",
      "Step 754 (611614) @ Episode 1769/10000, loss: 0.0052234600298106676\n",
      "Episode Reward: 15.0\n",
      "Step 996 (612610) @ Episode 1770/10000, loss: 0.0017263886984437704\n",
      "Episode Reward: 21.0\n",
      "Step 1452 (614062) @ Episode 1771/10000, loss: 0.0021571288816630842\n",
      "Episode Reward: 40.0\n",
      "Step 710 (614772) @ Episode 1772/10000, loss: 0.00246492843143641954\n",
      "Episode Reward: 12.0\n",
      "Step 1102 (615874) @ Episode 1773/10000, loss: 0.0087773548439145094\n",
      "Episode Reward: 21.0\n",
      "Step 919 (616793) @ Episode 1774/10000, loss: 0.0014178835554048422\n",
      "Episode Reward: 30.0\n",
      "Step 1033 (617826) @ Episode 1775/10000, loss: 0.0021234450396150357\n",
      "Episode Reward: 24.0\n",
      "Step 833 (618659) @ Episode 1776/10000, loss: 0.00110479467548429973\n",
      "Episode Reward: 14.0\n",
      "Step 1043 (619702) @ Episode 1777/10000, loss: 0.0033810096792876724\n",
      "Episode Reward: 22.0\n",
      "Step 297 (619999) @ Episode 1778/10000, loss: 0.00133340503089129926\n",
      " Copied model parameters to target network\n",
      "Step 897 (620599) @ Episode 1778/10000, loss: 0.00213999347761273473\n",
      "Episode Reward: 16.0\n",
      "Step 1159 (621758) @ Episode 1779/10000, loss: 0.0083658481016755105\n",
      "Episode Reward: 28.0\n",
      "Step 806 (622564) @ Episode 1780/10000, loss: 0.01097793132066726766\n",
      "Episode Reward: 18.0\n",
      "Step 891 (623455) @ Episode 1781/10000, loss: 0.00361235882155597274\n",
      "Episode Reward: 15.0\n",
      "Step 891 (624346) @ Episode 1782/10000, loss: 0.00501985521987080634\n",
      "Episode Reward: 16.0\n",
      "Step 758 (625104) @ Episode 1783/10000, loss: 0.01173261087387800244\n",
      "Episode Reward: 13.0\n",
      "Step 629 (625733) @ Episode 1784/10000, loss: 0.0024260871578007936\n",
      "Episode Reward: 11.0\n",
      "Step 603 (626336) @ Episode 1785/10000, loss: 0.00204945495352149424\n",
      "Episode Reward: 10.0\n",
      "Step 1125 (627461) @ Episode 1786/10000, loss: 0.0017414024332538247\n",
      "Episode Reward: 20.0\n",
      "Step 865 (628326) @ Episode 1787/10000, loss: 0.0009755330975167453\n",
      "Episode Reward: 18.0\n",
      "Step 1010 (629336) @ Episode 1788/10000, loss: 0.0029905382543802267\n",
      "Episode Reward: 22.0\n",
      "Step 663 (629999) @ Episode 1789/10000, loss: 0.0028303619474172592\n",
      " Copied model parameters to target network\n",
      "Step 811 (630147) @ Episode 1789/10000, loss: 0.0019587730057537556\n",
      "Episode Reward: 21.0\n",
      "Step 847 (630994) @ Episode 1790/10000, loss: 0.00248180818744003775\n",
      "Episode Reward: 14.0\n",
      "Step 827 (631821) @ Episode 1791/10000, loss: 0.00311730662360787434\n",
      "Episode Reward: 17.0\n",
      "Step 1405 (633226) @ Episode 1792/10000, loss: 0.0013985906261950731\n",
      "Episode Reward: 32.0\n",
      "Step 747 (633973) @ Episode 1793/10000, loss: 0.00912894774228334423\n",
      "Episode Reward: 13.0\n",
      "Step 751 (634724) @ Episode 1794/10000, loss: 0.00973000377416610783\n",
      "Episode Reward: 19.0\n",
      "Step 1056 (635780) @ Episode 1795/10000, loss: 0.0007194259087555115\n",
      "Episode Reward: 24.0\n",
      "Step 774 (636554) @ Episode 1796/10000, loss: 0.01447501964867115846\n",
      "Episode Reward: 12.0\n",
      "Step 699 (637253) @ Episode 1797/10000, loss: 0.0039507960900664333\n",
      "Episode Reward: 16.0\n",
      "Step 795 (638048) @ Episode 1798/10000, loss: 0.0229079890996217734\n",
      "Episode Reward: 13.0\n",
      "Step 709 (638757) @ Episode 1799/10000, loss: 0.0013027377426624298\n",
      "Episode Reward: 11.0\n",
      "Step 903 (639660) @ Episode 1800/10000, loss: 0.01815495081245899227\n",
      "Episode Reward: 21.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 18:23:49,656] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video001800.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 339 (639999) @ Episode 1801/10000, loss: 0.00187475432176142935\n",
      " Copied model parameters to target network\n",
      "Step 797 (640457) @ Episode 1801/10000, loss: 0.0017379745841026306\n",
      "Episode Reward: 19.0\n",
      "Step 728 (641185) @ Episode 1802/10000, loss: 0.00434535555541515355\n",
      "Episode Reward: 12.0\n",
      "Step 903 (642088) @ Episode 1803/10000, loss: 0.00216683326289057734\n",
      "Episode Reward: 18.0\n",
      "Step 785 (642873) @ Episode 1804/10000, loss: 0.00171170278917998084\n",
      "Episode Reward: 13.0\n",
      "Step 961 (643834) @ Episode 1805/10000, loss: 0.00081215251702815295\n",
      "Episode Reward: 24.0\n",
      "Step 921 (644755) @ Episode 1806/10000, loss: 0.00336827477440238744\n",
      "Episode Reward: 15.0\n",
      "Step 905 (645660) @ Episode 1807/10000, loss: 0.00162524171173572546\n",
      "Episode Reward: 19.0\n",
      "Step 1015 (646675) @ Episode 1808/10000, loss: 0.0037778252735733986\n",
      "Episode Reward: 22.0\n",
      "Step 914 (647589) @ Episode 1809/10000, loss: 0.00486887060105800646\n",
      "Episode Reward: 20.0\n",
      "Step 1418 (649007) @ Episode 1810/10000, loss: 0.00175373500678688293\n",
      "Episode Reward: 41.0\n",
      "Step 962 (649969) @ Episode 1811/10000, loss: 0.00153303565457463264\n",
      "Episode Reward: 15.0\n",
      "Step 30 (649999) @ Episode 1812/10000, loss: 0.0006713705370202661\n",
      " Copied model parameters to target network\n",
      "Step 857 (650826) @ Episode 1812/10000, loss: 0.00143784144893288613\n",
      "Episode Reward: 20.0\n",
      "Step 1008 (651834) @ Episode 1813/10000, loss: 0.0361148342490196232\n",
      "Episode Reward: 20.0\n",
      "Step 749 (652583) @ Episode 1814/10000, loss: 0.00073227420216426255\n",
      "Episode Reward: 16.0\n",
      "Step 814 (653397) @ Episode 1815/10000, loss: 0.00195842166431248284\n",
      "Episode Reward: 18.0\n",
      "Step 1304 (654701) @ Episode 1816/10000, loss: 0.00089094467693939876\n",
      "Episode Reward: 33.0\n",
      "Step 945 (655646) @ Episode 1817/10000, loss: 0.00107166287489235456\n",
      "Episode Reward: 15.0\n",
      "Step 782 (656428) @ Episode 1818/10000, loss: 0.00114027864765375855\n",
      "Episode Reward: 12.0\n",
      "Step 1361 (657789) @ Episode 1819/10000, loss: 0.01287929806858301236\n",
      "Episode Reward: 36.0\n",
      "Step 842 (658631) @ Episode 1820/10000, loss: 0.00172173604369163516\n",
      "Episode Reward: 17.0\n",
      "Step 719 (659350) @ Episode 1821/10000, loss: 0.00103028828743845224\n",
      "Episode Reward: 18.0\n",
      "Step 649 (659999) @ Episode 1822/10000, loss: 0.00135315663646906613\n",
      " Copied model parameters to target network\n",
      "Step 909 (660259) @ Episode 1822/10000, loss: 0.00276453187689185147\n",
      "Episode Reward: 15.0\n",
      "Step 939 (661198) @ Episode 1823/10000, loss: 0.00206067669205367576\n",
      "Episode Reward: 18.0\n",
      "Step 904 (662102) @ Episode 1824/10000, loss: 0.00314119551330804824\n",
      "Episode Reward: 15.0\n",
      "Step 931 (663033) @ Episode 1825/10000, loss: 0.00067697843769565225\n",
      "Episode Reward: 19.0\n",
      "Step 761 (663794) @ Episode 1826/10000, loss: 0.00070709607098251584\n",
      "Episode Reward: 10.0\n",
      "Step 1027 (664821) @ Episode 1827/10000, loss: 0.0017130214255303144\n",
      "Episode Reward: 20.0\n",
      "Step 897 (665718) @ Episode 1828/10000, loss: 0.00135318795219063763\n",
      "Episode Reward: 16.0\n",
      "Step 1311 (667029) @ Episode 1829/10000, loss: 0.00196357024833562255\n",
      "Episode Reward: 21.0\n",
      "Step 1230 (668259) @ Episode 1830/10000, loss: 0.00430002994835376727\n",
      "Episode Reward: 29.0\n",
      "Step 940 (669199) @ Episode 1831/10000, loss: 0.00116483052261173737\n",
      "Episode Reward: 21.0\n",
      "Step 800 (669999) @ Episode 1832/10000, loss: 0.02112795785069465645\n",
      " Copied model parameters to target network\n",
      "Step 1141 (670340) @ Episode 1832/10000, loss: 0.0038892764132469893\n",
      "Episode Reward: 23.0\n",
      "Step 1116 (671456) @ Episode 1833/10000, loss: 0.0024055920075625181\n",
      "Episode Reward: 19.0\n",
      "Step 1056 (672512) @ Episode 1834/10000, loss: 0.0022785714827477934\n",
      "Episode Reward: 21.0\n",
      "Step 927 (673439) @ Episode 1835/10000, loss: 0.00415439391508698574\n",
      "Episode Reward: 15.0\n",
      "Step 881 (674320) @ Episode 1836/10000, loss: 0.0107582490891218195\n",
      "Episode Reward: 15.0\n",
      "Step 1131 (675451) @ Episode 1837/10000, loss: 0.00496367085725069056\n",
      "Episode Reward: 24.0\n",
      "Step 1115 (676566) @ Episode 1838/10000, loss: 0.0010402095504105091\n",
      "Episode Reward: 27.0\n",
      "Step 783 (677349) @ Episode 1839/10000, loss: 0.00104109279345721476\n",
      "Episode Reward: 17.0\n",
      "Step 825 (678174) @ Episode 1840/10000, loss: 0.00103638239670544865\n",
      "Episode Reward: 17.0\n",
      "Step 849 (679023) @ Episode 1841/10000, loss: 0.00155952549539506444\n",
      "Episode Reward: 14.0\n",
      "Step 870 (679893) @ Episode 1842/10000, loss: 0.01005485933274030747\n",
      "Episode Reward: 17.0\n",
      "Step 106 (679999) @ Episode 1843/10000, loss: 0.0029956391081213953\n",
      " Copied model parameters to target network\n",
      "Step 822 (680715) @ Episode 1843/10000, loss: 0.00129122822545468835\n",
      "Episode Reward: 14.0\n",
      "Step 1068 (681783) @ Episode 1844/10000, loss: 0.0049312761984765535\n",
      "Episode Reward: 18.0\n",
      "Step 1182 (682965) @ Episode 1845/10000, loss: 0.0020006773993372917\n",
      "Episode Reward: 36.0\n",
      "Step 1086 (684051) @ Episode 1846/10000, loss: 0.0020202661398798227\n",
      "Episode Reward: 29.0\n",
      "Step 1017 (685068) @ Episode 1847/10000, loss: 0.0021789430174976587\n",
      "Episode Reward: 20.0\n",
      "Step 1051 (686119) @ Episode 1848/10000, loss: 0.0007167436415329576\n",
      "Episode Reward: 19.0\n",
      "Step 902 (687021) @ Episode 1849/10000, loss: 0.00252094678580760967\n",
      "Episode Reward: 20.0\n",
      "Step 899 (687920) @ Episode 1850/10000, loss: 0.0036499504931271076\n",
      "Episode Reward: 16.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 18:31:03,124] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video001850.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1053 (688973) @ Episode 1851/10000, loss: 0.0057131489738821989\n",
      "Episode Reward: 21.0\n",
      "Step 779 (689752) @ Episode 1852/10000, loss: 0.03285607323050499177\n",
      "Episode Reward: 13.0\n",
      "Step 247 (689999) @ Episode 1853/10000, loss: 0.00529812090098857965\n",
      " Copied model parameters to target network\n",
      "Step 924 (690676) @ Episode 1853/10000, loss: 0.0015462700976058842\n",
      "Episode Reward: 18.0\n",
      "Step 895 (691571) @ Episode 1854/10000, loss: 0.00072713172994554044\n",
      "Episode Reward: 16.0\n",
      "Step 1116 (692687) @ Episode 1855/10000, loss: 0.0010943206725642085\n",
      "Episode Reward: 19.0\n",
      "Step 840 (693527) @ Episode 1856/10000, loss: 0.00471498258411884325\n",
      "Episode Reward: 21.0\n",
      "Step 1069 (694596) @ Episode 1857/10000, loss: 0.0007132332539185882\n",
      "Episode Reward: 19.0\n",
      "Step 663 (695259) @ Episode 1858/10000, loss: 0.00097669428214430815\n",
      "Episode Reward: 8.0\n",
      "Step 631 (695890) @ Episode 1859/10000, loss: 0.00856091547757387274\n",
      "Episode Reward: 10.0\n",
      "Step 869 (696759) @ Episode 1860/10000, loss: 0.00109121017158031465\n",
      "Episode Reward: 14.0\n",
      "Step 788 (697547) @ Episode 1861/10000, loss: 0.00342769455164670943\n",
      "Episode Reward: 13.0\n",
      "Step 995 (698542) @ Episode 1862/10000, loss: 0.00114545656833797786\n",
      "Episode Reward: 25.0\n",
      "Step 1046 (699588) @ Episode 1863/10000, loss: 0.0016768781933933496\n",
      "Episode Reward: 26.0\n",
      "Step 411 (699999) @ Episode 1864/10000, loss: 0.0133482646197080613\n",
      " Copied model parameters to target network\n",
      "Step 972 (700560) @ Episode 1864/10000, loss: 0.00498776044696569453\n",
      "Episode Reward: 19.0\n",
      "Step 1013 (701573) @ Episode 1865/10000, loss: 0.0007984612602740526\n",
      "Episode Reward: 18.0\n",
      "Step 1078 (702651) @ Episode 1866/10000, loss: 0.0190532021224498754\n",
      "Episode Reward: 23.0\n",
      "Step 986 (703637) @ Episode 1867/10000, loss: 0.01546042412519455575\n",
      "Episode Reward: 18.0\n",
      "Step 719 (704356) @ Episode 1868/10000, loss: 0.0013083405792713165\n",
      "Episode Reward: 16.0\n",
      "Step 833 (705189) @ Episode 1869/10000, loss: 0.00282163033261895274\n",
      "Episode Reward: 16.0\n",
      "Step 707 (705896) @ Episode 1870/10000, loss: 0.00072871067095547917\n",
      "Episode Reward: 15.0\n",
      "Step 1166 (707062) @ Episode 1871/10000, loss: 0.0115794967859983441\n",
      "Episode Reward: 27.0\n",
      "Step 709 (707771) @ Episode 1872/10000, loss: 0.00331658171489834847\n",
      "Episode Reward: 12.0\n",
      "Step 866 (708637) @ Episode 1873/10000, loss: 0.00192179728765040646\n",
      "Episode Reward: 16.0\n",
      "Step 936 (709573) @ Episode 1874/10000, loss: 0.0011164827737957247\n",
      "Episode Reward: 18.0\n",
      "Step 426 (709999) @ Episode 1875/10000, loss: 0.00419033737853169496\n",
      " Copied model parameters to target network\n",
      "Step 882 (710455) @ Episode 1875/10000, loss: 0.00421545701101422347\n",
      "Episode Reward: 19.0\n",
      "Step 606 (711061) @ Episode 1876/10000, loss: 0.00154648814350366646\n",
      "Episode Reward: 10.0\n",
      "Step 622 (711683) @ Episode 1877/10000, loss: 0.00113437848631292584\n",
      "Episode Reward: 10.0\n",
      "Step 705 (712388) @ Episode 1878/10000, loss: 0.00134741258807480343\n",
      "Episode Reward: 13.0\n",
      "Step 872 (713260) @ Episode 1879/10000, loss: 0.00091915455413982277\n",
      "Episode Reward: 19.0\n",
      "Step 1030 (714290) @ Episode 1880/10000, loss: 0.0028051594272255898\n",
      "Episode Reward: 17.0\n",
      "Step 1115 (715405) @ Episode 1881/10000, loss: 0.00326301623135805136\n",
      "Episode Reward: 26.0\n",
      "Step 1194 (716599) @ Episode 1882/10000, loss: 0.0106504242867231378\n",
      "Episode Reward: 23.0\n",
      "Step 884 (717483) @ Episode 1883/10000, loss: 0.00126334989909082657\n",
      "Episode Reward: 14.0\n",
      "Step 1224 (718707) @ Episode 1884/10000, loss: 0.01927116140723228564\n",
      "Episode Reward: 24.0\n",
      "Step 829 (719536) @ Episode 1885/10000, loss: 0.00117296073585748675\n",
      "Episode Reward: 15.0\n",
      "Step 463 (719999) @ Episode 1886/10000, loss: 0.0019586447160691023\n",
      " Copied model parameters to target network\n",
      "Step 690 (720226) @ Episode 1886/10000, loss: 0.0079852584749460225\n",
      "Episode Reward: 11.0\n",
      "Step 1093 (721319) @ Episode 1887/10000, loss: 0.0021213828586041927\n",
      "Episode Reward: 23.0\n",
      "Step 629 (721948) @ Episode 1888/10000, loss: 0.0044524893164634705\n",
      "Episode Reward: 10.0\n",
      "Step 1129 (723077) @ Episode 1889/10000, loss: 0.0174643099308013995\n",
      "Episode Reward: 25.0\n",
      "Step 778 (723855) @ Episode 1890/10000, loss: 0.3065523803234100391\n",
      "Episode Reward: 12.0\n",
      "Step 937 (724792) @ Episode 1891/10000, loss: 0.00120078702457249165\n",
      "Episode Reward: 14.0\n",
      "Step 1084 (725876) @ Episode 1892/10000, loss: 0.0019295325037091977\n",
      "Episode Reward: 20.0\n",
      "Step 1118 (726994) @ Episode 1893/10000, loss: 0.0041597681120038033\n",
      "Episode Reward: 17.0\n",
      "Step 858 (727852) @ Episode 1894/10000, loss: 0.0011031420435756445\n",
      "Episode Reward: 15.0\n",
      "Step 1524 (729376) @ Episode 1895/10000, loss: 0.0060373954474925995\n",
      "Episode Reward: 29.0\n",
      "Step 623 (729999) @ Episode 1896/10000, loss: 0.0010343593312427402\n",
      " Copied model parameters to target network\n",
      "Step 1002 (730378) @ Episode 1896/10000, loss: 0.0017456079367548227\n",
      "Episode Reward: 18.0\n",
      "Step 813 (731191) @ Episode 1897/10000, loss: 0.0158670283854007723\n",
      "Episode Reward: 15.0\n",
      "Step 826 (732017) @ Episode 1898/10000, loss: 0.0015352804912254214\n",
      "Episode Reward: 14.0\n",
      "Step 967 (732984) @ Episode 1899/10000, loss: 0.03264898061752319844\n",
      "Episode Reward: 18.0\n",
      "Step 747 (733731) @ Episode 1900/10000, loss: 0.0012794709764420986\n",
      "Episode Reward: 18.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 18:37:54,510] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video001900.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1021 (734752) @ Episode 1901/10000, loss: 0.0020886461716145277\n",
      "Episode Reward: 21.0\n",
      "Step 931 (735683) @ Episode 1902/10000, loss: 0.02078149840235713476\n",
      "Episode Reward: 21.0\n",
      "Step 1053 (736736) @ Episode 1903/10000, loss: 0.0013559279032051563\n",
      "Episode Reward: 18.0\n",
      "Step 998 (737734) @ Episode 1904/10000, loss: 0.0014682461041957145\n",
      "Episode Reward: 22.0\n",
      "Step 1201 (738935) @ Episode 1905/10000, loss: 0.0383612439036369373\n",
      "Episode Reward: 26.0\n",
      "Step 802 (739737) @ Episode 1906/10000, loss: 0.00192569650243967773\n",
      "Episode Reward: 14.0\n",
      "Step 262 (739999) @ Episode 1907/10000, loss: 0.0032346202060580254\n",
      " Copied model parameters to target network\n",
      "Step 845 (740582) @ Episode 1907/10000, loss: 0.00171670189592987326\n",
      "Episode Reward: 24.0\n",
      "Step 816 (741398) @ Episode 1908/10000, loss: 0.00208701076917350344\n",
      "Episode Reward: 18.0\n",
      "Step 894 (742292) @ Episode 1909/10000, loss: 0.0021561481989920147\n",
      "Episode Reward: 20.0\n",
      "Step 643 (742935) @ Episode 1910/10000, loss: 0.0021820773836225279\n",
      "Episode Reward: 10.0\n",
      "Step 1198 (744133) @ Episode 1911/10000, loss: 0.0030194600112736225\n",
      "Episode Reward: 35.0\n",
      "Step 1223 (745356) @ Episode 1912/10000, loss: 0.0009208371629938483\n",
      "Episode Reward: 20.0\n",
      "Step 754 (746110) @ Episode 1913/10000, loss: 0.00259020086377859155\n",
      "Episode Reward: 13.0\n",
      "Step 681 (746791) @ Episode 1914/10000, loss: 0.01931961439549923655\n",
      "Episode Reward: 10.0\n",
      "Step 844 (747635) @ Episode 1915/10000, loss: 0.00150306324940174825\n",
      "Episode Reward: 15.0\n",
      "Step 979 (748614) @ Episode 1916/10000, loss: 0.00107379606924951085\n",
      "Episode Reward: 17.0\n",
      "Step 775 (749389) @ Episode 1917/10000, loss: 0.00093082687817513944\n",
      "Episode Reward: 17.0\n",
      "Step 610 (749999) @ Episode 1918/10000, loss: 0.00463018286973238733\n",
      " Copied model parameters to target network\n",
      "Step 1348 (750737) @ Episode 1918/10000, loss: 0.0012333894846960902\n",
      "Episode Reward: 25.0\n",
      "Step 1169 (751906) @ Episode 1919/10000, loss: 0.0054774596355855465\n",
      "Episode Reward: 24.0\n",
      "Step 750 (752656) @ Episode 1920/10000, loss: 0.0032694828696548942\n",
      "Episode Reward: 13.0\n",
      "Step 1118 (753774) @ Episode 1921/10000, loss: 0.0036914499942213297\n",
      "Episode Reward: 19.0\n",
      "Step 887 (754661) @ Episode 1922/10000, loss: 0.0022726794704794884\n",
      "Episode Reward: 15.0\n",
      "Step 1020 (755681) @ Episode 1923/10000, loss: 0.0021382570266723633\n",
      "Episode Reward: 18.0\n",
      "Step 1104 (756785) @ Episode 1924/10000, loss: 0.0024823811836540748\n",
      "Episode Reward: 29.0\n",
      "Step 1022 (757807) @ Episode 1925/10000, loss: 0.0014023639960214496\n",
      "Episode Reward: 20.0\n",
      "Step 795 (758602) @ Episode 1926/10000, loss: 0.0089723980054259344\n",
      "Episode Reward: 19.0\n",
      "Step 1004 (759606) @ Episode 1927/10000, loss: 0.0026236702688038358\n",
      "Episode Reward: 20.0\n",
      "Step 393 (759999) @ Episode 1928/10000, loss: 0.0041254493407905152\n",
      " Copied model parameters to target network\n",
      "Step 1028 (760634) @ Episode 1928/10000, loss: 0.0008827211568132043\n",
      "Episode Reward: 21.0\n",
      "Step 899 (761533) @ Episode 1929/10000, loss: 0.00138714467175304946\n",
      "Episode Reward: 14.0\n",
      "Step 836 (762369) @ Episode 1930/10000, loss: 0.00345207657665014275\n",
      "Episode Reward: 15.0\n",
      "Step 931 (763300) @ Episode 1931/10000, loss: 0.00197136937640607366\n",
      "Episode Reward: 21.0\n",
      "Step 1108 (764408) @ Episode 1932/10000, loss: 0.0013522201916202903\n",
      "Episode Reward: 27.0\n",
      "Step 1226 (765634) @ Episode 1933/10000, loss: 0.0009332672343589365\n",
      "Episode Reward: 22.0\n",
      "Step 682 (766316) @ Episode 1934/10000, loss: 0.00573762413114309356\n",
      "Episode Reward: 11.0\n",
      "Step 963 (767279) @ Episode 1935/10000, loss: 0.00644860882312059474\n",
      "Episode Reward: 16.0\n",
      "Step 1034 (768313) @ Episode 1936/10000, loss: 0.00213465024717152143\n",
      "Episode Reward: 22.0\n",
      "Step 737 (769050) @ Episode 1937/10000, loss: 0.0020811008289456367\n",
      "Episode Reward: 12.0\n",
      "Step 949 (769999) @ Episode 1938/10000, loss: 0.00111926626414060664\n",
      " Copied model parameters to target network\n",
      "Step 1266 (770316) @ Episode 1938/10000, loss: 0.0035323128104209965\n",
      "Episode Reward: 26.0\n",
      "Step 938 (771254) @ Episode 1939/10000, loss: 0.0032386900857090959\n",
      "Episode Reward: 19.0\n",
      "Step 882 (772136) @ Episode 1940/10000, loss: 0.00189665867947041997\n",
      "Episode Reward: 14.0\n",
      "Step 866 (773002) @ Episode 1941/10000, loss: 0.0011609833454713225\n",
      "Episode Reward: 18.0\n",
      "Step 949 (773951) @ Episode 1942/10000, loss: 0.00119093339890241625\n",
      "Episode Reward: 16.0\n",
      "Step 876 (774827) @ Episode 1943/10000, loss: 0.0008135335519909859\n",
      "Episode Reward: 16.0\n",
      "Step 1031 (775858) @ Episode 1944/10000, loss: 0.0016098502092063427\n",
      "Episode Reward: 31.0\n",
      "Step 690 (776548) @ Episode 1945/10000, loss: 0.00194557127542793754\n",
      "Episode Reward: 11.0\n",
      "Step 802 (777350) @ Episode 1946/10000, loss: 0.00147617107722908264\n",
      "Episode Reward: 18.0\n",
      "Step 1053 (778403) @ Episode 1947/10000, loss: 0.0022517801262438297\n",
      "Episode Reward: 22.0\n",
      "Step 873 (779276) @ Episode 1948/10000, loss: 0.0023114162031561136\n",
      "Episode Reward: 14.0\n",
      "Step 723 (779999) @ Episode 1949/10000, loss: 0.0010501029901206493\n",
      " Copied model parameters to target network\n",
      "Step 966 (780242) @ Episode 1949/10000, loss: 0.0057270722463727478\n",
      "Episode Reward: 21.0\n",
      "Step 737 (780979) @ Episode 1950/10000, loss: 0.00998394470661878667\n",
      "Episode Reward: 12.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 18:44:59,679] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video001950.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 910 (781889) @ Episode 1951/10000, loss: 0.0289425905793905268\n",
      "Episode Reward: 15.0\n",
      "Step 510 (782399) @ Episode 1952/10000, loss: 0.0028551616705954075\n",
      "Episode Reward: 7.0\n",
      "Step 700 (783099) @ Episode 1953/10000, loss: 0.0017428551800549034\n",
      "Episode Reward: 12.0\n",
      "Step 948 (784047) @ Episode 1954/10000, loss: 0.0021862282883375883\n",
      "Episode Reward: 17.0\n",
      "Step 1014 (785061) @ Episode 1955/10000, loss: 0.0206310693174600695\n",
      "Episode Reward: 23.0\n",
      "Step 1097 (786158) @ Episode 1956/10000, loss: 0.0037858304567635065\n",
      "Episode Reward: 17.0\n",
      "Step 646 (786804) @ Episode 1957/10000, loss: 0.00204508937895298377\n",
      "Episode Reward: 10.0\n",
      "Step 848 (787652) @ Episode 1958/10000, loss: 0.00495630968362093427\n",
      "Episode Reward: 21.0\n",
      "Step 974 (788626) @ Episode 1959/10000, loss: 0.00339075503870844845\n",
      "Episode Reward: 20.0\n",
      "Step 1151 (789777) @ Episode 1960/10000, loss: 0.0012372653000056744\n",
      "Episode Reward: 27.0\n",
      "Step 222 (789999) @ Episode 1961/10000, loss: 0.00145878433249890814\n",
      " Copied model parameters to target network\n",
      "Step 907 (790684) @ Episode 1961/10000, loss: 0.00201081461273133754\n",
      "Episode Reward: 15.0\n",
      "Step 988 (791672) @ Episode 1962/10000, loss: 0.0011333588045090437\n",
      "Episode Reward: 20.0\n",
      "Step 937 (792609) @ Episode 1963/10000, loss: 0.00506368791684508353\n",
      "Episode Reward: 16.0\n",
      "Step 727 (793336) @ Episode 1964/10000, loss: 0.0024148747324943542\n",
      "Episode Reward: 10.0\n",
      "Step 961 (794297) @ Episode 1965/10000, loss: 0.0027730024885386238\n",
      "Episode Reward: 21.0\n",
      "Step 673 (794970) @ Episode 1966/10000, loss: 0.00616115517914295265\n",
      "Episode Reward: 15.0\n",
      "Step 1167 (796137) @ Episode 1967/10000, loss: 0.00156681181397289043\n",
      "Episode Reward: 34.0\n",
      "Step 1147 (797284) @ Episode 1968/10000, loss: 0.0128679051995277416\n",
      "Episode Reward: 22.0\n",
      "Step 1115 (798399) @ Episode 1969/10000, loss: 0.0033182741608470683\n",
      "Episode Reward: 23.0\n",
      "Step 895 (799294) @ Episode 1970/10000, loss: 0.00253892177715897566\n",
      "Episode Reward: 16.0\n",
      "Step 705 (799999) @ Episode 1971/10000, loss: 0.00241891224868595627\n",
      " Copied model parameters to target network\n",
      "Step 1110 (800404) @ Episode 1971/10000, loss: 0.0010274698724970222\n",
      "Episode Reward: 25.0\n",
      "Step 849 (801253) @ Episode 1972/10000, loss: 0.01726376637816429447\n",
      "Episode Reward: 16.0\n",
      "Step 831 (802084) @ Episode 1973/10000, loss: 0.0023306047078222036\n",
      "Episode Reward: 15.0\n",
      "Step 978 (803062) @ Episode 1974/10000, loss: 0.0014346049865707755\n",
      "Episode Reward: 20.0\n",
      "Step 889 (803951) @ Episode 1975/10000, loss: 0.0012546001235023144\n",
      "Episode Reward: 14.0\n",
      "Step 791 (804742) @ Episode 1976/10000, loss: 0.0046186195686459546\n",
      "Episode Reward: 14.0\n",
      "Step 936 (805678) @ Episode 1977/10000, loss: 0.00182423857040703325\n",
      "Episode Reward: 16.0\n",
      "Step 890 (806568) @ Episode 1978/10000, loss: 0.0012682587839663029\n",
      "Episode Reward: 17.0\n",
      "Step 950 (807518) @ Episode 1979/10000, loss: 0.00694407382979989054\n",
      "Episode Reward: 24.0\n",
      "Step 587 (808105) @ Episode 1980/10000, loss: 0.0033424855209887028\n",
      "Episode Reward: 9.0\n",
      "Step 958 (809063) @ Episode 1981/10000, loss: 0.00131107913330197336\n",
      "Episode Reward: 22.0\n",
      "Step 734 (809797) @ Episode 1982/10000, loss: 0.00144683453254401685\n",
      "Episode Reward: 12.0\n",
      "Step 202 (809999) @ Episode 1983/10000, loss: 0.0018503466853871942\n",
      " Copied model parameters to target network\n",
      "Step 946 (810743) @ Episode 1983/10000, loss: 0.0008525819284841418\n",
      "Episode Reward: 22.0\n",
      "Step 882 (811625) @ Episode 1984/10000, loss: 0.00084863655501976616\n",
      "Episode Reward: 15.0\n",
      "Step 1089 (812714) @ Episode 1985/10000, loss: 0.0069776265881955626\n",
      "Episode Reward: 21.0\n",
      "Step 679 (813393) @ Episode 1986/10000, loss: 0.00452262302860617633\n",
      "Episode Reward: 11.0\n",
      "Step 957 (814350) @ Episode 1987/10000, loss: 0.0168416891247034077\n",
      "Episode Reward: 20.0\n",
      "Step 1015 (815365) @ Episode 1988/10000, loss: 0.0517611838877201155\n",
      "Episode Reward: 20.0\n",
      "Step 973 (816338) @ Episode 1989/10000, loss: 0.0064936410635709764\n",
      "Episode Reward: 24.0\n",
      "Step 796 (817134) @ Episode 1990/10000, loss: 0.0414946302771568335\n",
      "Episode Reward: 14.0\n",
      "Step 713 (817847) @ Episode 1991/10000, loss: 0.0152262933552265173\n",
      "Episode Reward: 11.0\n",
      "Step 819 (818666) @ Episode 1992/10000, loss: 0.00334856542758643636\n",
      "Episode Reward: 15.0\n",
      "Step 1000 (819666) @ Episode 1993/10000, loss: 0.066377095878124242\n",
      "Episode Reward: 19.0\n",
      "Step 333 (819999) @ Episode 1994/10000, loss: 0.0030953530222177505\n",
      " Copied model parameters to target network\n",
      "Step 832 (820498) @ Episode 1994/10000, loss: 0.2381387054920196505\n",
      "Episode Reward: 16.0\n",
      "Step 909 (821407) @ Episode 1995/10000, loss: 0.0012608699034899473\n",
      "Episode Reward: 20.0\n",
      "Step 815 (822222) @ Episode 1996/10000, loss: 0.0031741608399897814\n",
      "Episode Reward: 17.0\n",
      "Step 801 (823023) @ Episode 1997/10000, loss: 0.00312304403632879266\n",
      "Episode Reward: 16.0\n",
      "Step 844 (823867) @ Episode 1998/10000, loss: 0.00215940759517252456\n",
      "Episode Reward: 14.0\n",
      "Step 1057 (824924) @ Episode 1999/10000, loss: 0.0762465596199035673\n",
      "Episode Reward: 19.0\n",
      "Step 518 (825442) @ Episode 2000/10000, loss: 0.0065095322206616487\n",
      "Episode Reward: 7.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 18:51:42,146] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video002000.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1170 (826612) @ Episode 2001/10000, loss: 0.0065606283023953447\n",
      "Episode Reward: 21.0\n",
      "Step 709 (827321) @ Episode 2002/10000, loss: 0.01189628336578607686\n",
      "Episode Reward: 11.0\n",
      "Step 645 (827966) @ Episode 2003/10000, loss: 0.00154683133587241174\n",
      "Episode Reward: 13.0\n",
      "Step 901 (828867) @ Episode 2004/10000, loss: 0.00255071325227618236\n",
      "Episode Reward: 15.0\n",
      "Step 667 (829534) @ Episode 2005/10000, loss: 0.00368109717965126047\n",
      "Episode Reward: 13.0\n",
      "Step 465 (829999) @ Episode 2006/10000, loss: 0.0133148021996021277\n",
      " Copied model parameters to target network\n",
      "Step 845 (830379) @ Episode 2006/10000, loss: 0.0016447800444439054\n",
      "Episode Reward: 13.0\n",
      "Step 1252 (831631) @ Episode 2007/10000, loss: 0.0109896399080753336\n",
      "Episode Reward: 24.0\n",
      "Step 1110 (832741) @ Episode 2008/10000, loss: 0.0026279801968485117\n",
      "Episode Reward: 21.0\n",
      "Step 882 (833623) @ Episode 2009/10000, loss: 0.0016404251800850034\n",
      "Episode Reward: 14.0\n",
      "Step 762 (834385) @ Episode 2010/10000, loss: 0.0026231436058878935\n",
      "Episode Reward: 17.0\n",
      "Step 1320 (835705) @ Episode 2011/10000, loss: 0.0040334053337574005\n",
      "Episode Reward: 26.0\n",
      "Step 1085 (836790) @ Episode 2012/10000, loss: 0.0173747912049293524\n",
      "Episode Reward: 23.0\n",
      "Step 1047 (837837) @ Episode 2013/10000, loss: 0.0071158902719616893\n",
      "Episode Reward: 33.0\n",
      "Step 1070 (838907) @ Episode 2014/10000, loss: 0.0020208766218274835\n",
      "Episode Reward: 19.0\n",
      "Step 1047 (839954) @ Episode 2015/10000, loss: 0.0850913822650909432\n",
      "Episode Reward: 19.0\n",
      "Step 45 (839999) @ Episode 2016/10000, loss: 0.0119398143142461786\n",
      " Copied model parameters to target network\n",
      "Step 563 (840517) @ Episode 2016/10000, loss: 0.0032121255062520504\n",
      "Episode Reward: 12.0\n",
      "Step 997 (841514) @ Episode 2017/10000, loss: 0.0026199424173682935\n",
      "Episode Reward: 21.0\n",
      "Step 1042 (842556) @ Episode 2018/10000, loss: 0.0025922483764588833\n",
      "Episode Reward: 26.0\n",
      "Step 972 (843528) @ Episode 2019/10000, loss: 0.0032978197559714317\n",
      "Episode Reward: 17.0\n",
      "Step 517 (844045) @ Episode 2020/10000, loss: 0.0162505805492401123\n",
      "Episode Reward: 7.0\n",
      "Step 424 (844469) @ Episode 2021/10000, loss: 0.0210652146488428168\n",
      "Episode Reward: 6.0\n",
      "Step 848 (845317) @ Episode 2022/10000, loss: 0.0032478561624884605\n",
      "Episode Reward: 25.0\n",
      "Step 446 (845763) @ Episode 2023/10000, loss: 0.0078938705846667294\n",
      "Episode Reward: 7.0\n",
      "Step 819 (846582) @ Episode 2024/10000, loss: 0.0014769284753128886\n",
      "Episode Reward: 13.0\n",
      "Step 902 (847484) @ Episode 2025/10000, loss: 0.0009205213282257318\n",
      "Episode Reward: 15.0\n",
      "Step 755 (848239) @ Episode 2026/10000, loss: 0.0034706583246588707\n",
      "Episode Reward: 17.0\n",
      "Step 568 (848807) @ Episode 2027/10000, loss: 0.0037638992071151733\n",
      "Episode Reward: 8.0\n",
      "Step 1192 (849999) @ Episode 2028/10000, loss: 0.0021921477746218443\n",
      " Copied model parameters to target network\n",
      "Step 1306 (850113) @ Episode 2028/10000, loss: 0.0013164313277229667\n",
      "Episode Reward: 37.0\n",
      "Step 1082 (851195) @ Episode 2029/10000, loss: 0.0012044131290167574\n",
      "Episode Reward: 28.0\n",
      "Step 697 (851892) @ Episode 2030/10000, loss: 0.0020791543647646904\n",
      "Episode Reward: 19.0\n",
      "Step 861 (852753) @ Episode 2031/10000, loss: 0.0029182620346546173\n",
      "Episode Reward: 17.0\n",
      "Step 649 (853402) @ Episode 2032/10000, loss: 0.0009333882480859756\n",
      "Episode Reward: 11.0\n",
      "Step 581 (853983) @ Episode 2033/10000, loss: 0.0054191900417208673\n",
      "Episode Reward: 10.0\n",
      "Step 750 (854733) @ Episode 2034/10000, loss: 0.0019415693823248148\n",
      "Episode Reward: 12.0\n",
      "Step 1394 (856127) @ Episode 2035/10000, loss: 0.0049025844782590875\n",
      "Episode Reward: 34.0\n",
      "Step 951 (857078) @ Episode 2036/10000, loss: 0.0009831063216552138\n",
      "Episode Reward: 22.0\n",
      "Step 1261 (858339) @ Episode 2037/10000, loss: 0.0030961688607931137\n",
      "Episode Reward: 23.0\n",
      "Step 898 (859237) @ Episode 2038/10000, loss: 0.0020913397893309593\n",
      "Episode Reward: 15.0\n",
      "Step 585 (859822) @ Episode 2039/10000, loss: 0.0019786332268267878\n",
      "Episode Reward: 13.0\n",
      "Step 177 (859999) @ Episode 2040/10000, loss: 0.0227677300572395325\n",
      " Copied model parameters to target network\n",
      "Step 890 (860712) @ Episode 2040/10000, loss: 0.0022944053635001183\n",
      "Episode Reward: 18.0\n",
      "Step 773 (861485) @ Episode 2041/10000, loss: 0.0079620676115155226\n",
      "Episode Reward: 18.0\n",
      "Step 1025 (862510) @ Episode 2042/10000, loss: 0.1163398325443267856\n",
      "Episode Reward: 17.0\n",
      "Step 635 (863145) @ Episode 2043/10000, loss: 0.0102559989318251614\n",
      "Episode Reward: 9.0\n",
      "Step 939 (864084) @ Episode 2044/10000, loss: 0.0056975432671606545\n",
      "Episode Reward: 17.0\n",
      "Step 534 (864618) @ Episode 2045/10000, loss: 0.0447642058134079078\n",
      "Episode Reward: 7.0\n",
      "Step 768 (865386) @ Episode 2046/10000, loss: 0.0066105886362493046\n",
      "Episode Reward: 13.0\n",
      "Step 587 (865973) @ Episode 2047/10000, loss: 0.0032611733768135317\n",
      "Episode Reward: 9.0\n",
      "Step 940 (866913) @ Episode 2048/10000, loss: 0.0029551715124398474\n",
      "Episode Reward: 29.0\n",
      "Step 860 (867773) @ Episode 2049/10000, loss: 0.0154944192618131642\n",
      "Episode Reward: 19.0\n",
      "Step 1072 (868845) @ Episode 2050/10000, loss: 0.0014513405039906502\n",
      "Episode Reward: 24.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 18:58:11,688] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video002050.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 911 (869756) @ Episode 2051/10000, loss: 0.0016671664780005813\n",
      "Episode Reward: 17.0\n",
      "Step 243 (869999) @ Episode 2052/10000, loss: 0.0018522131722420454\n",
      " Copied model parameters to target network\n",
      "Step 735 (870491) @ Episode 2052/10000, loss: 0.0434286110103130347\n",
      "Episode Reward: 14.0\n",
      "Step 1023 (871514) @ Episode 2053/10000, loss: 0.0048179505392909057\n",
      "Episode Reward: 19.0\n",
      "Step 563 (872077) @ Episode 2054/10000, loss: 0.0108549576252698943\n",
      "Episode Reward: 7.0\n",
      "Step 864 (872941) @ Episode 2055/10000, loss: 0.0244668144732713757\n",
      "Episode Reward: 16.0\n",
      "Step 760 (873701) @ Episode 2056/10000, loss: 0.0108874775469303135\n",
      "Episode Reward: 13.0\n",
      "Step 693 (874394) @ Episode 2057/10000, loss: 0.0018978278385475278\n",
      "Episode Reward: 14.0\n",
      "Step 1422 (875816) @ Episode 2058/10000, loss: 0.0052253077737987044\n",
      "Episode Reward: 31.0\n",
      "Step 1019 (876835) @ Episode 2059/10000, loss: 0.0076760854572057727\n",
      "Episode Reward: 31.0\n",
      "Step 1003 (877838) @ Episode 2060/10000, loss: 0.0075743240304291255\n",
      "Episode Reward: 28.0\n",
      "Step 810 (878648) @ Episode 2061/10000, loss: 0.0021243612281978135\n",
      "Episode Reward: 13.0\n",
      "Step 931 (879579) @ Episode 2062/10000, loss: 0.0080026481300592424\n",
      "Episode Reward: 16.0\n",
      "Step 420 (879999) @ Episode 2063/10000, loss: 0.0038726809434592724\n",
      " Copied model parameters to target network\n",
      "Step 728 (880307) @ Episode 2063/10000, loss: 0.0195837598294019796\n",
      "Episode Reward: 12.0\n",
      "Step 1295 (881602) @ Episode 2064/10000, loss: 0.0075156069360673432\n",
      "Episode Reward: 25.0\n",
      "Step 1212 (882814) @ Episode 2065/10000, loss: 0.0165165271610021615\n",
      "Episode Reward: 37.0\n",
      "Step 836 (883650) @ Episode 2066/10000, loss: 0.0141084510833024987\n",
      "Episode Reward: 13.0\n",
      "Step 804 (884454) @ Episode 2067/10000, loss: 0.0037691742181777954\n",
      "Episode Reward: 14.0\n",
      "Step 1026 (885480) @ Episode 2068/10000, loss: 0.0385039485991001187\n",
      "Episode Reward: 19.0\n",
      "Step 820 (886300) @ Episode 2069/10000, loss: 0.0041566393338143826\n",
      "Episode Reward: 13.0\n",
      "Step 880 (887180) @ Episode 2070/10000, loss: 0.0034221382811665535\n",
      "Episode Reward: 15.0\n",
      "Step 1054 (888234) @ Episode 2071/10000, loss: 0.0023869276046752934\n",
      "Episode Reward: 22.0\n",
      "Step 670 (888904) @ Episode 2072/10000, loss: 0.0028137101326137786\n",
      "Episode Reward: 18.0\n",
      "Step 908 (889812) @ Episode 2073/10000, loss: 0.0031075603328645235\n",
      "Episode Reward: 19.0\n",
      "Step 187 (889999) @ Episode 2074/10000, loss: 0.0024965892080217628\n",
      " Copied model parameters to target network\n",
      "Step 847 (890659) @ Episode 2074/10000, loss: 0.0021103639155626297\n",
      "Episode Reward: 21.0\n",
      "Step 990 (891649) @ Episode 2075/10000, loss: 0.0017753411084413528\n",
      "Episode Reward: 27.0\n",
      "Step 1196 (892845) @ Episode 2076/10000, loss: 0.0106847044080495835\n",
      "Episode Reward: 21.0\n",
      "Step 1107 (893952) @ Episode 2077/10000, loss: 0.0102432928979396825\n",
      "Episode Reward: 21.0\n",
      "Step 1632 (895584) @ Episode 2078/10000, loss: 0.0065854256972670555\n",
      "Episode Reward: 46.0\n",
      "Step 1162 (896746) @ Episode 2079/10000, loss: 0.0037222201935946946\n",
      "Episode Reward: 29.0\n",
      "Step 833 (897579) @ Episode 2080/10000, loss: 0.0024336869828402996\n",
      "Episode Reward: 16.0\n",
      "Step 979 (898558) @ Episode 2081/10000, loss: 0.0015692468732595444\n",
      "Episode Reward: 26.0\n",
      "Step 688 (899246) @ Episode 2082/10000, loss: 0.0009616963216103613\n",
      "Episode Reward: 33.0\n",
      "Step 753 (899999) @ Episode 2083/10000, loss: 0.0071137556806206754\n",
      " Copied model parameters to target network\n",
      "Step 848 (900094) @ Episode 2083/10000, loss: 0.0039923954755067825\n",
      "Episode Reward: 21.0\n",
      "Step 600 (900694) @ Episode 2084/10000, loss: 0.0068307528272271165\n",
      "Episode Reward: 15.0\n",
      "Step 1458 (902152) @ Episode 2085/10000, loss: 0.0122920628637075423\n",
      "Episode Reward: 40.0\n",
      "Step 1045 (903197) @ Episode 2086/10000, loss: 0.0017823753878474236\n",
      "Episode Reward: 20.0\n",
      "Step 1474 (904671) @ Episode 2087/10000, loss: 0.0032317778095602996\n",
      "Episode Reward: 40.0\n",
      "Step 843 (905514) @ Episode 2088/10000, loss: 0.0022026973310858014\n",
      "Episode Reward: 14.0\n",
      "Step 882 (906396) @ Episode 2089/10000, loss: 0.0097370799630880366\n",
      "Episode Reward: 17.0\n",
      "Step 928 (907324) @ Episode 2090/10000, loss: 0.0129467342048883445\n",
      "Episode Reward: 19.0\n",
      "Step 1079 (908403) @ Episode 2091/10000, loss: 0.0029925871640443868\n",
      "Episode Reward: 24.0\n",
      "Step 898 (909301) @ Episode 2092/10000, loss: 0.00623555295169353534\n",
      "Episode Reward: 15.0\n",
      "Step 580 (909881) @ Episode 2093/10000, loss: 0.0576991699635982536\n",
      "Episode Reward: 8.0\n",
      "Step 118 (909999) @ Episode 2094/10000, loss: 0.0057222666218876846\n",
      " Copied model parameters to target network\n",
      "Step 789 (910670) @ Episode 2094/10000, loss: 0.0016172730829566717\n",
      "Episode Reward: 13.0\n",
      "Step 510 (911180) @ Episode 2095/10000, loss: 0.0245816446840763138\n",
      "Episode Reward: 6.0\n",
      "Step 982 (912162) @ Episode 2096/10000, loss: 0.0047100018709897995\n",
      "Episode Reward: 17.0\n",
      "Step 1164 (913326) @ Episode 2097/10000, loss: 0.0020123105496168137\n",
      "Episode Reward: 23.0\n",
      "Step 1261 (914587) @ Episode 2098/10000, loss: 0.0055019548162817955\n",
      "Episode Reward: 33.0\n",
      "Step 800 (915387) @ Episode 2099/10000, loss: 0.0019534435123205185\n",
      "Episode Reward: 17.0\n",
      "Step 911 (916298) @ Episode 2100/10000, loss: 0.0041176448576152325\n",
      "Episode Reward: 21.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 19:05:18,642] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video002100.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1301 (917599) @ Episode 2101/10000, loss: 0.0035948022268712525\n",
      "Episode Reward: 25.0\n",
      "Step 1289 (918888) @ Episode 2102/10000, loss: 0.0087875062599778185\n",
      "Episode Reward: 27.0\n",
      "Step 1111 (919999) @ Episode 2103/10000, loss: 0.0055216373875737195\n",
      " Copied model parameters to target network\n",
      "Step 1114 (920002) @ Episode 2103/10000, loss: 0.0019459335599094635\n",
      "Episode Reward: 30.0\n",
      "Step 901 (920903) @ Episode 2104/10000, loss: 0.0024203108623623858\n",
      "Episode Reward: 22.0\n",
      "Step 1079 (921982) @ Episode 2105/10000, loss: 0.0026529207825660706\n",
      "Episode Reward: 24.0\n",
      "Step 983 (922965) @ Episode 2106/10000, loss: 0.0034515094012022023\n",
      "Episode Reward: 20.0\n",
      "Step 1400 (924365) @ Episode 2107/10000, loss: 0.0053131161257624636\n",
      "Episode Reward: 36.0\n",
      "Step 1269 (925634) @ Episode 2108/10000, loss: 0.0064114518463611683\n",
      "Episode Reward: 25.0\n",
      "Step 1330 (926964) @ Episode 2109/10000, loss: 0.0064080641604959965\n",
      "Episode Reward: 27.0\n",
      "Step 764 (927728) @ Episode 2110/10000, loss: 0.0055478117428729572\n",
      "Episode Reward: 13.0\n",
      "Step 879 (928607) @ Episode 2111/10000, loss: 0.0039894413203001023\n",
      "Episode Reward: 14.0\n",
      "Step 772 (929379) @ Episode 2112/10000, loss: 0.0411219745874404975\n",
      "Episode Reward: 12.0\n",
      "Step 620 (929999) @ Episode 2113/10000, loss: 0.0058685452677309515\n",
      " Copied model parameters to target network\n",
      "Step 1064 (930443) @ Episode 2113/10000, loss: 0.0046130768023431326\n",
      "Episode Reward: 20.0\n",
      "Step 879 (931322) @ Episode 2114/10000, loss: 0.0067769493907690056\n",
      "Episode Reward: 15.0\n",
      "Step 1186 (932508) @ Episode 2115/10000, loss: 0.0011745969532057643\n",
      "Episode Reward: 31.0\n",
      "Step 1693 (934201) @ Episode 2116/10000, loss: 0.0039754980243742476\n",
      "Episode Reward: 55.0\n",
      "Step 1416 (935617) @ Episode 2117/10000, loss: 0.0039166985079646117\n",
      "Episode Reward: 35.0\n",
      "Step 746 (936363) @ Episode 2118/10000, loss: 0.0126331094652414323\n",
      "Episode Reward: 21.0\n",
      "Step 1017 (937380) @ Episode 2119/10000, loss: 0.004371039569377899\n",
      "Episode Reward: 21.0\n",
      "Step 1152 (938532) @ Episode 2120/10000, loss: 0.0094220936298370365\n",
      "Episode Reward: 28.0\n",
      "Step 819 (939351) @ Episode 2121/10000, loss: 0.0022635066416114574\n",
      "Episode Reward: 15.0\n",
      "Step 648 (939999) @ Episode 2122/10000, loss: 0.0176522918045520789\n",
      " Copied model parameters to target network\n",
      "Step 1739 (941090) @ Episode 2122/10000, loss: 0.0026718887966126204\n",
      "Episode Reward: 46.0\n",
      "Step 1186 (942276) @ Episode 2123/10000, loss: 0.0111214537173509686\n",
      "Episode Reward: 36.0\n",
      "Step 1275 (943551) @ Episode 2124/10000, loss: 0.0058185020461678505\n",
      "Episode Reward: 31.0\n",
      "Step 1015 (944566) @ Episode 2125/10000, loss: 0.0094924587756395346\n",
      "Episode Reward: 18.0\n",
      "Step 508 (945074) @ Episode 2126/10000, loss: 0.0036165183410048485\n",
      "Episode Reward: 8.0\n",
      "Step 1202 (946276) @ Episode 2127/10000, loss: 0.0031765140593051913\n",
      "Episode Reward: 41.0\n",
      "Step 817 (947093) @ Episode 2128/10000, loss: 0.0060711805708706383\n",
      "Episode Reward: 17.0\n",
      "Step 1162 (948255) @ Episode 2129/10000, loss: 0.0015789070166647434\n",
      "Episode Reward: 22.0\n",
      "Step 864 (949119) @ Episode 2130/10000, loss: 0.0036252043209969997\n",
      "Episode Reward: 14.0\n",
      "Step 880 (949999) @ Episode 2131/10000, loss: 0.0018960247980430722\n",
      " Copied model parameters to target network\n",
      "Step 1082 (950201) @ Episode 2131/10000, loss: 0.0074299499392509467\n",
      "Episode Reward: 23.0\n",
      "Step 1277 (951478) @ Episode 2132/10000, loss: 0.0031036855652928352\n",
      "Episode Reward: 21.0\n",
      "Step 1005 (952483) @ Episode 2133/10000, loss: 0.0132782133296132093\n",
      "Episode Reward: 25.0\n",
      "Step 710 (953193) @ Episode 2134/10000, loss: 0.0064062229357659825\n",
      "Episode Reward: 11.0\n",
      "Step 798 (953991) @ Episode 2135/10000, loss: 0.0068223290145397194\n",
      "Episode Reward: 15.0\n",
      "Step 1058 (955049) @ Episode 2136/10000, loss: 0.0051156375557184227\n",
      "Episode Reward: 23.0\n",
      "Step 1098 (956147) @ Episode 2137/10000, loss: 0.0017351869028061628\n",
      "Episode Reward: 24.0\n",
      "Step 635 (956782) @ Episode 2138/10000, loss: 0.0047884937375783926\n",
      "Episode Reward: 10.0\n",
      "Step 678 (957460) @ Episode 2139/10000, loss: 0.0045679430477321155\n",
      "Episode Reward: 16.0\n",
      "Step 753 (958213) @ Episode 2140/10000, loss: 0.0032884380780160427\n",
      "Episode Reward: 15.0\n",
      "Step 1344 (959557) @ Episode 2141/10000, loss: 0.0035588103346526623\n",
      "Episode Reward: 35.0\n",
      "Step 442 (959999) @ Episode 2142/10000, loss: 0.0030147843062877655\n",
      " Copied model parameters to target network\n",
      "Step 608 (960165) @ Episode 2142/10000, loss: 0.0539510436356067668\n",
      "Episode Reward: 16.0\n",
      "Step 887 (961052) @ Episode 2143/10000, loss: 0.0117797516286373145\n",
      "Episode Reward: 20.0\n",
      "Step 1125 (962177) @ Episode 2144/10000, loss: 0.0055320831015706065\n",
      "Episode Reward: 28.0\n",
      "Step 1025 (963202) @ Episode 2145/10000, loss: 0.0177392754703760152\n",
      "Episode Reward: 22.0\n",
      "Step 952 (964154) @ Episode 2146/10000, loss: 0.0035965861752629284\n",
      "Episode Reward: 16.0\n",
      "Step 884 (965038) @ Episode 2147/10000, loss: 0.0023959497921168804\n",
      "Episode Reward: 18.0\n",
      "Step 894 (965932) @ Episode 2148/10000, loss: 0.0018337535439059138\n",
      "Episode Reward: 16.0\n",
      "Step 691 (966623) @ Episode 2149/10000, loss: 0.0037930821999907494\n",
      "Episode Reward: 11.0\n",
      "Step 718 (967341) @ Episode 2150/10000, loss: 0.0037738853134214886\n",
      "Episode Reward: 10.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 19:12:52,082] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video002150.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1195 (968536) @ Episode 2151/10000, loss: 0.0031237627845257529\n",
      "Episode Reward: 31.0\n",
      "Step 678 (969214) @ Episode 2152/10000, loss: 0.0044282693415880235\n",
      "Episode Reward: 10.0\n",
      "Step 785 (969999) @ Episode 2153/10000, loss: 0.0089915283024311073\n",
      " Copied model parameters to target network\n",
      "Step 1384 (970598) @ Episode 2153/10000, loss: 0.0126293236389756235\n",
      "Episode Reward: 56.0\n",
      "Step 793 (971391) @ Episode 2154/10000, loss: 0.0105248466134071354\n",
      "Episode Reward: 13.0\n",
      "Step 1332 (972723) @ Episode 2155/10000, loss: 0.0211042333394289316\n",
      "Episode Reward: 31.0\n",
      "Step 1060 (973783) @ Episode 2156/10000, loss: 0.0088960658758878795\n",
      "Episode Reward: 21.0\n",
      "Step 1252 (975035) @ Episode 2157/10000, loss: 0.0024682981893420224\n",
      "Episode Reward: 35.0\n",
      "Step 1214 (976249) @ Episode 2158/10000, loss: 0.0025715788360685117\n",
      "Episode Reward: 19.0\n",
      "Step 808 (977057) @ Episode 2159/10000, loss: 0.0070543047040700915\n",
      "Episode Reward: 17.0\n",
      "Step 1013 (978070) @ Episode 2160/10000, loss: 0.0304396916180849086\n",
      "Episode Reward: 22.0\n",
      "Step 954 (979024) @ Episode 2161/10000, loss: 0.0030440348200500018\n",
      "Episode Reward: 23.0\n",
      "Step 922 (979946) @ Episode 2162/10000, loss: 0.0039909388870000845\n",
      "Episode Reward: 20.0\n",
      "Step 53 (979999) @ Episode 2163/10000, loss: 0.0029086708091199442\n",
      " Copied model parameters to target network\n",
      "Step 967 (980913) @ Episode 2163/10000, loss: 0.0024060390423983335\n",
      "Episode Reward: 19.0\n",
      "Step 937 (981850) @ Episode 2164/10000, loss: 0.0328255929052829743\n",
      "Episode Reward: 26.0\n",
      "Step 1153 (983003) @ Episode 2165/10000, loss: 0.0020598836708813906\n",
      "Episode Reward: 20.0\n",
      "Step 998 (984001) @ Episode 2166/10000, loss: 0.0053589441813528548\n",
      "Episode Reward: 18.0\n",
      "Step 730 (984731) @ Episode 2167/10000, loss: 0.0415413938462734282\n",
      "Episode Reward: 13.0\n",
      "Step 1062 (985793) @ Episode 2168/10000, loss: 0.0042993463575844756\n",
      "Episode Reward: 25.0\n",
      "Step 835 (986628) @ Episode 2169/10000, loss: 0.0387713424861431125\n",
      "Episode Reward: 14.0\n",
      "Step 1624 (988252) @ Episode 2170/10000, loss: 0.0029246630147099495\n",
      "Episode Reward: 49.0\n",
      "Step 938 (989190) @ Episode 2171/10000, loss: 0.0093130972236394886\n",
      "Episode Reward: 23.0\n",
      "Step 809 (989999) @ Episode 2172/10000, loss: 0.0053529161959886556\n",
      " Copied model parameters to target network\n",
      "Step 1034 (990224) @ Episode 2172/10000, loss: 0.0107609564438462265\n",
      "Episode Reward: 23.0\n",
      "Step 912 (991136) @ Episode 2173/10000, loss: 0.0055165435187518625\n",
      "Episode Reward: 18.0\n",
      "Step 1149 (992285) @ Episode 2174/10000, loss: 0.0042184703052043915\n",
      "Episode Reward: 24.0\n",
      "Step 1318 (993603) @ Episode 2175/10000, loss: 0.0047357454895973206\n",
      "Episode Reward: 31.0\n",
      "Step 1039 (994642) @ Episode 2176/10000, loss: 0.0025774061214178824\n",
      "Episode Reward: 24.0\n",
      "Step 1104 (995746) @ Episode 2177/10000, loss: 0.0138173783197999685\n",
      "Episode Reward: 21.0\n",
      "Step 928 (996674) @ Episode 2178/10000, loss: 0.0050863260403275495\n",
      "Episode Reward: 19.0\n",
      "Step 1354 (998028) @ Episode 2179/10000, loss: 0.0030697232577949762\n",
      "Episode Reward: 32.0\n",
      "Step 1285 (999313) @ Episode 2180/10000, loss: 0.0049341879785060888\n",
      "Episode Reward: 26.0\n",
      "Step 686 (999999) @ Episode 2181/10000, loss: 0.0029893857426941395\n",
      " Copied model parameters to target network\n",
      "Step 978 (1000291) @ Episode 2181/10000, loss: 0.0148505754768848426\n",
      "Episode Reward: 17.0\n",
      "Step 973 (1001264) @ Episode 2182/10000, loss: 0.0019544439855962997\n",
      "Episode Reward: 20.0\n",
      "Step 1365 (1002629) @ Episode 2183/10000, loss: 0.0047926940023899087\n",
      "Episode Reward: 32.0\n",
      "Step 1422 (1004051) @ Episode 2184/10000, loss: 0.0160836577415466342\n",
      "Episode Reward: 37.0\n",
      "Step 847 (1004898) @ Episode 2185/10000, loss: 0.0028042555786669254\n",
      "Episode Reward: 14.0\n",
      "Step 819 (1005717) @ Episode 2186/10000, loss: 0.0243822578340768884\n",
      "Episode Reward: 20.0\n",
      "Step 968 (1006685) @ Episode 2187/10000, loss: 0.0020495650824159384\n",
      "Episode Reward: 20.0\n",
      "Step 1144 (1007829) @ Episode 2188/10000, loss: 0.0033204685896635056\n",
      "Episode Reward: 38.0\n",
      "Step 932 (1008761) @ Episode 2189/10000, loss: 0.1292775869369506863\n",
      "Episode Reward: 22.0\n",
      "Step 1238 (1009999) @ Episode 2190/10000, loss: 0.0020973591599613432\n",
      " Copied model parameters to target network\n",
      "Step 1439 (1010200) @ Episode 2190/10000, loss: 0.0034379104617983103\n",
      "Episode Reward: 39.0\n",
      "Step 856 (1011056) @ Episode 2191/10000, loss: 0.0097712464630603794\n",
      "Episode Reward: 17.0\n",
      "Step 1549 (1012605) @ Episode 2192/10000, loss: 0.0339803956449031805\n",
      "Episode Reward: 40.0\n",
      "Step 942 (1013547) @ Episode 2193/10000, loss: 0.0061533320695161823\n",
      "Episode Reward: 15.0\n",
      "Step 1175 (1014722) @ Episode 2194/10000, loss: 0.0046197474002838135\n",
      "Episode Reward: 30.0\n",
      "Step 604 (1015326) @ Episode 2195/10000, loss: 0.0042158910073339947\n",
      "Episode Reward: 10.0\n",
      "Step 994 (1016320) @ Episode 2196/10000, loss: 0.0018204709049314263\n",
      "Episode Reward: 18.0\n",
      "Step 1084 (1017404) @ Episode 2197/10000, loss: 0.0017814076272770762\n",
      "Episode Reward: 20.0\n",
      "Step 960 (1018364) @ Episode 2198/10000, loss: 0.0682562217116355904\n",
      "Episode Reward: 21.0\n",
      "Step 1003 (1019367) @ Episode 2199/10000, loss: 0.0029490995220839977\n",
      "Episode Reward: 22.0\n",
      "Step 632 (1019999) @ Episode 2200/10000, loss: 0.0028253092896193266\n",
      " Copied model parameters to target network\n",
      "Step 911 (1020278) @ Episode 2200/10000, loss: 0.0127151962369680455\n",
      "Episode Reward: 18.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 19:20:48,717] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video002200.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 966 (1021244) @ Episode 2201/10000, loss: 0.0074922316707670696\n",
      "Episode Reward: 17.0\n",
      "Step 1255 (1022499) @ Episode 2202/10000, loss: 0.0048772427253425122\n",
      "Episode Reward: 37.0\n",
      "Step 1383 (1023882) @ Episode 2203/10000, loss: 0.0189033225178718578\n",
      "Episode Reward: 27.0\n",
      "Step 816 (1024698) @ Episode 2204/10000, loss: 0.0125466054305434235\n",
      "Episode Reward: 18.0\n",
      "Step 934 (1025632) @ Episode 2205/10000, loss: 0.00697492854669690155\n",
      "Episode Reward: 16.0\n",
      "Step 872 (1026504) @ Episode 2206/10000, loss: 0.0020131017081439495\n",
      "Episode Reward: 21.0\n",
      "Step 860 (1027364) @ Episode 2207/10000, loss: 0.0097432080656290054\n",
      "Episode Reward: 21.0\n",
      "Step 954 (1028318) @ Episode 2208/10000, loss: 0.0031764626037329435\n",
      "Episode Reward: 21.0\n",
      "Step 903 (1029221) @ Episode 2209/10000, loss: 0.0047123730182647705\n",
      "Episode Reward: 16.0\n",
      "Step 778 (1029999) @ Episode 2210/10000, loss: 0.0153043214231729545\n",
      " Copied model parameters to target network\n",
      "Step 1024 (1030245) @ Episode 2210/10000, loss: 0.0281267631798982627\n",
      "Episode Reward: 23.0\n",
      "Step 821 (1031066) @ Episode 2211/10000, loss: 0.0047806315124034884\n",
      "Episode Reward: 20.0\n",
      "Step 753 (1031819) @ Episode 2212/10000, loss: 0.0085374340415000926\n",
      "Episode Reward: 12.0\n",
      "Step 1127 (1032946) @ Episode 2213/10000, loss: 0.0021228820551186824\n",
      "Episode Reward: 26.0\n",
      "Step 965 (1033911) @ Episode 2214/10000, loss: 0.0080835185945034035\n",
      "Episode Reward: 21.0\n",
      "Step 814 (1034725) @ Episode 2215/10000, loss: 0.0044714291580021385\n",
      "Episode Reward: 15.0\n",
      "Step 712 (1035437) @ Episode 2216/10000, loss: 0.0071084895171225074\n",
      "Episode Reward: 12.0\n",
      "Step 636 (1036073) @ Episode 2217/10000, loss: 0.0017116155941039324\n",
      "Episode Reward: 11.0\n",
      "Step 1183 (1037256) @ Episode 2218/10000, loss: 0.0061081871390342717\n",
      "Episode Reward: 32.0\n",
      "Step 1070 (1038326) @ Episode 2219/10000, loss: 0.0063695264980196953\n",
      "Episode Reward: 24.0\n",
      "Step 953 (1039279) @ Episode 2220/10000, loss: 0.0022612777538597584\n",
      "Episode Reward: 17.0\n",
      "Step 720 (1039999) @ Episode 2221/10000, loss: 0.0028018800076097256\n",
      " Copied model parameters to target network\n",
      "Step 1362 (1040641) @ Episode 2221/10000, loss: 0.0099566308781504636\n",
      "Episode Reward: 34.0\n",
      "Step 1366 (1042007) @ Episode 2222/10000, loss: 0.0155057543888688096\n",
      "Episode Reward: 37.0\n",
      "Step 990 (1042997) @ Episode 2223/10000, loss: 0.0307877212762832646\n",
      "Episode Reward: 25.0\n",
      "Step 810 (1043807) @ Episode 2224/10000, loss: 0.0062548550777137288\n",
      "Episode Reward: 20.0\n",
      "Step 944 (1044751) @ Episode 2225/10000, loss: 0.0039565283805131912\n",
      "Episode Reward: 19.0\n",
      "Step 1448 (1046199) @ Episode 2226/10000, loss: 0.0184652972966432575\n",
      "Episode Reward: 38.0\n",
      "Step 1249 (1047448) @ Episode 2227/10000, loss: 0.0034504781942814595\n",
      "Episode Reward: 31.0\n",
      "Step 797 (1048245) @ Episode 2228/10000, loss: 0.0042498237453401093\n",
      "Episode Reward: 13.0\n",
      "Step 812 (1049057) @ Episode 2229/10000, loss: 0.0194274596869945537\n",
      "Episode Reward: 15.0\n",
      "Step 942 (1049999) @ Episode 2230/10000, loss: 0.0095256222411990175\n",
      " Copied model parameters to target network\n",
      "Step 1077 (1050134) @ Episode 2230/10000, loss: 0.0090666925534605984\n",
      "Episode Reward: 26.0\n",
      "Step 1188 (1051322) @ Episode 2231/10000, loss: 0.0033869678154587746\n",
      "Episode Reward: 24.0\n",
      "Step 1072 (1052394) @ Episode 2232/10000, loss: 0.0033834981732070446\n",
      "Episode Reward: 21.0\n",
      "Step 945 (1053339) @ Episode 2233/10000, loss: 0.0436972752213478163\n",
      "Episode Reward: 38.0\n",
      "Step 955 (1054294) @ Episode 2234/10000, loss: 0.0095787942409515383\n",
      "Episode Reward: 20.0\n",
      "Step 993 (1055287) @ Episode 2235/10000, loss: 0.0166445430368185045\n",
      "Episode Reward: 23.0\n",
      "Step 881 (1056168) @ Episode 2236/10000, loss: 0.0050772298127412884\n",
      "Episode Reward: 18.0\n",
      "Step 845 (1057013) @ Episode 2237/10000, loss: 0.0177584756165742875\n",
      "Episode Reward: 22.0\n",
      "Step 1340 (1058353) @ Episode 2238/10000, loss: 0.0044535542838275434\n",
      "Episode Reward: 29.0\n",
      "Step 1052 (1059405) @ Episode 2239/10000, loss: 0.0059272847138345245\n",
      "Episode Reward: 18.0\n",
      "Step 594 (1059999) @ Episode 2240/10000, loss: 0.0043013850226998335\n",
      " Copied model parameters to target network\n",
      "Step 1429 (1060834) @ Episode 2240/10000, loss: 0.0025051389820873737\n",
      "Episode Reward: 32.0\n",
      "Step 1330 (1062164) @ Episode 2241/10000, loss: 0.0033564069308340554\n",
      "Episode Reward: 41.0\n",
      "Step 1390 (1063554) @ Episode 2242/10000, loss: 0.0392156653106212656\n",
      "Episode Reward: 30.0\n",
      "Step 685 (1064239) @ Episode 2243/10000, loss: 0.0028603612445294857\n",
      "Episode Reward: 11.0\n",
      "Step 944 (1065183) @ Episode 2244/10000, loss: 0.0042789536528289324\n",
      "Episode Reward: 17.0\n",
      "Step 1378 (1066561) @ Episode 2245/10000, loss: 0.0054132230579853063\n",
      "Episode Reward: 27.0\n",
      "Step 766 (1067327) @ Episode 2246/10000, loss: 0.0084385257214307792\n",
      "Episode Reward: 24.0\n",
      "Step 1117 (1068444) @ Episode 2247/10000, loss: 0.1167159751057624898\n",
      "Episode Reward: 27.0\n",
      "Step 1092 (1069536) @ Episode 2248/10000, loss: 0.0126914884895086296\n",
      "Episode Reward: 25.0\n",
      "Step 463 (1069999) @ Episode 2249/10000, loss: 0.0065762843005359172\n",
      " Copied model parameters to target network\n",
      "Step 1199 (1070735) @ Episode 2249/10000, loss: 0.0142694991081953054\n",
      "Episode Reward: 28.0\n",
      "Step 1071 (1071806) @ Episode 2250/10000, loss: 0.0740790888667106672\n",
      "Episode Reward: 18.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 19:28:29,922] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video002250.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1189 (1072995) @ Episode 2251/10000, loss: 0.0058120060712099075\n",
      "Episode Reward: 20.0\n",
      "Step 998 (1073993) @ Episode 2252/10000, loss: 0.0049238940700888633\n",
      "Episode Reward: 29.0\n",
      "Step 1397 (1075390) @ Episode 2253/10000, loss: 0.0039123473688960075\n",
      "Episode Reward: 33.0\n",
      "Step 1282 (1076672) @ Episode 2254/10000, loss: 0.0047966754063963895\n",
      "Episode Reward: 27.0\n",
      "Step 813 (1077485) @ Episode 2255/10000, loss: 0.0031343123409897094\n",
      "Episode Reward: 14.0\n",
      "Step 1418 (1078903) @ Episode 2256/10000, loss: 0.0056126266717910774\n",
      "Episode Reward: 33.0\n",
      "Step 1096 (1079999) @ Episode 2257/10000, loss: 0.0046326047740876675\n",
      " Copied model parameters to target network\n",
      "Step 1198 (1080101) @ Episode 2257/10000, loss: 0.0044673108495771885\n",
      "Episode Reward: 22.0\n",
      "Step 1305 (1081406) @ Episode 2258/10000, loss: 0.0129668321460485466\n",
      "Episode Reward: 30.0\n",
      "Step 1116 (1082522) @ Episode 2259/10000, loss: 0.0104641234502196317\n",
      "Episode Reward: 28.0\n",
      "Step 1608 (1084130) @ Episode 2260/10000, loss: 0.0021904555615037687\n",
      "Episode Reward: 45.0\n",
      "Step 1015 (1085145) @ Episode 2261/10000, loss: 0.0115805026143789383\n",
      "Episode Reward: 18.0\n",
      "Step 1524 (1086669) @ Episode 2262/10000, loss: 0.0073199253529310234\n",
      "Episode Reward: 43.0\n",
      "Step 1510 (1088179) @ Episode 2263/10000, loss: 0.0089459586888551712\n",
      "Episode Reward: 39.0\n",
      "Step 930 (1089109) @ Episode 2264/10000, loss: 0.0065772933885455138\n",
      "Episode Reward: 17.0\n",
      "Step 890 (1089999) @ Episode 2265/10000, loss: 0.0160941630601882939\n",
      " Copied model parameters to target network\n",
      "Step 1181 (1090290) @ Episode 2265/10000, loss: 0.0050230300985276796\n",
      "Episode Reward: 28.0\n",
      "Step 1050 (1091340) @ Episode 2266/10000, loss: 0.0021822596900165084\n",
      "Episode Reward: 26.0\n",
      "Step 1707 (1093047) @ Episode 2267/10000, loss: 0.0959948748350143412\n",
      "Episode Reward: 52.0\n",
      "Step 860 (1093907) @ Episode 2268/10000, loss: 0.0102511886507272722\n",
      "Episode Reward: 23.0\n",
      "Step 1207 (1095114) @ Episode 2269/10000, loss: 0.0044094873592257525\n",
      "Episode Reward: 31.0\n",
      "Step 1103 (1096217) @ Episode 2270/10000, loss: 0.0028681373223662376\n",
      "Episode Reward: 21.0\n",
      "Step 1078 (1097295) @ Episode 2271/10000, loss: 0.0034131200518459086\n",
      "Episode Reward: 17.0\n",
      "Step 1091 (1098386) @ Episode 2272/10000, loss: 0.0039258445613086223\n",
      "Episode Reward: 21.0\n",
      "Step 1191 (1099577) @ Episode 2273/10000, loss: 0.0051570557989180095\n",
      "Episode Reward: 29.0\n",
      "Step 422 (1099999) @ Episode 2274/10000, loss: 0.0038392194546759136\n",
      " Copied model parameters to target network\n",
      "Step 740 (1100317) @ Episode 2274/10000, loss: 0.0072739673778414734\n",
      "Episode Reward: 12.0\n",
      "Step 1103 (1101420) @ Episode 2275/10000, loss: 0.0049595450982451445\n",
      "Episode Reward: 29.0\n",
      "Step 941 (1102361) @ Episode 2276/10000, loss: 0.0101570952683687217\n",
      "Episode Reward: 15.0\n",
      "Step 1313 (1103674) @ Episode 2277/10000, loss: 0.0151117872446775444\n",
      "Episode Reward: 30.0\n",
      "Step 973 (1104647) @ Episode 2278/10000, loss: 0.0036202361807227135\n",
      "Episode Reward: 18.0\n",
      "Step 993 (1105640) @ Episode 2279/10000, loss: 0.0026229787617921834\n",
      "Episode Reward: 20.0\n",
      "Step 978 (1106618) @ Episode 2280/10000, loss: 0.0038640713319182396\n",
      "Episode Reward: 17.0\n",
      "Step 757 (1107375) @ Episode 2281/10000, loss: 0.0062146252021193526\n",
      "Episode Reward: 13.0\n",
      "Step 1090 (1108465) @ Episode 2282/10000, loss: 0.0127528887242078784\n",
      "Episode Reward: 21.0\n",
      "Step 1248 (1109713) @ Episode 2283/10000, loss: 0.0011883740080520513\n",
      "Episode Reward: 30.0\n",
      "Step 286 (1109999) @ Episode 2284/10000, loss: 0.0251427050679922166\n",
      " Copied model parameters to target network\n",
      "Step 1163 (1110876) @ Episode 2284/10000, loss: 0.0112620610743761065\n",
      "Episode Reward: 22.0\n",
      "Step 1147 (1112023) @ Episode 2285/10000, loss: 0.0158789902925491336\n",
      "Episode Reward: 22.0\n",
      "Step 956 (1112979) @ Episode 2286/10000, loss: 0.0065653808414936074\n",
      "Episode Reward: 18.0\n",
      "Step 870 (1113849) @ Episode 2287/10000, loss: 0.0056379958987236025\n",
      "Episode Reward: 16.0\n",
      "Step 854 (1114703) @ Episode 2288/10000, loss: 0.0267241615802049648\n",
      "Episode Reward: 16.0\n",
      "Step 1286 (1115989) @ Episode 2289/10000, loss: 0.0067442394793033652\n",
      "Episode Reward: 32.0\n",
      "Step 973 (1116962) @ Episode 2290/10000, loss: 0.0073925522156059745\n",
      "Episode Reward: 20.0\n",
      "Step 789 (1117751) @ Episode 2291/10000, loss: 0.0079666767269372944\n",
      "Episode Reward: 19.0\n",
      "Step 1174 (1118925) @ Episode 2292/10000, loss: 0.0038459766656160355\n",
      "Episode Reward: 24.0\n",
      "Step 963 (1119888) @ Episode 2293/10000, loss: 0.0091956127434968958\n",
      "Episode Reward: 16.0\n",
      "Step 111 (1119999) @ Episode 2294/10000, loss: 0.0029716291464865208\n",
      " Copied model parameters to target network\n",
      "Step 947 (1120835) @ Episode 2294/10000, loss: 0.0023441317025572065\n",
      "Episode Reward: 19.0\n",
      "Step 816 (1121651) @ Episode 2295/10000, loss: 0.0253273379057645863\n",
      "Episode Reward: 15.0\n",
      "Step 551 (1122202) @ Episode 2296/10000, loss: 0.0030537405982613564\n",
      "Episode Reward: 7.0\n",
      "Step 1487 (1123689) @ Episode 2297/10000, loss: 0.0058106174692511568\n",
      "Episode Reward: 34.0\n",
      "Step 1031 (1124720) @ Episode 2298/10000, loss: 0.0050285439938306817\n",
      "Episode Reward: 21.0\n",
      "Step 1206 (1125926) @ Episode 2299/10000, loss: 0.0048167146742343972\n",
      "Episode Reward: 23.0\n",
      "Step 949 (1126875) @ Episode 2300/10000, loss: 0.0075959316454827785\n",
      "Episode Reward: 21.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 19:36:42,771] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video002300.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 894 (1127769) @ Episode 2301/10000, loss: 0.0364310927689075585\n",
      "Episode Reward: 21.0\n",
      "Step 1385 (1129154) @ Episode 2302/10000, loss: 0.0057538971304893494\n",
      "Episode Reward: 37.0\n",
      "Step 845 (1129999) @ Episode 2303/10000, loss: 0.0134161533787846573\n",
      " Copied model parameters to target network\n",
      "Step 921 (1130075) @ Episode 2303/10000, loss: 0.0039369710721075535\n",
      "Episode Reward: 16.0\n",
      "Step 1405 (1131480) @ Episode 2304/10000, loss: 0.0036340605001896623\n",
      "Episode Reward: 33.0\n",
      "Step 823 (1132303) @ Episode 2305/10000, loss: 0.0038216304965317253\n",
      "Episode Reward: 14.0\n",
      "Step 1217 (1133520) @ Episode 2306/10000, loss: 0.0141555778682231945\n",
      "Episode Reward: 26.0\n",
      "Step 494 (1134014) @ Episode 2307/10000, loss: 0.0100466217845678334\n",
      "Episode Reward: 7.0\n",
      "Step 1273 (1135287) @ Episode 2308/10000, loss: 0.0074746012687683105\n",
      "Episode Reward: 29.0\n",
      "Step 906 (1136193) @ Episode 2309/10000, loss: 0.0033567713107913733\n",
      "Episode Reward: 16.0\n",
      "Step 1095 (1137288) @ Episode 2310/10000, loss: 0.0091446368023753175\n",
      "Episode Reward: 30.0\n",
      "Step 1129 (1138417) @ Episode 2311/10000, loss: 0.0078363800421357157\n",
      "Episode Reward: 29.0\n",
      "Step 676 (1139093) @ Episode 2312/10000, loss: 0.0063588842749595647\n",
      "Episode Reward: 9.0\n",
      "Step 779 (1139872) @ Episode 2313/10000, loss: 0.0176339223980903635\n",
      "Episode Reward: 13.0\n",
      "Step 127 (1139999) @ Episode 2314/10000, loss: 0.0104153715074062354\n",
      " Copied model parameters to target network\n",
      "Step 1063 (1140935) @ Episode 2314/10000, loss: 0.0139829423278570186\n",
      "Episode Reward: 17.0\n",
      "Step 1068 (1142003) @ Episode 2315/10000, loss: 0.0109726097434759145\n",
      "Episode Reward: 27.0\n",
      "Step 678 (1142681) @ Episode 2316/10000, loss: 0.0307756289839744573\n",
      "Episode Reward: 22.0\n",
      "Step 1376 (1144057) @ Episode 2317/10000, loss: 0.0114323971793055535\n",
      "Episode Reward: 38.0\n",
      "Step 1045 (1145102) @ Episode 2318/10000, loss: 0.0032607084140181545\n",
      "Episode Reward: 23.0\n",
      "Step 1470 (1146572) @ Episode 2319/10000, loss: 0.0394076779484748844\n",
      "Episode Reward: 26.0\n",
      "Step 850 (1147422) @ Episode 2320/10000, loss: 0.0070555428974330425\n",
      "Episode Reward: 14.0\n",
      "Step 1368 (1148790) @ Episode 2321/10000, loss: 0.0055288639850914485\n",
      "Episode Reward: 39.0\n",
      "Step 888 (1149678) @ Episode 2322/10000, loss: 0.0046339016407728195\n",
      "Episode Reward: 27.0\n",
      "Step 321 (1149999) @ Episode 2323/10000, loss: 0.0026341406628489494\n",
      " Copied model parameters to target network\n",
      "Step 1224 (1150902) @ Episode 2323/10000, loss: 0.0031345046591013675\n",
      "Episode Reward: 22.0\n",
      "Step 856 (1151758) @ Episode 2324/10000, loss: 0.0044232374057173733\n",
      "Episode Reward: 14.0\n",
      "Step 986 (1152744) @ Episode 2325/10000, loss: 0.0694530233740806622\n",
      "Episode Reward: 19.0\n",
      "Step 747 (1153491) @ Episode 2326/10000, loss: 0.0053888582624495033\n",
      "Episode Reward: 11.0\n",
      "Step 925 (1154416) @ Episode 2327/10000, loss: 0.0179990697652101555\n",
      "Episode Reward: 23.0\n",
      "Step 791 (1155207) @ Episode 2328/10000, loss: 0.0099010979756712916\n",
      "Episode Reward: 14.0\n",
      "Step 1153 (1156360) @ Episode 2329/10000, loss: 0.0041763689368963244\n",
      "Episode Reward: 38.0\n",
      "Step 685 (1157045) @ Episode 2330/10000, loss: 0.0088504645973443985\n",
      "Episode Reward: 19.0\n",
      "Step 1073 (1158118) @ Episode 2331/10000, loss: 0.0080831013619899754\n",
      "Episode Reward: 23.0\n",
      "Step 1266 (1159384) @ Episode 2332/10000, loss: 0.0043788207694888115\n",
      "Episode Reward: 36.0\n",
      "Step 615 (1159999) @ Episode 2333/10000, loss: 0.0202326048165559772\n",
      " Copied model parameters to target network\n",
      "Step 1731 (1161115) @ Episode 2333/10000, loss: 0.0062276176176965243\n",
      "Episode Reward: 55.0\n",
      "Step 658 (1161773) @ Episode 2334/10000, loss: 0.0045248297974467289\n",
      "Episode Reward: 10.0\n",
      "Step 980 (1162753) @ Episode 2335/10000, loss: 0.0077233035117387777\n",
      "Episode Reward: 21.0\n",
      "Step 960 (1163713) @ Episode 2336/10000, loss: 0.0046886443160474316\n",
      "Episode Reward: 18.0\n",
      "Step 767 (1164480) @ Episode 2337/10000, loss: 0.0064190132543444635\n",
      "Episode Reward: 11.0\n",
      "Step 1300 (1165780) @ Episode 2338/10000, loss: 0.0087143350392580033\n",
      "Episode Reward: 32.0\n",
      "Step 821 (1166601) @ Episode 2339/10000, loss: 0.0030722292140126235\n",
      "Episode Reward: 15.0\n",
      "Step 673 (1167274) @ Episode 2340/10000, loss: 0.0072791590355336674\n",
      "Episode Reward: 17.0\n",
      "Step 1066 (1168340) @ Episode 2341/10000, loss: 0.0069640488363802437\n",
      "Episode Reward: 21.0\n",
      "Step 599 (1168939) @ Episode 2342/10000, loss: 0.0050897821784019475\n",
      "Episode Reward: 11.0\n",
      "Step 1060 (1169999) @ Episode 2343/10000, loss: 0.0780245959758758515\n",
      " Copied model parameters to target network\n",
      "Step 1100 (1170039) @ Episode 2343/10000, loss: 0.0049892431125044827\n",
      "Episode Reward: 18.0\n",
      "Step 900 (1170939) @ Episode 2344/10000, loss: 0.0132682546973228456\n",
      "Episode Reward: 15.0\n",
      "Step 1012 (1171951) @ Episode 2345/10000, loss: 0.0232781320810318835\n",
      "Episode Reward: 21.0\n",
      "Step 589 (1172540) @ Episode 2346/10000, loss: 0.0240525845438241966\n",
      "Episode Reward: 9.0\n",
      "Step 760 (1173300) @ Episode 2347/10000, loss: 0.0109466314315795995\n",
      "Episode Reward: 13.0\n",
      "Step 738 (1174038) @ Episode 2348/10000, loss: 0.0059725018218159676\n",
      "Episode Reward: 13.0\n",
      "Step 1146 (1175184) @ Episode 2349/10000, loss: 0.0101302461698651316\n",
      "Episode Reward: 32.0\n",
      "Step 929 (1176113) @ Episode 2350/10000, loss: 0.0235880650579929356\n",
      "Episode Reward: 25.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 19:43:59,455] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video002350.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1052 (1177165) @ Episode 2351/10000, loss: 0.0023847396951168776\n",
      "Episode Reward: 17.0\n",
      "Step 1057 (1178222) @ Episode 2352/10000, loss: 0.0137875555083155634\n",
      "Episode Reward: 26.0\n",
      "Step 958 (1179180) @ Episode 2353/10000, loss: 0.0046438663266599183\n",
      "Episode Reward: 23.0\n",
      "Step 819 (1179999) @ Episode 2354/10000, loss: 0.0048787007108330735\n",
      " Copied model parameters to target network\n",
      "Step 927 (1180107) @ Episode 2354/10000, loss: 0.0062933694571256642\n",
      "Episode Reward: 25.0\n",
      "Step 1226 (1181333) @ Episode 2355/10000, loss: 0.0053750923834741116\n",
      "Episode Reward: 22.0\n",
      "Step 1029 (1182362) @ Episode 2356/10000, loss: 0.0160477757453918465\n",
      "Episode Reward: 24.0\n",
      "Step 1054 (1183416) @ Episode 2357/10000, loss: 0.0345045067369937954\n",
      "Episode Reward: 20.0\n",
      "Step 687 (1184103) @ Episode 2358/10000, loss: 0.0691755264997482355\n",
      "Episode Reward: 14.0\n",
      "Step 970 (1185073) @ Episode 2359/10000, loss: 0.0033855959773063664\n",
      "Episode Reward: 18.0\n",
      "Step 1184 (1186257) @ Episode 2360/10000, loss: 0.0717117786407470727\n",
      "Episode Reward: 21.0\n",
      "Step 609 (1186866) @ Episode 2361/10000, loss: 0.0258079618215560976\n",
      "Episode Reward: 10.0\n",
      "Step 1136 (1188002) @ Episode 2362/10000, loss: 0.0103118959814310076\n",
      "Episode Reward: 25.0\n",
      "Step 880 (1188882) @ Episode 2363/10000, loss: 0.0100765209645032885\n",
      "Episode Reward: 16.0\n",
      "Step 1101 (1189983) @ Episode 2364/10000, loss: 0.0109018459916114853\n",
      "Episode Reward: 18.0\n",
      "Step 16 (1189999) @ Episode 2365/10000, loss: 0.003574350383132696\n",
      " Copied model parameters to target network\n",
      "Step 943 (1190926) @ Episode 2365/10000, loss: 0.0238554142415523536\n",
      "Episode Reward: 15.0\n",
      "Step 1158 (1192084) @ Episode 2366/10000, loss: 0.0064866477623581894\n",
      "Episode Reward: 25.0\n",
      "Step 1233 (1193317) @ Episode 2367/10000, loss: 0.0109617700800299647\n",
      "Episode Reward: 29.0\n",
      "Step 785 (1194102) @ Episode 2368/10000, loss: 0.0061372378841042527\n",
      "Episode Reward: 12.0\n",
      "Step 447 (1194549) @ Episode 2369/10000, loss: 0.0075529236346483235\n",
      "Episode Reward: 5.0\n",
      "Step 760 (1195309) @ Episode 2370/10000, loss: 0.0032131220214068897\n",
      "Episode Reward: 28.0\n",
      "Step 1363 (1196672) @ Episode 2371/10000, loss: 0.0069174394011497543\n",
      "Episode Reward: 33.0\n",
      "Step 957 (1197629) @ Episode 2372/10000, loss: 0.0120606934651732445\n",
      "Episode Reward: 15.0\n",
      "Step 959 (1198588) @ Episode 2373/10000, loss: 0.0053596254438161856\n",
      "Episode Reward: 20.0\n",
      "Step 1332 (1199920) @ Episode 2374/10000, loss: 0.0076520736329257494\n",
      "Episode Reward: 19.0\n",
      "Step 79 (1199999) @ Episode 2375/10000, loss: 0.0270770080387592365\n",
      " Copied model parameters to target network\n",
      "Step 1272 (1201192) @ Episode 2375/10000, loss: 0.0200515389442443855\n",
      "Episode Reward: 24.0\n",
      "Step 856 (1202048) @ Episode 2376/10000, loss: 0.0149633605033159266\n",
      "Episode Reward: 17.0\n",
      "Step 540 (1202588) @ Episode 2377/10000, loss: 0.0163930505514144956\n",
      "Episode Reward: 8.0\n",
      "Step 732 (1203320) @ Episode 2378/10000, loss: 0.0091163627803325655\n",
      "Episode Reward: 19.0\n",
      "Step 737 (1204057) @ Episode 2379/10000, loss: 0.0134218875318765647\n",
      "Episode Reward: 13.0\n",
      "Step 873 (1204930) @ Episode 2380/10000, loss: 0.0043895826674997815\n",
      "Episode Reward: 15.0\n",
      "Step 800 (1205730) @ Episode 2381/10000, loss: 0.0143933612853288657\n",
      "Episode Reward: 15.0\n",
      "Step 749 (1206479) @ Episode 2382/10000, loss: 0.0128584410995244985\n",
      "Episode Reward: 15.0\n",
      "Step 516 (1206995) @ Episode 2383/10000, loss: 0.0061155315488576895\n",
      "Episode Reward: 7.0\n",
      "Step 993 (1207988) @ Episode 2384/10000, loss: 0.0059118894860148434\n",
      "Episode Reward: 16.0\n",
      "Step 795 (1208783) @ Episode 2385/10000, loss: 0.0059637315571308145\n",
      "Episode Reward: 15.0\n",
      "Step 756 (1209539) @ Episode 2386/10000, loss: 0.0108555108308792114\n",
      "Episode Reward: 13.0\n",
      "Step 460 (1209999) @ Episode 2387/10000, loss: 0.0168451201170682977\n",
      " Copied model parameters to target network\n",
      "Step 830 (1210369) @ Episode 2387/10000, loss: 0.0043639708310365684\n",
      "Episode Reward: 14.0\n",
      "Step 825 (1211194) @ Episode 2388/10000, loss: 0.0052120857872068884\n",
      "Episode Reward: 13.0\n",
      "Step 1115 (1212309) @ Episode 2389/10000, loss: 0.0061323363333940516\n",
      "Episode Reward: 33.0\n",
      "Step 708 (1213017) @ Episode 2390/10000, loss: 0.0026038046926259995\n",
      "Episode Reward: 13.0\n",
      "Step 1140 (1214157) @ Episode 2391/10000, loss: 0.0067706340923905373\n",
      "Episode Reward: 18.0\n",
      "Step 1115 (1215272) @ Episode 2392/10000, loss: 0.0100767323747277267\n",
      "Episode Reward: 39.0\n",
      "Step 1013 (1216285) @ Episode 2393/10000, loss: 0.0068211671896278866\n",
      "Episode Reward: 19.0\n",
      "Step 1031 (1217316) @ Episode 2394/10000, loss: 0.0093914596363902145\n",
      "Episode Reward: 17.0\n",
      "Step 1037 (1218353) @ Episode 2395/10000, loss: 0.0149932503700256355\n",
      "Episode Reward: 18.0\n",
      "Step 1161 (1219514) @ Episode 2396/10000, loss: 0.0051552597433328635\n",
      "Episode Reward: 53.0\n",
      "Step 485 (1219999) @ Episode 2397/10000, loss: 0.0069335955195128926\n",
      " Copied model parameters to target network\n",
      "Step 1155 (1220669) @ Episode 2397/10000, loss: 0.0086928242817521156\n",
      "Episode Reward: 28.0\n",
      "Step 881 (1221550) @ Episode 2398/10000, loss: 0.0066749537363648415\n",
      "Episode Reward: 22.0\n",
      "Step 761 (1222311) @ Episode 2399/10000, loss: 0.0034278007224202156\n",
      "Episode Reward: 13.0\n",
      "Step 970 (1223281) @ Episode 2400/10000, loss: 0.0036352395545691253\n",
      "Episode Reward: 24.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 19:51:06,303] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video002400.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 605 (1223886) @ Episode 2401/10000, loss: 0.0039190752431750356\n",
      "Episode Reward: 9.0\n",
      "Step 1326 (1225212) @ Episode 2402/10000, loss: 0.0033926460891962056\n",
      "Episode Reward: 31.0\n",
      "Step 729 (1225941) @ Episode 2403/10000, loss: 0.0075327465310692797\n",
      "Episode Reward: 12.0\n",
      "Step 838 (1226779) @ Episode 2404/10000, loss: 0.0114368759095668835\n",
      "Episode Reward: 17.0\n",
      "Step 1358 (1228137) @ Episode 2405/10000, loss: 0.0055287242867052555\n",
      "Episode Reward: 33.0\n",
      "Step 750 (1228887) @ Episode 2406/10000, loss: 0.0150207234546542175\n",
      "Episode Reward: 15.0\n",
      "Step 480 (1229367) @ Episode 2407/10000, loss: 0.0124660115689039235\n",
      "Episode Reward: 6.0\n",
      "Step 632 (1229999) @ Episode 2408/10000, loss: 0.0109151694923639375\n",
      " Copied model parameters to target network\n",
      "Step 758 (1230125) @ Episode 2408/10000, loss: 0.0730143189430236884\n",
      "Episode Reward: 14.0\n",
      "Step 857 (1230982) @ Episode 2409/10000, loss: 0.0145259033888578413\n",
      "Episode Reward: 14.0\n",
      "Step 590 (1231572) @ Episode 2410/10000, loss: 0.0063800960779190065\n",
      "Episode Reward: 10.0\n",
      "Step 1145 (1232717) @ Episode 2411/10000, loss: 0.0083145583048462873\n",
      "Episode Reward: 27.0\n",
      "Step 971 (1233688) @ Episode 2412/10000, loss: 0.0048648887313902388\n",
      "Episode Reward: 20.0\n",
      "Step 729 (1234417) @ Episode 2413/10000, loss: 0.0030545494519174175\n",
      "Episode Reward: 12.0\n",
      "Step 1120 (1235537) @ Episode 2414/10000, loss: 0.0070536150597035885\n",
      "Episode Reward: 22.0\n",
      "Step 628 (1236165) @ Episode 2415/10000, loss: 0.0268057808279991158\n",
      "Episode Reward: 11.0\n",
      "Step 794 (1236959) @ Episode 2416/10000, loss: 0.0025913263671100142\n",
      "Episode Reward: 14.0\n",
      "Step 983 (1237942) @ Episode 2417/10000, loss: 0.0498255304992198947\n",
      "Episode Reward: 17.0\n",
      "Step 985 (1238927) @ Episode 2418/10000, loss: 0.0064596887677907945\n",
      "Episode Reward: 22.0\n",
      "Step 823 (1239750) @ Episode 2419/10000, loss: 0.0066673210822045896\n",
      "Episode Reward: 13.0\n",
      "Step 249 (1239999) @ Episode 2420/10000, loss: 0.0048611620441079145\n",
      " Copied model parameters to target network\n",
      "Step 808 (1240558) @ Episode 2420/10000, loss: 0.0037177854683250194\n",
      "Episode Reward: 13.0\n",
      "Step 1158 (1241716) @ Episode 2421/10000, loss: 0.0128077259287238127\n",
      "Episode Reward: 25.0\n",
      "Step 966 (1242682) @ Episode 2422/10000, loss: 0.0063053630292415624\n",
      "Episode Reward: 25.0\n",
      "Step 994 (1243676) @ Episode 2423/10000, loss: 0.0277309268712997444\n",
      "Episode Reward: 19.0\n",
      "Step 919 (1244595) @ Episode 2424/10000, loss: 0.0099093019962310796\n",
      "Episode Reward: 19.0\n",
      "Step 719 (1245314) @ Episode 2425/10000, loss: 0.0036817661020904782\n",
      "Episode Reward: 17.0\n",
      "Step 962 (1246276) @ Episode 2426/10000, loss: 0.0141554959118366243\n",
      "Episode Reward: 19.0\n",
      "Step 899 (1247175) @ Episode 2427/10000, loss: 0.0049122376367449765\n",
      "Episode Reward: 15.0\n",
      "Step 872 (1248047) @ Episode 2428/10000, loss: 0.0071508693508803844\n",
      "Episode Reward: 14.0\n",
      "Step 816 (1248863) @ Episode 2429/10000, loss: 0.0042658448219299325\n",
      "Episode Reward: 20.0\n",
      "Step 830 (1249693) @ Episode 2430/10000, loss: 0.0065045794472098357\n",
      "Episode Reward: 18.0\n",
      "Step 306 (1249999) @ Episode 2431/10000, loss: 0.0029583405703306247\n",
      " Copied model parameters to target network\n",
      "Step 832 (1250525) @ Episode 2431/10000, loss: 0.0074424911290407185\n",
      "Episode Reward: 14.0\n",
      "Step 627 (1251152) @ Episode 2432/10000, loss: 0.0110756913200020792\n",
      "Episode Reward: 10.0\n",
      "Step 969 (1252121) @ Episode 2433/10000, loss: 0.0100507233291864415\n",
      "Episode Reward: 17.0\n",
      "Step 856 (1252977) @ Episode 2434/10000, loss: 0.0039659407921135426\n",
      "Episode Reward: 15.0\n",
      "Step 1138 (1254115) @ Episode 2435/10000, loss: 0.0064089135266840465\n",
      "Episode Reward: 24.0\n",
      "Step 748 (1254863) @ Episode 2436/10000, loss: 0.0091006867587566386\n",
      "Episode Reward: 15.0\n",
      "Step 796 (1255659) @ Episode 2437/10000, loss: 0.0034267553128302097\n",
      "Episode Reward: 13.0\n",
      "Step 843 (1256502) @ Episode 2438/10000, loss: 0.0086262840777635574\n",
      "Episode Reward: 12.0\n",
      "Step 762 (1257264) @ Episode 2439/10000, loss: 0.0051834895275533248\n",
      "Episode Reward: 10.0\n",
      "Step 1048 (1258312) @ Episode 2440/10000, loss: 0.0126758571714162836\n",
      "Episode Reward: 26.0\n",
      "Step 853 (1259165) @ Episode 2441/10000, loss: 0.0090055987238883974\n",
      "Episode Reward: 17.0\n",
      "Step 693 (1259858) @ Episode 2442/10000, loss: 0.0074182571843266495\n",
      "Episode Reward: 10.0\n",
      "Step 141 (1259999) @ Episode 2443/10000, loss: 0.0039717075414955625\n",
      " Copied model parameters to target network\n",
      "Step 954 (1260812) @ Episode 2443/10000, loss: 0.0085711348801851275\n",
      "Episode Reward: 17.0\n",
      "Step 780 (1261592) @ Episode 2444/10000, loss: 0.0025579321663826704\n",
      "Episode Reward: 13.0\n",
      "Step 1109 (1262701) @ Episode 2445/10000, loss: 0.0097727067768573765\n",
      "Episode Reward: 33.0\n",
      "Step 642 (1263343) @ Episode 2446/10000, loss: 0.0064374571666121488\n",
      "Episode Reward: 11.0\n",
      "Step 1014 (1264357) @ Episode 2447/10000, loss: 0.0197701901197433475\n",
      "Episode Reward: 24.0\n",
      "Step 601 (1264958) @ Episode 2448/10000, loss: 0.0303999781608581547\n",
      "Episode Reward: 10.0\n",
      "Step 823 (1265781) @ Episode 2449/10000, loss: 0.0074551994912326345\n",
      "Episode Reward: 19.0\n",
      "Step 817 (1266598) @ Episode 2450/10000, loss: 0.0040965415537357333\n",
      "Episode Reward: 18.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 19:57:36,752] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video002450.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1226 (1267824) @ Episode 2451/10000, loss: 0.0106939924880862247\n",
      "Episode Reward: 34.0\n",
      "Step 1381 (1269205) @ Episode 2452/10000, loss: 0.0109222438186407095\n",
      "Episode Reward: 33.0\n",
      "Step 704 (1269909) @ Episode 2453/10000, loss: 0.0040212962776422564\n",
      "Episode Reward: 12.0\n",
      "Step 90 (1269999) @ Episode 2454/10000, loss: 0.0077080102637410165\n",
      " Copied model parameters to target network\n",
      "Step 618 (1270527) @ Episode 2454/10000, loss: 0.0139473341405391765\n",
      "Episode Reward: 11.0\n",
      "Step 1042 (1271569) @ Episode 2455/10000, loss: 0.0076092928647994995\n",
      "Episode Reward: 20.0\n",
      "Step 1195 (1272764) @ Episode 2456/10000, loss: 0.0115096587687730794\n",
      "Episode Reward: 21.0\n",
      "Step 1567 (1274331) @ Episode 2457/10000, loss: 0.0057895402424037465\n",
      "Episode Reward: 34.0\n",
      "Step 884 (1275215) @ Episode 2458/10000, loss: 0.0102277807891368877\n",
      "Episode Reward: 22.0\n",
      "Step 884 (1276099) @ Episode 2459/10000, loss: 0.0107862809672951763\n",
      "Episode Reward: 16.0\n",
      "Step 1275 (1277374) @ Episode 2460/10000, loss: 0.0026997651439160117\n",
      "Episode Reward: 31.0\n",
      "Step 716 (1278090) @ Episode 2461/10000, loss: 0.0083002392202615745\n",
      "Episode Reward: 15.0\n",
      "Step 1001 (1279091) @ Episode 2462/10000, loss: 0.008699584752321243\n",
      "Episode Reward: 19.0\n",
      "Step 647 (1279738) @ Episode 2463/10000, loss: 0.0046999645419418817\n",
      "Episode Reward: 11.0\n",
      "Step 261 (1279999) @ Episode 2464/10000, loss: 0.0048177177086472516\n",
      " Copied model parameters to target network\n",
      "Step 850 (1280588) @ Episode 2464/10000, loss: 0.0025656428188085556\n",
      "Episode Reward: 22.0\n",
      "Step 1321 (1281909) @ Episode 2465/10000, loss: 0.0064040990546345714\n",
      "Episode Reward: 30.0\n",
      "Step 687 (1282596) @ Episode 2466/10000, loss: 0.0060254633426666263\n",
      "Episode Reward: 11.0\n",
      "Step 942 (1283538) @ Episode 2467/10000, loss: 0.0056582055985927587\n",
      "Episode Reward: 24.0\n",
      "Step 789 (1284327) @ Episode 2468/10000, loss: 0.0048223054036498075\n",
      "Episode Reward: 13.0\n",
      "Step 731 (1285058) @ Episode 2469/10000, loss: 0.0063186790794134148\n",
      "Episode Reward: 15.0\n",
      "Step 992 (1286050) @ Episode 2470/10000, loss: 0.0064629446715116535\n",
      "Episode Reward: 29.0\n",
      "Step 534 (1286584) @ Episode 2471/10000, loss: 0.0081039872020483023\n",
      "Episode Reward: 8.0\n",
      "Step 879 (1287463) @ Episode 2472/10000, loss: 0.0137481931596994422\n",
      "Episode Reward: 21.0\n",
      "Step 1293 (1288756) @ Episode 2473/10000, loss: 0.0084524601697921755\n",
      "Episode Reward: 31.0\n",
      "Step 1243 (1289999) @ Episode 2474/10000, loss: 0.0213260818272829064\n",
      " Copied model parameters to target network\n",
      "Step 1311 (1290067) @ Episode 2474/10000, loss: 0.0092892013490200046\n",
      "Episode Reward: 37.0\n",
      "Step 723 (1290790) @ Episode 2475/10000, loss: 0.0067471712827682495\n",
      "Episode Reward: 15.0\n",
      "Step 960 (1291750) @ Episode 2476/10000, loss: 0.0095622437074780468\n",
      "Episode Reward: 33.0\n",
      "Step 865 (1292615) @ Episode 2477/10000, loss: 0.0070092887617647655\n",
      "Episode Reward: 28.0\n",
      "Step 1029 (1293644) @ Episode 2478/10000, loss: 0.0052941716276109225\n",
      "Episode Reward: 17.0\n",
      "Step 646 (1294290) @ Episode 2479/10000, loss: 0.0048269676044583325\n",
      "Episode Reward: 11.0\n",
      "Step 818 (1295108) @ Episode 2480/10000, loss: 0.0091338707134127625\n",
      "Episode Reward: 13.0\n",
      "Step 1120 (1296228) @ Episode 2481/10000, loss: 0.0066932281479239467\n",
      "Episode Reward: 30.0\n",
      "Step 1114 (1297342) @ Episode 2482/10000, loss: 0.0063274521380662927\n",
      "Episode Reward: 24.0\n",
      "Step 964 (1298306) @ Episode 2483/10000, loss: 0.0099352942779660227\n",
      "Episode Reward: 24.0\n",
      "Step 1158 (1299464) @ Episode 2484/10000, loss: 0.0057029230520129243\n",
      "Episode Reward: 34.0\n",
      "Step 535 (1299999) @ Episode 2485/10000, loss: 0.0046985270455479626\n",
      " Copied model parameters to target network\n",
      "Step 960 (1300424) @ Episode 2485/10000, loss: 0.0031559732742607594\n",
      "Episode Reward: 15.0\n",
      "Step 540 (1300964) @ Episode 2486/10000, loss: 0.0051643075421452525\n",
      "Episode Reward: 7.0\n",
      "Step 1075 (1302039) @ Episode 2487/10000, loss: 0.0109662432223558435\n",
      "Episode Reward: 20.0\n",
      "Step 1109 (1303148) @ Episode 2488/10000, loss: 0.0047344481572508813\n",
      "Episode Reward: 20.0\n",
      "Step 1004 (1304152) @ Episode 2489/10000, loss: 0.014949994161725044\n",
      "Episode Reward: 18.0\n",
      "Step 651 (1304803) @ Episode 2490/10000, loss: 0.0141801498830318455\n",
      "Episode Reward: 11.0\n",
      "Step 824 (1305627) @ Episode 2491/10000, loss: 0.0035907570272684097\n",
      "Episode Reward: 13.0\n",
      "Step 1121 (1306748) @ Episode 2492/10000, loss: 0.0026826527900993824\n",
      "Episode Reward: 26.0\n",
      "Step 909 (1307657) @ Episode 2493/10000, loss: 0.0111156422644853615\n",
      "Episode Reward: 14.0\n",
      "Step 1044 (1308701) @ Episode 2494/10000, loss: 0.0037014840636402375\n",
      "Episode Reward: 22.0\n",
      "Step 1298 (1309999) @ Episode 2495/10000, loss: 0.0141410864889621734\n",
      " Copied model parameters to target network\n",
      "Step 1352 (1310053) @ Episode 2495/10000, loss: 0.0041190003976225856\n",
      "Episode Reward: 31.0\n",
      "Step 677 (1310730) @ Episode 2496/10000, loss: 0.0060650659725071913\n",
      "Episode Reward: 12.0\n",
      "Step 1242 (1311972) @ Episode 2497/10000, loss: 0.0051570371724665165\n",
      "Episode Reward: 27.0\n",
      "Step 1512 (1313484) @ Episode 2498/10000, loss: 0.0239736475050449375\n",
      "Episode Reward: 46.0\n",
      "Step 803 (1314287) @ Episode 2499/10000, loss: 0.0076045421883463868\n",
      "Episode Reward: 14.0\n",
      "Step 951 (1315238) @ Episode 2500/10000, loss: 0.0098068779334425937\n",
      "Episode Reward: 20.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 20:04:54,748] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video002500.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 805 (1316043) @ Episode 2501/10000, loss: 0.0246911570429801944\n",
      "Episode Reward: 17.0\n",
      "Step 1377 (1317420) @ Episode 2502/10000, loss: 0.0045362901873886585\n",
      "Episode Reward: 44.0\n",
      "Step 1518 (1318938) @ Episode 2503/10000, loss: 0.0107721192762255674\n",
      "Episode Reward: 43.0\n",
      "Step 893 (1319831) @ Episode 2504/10000, loss: 0.0141349993646144875\n",
      "Episode Reward: 21.0\n",
      "Step 168 (1319999) @ Episode 2505/10000, loss: 0.0060716019943356516\n",
      " Copied model parameters to target network\n",
      "Step 892 (1320723) @ Episode 2505/10000, loss: 0.0089004253968596467\n",
      "Episode Reward: 20.0\n",
      "Step 1267 (1321990) @ Episode 2506/10000, loss: 0.0128054479137063035\n",
      "Episode Reward: 25.0\n",
      "Step 1305 (1323295) @ Episode 2507/10000, loss: 0.1141275614500045875\n",
      "Episode Reward: 37.0\n",
      "Step 1651 (1324946) @ Episode 2508/10000, loss: 0.0057455725036561495\n",
      "Episode Reward: 40.0\n",
      "Step 846 (1325792) @ Episode 2509/10000, loss: 0.0067666624672710896\n",
      "Episode Reward: 15.0\n",
      "Step 876 (1326668) @ Episode 2510/10000, loss: 0.0068257870152592666\n",
      "Episode Reward: 17.0\n",
      "Step 889 (1327557) @ Episode 2511/10000, loss: 0.0132962241768836983\n",
      "Episode Reward: 12.0\n",
      "Step 896 (1328453) @ Episode 2512/10000, loss: 0.0074529219418764114\n",
      "Episode Reward: 22.0\n",
      "Step 1198 (1329651) @ Episode 2513/10000, loss: 0.0052378163672983657\n",
      "Episode Reward: 26.0\n",
      "Step 348 (1329999) @ Episode 2514/10000, loss: 0.0047269994392991076\n",
      " Copied model parameters to target network\n",
      "Step 1368 (1331019) @ Episode 2514/10000, loss: 0.0105216279625892642\n",
      "Episode Reward: 36.0\n",
      "Step 826 (1331845) @ Episode 2515/10000, loss: 0.0137189608067274165\n",
      "Episode Reward: 16.0\n",
      "Step 1618 (1333463) @ Episode 2516/10000, loss: 0.0120891118422150614\n",
      "Episode Reward: 35.0\n",
      "Step 1137 (1334600) @ Episode 2517/10000, loss: 0.0320824794471263955\n",
      "Episode Reward: 22.0\n",
      "Step 708 (1335308) @ Episode 2518/10000, loss: 0.0047557046636939055\n",
      "Episode Reward: 15.0\n",
      "Step 938 (1336246) @ Episode 2519/10000, loss: 0.0067826844751834875\n",
      "Episode Reward: 23.0\n",
      "Step 965 (1337211) @ Episode 2520/10000, loss: 0.0081309676170349123\n",
      "Episode Reward: 18.0\n",
      "Step 903 (1338114) @ Episode 2521/10000, loss: 0.0169073268771171575\n",
      "Episode Reward: 16.0\n",
      "Step 1064 (1339178) @ Episode 2522/10000, loss: 0.0166421998292207726\n",
      "Episode Reward: 25.0\n",
      "Step 821 (1339999) @ Episode 2523/10000, loss: 0.0230276901274919575\n",
      " Copied model parameters to target network\n",
      "Step 1392 (1340570) @ Episode 2523/10000, loss: 0.0205256305634975437\n",
      "Episode Reward: 31.0\n",
      "Step 853 (1341423) @ Episode 2524/10000, loss: 0.0041058678179979324\n",
      "Episode Reward: 22.0\n",
      "Step 1045 (1342468) @ Episode 2525/10000, loss: 0.0098214037716388725\n",
      "Episode Reward: 36.0\n",
      "Step 1389 (1343857) @ Episode 2526/10000, loss: 0.0115765305235981945\n",
      "Episode Reward: 30.0\n",
      "Step 847 (1344704) @ Episode 2527/10000, loss: 0.0103198578581213956\n",
      "Episode Reward: 15.0\n",
      "Step 961 (1345665) @ Episode 2528/10000, loss: 0.0059292707592248925\n",
      "Episode Reward: 18.0\n",
      "Step 1381 (1347046) @ Episode 2529/10000, loss: 0.0753447785973548955\n",
      "Episode Reward: 30.0\n",
      "Step 930 (1347976) @ Episode 2530/10000, loss: 0.0087774721905589115\n",
      "Episode Reward: 19.0\n",
      "Step 1452 (1349428) @ Episode 2531/10000, loss: 0.0114419413730502134\n",
      "Episode Reward: 36.0\n",
      "Step 571 (1349999) @ Episode 2532/10000, loss: 0.0346429273486137457\n",
      " Copied model parameters to target network\n",
      "Step 1140 (1350568) @ Episode 2532/10000, loss: 0.0143858026713132864\n",
      "Episode Reward: 26.0\n",
      "Step 1470 (1352038) @ Episode 2533/10000, loss: 0.0053863674402236944\n",
      "Episode Reward: 37.0\n",
      "Step 816 (1352854) @ Episode 2534/10000, loss: 0.0144244972616434117\n",
      "Episode Reward: 23.0\n",
      "Step 1154 (1354008) @ Episode 2535/10000, loss: 0.0220931917428970345\n",
      "Episode Reward: 22.0\n",
      "Step 676 (1354684) @ Episode 2536/10000, loss: 0.0074816634878516275\n",
      "Episode Reward: 9.0\n",
      "Step 1156 (1355840) @ Episode 2537/10000, loss: 0.0125555507838726046\n",
      "Episode Reward: 20.0\n",
      "Step 514 (1356354) @ Episode 2538/10000, loss: 0.0039076167158782485\n",
      "Episode Reward: 8.0\n",
      "Step 1248 (1357602) @ Episode 2539/10000, loss: 0.0081528834998607644\n",
      "Episode Reward: 40.0\n",
      "Step 1053 (1358655) @ Episode 2540/10000, loss: 0.0052217412739992144\n",
      "Episode Reward: 21.0\n",
      "Step 738 (1359393) @ Episode 2541/10000, loss: 0.0074988692067563535\n",
      "Episode Reward: 11.0\n",
      "Step 606 (1359999) @ Episode 2542/10000, loss: 0.0347391925752162965\n",
      " Copied model parameters to target network\n",
      "Step 957 (1360350) @ Episode 2542/10000, loss: 0.0054258573800325395\n",
      "Episode Reward: 19.0\n",
      "Step 1110 (1361460) @ Episode 2543/10000, loss: 0.0093634482473135483\n",
      "Episode Reward: 30.0\n",
      "Step 1125 (1362585) @ Episode 2544/10000, loss: 0.0220079906284809155\n",
      "Episode Reward: 19.0\n",
      "Step 879 (1363464) @ Episode 2545/10000, loss: 0.0044325944036245355\n",
      "Episode Reward: 16.0\n",
      "Step 587 (1364051) @ Episode 2546/10000, loss: 0.0110440365970134745\n",
      "Episode Reward: 9.0\n",
      "Step 1554 (1365605) @ Episode 2547/10000, loss: 0.0076192971318960194\n",
      "Episode Reward: 44.0\n",
      "Step 855 (1366460) @ Episode 2548/10000, loss: 0.0095866471529006962\n",
      "Episode Reward: 13.0\n",
      "Step 557 (1367017) @ Episode 2549/10000, loss: 0.0137499179691076285\n",
      "Episode Reward: 8.0\n",
      "Step 1016 (1368033) @ Episode 2550/10000, loss: 0.0054943612776696683\n",
      "Episode Reward: 23.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 20:12:46,282] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video002550.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1162 (1369195) @ Episode 2551/10000, loss: 0.0197409689426422127\n",
      "Episode Reward: 33.0\n",
      "Step 804 (1369999) @ Episode 2552/10000, loss: 0.0084969298914074973\n",
      " Copied model parameters to target network\n",
      "Step 1450 (1370645) @ Episode 2552/10000, loss: 0.0163201577961444854\n",
      "Episode Reward: 43.0\n",
      "Step 1625 (1372270) @ Episode 2553/10000, loss: 0.0038186910096555956\n",
      "Episode Reward: 46.0\n",
      "Step 1180 (1373450) @ Episode 2554/10000, loss: 0.0208310410380363465\n",
      "Episode Reward: 27.0\n",
      "Step 910 (1374360) @ Episode 2555/10000, loss: 0.0105513632297515877\n",
      "Episode Reward: 15.0\n",
      "Step 1203 (1375563) @ Episode 2556/10000, loss: 0.0040314863435924053\n",
      "Episode Reward: 28.0\n",
      "Step 1074 (1376637) @ Episode 2557/10000, loss: 0.0039543756283819675\n",
      "Episode Reward: 21.0\n",
      "Step 842 (1377479) @ Episode 2558/10000, loss: 0.0050622979179024785\n",
      "Episode Reward: 18.0\n",
      "Step 912 (1378391) @ Episode 2559/10000, loss: 0.0042117726989090446\n",
      "Episode Reward: 17.0\n",
      "Step 838 (1379229) @ Episode 2560/10000, loss: 0.0081407679244875948\n",
      "Episode Reward: 19.0\n",
      "Step 770 (1379999) @ Episode 2561/10000, loss: 0.0034643146209418774\n",
      " Copied model parameters to target network\n",
      "Step 836 (1380065) @ Episode 2561/10000, loss: 0.0057074348442256454\n",
      "Episode Reward: 14.0\n",
      "Step 1352 (1381417) @ Episode 2562/10000, loss: 0.0024422765709459785\n",
      "Episode Reward: 33.0\n",
      "Step 1041 (1382458) @ Episode 2563/10000, loss: 0.0034050256945192814\n",
      "Episode Reward: 22.0\n",
      "Step 1293 (1383751) @ Episode 2564/10000, loss: 0.0192279815673828125\n",
      "Episode Reward: 35.0\n",
      "Step 722 (1384473) @ Episode 2565/10000, loss: 0.0036168508231639865\n",
      "Episode Reward: 11.0\n",
      "Step 1083 (1385556) @ Episode 2566/10000, loss: 0.0199309848248958657\n",
      "Episode Reward: 23.0\n",
      "Step 1025 (1386581) @ Episode 2567/10000, loss: 0.0099538536742329655\n",
      "Episode Reward: 23.0\n",
      "Step 1322 (1387903) @ Episode 2568/10000, loss: 0.0101243993267416954\n",
      "Episode Reward: 32.0\n",
      "Step 1228 (1389131) @ Episode 2569/10000, loss: 0.0160251818597316745\n",
      "Episode Reward: 29.0\n",
      "Step 868 (1389999) @ Episode 2570/10000, loss: 0.0379370376467704837\n",
      " Copied model parameters to target network\n",
      "Step 1100 (1390231) @ Episode 2570/10000, loss: 0.0097353700548410424\n",
      "Episode Reward: 28.0\n",
      "Step 1566 (1391797) @ Episode 2571/10000, loss: 0.0031271495390683413\n",
      "Episode Reward: 43.0\n",
      "Step 724 (1392521) @ Episode 2572/10000, loss: 0.0278154984116554263\n",
      "Episode Reward: 12.0\n",
      "Step 764 (1393285) @ Episode 2573/10000, loss: 0.0099798440933227545\n",
      "Episode Reward: 11.0\n",
      "Step 472 (1393757) @ Episode 2574/10000, loss: 0.0049144830554723743\n",
      "Episode Reward: 7.0\n",
      "Step 835 (1394592) @ Episode 2575/10000, loss: 0.0077859647572040565\n",
      "Episode Reward: 17.0\n",
      "Step 1397 (1395989) @ Episode 2576/10000, loss: 0.0160965062677860264\n",
      "Episode Reward: 34.0\n",
      "Step 962 (1396951) @ Episode 2577/10000, loss: 0.0048743663355708125\n",
      "Episode Reward: 16.0\n",
      "Step 959 (1397910) @ Episode 2578/10000, loss: 0.0084484331309795385\n",
      "Episode Reward: 23.0\n",
      "Step 1318 (1399228) @ Episode 2579/10000, loss: 0.0066151134669780735\n",
      "Episode Reward: 33.0\n",
      "Step 771 (1399999) @ Episode 2580/10000, loss: 0.0056270882487297066\n",
      " Copied model parameters to target network\n",
      "Step 947 (1400175) @ Episode 2580/10000, loss: 0.0724272355437278745\n",
      "Episode Reward: 15.0\n",
      "Step 1169 (1401344) @ Episode 2581/10000, loss: 0.0136690409854054457\n",
      "Episode Reward: 21.0\n",
      "Step 793 (1402137) @ Episode 2582/10000, loss: 0.0049696587957441816\n",
      "Episode Reward: 13.0\n",
      "Step 1127 (1403264) @ Episode 2583/10000, loss: 0.0075291879475116735\n",
      "Episode Reward: 26.0\n",
      "Step 775 (1404039) @ Episode 2584/10000, loss: 0.0116450665518641475\n",
      "Episode Reward: 16.0\n",
      "Step 1243 (1405282) @ Episode 2585/10000, loss: 0.0031363146845251326\n",
      "Episode Reward: 26.0\n",
      "Step 829 (1406111) @ Episode 2586/10000, loss: 0.0279683135449886325\n",
      "Episode Reward: 14.0\n",
      "Step 1314 (1407425) @ Episode 2587/10000, loss: 0.0037634209729731083\n",
      "Episode Reward: 33.0\n",
      "Step 947 (1408372) @ Episode 2588/10000, loss: 0.0058357147499918945\n",
      "Episode Reward: 19.0\n",
      "Step 997 (1409369) @ Episode 2589/10000, loss: 0.0097725205123424535\n",
      "Episode Reward: 25.0\n",
      "Step 630 (1409999) @ Episode 2590/10000, loss: 0.0041878675110638145\n",
      " Copied model parameters to target network\n",
      "Step 680 (1410049) @ Episode 2590/10000, loss: 0.0328182727098465514\n",
      "Episode Reward: 11.0\n",
      "Step 1312 (1411361) @ Episode 2591/10000, loss: 0.0048274509608745575\n",
      "Episode Reward: 38.0\n",
      "Step 894 (1412255) @ Episode 2592/10000, loss: 0.0039512719959020615\n",
      "Episode Reward: 14.0\n",
      "Step 695 (1412950) @ Episode 2593/10000, loss: 0.0070590702816843997\n",
      "Episode Reward: 11.0\n",
      "Step 873 (1413823) @ Episode 2594/10000, loss: 0.0079835802316665655\n",
      "Episode Reward: 18.0\n",
      "Step 761 (1414584) @ Episode 2595/10000, loss: 0.0042128348723053934\n",
      "Episode Reward: 16.0\n",
      "Step 933 (1415517) @ Episode 2596/10000, loss: 0.0057905064895749097\n",
      "Episode Reward: 25.0\n",
      "Step 720 (1416237) @ Episode 2597/10000, loss: 0.0129465293139219285\n",
      "Episode Reward: 9.0\n",
      "Step 782 (1417019) @ Episode 2598/10000, loss: 0.0187380518764257433\n",
      "Episode Reward: 9.0\n",
      "Step 814 (1417833) @ Episode 2599/10000, loss: 0.0056767957285046584\n",
      "Episode Reward: 18.0\n",
      "Step 651 (1418484) @ Episode 2600/10000, loss: 0.0106958458200097083\n",
      "Episode Reward: 13.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 20:20:18,614] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video002600.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1459 (1419943) @ Episode 2601/10000, loss: 0.0375502817332744667\n",
      "Episode Reward: 36.0\n",
      "Step 56 (1419999) @ Episode 2602/10000, loss: 0.0075926892459392555\n",
      " Copied model parameters to target network\n",
      "Step 632 (1420575) @ Episode 2602/10000, loss: 0.0108084129169583327\n",
      "Episode Reward: 9.0\n",
      "Step 822 (1421397) @ Episode 2603/10000, loss: 0.0461382195353508744\n",
      "Episode Reward: 15.0\n",
      "Step 621 (1422018) @ Episode 2604/10000, loss: 0.0075518139638006694\n",
      "Episode Reward: 10.0\n",
      "Step 696 (1422714) @ Episode 2605/10000, loss: 0.0088661070913076423\n",
      "Episode Reward: 11.0\n",
      "Step 779 (1423493) @ Episode 2606/10000, loss: 0.0140488231554627425\n",
      "Episode Reward: 14.0\n",
      "Step 1112 (1424605) @ Episode 2607/10000, loss: 0.0124505739659070975\n",
      "Episode Reward: 21.0\n",
      "Step 1432 (1426037) @ Episode 2608/10000, loss: 0.0133586991578340536\n",
      "Episode Reward: 33.0\n",
      "Step 960 (1426997) @ Episode 2609/10000, loss: 0.0138920061290264136\n",
      "Episode Reward: 15.0\n",
      "Step 936 (1427933) @ Episode 2610/10000, loss: 0.0019269356271252036\n",
      "Episode Reward: 19.0\n",
      "Step 881 (1428814) @ Episode 2611/10000, loss: 0.0093126585707068446\n",
      "Episode Reward: 15.0\n",
      "Step 518 (1429332) @ Episode 2612/10000, loss: 0.0172285642474889765\n",
      "Episode Reward: 5.0\n",
      "Step 667 (1429999) @ Episode 2613/10000, loss: 0.0059003550559282346\n",
      " Copied model parameters to target network\n",
      "Step 1067 (1430399) @ Episode 2613/10000, loss: 0.0327555611729621915\n",
      "Episode Reward: 24.0\n",
      "Step 1324 (1431723) @ Episode 2614/10000, loss: 0.0155698694288730623\n",
      "Episode Reward: 24.0\n",
      "Step 768 (1432491) @ Episode 2615/10000, loss: 0.0045035881921648985\n",
      "Episode Reward: 10.0\n",
      "Step 752 (1433243) @ Episode 2616/10000, loss: 0.0058135152794420722\n",
      "Episode Reward: 9.0\n",
      "Step 781 (1434024) @ Episode 2617/10000, loss: 0.0037266055587679148\n",
      "Episode Reward: 16.0\n",
      "Step 940 (1434964) @ Episode 2618/10000, loss: 0.0228575449436903165\n",
      "Episode Reward: 18.0\n",
      "Step 1257 (1436221) @ Episode 2619/10000, loss: 0.0035036406479775906\n",
      "Episode Reward: 28.0\n",
      "Step 848 (1437069) @ Episode 2620/10000, loss: 0.0116731636226177224\n",
      "Episode Reward: 13.0\n",
      "Step 1010 (1438079) @ Episode 2621/10000, loss: 0.0098174437880516053\n",
      "Episode Reward: 17.0\n",
      "Step 918 (1438997) @ Episode 2622/10000, loss: 0.0075266216881573245\n",
      "Episode Reward: 21.0\n",
      "Step 733 (1439730) @ Episode 2623/10000, loss: 0.0076519716531038284\n",
      "Episode Reward: 12.0\n",
      "Step 269 (1439999) @ Episode 2624/10000, loss: 0.0036221868358552456\n",
      " Copied model parameters to target network\n",
      "Step 1242 (1440972) @ Episode 2624/10000, loss: 0.0046112155541777613\n",
      "Episode Reward: 31.0\n",
      "Step 1241 (1442213) @ Episode 2625/10000, loss: 0.0059856986626982692\n",
      "Episode Reward: 24.0\n",
      "Step 1097 (1443310) @ Episode 2626/10000, loss: 0.0119265876710414895\n",
      "Episode Reward: 24.0\n",
      "Step 740 (1444050) @ Episode 2627/10000, loss: 0.0436539165675640175\n",
      "Episode Reward: 11.0\n",
      "Step 1010 (1445060) @ Episode 2628/10000, loss: 0.004287001211196184\n",
      "Episode Reward: 20.0\n",
      "Step 522 (1445582) @ Episode 2629/10000, loss: 0.0095418468117713935\n",
      "Episode Reward: 7.0\n",
      "Step 565 (1446147) @ Episode 2630/10000, loss: 0.0032953843474388123\n",
      "Episode Reward: 9.0\n",
      "Step 1110 (1447257) @ Episode 2631/10000, loss: 0.0154548734426498413\n",
      "Episode Reward: 22.0\n",
      "Step 1105 (1448362) @ Episode 2632/10000, loss: 0.0049780663102865225\n",
      "Episode Reward: 20.0\n",
      "Step 530 (1448892) @ Episode 2633/10000, loss: 0.0049792733043432245\n",
      "Episode Reward: 7.0\n",
      "Step 1107 (1449999) @ Episode 2634/10000, loss: 0.0069187763147056176\n",
      " Copied model parameters to target network\n",
      "Step 1185 (1450077) @ Episode 2634/10000, loss: 0.0055769085884094243\n",
      "Episode Reward: 23.0\n",
      "Step 699 (1450776) @ Episode 2635/10000, loss: 0.0137733556330204015\n",
      "Episode Reward: 12.0\n",
      "Step 1133 (1451909) @ Episode 2636/10000, loss: 0.0105056557804346085\n",
      "Episode Reward: 25.0\n",
      "Step 981 (1452890) @ Episode 2637/10000, loss: 0.0066844848915934564\n",
      "Episode Reward: 21.0\n",
      "Step 893 (1453783) @ Episode 2638/10000, loss: 0.0635549575090408345\n",
      "Episode Reward: 17.0\n",
      "Step 944 (1454727) @ Episode 2639/10000, loss: 0.0064989179372787476\n",
      "Episode Reward: 16.0\n",
      "Step 873 (1455600) @ Episode 2640/10000, loss: 0.0045218314044177538\n",
      "Episode Reward: 19.0\n",
      "Step 779 (1456379) @ Episode 2641/10000, loss: 0.0089164189994335175\n",
      "Episode Reward: 14.0\n",
      "Step 751 (1457130) @ Episode 2642/10000, loss: 0.0095526352524757397\n",
      "Episode Reward: 12.0\n",
      "Step 826 (1457956) @ Episode 2643/10000, loss: 0.0085509587079286585\n",
      "Episode Reward: 14.0\n",
      "Step 1395 (1459351) @ Episode 2644/10000, loss: 0.0170670449733734135\n",
      "Episode Reward: 34.0\n",
      "Step 648 (1459999) @ Episode 2645/10000, loss: 0.0402891710400581365\n",
      " Copied model parameters to target network\n",
      "Step 1050 (1460401) @ Episode 2645/10000, loss: 0.0334686674177646645\n",
      "Episode Reward: 28.0\n",
      "Step 1030 (1461431) @ Episode 2646/10000, loss: 0.0063556451350450526\n",
      "Episode Reward: 22.0\n",
      "Step 1075 (1462506) @ Episode 2647/10000, loss: 0.0062806345522403725\n",
      "Episode Reward: 26.0\n",
      "Step 952 (1463458) @ Episode 2648/10000, loss: 0.0200162380933761643\n",
      "Episode Reward: 16.0\n",
      "Step 1135 (1464593) @ Episode 2649/10000, loss: 0.0061568301171064385\n",
      "Episode Reward: 38.0\n",
      "Step 1183 (1465776) @ Episode 2650/10000, loss: 0.0047790175303816795\n",
      "Episode Reward: 36.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 20:27:24,522] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video002650.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1135 (1466911) @ Episode 2651/10000, loss: 0.0070664295926690155\n",
      "Episode Reward: 25.0\n",
      "Step 1055 (1467966) @ Episode 2652/10000, loss: 0.2494766116142273477\n",
      "Episode Reward: 28.0\n",
      "Step 868 (1468834) @ Episode 2653/10000, loss: 0.0060186479240655945\n",
      "Episode Reward: 20.0\n",
      "Step 1038 (1469872) @ Episode 2654/10000, loss: 0.0156499966979026845\n",
      "Episode Reward: 22.0\n",
      "Step 127 (1469999) @ Episode 2655/10000, loss: 0.0054928120225667955\n",
      " Copied model parameters to target network\n",
      "Step 541 (1470413) @ Episode 2655/10000, loss: 0.0154538433998823174\n",
      "Episode Reward: 9.0\n",
      "Step 992 (1471405) @ Episode 2656/10000, loss: 0.0105462921783328064\n",
      "Episode Reward: 24.0\n",
      "Step 1220 (1472625) @ Episode 2657/10000, loss: 0.0100831668823957443\n",
      "Episode Reward: 25.0\n",
      "Step 886 (1473511) @ Episode 2658/10000, loss: 0.0075574028305709364\n",
      "Episode Reward: 22.0\n",
      "Step 821 (1474332) @ Episode 2659/10000, loss: 0.0073693683370947843\n",
      "Episode Reward: 13.0\n",
      "Step 1014 (1475346) @ Episode 2660/10000, loss: 0.0196389667689800265\n",
      "Episode Reward: 26.0\n",
      "Step 958 (1476304) @ Episode 2661/10000, loss: 0.0038907800335437065\n",
      "Episode Reward: 23.0\n",
      "Step 855 (1477159) @ Episode 2662/10000, loss: 0.0156098091974854475\n",
      "Episode Reward: 23.0\n",
      "Step 1628 (1478787) @ Episode 2663/10000, loss: 0.0132981305941939355\n",
      "Episode Reward: 35.0\n",
      "Step 629 (1479416) @ Episode 2664/10000, loss: 0.0215018764138221747\n",
      "Episode Reward: 11.0\n",
      "Step 583 (1479999) @ Episode 2665/10000, loss: 0.0199233461171388636\n",
      " Copied model parameters to target network\n",
      "Step 1168 (1480584) @ Episode 2665/10000, loss: 0.0073719955980777747\n",
      "Episode Reward: 27.0\n",
      "Step 616 (1481200) @ Episode 2666/10000, loss: 0.0153884720057249078\n",
      "Episode Reward: 8.0\n",
      "Step 831 (1482031) @ Episode 2667/10000, loss: 0.0587266720831394286\n",
      "Episode Reward: 15.0\n",
      "Step 1258 (1483289) @ Episode 2668/10000, loss: 0.0075925779528915885\n",
      "Episode Reward: 24.0\n",
      "Step 854 (1484143) @ Episode 2669/10000, loss: 0.0054539432749152187\n",
      "Episode Reward: 14.0\n",
      "Step 1016 (1485159) @ Episode 2670/10000, loss: 0.0037968824617564686\n",
      "Episode Reward: 20.0\n",
      "Step 1562 (1486721) @ Episode 2671/10000, loss: 0.0057849641889333725\n",
      "Episode Reward: 32.0\n",
      "Step 1197 (1487918) @ Episode 2672/10000, loss: 0.0088756885379552846\n",
      "Episode Reward: 32.0\n",
      "Step 895 (1488813) @ Episode 2673/10000, loss: 0.0078901667147874836\n",
      "Episode Reward: 15.0\n",
      "Step 800 (1489613) @ Episode 2674/10000, loss: 0.0041081472299993043\n",
      "Episode Reward: 13.0\n",
      "Step 386 (1489999) @ Episode 2675/10000, loss: 0.0080419927835464485\n",
      " Copied model parameters to target network\n",
      "Step 790 (1490403) @ Episode 2675/10000, loss: 0.0080289710313081744\n",
      "Episode Reward: 14.0\n",
      "Step 1521 (1491924) @ Episode 2676/10000, loss: 0.0139317102730274265\n",
      "Episode Reward: 39.0\n",
      "Step 727 (1492651) @ Episode 2677/10000, loss: 0.0141594605520367624\n",
      "Episode Reward: 12.0\n",
      "Step 794 (1493445) @ Episode 2678/10000, loss: 0.0077185989357531072\n",
      "Episode Reward: 12.0\n",
      "Step 1058 (1494503) @ Episode 2679/10000, loss: 0.0117513034492731196\n",
      "Episode Reward: 22.0\n",
      "Step 1242 (1495745) @ Episode 2680/10000, loss: 0.0107784438878297858\n",
      "Episode Reward: 26.0\n",
      "Step 897 (1496642) @ Episode 2681/10000, loss: 0.0057612545788288123\n",
      "Episode Reward: 17.0\n",
      "Step 938 (1497580) @ Episode 2682/10000, loss: 0.0065640914253890514\n",
      "Episode Reward: 18.0\n",
      "Step 449 (1498029) @ Episode 2683/10000, loss: 0.0073105613701045515\n",
      "Episode Reward: 7.0\n",
      "Step 461 (1498490) @ Episode 2684/10000, loss: 0.0334491804242134165\n",
      "Episode Reward: 7.0\n",
      "Step 891 (1499381) @ Episode 2685/10000, loss: 0.0031274273060262203\n",
      "Episode Reward: 22.0\n",
      "Step 618 (1499999) @ Episode 2686/10000, loss: 0.0062041347846388825\n",
      " Copied model parameters to target network\n",
      "Step 752 (1500133) @ Episode 2686/10000, loss: 0.0445916578173637474\n",
      "Episode Reward: 17.0\n",
      "Step 1207 (1501340) @ Episode 2687/10000, loss: 0.0172735862433910377\n",
      "Episode Reward: 22.0\n",
      "Step 796 (1502136) @ Episode 2688/10000, loss: 0.0025390656664967537\n",
      "Episode Reward: 11.0\n",
      "Step 814 (1502950) @ Episode 2689/10000, loss: 0.0051329485140740874\n",
      "Episode Reward: 16.0\n",
      "Step 886 (1503836) @ Episode 2690/10000, loss: 0.0042291297577321533\n",
      "Episode Reward: 13.0\n",
      "Step 1028 (1504864) @ Episode 2691/10000, loss: 0.0092911701649427413\n",
      "Episode Reward: 22.0\n",
      "Step 835 (1505699) @ Episode 2692/10000, loss: 0.0072612310759723195\n",
      "Episode Reward: 14.0\n",
      "Step 1467 (1507166) @ Episode 2693/10000, loss: 0.0142568442970514315\n",
      "Episode Reward: 35.0\n",
      "Step 687 (1507853) @ Episode 2694/10000, loss: 0.0087612383067607883\n",
      "Episode Reward: 11.0\n",
      "Step 1278 (1509131) @ Episode 2695/10000, loss: 0.0048728259280323984\n",
      "Episode Reward: 34.0\n",
      "Step 683 (1509814) @ Episode 2696/10000, loss: 0.0056741740554571158\n",
      "Episode Reward: 11.0\n",
      "Step 185 (1509999) @ Episode 2697/10000, loss: 0.0051266732625663284\n",
      " Copied model parameters to target network\n",
      "Step 605 (1510419) @ Episode 2697/10000, loss: 0.0195234213024377825\n",
      "Episode Reward: 10.0\n",
      "Step 786 (1511205) @ Episode 2698/10000, loss: 0.0246788226068019872\n",
      "Episode Reward: 17.0\n",
      "Step 1024 (1512229) @ Episode 2699/10000, loss: 0.010894292965531353\n",
      "Episode Reward: 24.0\n",
      "Step 1217 (1513446) @ Episode 2700/10000, loss: 0.0107770105823874475\n",
      "Episode Reward: 37.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 20:34:30,811] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video002700.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 875 (1514321) @ Episode 2701/10000, loss: 0.0028097173199057588\n",
      "Episode Reward: 13.0\n",
      "Step 854 (1515175) @ Episode 2702/10000, loss: 0.0087194815278053285\n",
      "Episode Reward: 12.0\n",
      "Step 804 (1515979) @ Episode 2703/10000, loss: 0.0130918044596910483\n",
      "Episode Reward: 19.0\n",
      "Step 787 (1516766) @ Episode 2704/10000, loss: 0.0117772091180086142\n",
      "Episode Reward: 13.0\n",
      "Step 1399 (1518165) @ Episode 2705/10000, loss: 0.0084031205624341963\n",
      "Episode Reward: 43.0\n",
      "Step 1294 (1519459) @ Episode 2706/10000, loss: 0.0074804322794079786\n",
      "Episode Reward: 29.0\n",
      "Step 540 (1519999) @ Episode 2707/10000, loss: 0.0126155698671936995\n",
      " Copied model parameters to target network\n",
      "Step 1008 (1520467) @ Episode 2707/10000, loss: 0.0165019650012254735\n",
      "Episode Reward: 26.0\n",
      "Step 850 (1521317) @ Episode 2708/10000, loss: 0.0058576110750436786\n",
      "Episode Reward: 21.0\n",
      "Step 1090 (1522407) @ Episode 2709/10000, loss: 0.0083439815789461144\n",
      "Episode Reward: 35.0\n",
      "Step 826 (1523233) @ Episode 2710/10000, loss: 0.0821950361132621862\n",
      "Episode Reward: 17.0\n",
      "Step 702 (1523935) @ Episode 2711/10000, loss: 0.0048579238355159765\n",
      "Episode Reward: 15.0\n",
      "Step 913 (1524848) @ Episode 2712/10000, loss: 0.0100489482283592223\n",
      "Episode Reward: 16.0\n",
      "Step 1032 (1525880) @ Episode 2713/10000, loss: 0.0026148494798690084\n",
      "Episode Reward: 19.0\n",
      "Step 969 (1526849) @ Episode 2714/10000, loss: 0.0039236848242580895\n",
      "Episode Reward: 18.0\n",
      "Step 707 (1527556) @ Episode 2715/10000, loss: 0.0048503535799682145\n",
      "Episode Reward: 11.0\n",
      "Step 1253 (1528809) @ Episode 2716/10000, loss: 0.0044953948818147183\n",
      "Episode Reward: 23.0\n",
      "Step 723 (1529532) @ Episode 2717/10000, loss: 0.0065720286220312125\n",
      "Episode Reward: 15.0\n",
      "Step 467 (1529999) @ Episode 2718/10000, loss: 0.0098880780860781674\n",
      " Copied model parameters to target network\n",
      "Step 851 (1530383) @ Episode 2718/10000, loss: 0.0034601995721459395\n",
      "Episode Reward: 20.0\n",
      "Step 1275 (1531658) @ Episode 2719/10000, loss: 0.0180868897587060937\n",
      "Episode Reward: 40.0\n",
      "Step 1062 (1532720) @ Episode 2720/10000, loss: 0.0067964075133204464\n",
      "Episode Reward: 30.0\n",
      "Step 1119 (1533839) @ Episode 2721/10000, loss: 0.0026079681701958185\n",
      "Episode Reward: 31.0\n",
      "Step 1109 (1534948) @ Episode 2722/10000, loss: 0.0022587815765291452\n",
      "Episode Reward: 23.0\n",
      "Step 1166 (1536114) @ Episode 2723/10000, loss: 0.0121727902442216875\n",
      "Episode Reward: 23.0\n",
      "Step 762 (1536876) @ Episode 2724/10000, loss: 0.0059613510966300964\n",
      "Episode Reward: 14.0\n",
      "Step 710 (1537586) @ Episode 2725/10000, loss: 0.0126637779176235235\n",
      "Episode Reward: 11.0\n",
      "Step 1144 (1538730) @ Episode 2726/10000, loss: 0.0133814718574285565\n",
      "Episode Reward: 25.0\n",
      "Step 734 (1539464) @ Episode 2727/10000, loss: 0.0055406652390956885\n",
      "Episode Reward: 10.0\n",
      "Step 535 (1539999) @ Episode 2728/10000, loss: 0.0107438722625374833\n",
      " Copied model parameters to target network\n",
      "Step 1090 (1540554) @ Episode 2728/10000, loss: 0.0041673397645354275\n",
      "Episode Reward: 22.0\n",
      "Step 1163 (1541717) @ Episode 2729/10000, loss: 0.0214587096124887476\n",
      "Episode Reward: 30.0\n",
      "Step 935 (1542652) @ Episode 2730/10000, loss: 0.0331867188215255744\n",
      "Episode Reward: 15.0\n",
      "Step 943 (1543595) @ Episode 2731/10000, loss: 0.0113560277968645172\n",
      "Episode Reward: 15.0\n",
      "Step 963 (1544558) @ Episode 2732/10000, loss: 0.0079708276316523554\n",
      "Episode Reward: 23.0\n",
      "Step 895 (1545453) @ Episode 2733/10000, loss: 0.0104173906147480017\n",
      "Episode Reward: 18.0\n",
      "Step 996 (1546449) @ Episode 2734/10000, loss: 0.0068755755200982095\n",
      "Episode Reward: 24.0\n",
      "Step 550 (1546999) @ Episode 2735/10000, loss: 0.0063670100644230846\n",
      "Episode Reward: 8.0\n",
      "Step 593 (1547592) @ Episode 2736/10000, loss: 0.0091996435075998374\n",
      "Episode Reward: 9.0\n",
      "Step 810 (1548402) @ Episode 2737/10000, loss: 0.0108041204512119365\n",
      "Episode Reward: 23.0\n",
      "Step 857 (1549259) @ Episode 2738/10000, loss: 0.0043006045743823054\n",
      "Episode Reward: 18.0\n",
      "Step 740 (1549999) @ Episode 2739/10000, loss: 0.0105478651821613315\n",
      " Copied model parameters to target network\n",
      "Step 823 (1550082) @ Episode 2739/10000, loss: 0.0096312640234828276\n",
      "Episode Reward: 19.0\n",
      "Step 505 (1550587) @ Episode 2740/10000, loss: 0.0145899718627333644\n",
      "Episode Reward: 7.0\n",
      "Step 649 (1551236) @ Episode 2741/10000, loss: 0.0087327864021062857\n",
      "Episode Reward: 14.0\n",
      "Step 951 (1552187) @ Episode 2742/10000, loss: 0.0094058606773614885\n",
      "Episode Reward: 19.0\n",
      "Step 869 (1553056) @ Episode 2743/10000, loss: 0.0064771967008709915\n",
      "Episode Reward: 14.0\n",
      "Step 869 (1553925) @ Episode 2744/10000, loss: 0.0222364328801631935\n",
      "Episode Reward: 14.0\n",
      "Step 782 (1554707) @ Episode 2745/10000, loss: 0.0035483338870108128\n",
      "Episode Reward: 13.0\n",
      "Step 557 (1555264) @ Episode 2746/10000, loss: 0.0083212237805128135\n",
      "Episode Reward: 8.0\n",
      "Step 860 (1556124) @ Episode 2747/10000, loss: 0.0088499076664447787\n",
      "Episode Reward: 16.0\n",
      "Step 483 (1556607) @ Episode 2748/10000, loss: 0.0048720231279730825\n",
      "Episode Reward: 7.0\n",
      "Step 806 (1557413) @ Episode 2749/10000, loss: 0.0296574439853429845\n",
      "Episode Reward: 13.0\n",
      "Step 778 (1558191) @ Episode 2750/10000, loss: 0.0231512710452079774\n",
      "Episode Reward: 16.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 20:41:16,027] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video002750.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1193 (1559384) @ Episode 2751/10000, loss: 0.0072018741630017762\n",
      "Episode Reward: 20.0\n",
      "Step 615 (1559999) @ Episode 2752/10000, loss: 0.0204139351844787642\n",
      " Copied model parameters to target network\n",
      "Step 676 (1560060) @ Episode 2752/10000, loss: 0.0085146659985184678\n",
      "Episode Reward: 11.0\n",
      "Step 852 (1560912) @ Episode 2753/10000, loss: 0.0157315023243427285\n",
      "Episode Reward: 14.0\n",
      "Step 810 (1561722) @ Episode 2754/10000, loss: 0.0135010490193963055\n",
      "Episode Reward: 13.0\n",
      "Step 898 (1562620) @ Episode 2755/10000, loss: 0.0066626053303480155\n",
      "Episode Reward: 21.0\n",
      "Step 964 (1563584) @ Episode 2756/10000, loss: 0.0095291025936603555\n",
      "Episode Reward: 20.0\n",
      "Step 680 (1564264) @ Episode 2757/10000, loss: 0.0047726808115839966\n",
      "Episode Reward: 12.0\n",
      "Step 1226 (1565490) @ Episode 2758/10000, loss: 0.0290527045726776124\n",
      "Episode Reward: 32.0\n",
      "Step 790 (1566280) @ Episode 2759/10000, loss: 0.0103477416560053835\n",
      "Episode Reward: 13.0\n",
      "Step 796 (1567076) @ Episode 2760/10000, loss: 0.0067531075328588495\n",
      "Episode Reward: 13.0\n",
      "Step 484 (1567560) @ Episode 2761/10000, loss: 0.0075091253966093065\n",
      "Episode Reward: 5.0\n",
      "Step 953 (1568513) @ Episode 2762/10000, loss: 0.0075324890203773975\n",
      "Episode Reward: 22.0\n",
      "Step 825 (1569338) @ Episode 2763/10000, loss: 0.0077930432744324215\n",
      "Episode Reward: 14.0\n",
      "Step 661 (1569999) @ Episode 2764/10000, loss: 0.0148308072239160545\n",
      " Copied model parameters to target network\n",
      "Step 966 (1570304) @ Episode 2764/10000, loss: 0.0073616551235318184\n",
      "Episode Reward: 24.0\n",
      "Step 859 (1571163) @ Episode 2765/10000, loss: 0.0090391486883163457\n",
      "Episode Reward: 18.0\n",
      "Step 924 (1572087) @ Episode 2766/10000, loss: 0.0355962328612804485\n",
      "Episode Reward: 15.0\n",
      "Step 741 (1572828) @ Episode 2767/10000, loss: 0.0056566987186670345\n",
      "Episode Reward: 12.0\n",
      "Step 1004 (1573832) @ Episode 2768/10000, loss: 0.052491843700408936\n",
      "Episode Reward: 23.0\n",
      "Step 886 (1574718) @ Episode 2769/10000, loss: 0.0054628862999379635\n",
      "Episode Reward: 14.0\n",
      "Step 1226 (1575944) @ Episode 2770/10000, loss: 0.0140550304204225544\n",
      "Episode Reward: 30.0\n",
      "Step 864 (1576808) @ Episode 2771/10000, loss: 0.0112703805789351467\n",
      "Episode Reward: 17.0\n",
      "Step 1031 (1577839) @ Episode 2772/10000, loss: 0.0149474982172250757\n",
      "Episode Reward: 20.0\n",
      "Step 1009 (1578848) @ Episode 2773/10000, loss: 0.004918482154607773\n",
      "Episode Reward: 20.0\n",
      "Step 1002 (1579850) @ Episode 2774/10000, loss: 0.007298348471522331\n",
      "Episode Reward: 21.0\n",
      "Step 149 (1579999) @ Episode 2775/10000, loss: 0.0088818445801734924\n",
      " Copied model parameters to target network\n",
      "Step 977 (1580827) @ Episode 2775/10000, loss: 0.0135105643421411515\n",
      "Episode Reward: 25.0\n",
      "Step 847 (1581674) @ Episode 2776/10000, loss: 0.0376085862517356945\n",
      "Episode Reward: 22.0\n",
      "Step 427 (1582101) @ Episode 2777/10000, loss: 0.0089540183544158943\n",
      "Episode Reward: 6.0\n",
      "Step 782 (1582883) @ Episode 2778/10000, loss: 0.0099336020648479465\n",
      "Episode Reward: 14.0\n",
      "Step 811 (1583694) @ Episode 2779/10000, loss: 0.0148551035672426224\n",
      "Episode Reward: 17.0\n",
      "Step 966 (1584660) @ Episode 2780/10000, loss: 0.0318824909627437627\n",
      "Episode Reward: 16.0\n",
      "Step 904 (1585564) @ Episode 2781/10000, loss: 0.0045605092309415344\n",
      "Episode Reward: 20.0\n",
      "Step 902 (1586466) @ Episode 2782/10000, loss: 0.0103232190012931825\n",
      "Episode Reward: 16.0\n",
      "Step 1004 (1587470) @ Episode 2783/10000, loss: 0.012559542432427406\n",
      "Episode Reward: 20.0\n",
      "Step 620 (1588090) @ Episode 2784/10000, loss: 0.0033406307920813565\n",
      "Episode Reward: 17.0\n",
      "Step 867 (1588957) @ Episode 2785/10000, loss: 0.0138533227145671845\n",
      "Episode Reward: 12.0\n",
      "Step 1042 (1589999) @ Episode 2786/10000, loss: 0.0129228346049785618\n",
      " Copied model parameters to target network\n",
      "Step 1532 (1590489) @ Episode 2786/10000, loss: 0.0123103158548474315\n",
      "Episode Reward: 33.0\n",
      "Step 1431 (1591920) @ Episode 2787/10000, loss: 0.0114717828109860425\n",
      "Episode Reward: 38.0\n",
      "Step 693 (1592613) @ Episode 2788/10000, loss: 0.0032803458161652093\n",
      "Episode Reward: 14.0\n",
      "Step 865 (1593478) @ Episode 2789/10000, loss: 0.0173718780279159557\n",
      "Episode Reward: 11.0\n",
      "Step 745 (1594223) @ Episode 2790/10000, loss: 0.0053939353674650195\n",
      "Episode Reward: 16.0\n",
      "Step 774 (1594997) @ Episode 2791/10000, loss: 0.0127337742596864793\n",
      "Episode Reward: 16.0\n",
      "Step 707 (1595704) @ Episode 2792/10000, loss: 0.0850911289453506544\n",
      "Episode Reward: 12.0\n",
      "Step 1145 (1596849) @ Episode 2793/10000, loss: 0.0256320368498563775\n",
      "Episode Reward: 30.0\n",
      "Step 1149 (1597998) @ Episode 2794/10000, loss: 0.0036923820152878766\n",
      "Episode Reward: 30.0\n",
      "Step 930 (1598928) @ Episode 2795/10000, loss: 0.0053799422457814225\n",
      "Episode Reward: 20.0\n",
      "Step 693 (1599621) @ Episode 2796/10000, loss: 0.0126414867118000988\n",
      "Episode Reward: 11.0\n",
      "Step 378 (1599999) @ Episode 2797/10000, loss: 0.0085509326308965682\n",
      " Copied model parameters to target network\n",
      "Step 1110 (1600731) @ Episode 2797/10000, loss: 0.0180516801774501877\n",
      "Episode Reward: 31.0\n",
      "Step 848 (1601579) @ Episode 2798/10000, loss: 0.0046612406149506575\n",
      "Episode Reward: 16.0\n",
      "Step 833 (1602412) @ Episode 2799/10000, loss: 0.0094271339476108553\n",
      "Episode Reward: 18.0\n",
      "Step 792 (1603204) @ Episode 2800/10000, loss: 0.0080999713391065656\n",
      "Episode Reward: 12.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 20:48:02,685] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video002800.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 863 (1604067) @ Episode 2801/10000, loss: 0.0144864851608872415\n",
      "Episode Reward: 14.0\n",
      "Step 720 (1604787) @ Episode 2802/10000, loss: 0.0041745272465050226\n",
      "Episode Reward: 16.0\n",
      "Step 1078 (1605865) @ Episode 2803/10000, loss: 0.0305617302656173767\n",
      "Episode Reward: 18.0\n",
      "Step 693 (1606558) @ Episode 2804/10000, loss: 0.0191971436142921455\n",
      "Episode Reward: 14.0\n",
      "Step 679 (1607237) @ Episode 2805/10000, loss: 0.0209640543907880857\n",
      "Episode Reward: 18.0\n",
      "Step 714 (1607951) @ Episode 2806/10000, loss: 0.0171958971768617638\n",
      "Episode Reward: 10.0\n",
      "Step 1024 (1608975) @ Episode 2807/10000, loss: 0.0084794824942946435\n",
      "Episode Reward: 24.0\n",
      "Step 945 (1609920) @ Episode 2808/10000, loss: 0.0084272157400846485\n",
      "Episode Reward: 25.0\n",
      "Step 79 (1609999) @ Episode 2809/10000, loss: 0.0154870804399251945\n",
      " Copied model parameters to target network\n",
      "Step 897 (1610817) @ Episode 2809/10000, loss: 0.0335934869945049334\n",
      "Episode Reward: 23.0\n",
      "Step 600 (1611417) @ Episode 2810/10000, loss: 0.0186586249619722377\n",
      "Episode Reward: 8.0\n",
      "Step 467 (1611884) @ Episode 2811/10000, loss: 0.0078529547899961475\n",
      "Episode Reward: 6.0\n",
      "Step 1028 (1612912) @ Episode 2812/10000, loss: 0.0143430875614285475\n",
      "Episode Reward: 24.0\n",
      "Step 842 (1613754) @ Episode 2813/10000, loss: 0.0412458963692188265\n",
      "Episode Reward: 16.0\n",
      "Step 909 (1614663) @ Episode 2814/10000, loss: 0.0034608175046741962\n",
      "Episode Reward: 17.0\n",
      "Step 1363 (1616026) @ Episode 2815/10000, loss: 0.0068212281912565233\n",
      "Episode Reward: 38.0\n",
      "Step 570 (1616596) @ Episode 2816/10000, loss: 0.0081979706883430485\n",
      "Episode Reward: 8.0\n",
      "Step 573 (1617169) @ Episode 2817/10000, loss: 0.0123534407466650016\n",
      "Episode Reward: 8.0\n",
      "Step 1323 (1618492) @ Episode 2818/10000, loss: 0.0403336845338344685\n",
      "Episode Reward: 37.0\n",
      "Step 853 (1619345) @ Episode 2819/10000, loss: 0.0027757347561419015\n",
      "Episode Reward: 21.0\n",
      "Step 654 (1619999) @ Episode 2820/10000, loss: 0.0229453481733798984\n",
      " Copied model parameters to target network\n",
      "Step 854 (1620199) @ Episode 2820/10000, loss: 0.0064383787102997355\n",
      "Episode Reward: 15.0\n",
      "Step 1429 (1621628) @ Episode 2821/10000, loss: 0.0124676274135708813\n",
      "Episode Reward: 33.0\n",
      "Step 1036 (1622664) @ Episode 2822/10000, loss: 0.0105092348530888566\n",
      "Episode Reward: 21.0\n",
      "Step 1211 (1623875) @ Episode 2823/10000, loss: 0.0368277877569198676\n",
      "Episode Reward: 25.0\n",
      "Step 630 (1624505) @ Episode 2824/10000, loss: 0.0482777208089828535\n",
      "Episode Reward: 11.0\n",
      "Step 991 (1625496) @ Episode 2825/10000, loss: 0.0245196763426065446\n",
      "Episode Reward: 20.0\n",
      "Step 900 (1626396) @ Episode 2826/10000, loss: 0.0214157346636056953\n",
      "Episode Reward: 20.0\n",
      "Step 884 (1627280) @ Episode 2827/10000, loss: 0.0144269755110144623\n",
      "Episode Reward: 22.0\n",
      "Step 733 (1628013) @ Episode 2828/10000, loss: 0.0055366908200085165\n",
      "Episode Reward: 13.0\n",
      "Step 781 (1628794) @ Episode 2829/10000, loss: 0.0124976988881826455\n",
      "Episode Reward: 16.0\n",
      "Step 883 (1629677) @ Episode 2830/10000, loss: 0.0110851172357797626\n",
      "Episode Reward: 16.0\n",
      "Step 322 (1629999) @ Episode 2831/10000, loss: 0.0040649659931659784\n",
      " Copied model parameters to target network\n",
      "Step 916 (1630593) @ Episode 2831/10000, loss: 0.0125571778044104584\n",
      "Episode Reward: 22.0\n",
      "Step 1251 (1631844) @ Episode 2832/10000, loss: 0.0098919030278921138\n",
      "Episode Reward: 25.0\n",
      "Step 477 (1632321) @ Episode 2833/10000, loss: 0.4169678986072540398\n",
      "Episode Reward: 7.0\n",
      "Step 648 (1632969) @ Episode 2834/10000, loss: 0.0043496880680322655\n",
      "Episode Reward: 14.0\n",
      "Step 985 (1633954) @ Episode 2835/10000, loss: 0.0085373166948556997\n",
      "Episode Reward: 13.0\n",
      "Step 952 (1634906) @ Episode 2836/10000, loss: 0.0097363684326410325\n",
      "Episode Reward: 19.0\n",
      "Step 717 (1635623) @ Episode 2837/10000, loss: 0.0081691723316907885\n",
      "Episode Reward: 12.0\n",
      "Step 914 (1636537) @ Episode 2838/10000, loss: 0.0130820758640766145\n",
      "Episode Reward: 19.0\n",
      "Step 1048 (1637585) @ Episode 2839/10000, loss: 0.0171348843723535544\n",
      "Episode Reward: 21.0\n",
      "Step 1025 (1638610) @ Episode 2840/10000, loss: 0.0160608720034360966\n",
      "Episode Reward: 17.0\n",
      "Step 689 (1639299) @ Episode 2841/10000, loss: 0.0047644656151533133\n",
      "Episode Reward: 11.0\n",
      "Step 637 (1639936) @ Episode 2842/10000, loss: 0.0064229015260934835\n",
      "Episode Reward: 11.0\n",
      "Step 63 (1639999) @ Episode 2843/10000, loss: 0.0085033811628818512\n",
      " Copied model parameters to target network\n",
      "Step 1252 (1641188) @ Episode 2843/10000, loss: 0.0029585612937808037\n",
      "Episode Reward: 21.0\n",
      "Step 1479 (1642667) @ Episode 2844/10000, loss: 0.0042778700590133675\n",
      "Episode Reward: 35.0\n",
      "Step 836 (1643503) @ Episode 2845/10000, loss: 0.0154331391677260445\n",
      "Episode Reward: 13.0\n",
      "Step 287 (1643790) @ Episode 2846/10000, loss: 0.0033566120546311144\n",
      "Episode Reward: 3.0\n",
      "Step 673 (1644463) @ Episode 2847/10000, loss: 0.0121489213779568674\n",
      "Episode Reward: 8.0\n",
      "Step 1042 (1645505) @ Episode 2848/10000, loss: 0.0163025483489036565\n",
      "Episode Reward: 21.0\n",
      "Step 1021 (1646526) @ Episode 2849/10000, loss: 0.0068294713273644455\n",
      "Episode Reward: 18.0\n",
      "Step 768 (1647294) @ Episode 2850/10000, loss: 0.0129765709862113695\n",
      "Episode Reward: 8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 20:54:42,983] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video002850.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 548 (1647842) @ Episode 2851/10000, loss: 0.0177977941930294044\n",
      "Episode Reward: 9.0\n",
      "Step 925 (1648767) @ Episode 2852/10000, loss: 0.0108764525502920155\n",
      "Episode Reward: 21.0\n",
      "Step 876 (1649643) @ Episode 2853/10000, loss: 0.0068866321817040445\n",
      "Episode Reward: 14.0\n",
      "Step 356 (1649999) @ Episode 2854/10000, loss: 0.0070807849988341334\n",
      " Copied model parameters to target network\n",
      "Step 454 (1650097) @ Episode 2854/10000, loss: 0.0217068456113338474\n",
      "Episode Reward: 8.0\n",
      "Step 572 (1650669) @ Episode 2855/10000, loss: 0.0059720994904637343\n",
      "Episode Reward: 11.0\n",
      "Step 1302 (1651971) @ Episode 2856/10000, loss: 0.0340512394905090392\n",
      "Episode Reward: 25.0\n",
      "Step 1089 (1653060) @ Episode 2857/10000, loss: 0.0193376876413822175\n",
      "Episode Reward: 25.0\n",
      "Step 996 (1654056) @ Episode 2858/10000, loss: 0.0119326580315828327\n",
      "Episode Reward: 18.0\n",
      "Step 1250 (1655306) @ Episode 2859/10000, loss: 0.0065002380870282655\n",
      "Episode Reward: 25.0\n",
      "Step 1025 (1656331) @ Episode 2860/10000, loss: 0.0431950315833091746\n",
      "Episode Reward: 27.0\n",
      "Step 1027 (1657358) @ Episode 2861/10000, loss: 0.0142710367217659957\n",
      "Episode Reward: 25.0\n",
      "Step 501 (1657859) @ Episode 2862/10000, loss: 0.0071733528748154647\n",
      "Episode Reward: 8.0\n",
      "Step 724 (1658583) @ Episode 2863/10000, loss: 0.0033703970257192854\n",
      "Episode Reward: 13.0\n",
      "Step 846 (1659429) @ Episode 2864/10000, loss: 0.0287122130393981935\n",
      "Episode Reward: 13.0\n",
      "Step 570 (1659999) @ Episode 2865/10000, loss: 0.0083240400999784475\n",
      " Copied model parameters to target network\n",
      "Step 964 (1660393) @ Episode 2865/10000, loss: 0.0094481706619262797\n",
      "Episode Reward: 21.0\n",
      "Step 921 (1661314) @ Episode 2866/10000, loss: 0.0110631454735994345\n",
      "Episode Reward: 23.0\n",
      "Step 964 (1662278) @ Episode 2867/10000, loss: 0.0054899826645851135\n",
      "Episode Reward: 22.0\n",
      "Step 886 (1663164) @ Episode 2868/10000, loss: 0.0046464726328849795\n",
      "Episode Reward: 19.0\n",
      "Step 967 (1664131) @ Episode 2869/10000, loss: 0.0027718469500541687\n",
      "Episode Reward: 20.0\n",
      "Step 845 (1664976) @ Episode 2870/10000, loss: 0.0032068698201328516\n",
      "Episode Reward: 14.0\n",
      "Step 871 (1665847) @ Episode 2871/10000, loss: 0.0052860602736473085\n",
      "Episode Reward: 18.0\n",
      "Step 1127 (1666974) @ Episode 2872/10000, loss: 0.0035894222091883427\n",
      "Episode Reward: 34.0\n",
      "Step 1061 (1668035) @ Episode 2873/10000, loss: 0.0170864667743444445\n",
      "Episode Reward: 24.0\n",
      "Step 734 (1668769) @ Episode 2874/10000, loss: 0.0168400127440691474\n",
      "Episode Reward: 11.0\n",
      "Step 724 (1669493) @ Episode 2875/10000, loss: 0.0107410140335559845\n",
      "Episode Reward: 15.0\n",
      "Step 506 (1669999) @ Episode 2876/10000, loss: 0.0539859198033809665\n",
      " Copied model parameters to target network\n",
      "Step 805 (1670298) @ Episode 2876/10000, loss: 0.0296368487179279337\n",
      "Episode Reward: 19.0\n",
      "Step 478 (1670776) @ Episode 2877/10000, loss: 0.0183559209108352665\n",
      "Episode Reward: 6.0\n",
      "Step 745 (1671521) @ Episode 2878/10000, loss: 0.0162940919399261475\n",
      "Episode Reward: 12.0\n",
      "Step 851 (1672372) @ Episode 2879/10000, loss: 0.0084138475358486185\n",
      "Episode Reward: 15.0\n",
      "Step 1171 (1673543) @ Episode 2880/10000, loss: 0.0107882386073470125\n",
      "Episode Reward: 22.0\n",
      "Step 1297 (1674840) @ Episode 2881/10000, loss: 0.0031485874205827713\n",
      "Episode Reward: 31.0\n",
      "Step 857 (1675697) @ Episode 2882/10000, loss: 0.0088678644970059456\n",
      "Episode Reward: 17.0\n",
      "Step 878 (1676575) @ Episode 2883/10000, loss: 0.0292765069752931675\n",
      "Episode Reward: 16.0\n",
      "Step 630 (1677205) @ Episode 2884/10000, loss: 0.0085099563002586367\n",
      "Episode Reward: 10.0\n",
      "Step 691 (1677896) @ Episode 2885/10000, loss: 0.0151499658823013347\n",
      "Episode Reward: 9.0\n",
      "Step 794 (1678690) @ Episode 2886/10000, loss: 0.0046112444251775746\n",
      "Episode Reward: 14.0\n",
      "Step 628 (1679318) @ Episode 2887/10000, loss: 0.0054954756051301967\n",
      "Episode Reward: 8.0\n",
      "Step 681 (1679999) @ Episode 2888/10000, loss: 0.0065487734973430636\n",
      " Copied model parameters to target network\n",
      "Step 1049 (1680367) @ Episode 2888/10000, loss: 0.0064850854687392715\n",
      "Episode Reward: 21.0\n",
      "Step 1192 (1681559) @ Episode 2889/10000, loss: 0.0054153008386492735\n",
      "Episode Reward: 19.0\n",
      "Step 853 (1682412) @ Episode 2890/10000, loss: 0.0050210575573146346\n",
      "Episode Reward: 15.0\n",
      "Step 641 (1683053) @ Episode 2891/10000, loss: 0.0055891703814268115\n",
      "Episode Reward: 10.0\n",
      "Step 1125 (1684178) @ Episode 2892/10000, loss: 0.0111501608043909077\n",
      "Episode Reward: 24.0\n",
      "Step 947 (1685125) @ Episode 2893/10000, loss: 0.1249857693910598878\n",
      "Episode Reward: 21.0\n",
      "Step 525 (1685650) @ Episode 2894/10000, loss: 0.0066408845596015454\n",
      "Episode Reward: 7.0\n",
      "Step 789 (1686439) @ Episode 2895/10000, loss: 0.0098801329731941224\n",
      "Episode Reward: 15.0\n",
      "Step 1046 (1687485) @ Episode 2896/10000, loss: 0.0037675816565752036\n",
      "Episode Reward: 21.0\n",
      "Step 1115 (1688600) @ Episode 2897/10000, loss: 0.0704130753874778775\n",
      "Episode Reward: 23.0\n",
      "Step 793 (1689393) @ Episode 2898/10000, loss: 0.0027026035822927955\n",
      "Episode Reward: 15.0\n",
      "Step 606 (1689999) @ Episode 2899/10000, loss: 0.0145519468933343896\n",
      " Copied model parameters to target network\n",
      "Step 736 (1690129) @ Episode 2899/10000, loss: 0.0039721704088151455\n",
      "Episode Reward: 12.0\n",
      "Step 533 (1690662) @ Episode 2900/10000, loss: 0.0124143604189157494\n",
      "Episode Reward: 9.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 21:01:16,182] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video002900.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 868 (1691530) @ Episode 2901/10000, loss: 0.0078053716570138933\n",
      "Episode Reward: 19.0\n",
      "Step 745 (1692275) @ Episode 2902/10000, loss: 0.0046268505975604065\n",
      "Episode Reward: 12.0\n",
      "Step 974 (1693249) @ Episode 2903/10000, loss: 0.0050471508875489235\n",
      "Episode Reward: 21.0\n",
      "Step 870 (1694119) @ Episode 2904/10000, loss: 0.0062280292622745044\n",
      "Episode Reward: 15.0\n",
      "Step 1168 (1695287) @ Episode 2905/10000, loss: 0.0070625031366944314\n",
      "Episode Reward: 25.0\n",
      "Step 640 (1695927) @ Episode 2906/10000, loss: 0.0087744230404496225\n",
      "Episode Reward: 9.0\n",
      "Step 507 (1696434) @ Episode 2907/10000, loss: 0.0091300588101148685\n",
      "Episode Reward: 8.0\n",
      "Step 940 (1697374) @ Episode 2908/10000, loss: 0.0195672661066055325\n",
      "Episode Reward: 20.0\n",
      "Step 241 (1697615) @ Episode 2909/10000, loss: 0.0079507278278470048\n",
      "Episode Reward: 2.0\n",
      "Step 898 (1698513) @ Episode 2910/10000, loss: 0.0052260998636484156\n",
      "Episode Reward: 15.0\n",
      "Step 860 (1699373) @ Episode 2911/10000, loss: 0.0072829695418477066\n",
      "Episode Reward: 19.0\n",
      "Step 480 (1699853) @ Episode 2912/10000, loss: 0.0108791403472423555\n",
      "Episode Reward: 7.0\n",
      "Step 146 (1699999) @ Episode 2913/10000, loss: 0.0090630864724516874\n",
      " Copied model parameters to target network\n",
      "Step 744 (1700597) @ Episode 2913/10000, loss: 0.0105981305241584787\n",
      "Episode Reward: 12.0\n",
      "Step 1356 (1701953) @ Episode 2914/10000, loss: 0.0061393124051392085\n",
      "Episode Reward: 31.0\n",
      "Step 897 (1702850) @ Episode 2915/10000, loss: 0.0156262014061212547\n",
      "Episode Reward: 14.0\n",
      "Step 872 (1703722) @ Episode 2916/10000, loss: 0.0647331625223159815\n",
      "Episode Reward: 14.0\n",
      "Step 1128 (1704850) @ Episode 2917/10000, loss: 0.0080593172460794455\n",
      "Episode Reward: 22.0\n",
      "Step 692 (1705542) @ Episode 2918/10000, loss: 0.0145167401060462785\n",
      "Episode Reward: 12.0\n",
      "Step 1446 (1706988) @ Episode 2919/10000, loss: 0.0091112749651074414\n",
      "Episode Reward: 29.0\n",
      "Step 666 (1707654) @ Episode 2920/10000, loss: 0.0114954393357038586\n",
      "Episode Reward: 14.0\n",
      "Step 730 (1708384) @ Episode 2921/10000, loss: 0.0053096199408173564\n",
      "Episode Reward: 11.0\n",
      "Step 1364 (1709748) @ Episode 2922/10000, loss: 0.0122151449322700593\n",
      "Episode Reward: 41.0\n",
      "Step 251 (1709999) @ Episode 2923/10000, loss: 0.0042599840089678764\n",
      " Copied model parameters to target network\n",
      "Step 764 (1710512) @ Episode 2923/10000, loss: 0.0023312978446483614\n",
      "Episode Reward: 10.0\n",
      "Step 757 (1711269) @ Episode 2924/10000, loss: 0.0044473321177065375\n",
      "Episode Reward: 19.0\n",
      "Step 1040 (1712309) @ Episode 2925/10000, loss: 0.0081281289458274845\n",
      "Episode Reward: 17.0\n",
      "Step 537 (1712846) @ Episode 2926/10000, loss: 0.0062875570729374886\n",
      "Episode Reward: 14.0\n",
      "Step 775 (1713621) @ Episode 2927/10000, loss: 0.0063278544694185264\n",
      "Episode Reward: 14.0\n",
      "Step 881 (1714502) @ Episode 2928/10000, loss: 0.0087679671123623855\n",
      "Episode Reward: 22.0\n",
      "Step 741 (1715243) @ Episode 2929/10000, loss: 0.0078692827373743065\n",
      "Episode Reward: 19.0\n",
      "Step 762 (1716005) @ Episode 2930/10000, loss: 0.0060946717858314515\n",
      "Episode Reward: 11.0\n",
      "Step 881 (1716886) @ Episode 2931/10000, loss: 0.0224741082638502125\n",
      "Episode Reward: 21.0\n",
      "Step 746 (1717632) @ Episode 2932/10000, loss: 0.0268066376447677655\n",
      "Episode Reward: 12.0\n",
      "Step 455 (1718087) @ Episode 2933/10000, loss: 0.0206061899662017826\n",
      "Episode Reward: 6.0\n",
      "Step 669 (1718756) @ Episode 2934/10000, loss: 0.0353432446718215945\n",
      "Episode Reward: 10.0\n",
      "Step 932 (1719688) @ Episode 2935/10000, loss: 0.0240558162331581144\n",
      "Episode Reward: 18.0\n",
      "Step 311 (1719999) @ Episode 2936/10000, loss: 0.0068326103501021866\n",
      " Copied model parameters to target network\n",
      "Step 929 (1720617) @ Episode 2936/10000, loss: 0.0122966924682259565\n",
      "Episode Reward: 15.0\n",
      "Step 1403 (1722020) @ Episode 2937/10000, loss: 0.0048357825726270676\n",
      "Episode Reward: 36.0\n",
      "Step 560 (1722580) @ Episode 2938/10000, loss: 0.0047207670286297816\n",
      "Episode Reward: 9.0\n",
      "Step 984 (1723564) @ Episode 2939/10000, loss: 0.0268732514232397085\n",
      "Episode Reward: 19.0\n",
      "Step 978 (1724542) @ Episode 2940/10000, loss: 0.0044789928942918785\n",
      "Episode Reward: 16.0\n",
      "Step 589 (1725131) @ Episode 2941/10000, loss: 0.0194607060402631767\n",
      "Episode Reward: 8.0\n",
      "Step 697 (1725828) @ Episode 2942/10000, loss: 0.0087916497141122827\n",
      "Episode Reward: 16.0\n",
      "Step 2011 (1727839) @ Episode 2943/10000, loss: 0.0032238250132650137\n",
      "Episode Reward: 62.0\n",
      "Step 997 (1728836) @ Episode 2944/10000, loss: 0.0046199103817343714\n",
      "Episode Reward: 21.0\n",
      "Step 748 (1729584) @ Episode 2945/10000, loss: 0.0202815327793359761\n",
      "Episode Reward: 12.0\n",
      "Step 415 (1729999) @ Episode 2946/10000, loss: 0.0083193620666861533\n",
      " Copied model parameters to target network\n",
      "Step 825 (1730409) @ Episode 2946/10000, loss: 0.0018218039767816663\n",
      "Episode Reward: 12.0\n",
      "Step 651 (1731060) @ Episode 2947/10000, loss: 0.0043501807376742365\n",
      "Episode Reward: 21.0\n",
      "Step 888 (1731948) @ Episode 2948/10000, loss: 0.0122703323140740465\n",
      "Episode Reward: 15.0\n",
      "Step 1184 (1733132) @ Episode 2949/10000, loss: 0.0049581290222704415\n",
      "Episode Reward: 28.0\n",
      "Step 1909 (1735041) @ Episode 2950/10000, loss: 0.0045995377004146585\n",
      "Episode Reward: 65.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 21:07:54,496] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video002950.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 920 (1735961) @ Episode 2951/10000, loss: 0.0065040448680520065\n",
      "Episode Reward: 20.0\n",
      "Step 940 (1736901) @ Episode 2952/10000, loss: 0.0068919835612177855\n",
      "Episode Reward: 14.0\n",
      "Step 1228 (1738129) @ Episode 2953/10000, loss: 0.0050592049956321725\n",
      "Episode Reward: 26.0\n",
      "Step 912 (1739041) @ Episode 2954/10000, loss: 0.0065119015052914625\n",
      "Episode Reward: 14.0\n",
      "Step 941 (1739982) @ Episode 2955/10000, loss: 0.0093725323677062995\n",
      "Episode Reward: 17.0\n",
      "Step 17 (1739999) @ Episode 2956/10000, loss: 0.0294118840247392655\n",
      " Copied model parameters to target network\n",
      "Step 623 (1740605) @ Episode 2956/10000, loss: 0.0047012325376272264\n",
      "Episode Reward: 9.0\n",
      "Step 886 (1741491) @ Episode 2957/10000, loss: 0.0037385411560535435\n",
      "Episode Reward: 15.0\n",
      "Step 936 (1742427) @ Episode 2958/10000, loss: 0.0062839724123477946\n",
      "Episode Reward: 20.0\n",
      "Step 762 (1743189) @ Episode 2959/10000, loss: 0.0093524213880300527\n",
      "Episode Reward: 12.0\n",
      "Step 1342 (1744531) @ Episode 2960/10000, loss: 0.0135654918849468233\n",
      "Episode Reward: 29.0\n",
      "Step 634 (1745165) @ Episode 2961/10000, loss: 0.0026364023797214035\n",
      "Episode Reward: 11.0\n",
      "Step 745 (1745910) @ Episode 2962/10000, loss: 0.0099754901602864274\n",
      "Episode Reward: 23.0\n",
      "Step 1004 (1746914) @ Episode 2963/10000, loss: 0.005435360595583916\n",
      "Episode Reward: 17.0\n",
      "Step 893 (1747807) @ Episode 2964/10000, loss: 0.0101326284930109985\n",
      "Episode Reward: 14.0\n",
      "Step 780 (1748587) @ Episode 2965/10000, loss: 0.0051022623665630825\n",
      "Episode Reward: 14.0\n",
      "Step 681 (1749268) @ Episode 2966/10000, loss: 0.0040170839056372645\n",
      "Episode Reward: 10.0\n",
      "Step 731 (1749999) @ Episode 2967/10000, loss: 0.0586923286318779875\n",
      " Copied model parameters to target network\n",
      "Step 885 (1750153) @ Episode 2967/10000, loss: 0.0050905430689454086\n",
      "Episode Reward: 14.0\n",
      "Step 1081 (1751234) @ Episode 2968/10000, loss: 0.0063471733592450627\n",
      "Episode Reward: 29.0\n",
      "Step 883 (1752117) @ Episode 2969/10000, loss: 0.0046479972079396253\n",
      "Episode Reward: 13.0\n",
      "Step 875 (1752992) @ Episode 2970/10000, loss: 0.0632885098457336453\n",
      "Episode Reward: 14.0\n",
      "Step 741 (1753733) @ Episode 2971/10000, loss: 0.0135697312653064735\n",
      "Episode Reward: 12.0\n",
      "Step 704 (1754437) @ Episode 2972/10000, loss: 0.0077209593728184756\n",
      "Episode Reward: 19.0\n",
      "Step 846 (1755283) @ Episode 2973/10000, loss: 0.0795661509037017857\n",
      "Episode Reward: 14.0\n",
      "Step 1374 (1756657) @ Episode 2974/10000, loss: 0.0075202025473117835\n",
      "Episode Reward: 29.0\n",
      "Step 891 (1757548) @ Episode 2975/10000, loss: 0.0044429749250411994\n",
      "Episode Reward: 17.0\n",
      "Step 282 (1757830) @ Episode 2976/10000, loss: 0.0049945833161473273\n",
      "Episode Reward: 3.0\n",
      "Step 756 (1758586) @ Episode 2977/10000, loss: 0.0037374845705926422\n",
      "Episode Reward: 10.0\n",
      "Step 776 (1759362) @ Episode 2978/10000, loss: 0.0037441854365178125\n",
      "Episode Reward: 12.0\n",
      "Step 637 (1759999) @ Episode 2979/10000, loss: 0.0100173465907573753\n",
      " Copied model parameters to target network\n",
      "Step 673 (1760035) @ Episode 2979/10000, loss: 0.0045116823166608818\n",
      "Episode Reward: 10.0\n",
      "Step 869 (1760904) @ Episode 2980/10000, loss: 0.0143144037574529655\n",
      "Episode Reward: 15.0\n",
      "Step 402 (1761306) @ Episode 2981/10000, loss: 0.0058837141841650015\n",
      "Episode Reward: 5.0\n",
      "Step 1155 (1762461) @ Episode 2982/10000, loss: 0.0290457475930452354\n",
      "Episode Reward: 27.0\n",
      "Step 947 (1763408) @ Episode 2983/10000, loss: 0.0170217808336019584\n",
      "Episode Reward: 22.0\n",
      "Step 714 (1764122) @ Episode 2984/10000, loss: 0.0033660503104329115\n",
      "Episode Reward: 18.0\n",
      "Step 1051 (1765173) @ Episode 2985/10000, loss: 0.0257820077240467075\n",
      "Episode Reward: 22.0\n",
      "Step 1349 (1766522) @ Episode 2986/10000, loss: 0.0054608504287898548\n",
      "Episode Reward: 31.0\n",
      "Step 863 (1767385) @ Episode 2987/10000, loss: 0.0031306385062634945\n",
      "Episode Reward: 14.0\n",
      "Step 1128 (1768513) @ Episode 2988/10000, loss: 0.0089119216427207315\n",
      "Episode Reward: 27.0\n",
      "Step 938 (1769451) @ Episode 2989/10000, loss: 0.0080922041088342678\n",
      "Episode Reward: 15.0\n",
      "Step 548 (1769999) @ Episode 2990/10000, loss: 0.0061649102717638025\n",
      " Copied model parameters to target network\n",
      "Step 863 (1770314) @ Episode 2990/10000, loss: 0.0027002883143723012\n",
      "Episode Reward: 16.0\n",
      "Step 609 (1770923) @ Episode 2991/10000, loss: 0.0031296608503907927\n",
      "Episode Reward: 11.0\n",
      "Step 697 (1771620) @ Episode 2992/10000, loss: 0.0073932060040533544\n",
      "Episode Reward: 11.0\n",
      "Step 885 (1772505) @ Episode 2993/10000, loss: 0.0049630417488515385\n",
      "Episode Reward: 11.0\n",
      "Step 823 (1773328) @ Episode 2994/10000, loss: 0.0041816160082817085\n",
      "Episode Reward: 21.0\n",
      "Step 1240 (1774568) @ Episode 2995/10000, loss: 0.0070122419856488705\n",
      "Episode Reward: 30.0\n",
      "Step 643 (1775211) @ Episode 2996/10000, loss: 0.0034799261484295135\n",
      "Episode Reward: 10.0\n",
      "Step 1082 (1776293) @ Episode 2997/10000, loss: 0.0063467356376349935\n",
      "Episode Reward: 21.0\n",
      "Step 1402 (1777695) @ Episode 2998/10000, loss: 0.0127460788935422946\n",
      "Episode Reward: 34.0\n",
      "Step 1058 (1778753) @ Episode 2999/10000, loss: 0.0073657641187310223\n",
      "Episode Reward: 16.0\n",
      "Step 830 (1779583) @ Episode 3000/10000, loss: 0.0165037978440523153\n",
      "Episode Reward: 12.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 21:14:38,550] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video003000.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 416 (1779999) @ Episode 3001/10000, loss: 0.0048481570556759834\n",
      " Copied model parameters to target network\n",
      "Step 536 (1780119) @ Episode 3001/10000, loss: 0.0034292074851691723\n",
      "Episode Reward: 6.0\n",
      "Step 885 (1781004) @ Episode 3002/10000, loss: 0.0048756292089819915\n",
      "Episode Reward: 16.0\n",
      "Step 1068 (1782072) @ Episode 3003/10000, loss: 0.0076806298457086096\n",
      "Episode Reward: 20.0\n",
      "Step 1000 (1783072) @ Episode 3004/10000, loss: 0.010624892078340054\n",
      "Episode Reward: 25.0\n",
      "Step 998 (1784070) @ Episode 3005/10000, loss: 0.0301970224827528215\n",
      "Episode Reward: 22.0\n",
      "Step 789 (1784859) @ Episode 3006/10000, loss: 0.0098440479487180717\n",
      "Episode Reward: 19.0\n",
      "Step 755 (1785614) @ Episode 3007/10000, loss: 0.0120356259867548945\n",
      "Episode Reward: 15.0\n",
      "Step 715 (1786329) @ Episode 3008/10000, loss: 0.0038687502965331078\n",
      "Episode Reward: 15.0\n",
      "Step 766 (1787095) @ Episode 3009/10000, loss: 0.0030133714899420745\n",
      "Episode Reward: 12.0\n",
      "Step 1060 (1788155) @ Episode 3010/10000, loss: 0.0035551064647734165\n",
      "Episode Reward: 27.0\n",
      "Step 472 (1788627) @ Episode 3011/10000, loss: 0.0150463981553912164\n",
      "Episode Reward: 7.0\n",
      "Step 615 (1789242) @ Episode 3012/10000, loss: 0.0052441917359828955\n",
      "Episode Reward: 8.0\n",
      "Step 757 (1789999) @ Episode 3013/10000, loss: 0.0048239533789455895\n",
      " Copied model parameters to target network\n",
      "Step 1030 (1790272) @ Episode 3013/10000, loss: 0.0087603945285081863\n",
      "Episode Reward: 27.0\n",
      "Step 1137 (1791409) @ Episode 3014/10000, loss: 0.0265882313251495366\n",
      "Episode Reward: 27.0\n",
      "Step 629 (1792038) @ Episode 3015/10000, loss: 0.0070709111168980637\n",
      "Episode Reward: 15.0\n",
      "Step 682 (1792720) @ Episode 3016/10000, loss: 0.0033295839093625546\n",
      "Episode Reward: 12.0\n",
      "Step 926 (1793646) @ Episode 3017/10000, loss: 0.0041422415524721146\n",
      "Episode Reward: 22.0\n",
      "Step 1020 (1794666) @ Episode 3018/10000, loss: 0.0057562934234738353\n",
      "Episode Reward: 20.0\n",
      "Step 855 (1795521) @ Episode 3019/10000, loss: 0.0122374165803194054\n",
      "Episode Reward: 16.0\n",
      "Step 1395 (1796916) @ Episode 3020/10000, loss: 0.0033766548149287775\n",
      "Episode Reward: 30.0\n",
      "Step 746 (1797662) @ Episode 3021/10000, loss: 0.0199248827993869787\n",
      "Episode Reward: 12.0\n",
      "Step 850 (1798512) @ Episode 3022/10000, loss: 0.0150221306830644645\n",
      "Episode Reward: 19.0\n",
      "Step 729 (1799241) @ Episode 3023/10000, loss: 0.0069529390893876557\n",
      "Episode Reward: 10.0\n",
      "Step 758 (1799999) @ Episode 3024/10000, loss: 0.0044315019622445117\n",
      " Copied model parameters to target network\n",
      "Step 953 (1800194) @ Episode 3024/10000, loss: 0.0090049281716346744\n",
      "Episode Reward: 18.0\n",
      "Step 1140 (1801334) @ Episode 3025/10000, loss: 0.0032751965336501675\n",
      "Episode Reward: 26.0\n",
      "Step 967 (1802301) @ Episode 3026/10000, loss: 0.0062127029523253445\n",
      "Episode Reward: 19.0\n",
      "Step 658 (1802959) @ Episode 3027/10000, loss: 0.0023809098638594156\n",
      "Episode Reward: 9.0\n",
      "Step 526 (1803485) @ Episode 3028/10000, loss: 0.0091760605573654172\n",
      "Episode Reward: 7.0\n",
      "Step 989 (1804474) @ Episode 3029/10000, loss: 0.0276208966970443735\n",
      "Episode Reward: 16.0\n",
      "Step 845 (1805319) @ Episode 3030/10000, loss: 0.0033008882310241465\n",
      "Episode Reward: 14.0\n",
      "Step 866 (1806185) @ Episode 3031/10000, loss: 0.0053634252399206165\n",
      "Episode Reward: 15.0\n",
      "Step 790 (1806975) @ Episode 3032/10000, loss: 0.0043139904737472535\n",
      "Episode Reward: 13.0\n",
      "Step 941 (1807916) @ Episode 3033/10000, loss: 0.0037165859248489144\n",
      "Episode Reward: 14.0\n",
      "Step 794 (1808710) @ Episode 3034/10000, loss: 0.0010845256038010125\n",
      "Episode Reward: 15.0\n",
      "Step 886 (1809596) @ Episode 3035/10000, loss: 0.0055036712437868125\n",
      "Episode Reward: 14.0\n",
      "Step 403 (1809999) @ Episode 3036/10000, loss: 0.1241601631045341592\n",
      " Copied model parameters to target network\n",
      "Step 853 (1810449) @ Episode 3036/10000, loss: 0.0423835813999176424\n",
      "Episode Reward: 14.0\n",
      "Step 1065 (1811514) @ Episode 3037/10000, loss: 0.0081291617825627335\n",
      "Episode Reward: 19.0\n",
      "Step 946 (1812460) @ Episode 3038/10000, loss: 0.0026015364564955235\n",
      "Episode Reward: 17.0\n",
      "Step 991 (1813451) @ Episode 3039/10000, loss: 0.0061998367309570315\n",
      "Episode Reward: 15.0\n",
      "Step 861 (1814312) @ Episode 3040/10000, loss: 0.0056326300837099553\n",
      "Episode Reward: 22.0\n",
      "Step 991 (1815303) @ Episode 3041/10000, loss: 0.0105709405615925793\n",
      "Episode Reward: 20.0\n",
      "Step 763 (1816066) @ Episode 3042/10000, loss: 0.0087868198752403264\n",
      "Episode Reward: 19.0\n",
      "Step 955 (1817021) @ Episode 3043/10000, loss: 0.0101592158898711285\n",
      "Episode Reward: 21.0\n",
      "Step 940 (1817961) @ Episode 3044/10000, loss: 0.0050477478653192525\n",
      "Episode Reward: 23.0\n",
      "Step 772 (1818733) @ Episode 3045/10000, loss: 0.0060780066996812825\n",
      "Episode Reward: 12.0\n",
      "Step 905 (1819638) @ Episode 3046/10000, loss: 0.0105514219030737886\n",
      "Episode Reward: 18.0\n",
      "Step 361 (1819999) @ Episode 3047/10000, loss: 0.0545188076794147554\n",
      " Copied model parameters to target network\n",
      "Step 865 (1820503) @ Episode 3047/10000, loss: 0.0027315313927829266\n",
      "Episode Reward: 19.0\n",
      "Step 821 (1821324) @ Episode 3048/10000, loss: 0.0079948185011744535\n",
      "Episode Reward: 15.0\n",
      "Step 981 (1822305) @ Episode 3049/10000, loss: 0.0051241526380181316\n",
      "Episode Reward: 18.0\n",
      "Step 894 (1823199) @ Episode 3050/10000, loss: 0.0066043059341609487\n",
      "Episode Reward: 30.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 21:21:11,300] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video003050.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 708 (1823907) @ Episode 3051/10000, loss: 0.0056410273537039766\n",
      "Episode Reward: 11.0\n",
      "Step 531 (1824438) @ Episode 3052/10000, loss: 0.0129920681938529014\n",
      "Episode Reward: 8.0\n",
      "Step 872 (1825310) @ Episode 3053/10000, loss: 0.0072009107097983363\n",
      "Episode Reward: 19.0\n",
      "Step 841 (1826151) @ Episode 3054/10000, loss: 0.0029760203324258327\n",
      "Episode Reward: 14.0\n",
      "Step 935 (1827086) @ Episode 3055/10000, loss: 0.0055606961250305183\n",
      "Episode Reward: 22.0\n",
      "Step 836 (1827922) @ Episode 3056/10000, loss: 0.0075172092765569695\n",
      "Episode Reward: 23.0\n",
      "Step 1093 (1829015) @ Episode 3057/10000, loss: 0.0089164692908525475\n",
      "Episode Reward: 26.0\n",
      "Step 984 (1829999) @ Episode 3058/10000, loss: 0.0023370634298771626\n",
      " Copied model parameters to target network\n",
      "Step 1177 (1830192) @ Episode 3058/10000, loss: 0.0029230425134301186\n",
      "Episode Reward: 25.0\n",
      "Step 928 (1831120) @ Episode 3059/10000, loss: 0.0019133910536766052\n",
      "Episode Reward: 23.0\n",
      "Step 996 (1832116) @ Episode 3060/10000, loss: 0.0035385852679610252\n",
      "Episode Reward: 20.0\n",
      "Step 1177 (1833293) @ Episode 3061/10000, loss: 0.0028199399821460247\n",
      "Episode Reward: 32.0\n",
      "Step 1151 (1834444) @ Episode 3062/10000, loss: 0.0042457659728825097\n",
      "Episode Reward: 25.0\n",
      "Step 884 (1835328) @ Episode 3063/10000, loss: 0.0047947973944246775\n",
      "Episode Reward: 14.0\n",
      "Step 1092 (1836420) @ Episode 3064/10000, loss: 0.0107725802809000024\n",
      "Episode Reward: 19.0\n",
      "Step 787 (1837207) @ Episode 3065/10000, loss: 0.0069139907136559494\n",
      "Episode Reward: 19.0\n",
      "Step 728 (1837935) @ Episode 3066/10000, loss: 0.0030701789073646075\n",
      "Episode Reward: 13.0\n",
      "Step 729 (1838664) @ Episode 3067/10000, loss: 0.0239477269351482426\n",
      "Episode Reward: 13.0\n",
      "Step 534 (1839198) @ Episode 3068/10000, loss: 0.0066078179515898237\n",
      "Episode Reward: 9.0\n",
      "Step 540 (1839738) @ Episode 3069/10000, loss: 0.0030452010687440634\n",
      "Episode Reward: 9.0\n",
      "Step 261 (1839999) @ Episode 3070/10000, loss: 0.0185795985162258155\n",
      " Copied model parameters to target network\n",
      "Step 1350 (1841088) @ Episode 3070/10000, loss: 0.0202635675668716433\n",
      "Episode Reward: 33.0\n",
      "Step 922 (1842010) @ Episode 3071/10000, loss: 0.0162191651761531835\n",
      "Episode Reward: 17.0\n",
      "Step 714 (1842724) @ Episode 3072/10000, loss: 0.0047430465929210196\n",
      "Episode Reward: 11.0\n",
      "Step 814 (1843538) @ Episode 3073/10000, loss: 0.0297107230871915825\n",
      "Episode Reward: 21.0\n",
      "Step 1134 (1844672) @ Episode 3074/10000, loss: 0.0090353516861796383\n",
      "Episode Reward: 20.0\n",
      "Step 492 (1845164) @ Episode 3075/10000, loss: 0.0096938684582710276\n",
      "Episode Reward: 7.0\n",
      "Step 874 (1846038) @ Episode 3076/10000, loss: 0.0074404254555702215\n",
      "Episode Reward: 18.0\n",
      "Step 792 (1846830) @ Episode 3077/10000, loss: 0.0750947594642639253\n",
      "Episode Reward: 18.0\n",
      "Step 844 (1847674) @ Episode 3078/10000, loss: 0.0050086025148630146\n",
      "Episode Reward: 16.0\n",
      "Step 774 (1848448) @ Episode 3079/10000, loss: 0.0181045047938823725\n",
      "Episode Reward: 19.0\n",
      "Step 711 (1849159) @ Episode 3080/10000, loss: 0.0062299035489559175\n",
      "Episode Reward: 12.0\n",
      "Step 840 (1849999) @ Episode 3081/10000, loss: 0.0119471140205860145\n",
      " Copied model parameters to target network\n",
      "Step 910 (1850069) @ Episode 3081/10000, loss: 0.0319028571248054556\n",
      "Episode Reward: 17.0\n",
      "Step 908 (1850977) @ Episode 3082/10000, loss: 0.0627582371234893834\n",
      "Episode Reward: 12.0\n",
      "Step 742 (1851719) @ Episode 3083/10000, loss: 0.0035637884866446257\n",
      "Episode Reward: 11.0\n",
      "Step 888 (1852607) @ Episode 3084/10000, loss: 0.0056890067644417295\n",
      "Episode Reward: 14.0\n",
      "Step 773 (1853380) @ Episode 3085/10000, loss: 0.0101420795544981963\n",
      "Episode Reward: 15.0\n",
      "Step 1022 (1854402) @ Episode 3086/10000, loss: 0.0093224020674824714\n",
      "Episode Reward: 17.0\n",
      "Step 877 (1855279) @ Episode 3087/10000, loss: 0.0093949176371097567\n",
      "Episode Reward: 21.0\n",
      "Step 961 (1856240) @ Episode 3088/10000, loss: 0.0107207400724291887\n",
      "Episode Reward: 18.0\n",
      "Step 839 (1857079) @ Episode 3089/10000, loss: 0.0079982187598943716\n",
      "Episode Reward: 11.0\n",
      "Step 928 (1858007) @ Episode 3090/10000, loss: 0.0041454914025962355\n",
      "Episode Reward: 20.0\n",
      "Step 1093 (1859100) @ Episode 3091/10000, loss: 0.0023732027038931847\n",
      "Episode Reward: 23.0\n",
      "Step 666 (1859766) @ Episode 3092/10000, loss: 0.0045349048450589184\n",
      "Episode Reward: 10.0\n",
      "Step 233 (1859999) @ Episode 3093/10000, loss: 0.0044456049799919138\n",
      " Copied model parameters to target network\n",
      "Step 748 (1860514) @ Episode 3093/10000, loss: 0.0116631314158439645\n",
      "Episode Reward: 12.0\n",
      "Step 786 (1861300) @ Episode 3094/10000, loss: 0.0042832926847040653\n",
      "Episode Reward: 16.0\n",
      "Step 543 (1861843) @ Episode 3095/10000, loss: 0.0035579644609242678\n",
      "Episode Reward: 8.0\n",
      "Step 1214 (1863057) @ Episode 3096/10000, loss: 0.0122673986479648195\n",
      "Episode Reward: 19.0\n",
      "Step 820 (1863877) @ Episode 3097/10000, loss: 0.0066272616386413576\n",
      "Episode Reward: 18.0\n",
      "Step 907 (1864784) @ Episode 3098/10000, loss: 0.0027179257012903696\n",
      "Episode Reward: 13.0\n",
      "Step 957 (1865741) @ Episode 3099/10000, loss: 0.0103002004325389866\n",
      "Episode Reward: 14.0\n",
      "Step 703 (1866444) @ Episode 3100/10000, loss: 0.0065656444057822233\n",
      "Episode Reward: 12.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 21:27:42,239] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video003100.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 927 (1867371) @ Episode 3101/10000, loss: 0.0072556696832180022\n",
      "Episode Reward: 15.0\n",
      "Step 726 (1868097) @ Episode 3102/10000, loss: 0.0086071928963065154\n",
      "Episode Reward: 12.0\n",
      "Step 688 (1868785) @ Episode 3103/10000, loss: 0.0137255312874913227\n",
      "Episode Reward: 12.0\n",
      "Step 904 (1869689) @ Episode 3104/10000, loss: 0.0088085513561964046\n",
      "Episode Reward: 19.0\n",
      "Step 310 (1869999) @ Episode 3105/10000, loss: 0.0041758017614483838\n",
      " Copied model parameters to target network\n",
      "Step 675 (1870364) @ Episode 3105/10000, loss: 0.0029210783541202545\n",
      "Episode Reward: 10.0\n",
      "Step 972 (1871336) @ Episode 3106/10000, loss: 0.0045102741569280624\n",
      "Episode Reward: 18.0\n",
      "Step 1005 (1872341) @ Episode 3107/10000, loss: 0.0138813909143209465\n",
      "Episode Reward: 23.0\n",
      "Step 683 (1873024) @ Episode 3108/10000, loss: 0.0029499083757400513\n",
      "Episode Reward: 9.0\n",
      "Step 667 (1873691) @ Episode 3109/10000, loss: 0.0063094408251345165\n",
      "Episode Reward: 9.0\n",
      "Step 817 (1874508) @ Episode 3110/10000, loss: 0.0050728642381727695\n",
      "Episode Reward: 11.0\n",
      "Step 958 (1875466) @ Episode 3111/10000, loss: 0.0054393135942518717\n",
      "Episode Reward: 17.0\n",
      "Step 1018 (1876484) @ Episode 3112/10000, loss: 0.0031396599952131513\n",
      "Episode Reward: 15.0\n",
      "Step 642 (1877126) @ Episode 3113/10000, loss: 0.0045433519408106864\n",
      "Episode Reward: 9.0\n",
      "Step 756 (1877882) @ Episode 3114/10000, loss: 0.0047923368401825437\n",
      "Episode Reward: 12.0\n",
      "Step 814 (1878696) @ Episode 3115/10000, loss: 0.0055702477693557746\n",
      "Episode Reward: 14.0\n",
      "Step 885 (1879581) @ Episode 3116/10000, loss: 0.0133308805525302897\n",
      "Episode Reward: 20.0\n",
      "Step 418 (1879999) @ Episode 3117/10000, loss: 0.0124548403546214117\n",
      " Copied model parameters to target network\n",
      "Step 880 (1880461) @ Episode 3117/10000, loss: 0.0069078779779374626\n",
      "Episode Reward: 15.0\n",
      "Step 850 (1881311) @ Episode 3118/10000, loss: 0.0067431777715682984\n",
      "Episode Reward: 17.0\n",
      "Step 1412 (1882723) @ Episode 3119/10000, loss: 0.0042489315383136275\n",
      "Episode Reward: 35.0\n",
      "Step 933 (1883656) @ Episode 3120/10000, loss: 0.0103830341249704367\n",
      "Episode Reward: 19.0\n",
      "Step 823 (1884479) @ Episode 3121/10000, loss: 0.0076337205246090895\n",
      "Episode Reward: 14.0\n",
      "Step 1124 (1885603) @ Episode 3122/10000, loss: 0.0108157899230718615\n",
      "Episode Reward: 21.0\n",
      "Step 1133 (1886736) @ Episode 3123/10000, loss: 0.0363724604249000557\n",
      "Episode Reward: 18.0\n",
      "Step 931 (1887667) @ Episode 3124/10000, loss: 0.0177928972989320762\n",
      "Episode Reward: 15.0\n",
      "Step 699 (1888366) @ Episode 3125/10000, loss: 0.0046016764827072625\n",
      "Episode Reward: 13.0\n",
      "Step 809 (1889175) @ Episode 3126/10000, loss: 0.0036151572130620484\n",
      "Episode Reward: 20.0\n",
      "Step 799 (1889974) @ Episode 3127/10000, loss: 0.0030411635525524616\n",
      "Episode Reward: 13.0\n",
      "Step 25 (1889999) @ Episode 3128/10000, loss: 0.0055164033547043874\n",
      " Copied model parameters to target network\n",
      "Step 748 (1890722) @ Episode 3128/10000, loss: 0.0102363722398877147\n",
      "Episode Reward: 10.0\n",
      "Step 549 (1891271) @ Episode 3129/10000, loss: 0.0059301708824932575\n",
      "Episode Reward: 9.0\n",
      "Step 1308 (1892579) @ Episode 3130/10000, loss: 0.0030586377251893285\n",
      "Episode Reward: 28.0\n",
      "Step 1027 (1893606) @ Episode 3131/10000, loss: 0.0329474434256553655\n",
      "Episode Reward: 18.0\n",
      "Step 864 (1894470) @ Episode 3132/10000, loss: 0.0031571688596159227\n",
      "Episode Reward: 19.0\n",
      "Step 693 (1895163) @ Episode 3133/10000, loss: 0.0035890107974410057\n",
      "Episode Reward: 11.0\n",
      "Step 1207 (1896370) @ Episode 3134/10000, loss: 0.0061788060702383525\n",
      "Episode Reward: 34.0\n",
      "Step 501 (1896871) @ Episode 3135/10000, loss: 0.0238136742264032365\n",
      "Episode Reward: 12.0\n",
      "Step 563 (1897434) @ Episode 3136/10000, loss: 0.0143994530662894254\n",
      "Episode Reward: 10.0\n",
      "Step 633 (1898067) @ Episode 3137/10000, loss: 0.0148262651637196545\n",
      "Episode Reward: 11.0\n",
      "Step 1348 (1899415) @ Episode 3138/10000, loss: 0.0028323747683316472\n",
      "Episode Reward: 46.0\n",
      "Step 584 (1899999) @ Episode 3139/10000, loss: 0.0334061942994594635\n",
      " Copied model parameters to target network\n",
      "Step 1067 (1900482) @ Episode 3139/10000, loss: 0.0058456063270568854\n",
      "Episode Reward: 20.0\n",
      "Step 893 (1901375) @ Episode 3140/10000, loss: 0.0039739268831908755\n",
      "Episode Reward: 16.0\n",
      "Step 559 (1901934) @ Episode 3141/10000, loss: 0.0092675043269991878\n",
      "Episode Reward: 8.0\n",
      "Step 875 (1902809) @ Episode 3142/10000, loss: 0.0042585092596709732\n",
      "Episode Reward: 15.0\n",
      "Step 1224 (1904033) @ Episode 3143/10000, loss: 0.0184808224439620973\n",
      "Episode Reward: 29.0\n",
      "Step 562 (1904595) @ Episode 3144/10000, loss: 0.0034070126712322235\n",
      "Episode Reward: 9.0\n",
      "Step 969 (1905564) @ Episode 3145/10000, loss: 0.0051986360922455795\n",
      "Episode Reward: 17.0\n",
      "Step 640 (1906204) @ Episode 3146/10000, loss: 0.0067908745259046555\n",
      "Episode Reward: 13.0\n",
      "Step 697 (1906901) @ Episode 3147/10000, loss: 0.0075961113907396795\n",
      "Episode Reward: 11.0\n",
      "Step 720 (1907621) @ Episode 3148/10000, loss: 0.0092446003109216692\n",
      "Episode Reward: 19.0\n",
      "Step 823 (1908444) @ Episode 3149/10000, loss: 0.0060600303113460542\n",
      "Episode Reward: 15.0\n",
      "Step 658 (1909102) @ Episode 3150/10000, loss: 0.0149614308029413226\n",
      "Episode Reward: 13.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 21:34:08,866] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video003150.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 572 (1909674) @ Episode 3151/10000, loss: 0.0083194598555564885\n",
      "Episode Reward: 9.0\n",
      "Step 325 (1909999) @ Episode 3152/10000, loss: 0.0036574043333530426\n",
      " Copied model parameters to target network\n",
      "Step 1007 (1910681) @ Episode 3152/10000, loss: 0.0049212984740734128\n",
      "Episode Reward: 22.0\n",
      "Step 753 (1911434) @ Episode 3153/10000, loss: 0.0090847080573439675\n",
      "Episode Reward: 13.0\n",
      "Step 775 (1912209) @ Episode 3154/10000, loss: 0.0027395505458116533\n",
      "Episode Reward: 12.0\n",
      "Step 929 (1913138) @ Episode 3155/10000, loss: 0.0051909298636019237\n",
      "Episode Reward: 16.0\n",
      "Step 780 (1913918) @ Episode 3156/10000, loss: 0.0024678937625139953\n",
      "Episode Reward: 13.0\n",
      "Step 1096 (1915014) @ Episode 3157/10000, loss: 0.0032856571488082415\n",
      "Episode Reward: 21.0\n",
      "Step 1315 (1916329) @ Episode 3158/10000, loss: 0.0063203480094671251\n",
      "Episode Reward: 28.0\n",
      "Step 692 (1917021) @ Episode 3159/10000, loss: 0.0096722040325403215\n",
      "Episode Reward: 12.0\n",
      "Step 1090 (1918111) @ Episode 3160/10000, loss: 0.0018590614199638367\n",
      "Episode Reward: 17.0\n",
      "Step 492 (1918603) @ Episode 3161/10000, loss: 0.0057886899448931227\n",
      "Episode Reward: 7.0\n",
      "Step 661 (1919264) @ Episode 3162/10000, loss: 0.0116419056430459025\n",
      "Episode Reward: 11.0\n",
      "Step 730 (1919994) @ Episode 3163/10000, loss: 0.0087777376174926768\n",
      "Episode Reward: 13.0\n",
      "Step 5 (1919999) @ Episode 3164/10000, loss: 0.004527031444013119\n",
      " Copied model parameters to target network\n",
      "Step 589 (1920583) @ Episode 3164/10000, loss: 0.0080047110095620164\n",
      "Episode Reward: 9.0\n",
      "Step 889 (1921472) @ Episode 3165/10000, loss: 0.0141340522095561034\n",
      "Episode Reward: 18.0\n",
      "Step 716 (1922188) @ Episode 3166/10000, loss: 0.0089226877316832542\n",
      "Episode Reward: 14.0\n",
      "Step 753 (1922941) @ Episode 3167/10000, loss: 0.0057213385589420795\n",
      "Episode Reward: 19.0\n",
      "Step 634 (1923575) @ Episode 3168/10000, loss: 0.0124225942417979244\n",
      "Episode Reward: 9.0\n",
      "Step 867 (1924442) @ Episode 3169/10000, loss: 0.0041762604378163815\n",
      "Episode Reward: 16.0\n",
      "Step 828 (1925270) @ Episode 3170/10000, loss: 0.0081637715920805935\n",
      "Episode Reward: 13.0\n",
      "Step 894 (1926164) @ Episode 3171/10000, loss: 0.0044089085422456264\n",
      "Episode Reward: 13.0\n",
      "Step 981 (1927145) @ Episode 3172/10000, loss: 0.0122659672051668175\n",
      "Episode Reward: 21.0\n",
      "Step 1391 (1928536) @ Episode 3173/10000, loss: 0.0103797893971204764\n",
      "Episode Reward: 35.0\n",
      "Step 976 (1929512) @ Episode 3174/10000, loss: 0.0049313819035887725\n",
      "Episode Reward: 17.0\n",
      "Step 487 (1929999) @ Episode 3175/10000, loss: 0.0020022620446982316\n",
      " Copied model parameters to target network\n",
      "Step 1058 (1930570) @ Episode 3175/10000, loss: 0.0058409771881997585\n",
      "Episode Reward: 26.0\n",
      "Step 943 (1931513) @ Episode 3176/10000, loss: 0.0199126321822404863\n",
      "Episode Reward: 14.0\n",
      "Step 906 (1932419) @ Episode 3177/10000, loss: 0.0036521404981613166\n",
      "Episode Reward: 13.0\n",
      "Step 860 (1933279) @ Episode 3178/10000, loss: 0.0154516473412513735\n",
      "Episode Reward: 21.0\n",
      "Step 679 (1933958) @ Episode 3179/10000, loss: 0.0062190052121877675\n",
      "Episode Reward: 15.0\n",
      "Step 864 (1934822) @ Episode 3180/10000, loss: 0.0163644645363092426\n",
      "Episode Reward: 12.0\n",
      "Step 692 (1935514) @ Episode 3181/10000, loss: 0.0018925222102552652\n",
      "Episode Reward: 15.0\n",
      "Step 677 (1936191) @ Episode 3182/10000, loss: 0.0083450982347130785\n",
      "Episode Reward: 10.0\n",
      "Step 478 (1936669) @ Episode 3183/10000, loss: 0.0128982895985245785\n",
      "Episode Reward: 8.0\n",
      "Step 791 (1937460) @ Episode 3184/10000, loss: 0.0048315902240574365\n",
      "Episode Reward: 21.0\n",
      "Step 1187 (1938647) @ Episode 3185/10000, loss: 0.0074169887229800225\n",
      "Episode Reward: 24.0\n",
      "Step 878 (1939525) @ Episode 3186/10000, loss: 0.0203639455139637986\n",
      "Episode Reward: 20.0\n",
      "Step 474 (1939999) @ Episode 3187/10000, loss: 0.0104345697909593586\n",
      " Copied model parameters to target network\n",
      "Step 831 (1940356) @ Episode 3187/10000, loss: 0.0065124062821269035\n",
      "Episode Reward: 18.0\n",
      "Step 900 (1941256) @ Episode 3188/10000, loss: 0.0058931550011038787\n",
      "Episode Reward: 15.0\n",
      "Step 1050 (1942306) @ Episode 3189/10000, loss: 0.0164832249283790685\n",
      "Episode Reward: 17.0\n",
      "Step 509 (1942815) @ Episode 3190/10000, loss: 0.0074525019153952655\n",
      "Episode Reward: 7.0\n",
      "Step 876 (1943691) @ Episode 3191/10000, loss: 0.0041083428077399735\n",
      "Episode Reward: 18.0\n",
      "Step 1058 (1944749) @ Episode 3192/10000, loss: 0.0067964023910462863\n",
      "Episode Reward: 17.0\n",
      "Step 921 (1945670) @ Episode 3193/10000, loss: 0.0074966680258512594\n",
      "Episode Reward: 19.0\n",
      "Step 855 (1946525) @ Episode 3194/10000, loss: 0.0180453397333621983\n",
      "Episode Reward: 16.0\n",
      "Step 964 (1947489) @ Episode 3195/10000, loss: 0.0082558356225490576\n",
      "Episode Reward: 21.0\n",
      "Step 1020 (1948509) @ Episode 3196/10000, loss: 0.0425198152661323556\n",
      "Episode Reward: 21.0\n",
      "Step 994 (1949503) @ Episode 3197/10000, loss: 0.0152623001486063344\n",
      "Episode Reward: 15.0\n",
      "Step 496 (1949999) @ Episode 3198/10000, loss: 0.0128134349361062056\n",
      " Copied model parameters to target network\n",
      "Step 976 (1950479) @ Episode 3198/10000, loss: 0.0058146202936768535\n",
      "Episode Reward: 17.0\n",
      "Step 1141 (1951620) @ Episode 3199/10000, loss: 0.0021666632965207136\n",
      "Episode Reward: 25.0\n",
      "Step 849 (1952469) @ Episode 3200/10000, loss: 0.0031779606360942125\n",
      "Episode Reward: 23.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 21:40:44,781] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video003200.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 881 (1953350) @ Episode 3201/10000, loss: 0.0159671530127525336\n",
      "Episode Reward: 15.0\n",
      "Step 1196 (1954546) @ Episode 3202/10000, loss: 0.0038633942604064947\n",
      "Episode Reward: 30.0\n",
      "Step 869 (1955415) @ Episode 3203/10000, loss: 0.0072121964767575265\n",
      "Episode Reward: 15.0\n",
      "Step 764 (1956179) @ Episode 3204/10000, loss: 0.0154866296797990835\n",
      "Episode Reward: 17.0\n",
      "Step 805 (1956984) @ Episode 3205/10000, loss: 0.0068464321084320545\n",
      "Episode Reward: 16.0\n",
      "Step 1076 (1958060) @ Episode 3206/10000, loss: 0.0129385823383927356\n",
      "Episode Reward: 25.0\n",
      "Step 468 (1958528) @ Episode 3207/10000, loss: 0.0475919917225837745\n",
      "Episode Reward: 9.0\n",
      "Step 831 (1959359) @ Episode 3208/10000, loss: 0.0118349650874733927\n",
      "Episode Reward: 25.0\n",
      "Step 640 (1959999) @ Episode 3209/10000, loss: 0.0040689678862690926\n",
      " Copied model parameters to target network\n",
      "Step 1496 (1960855) @ Episode 3209/10000, loss: 0.0214739739894866947\n",
      "Episode Reward: 32.0\n",
      "Step 687 (1961542) @ Episode 3210/10000, loss: 0.0102768540382385255\n",
      "Episode Reward: 11.0\n",
      "Step 1054 (1962596) @ Episode 3211/10000, loss: 0.0107058072462677963\n",
      "Episode Reward: 21.0\n",
      "Step 484 (1963080) @ Episode 3212/10000, loss: 0.0057071861810982236\n",
      "Episode Reward: 7.0\n",
      "Step 843 (1963923) @ Episode 3213/10000, loss: 0.0055427160114049913\n",
      "Episode Reward: 14.0\n",
      "Step 1172 (1965095) @ Episode 3214/10000, loss: 0.0027953488752245903\n",
      "Episode Reward: 26.0\n",
      "Step 860 (1965955) @ Episode 3215/10000, loss: 0.0024140034802258015\n",
      "Episode Reward: 15.0\n",
      "Step 979 (1966934) @ Episode 3216/10000, loss: 0.0123685076832771313\n",
      "Episode Reward: 17.0\n",
      "Step 912 (1967846) @ Episode 3217/10000, loss: 0.0083648320287466053\n",
      "Episode Reward: 17.0\n",
      "Step 621 (1968467) @ Episode 3218/10000, loss: 0.0061453217640519146\n",
      "Episode Reward: 9.0\n",
      "Step 1172 (1969639) @ Episode 3219/10000, loss: 0.0026922009419649842\n",
      "Episode Reward: 25.0\n",
      "Step 360 (1969999) @ Episode 3220/10000, loss: 0.0066950079053640366\n",
      " Copied model parameters to target network\n",
      "Step 756 (1970395) @ Episode 3220/10000, loss: 0.0386485271155834207\n",
      "Episode Reward: 13.0\n",
      "Step 846 (1971241) @ Episode 3221/10000, loss: 0.0079373139888048175\n",
      "Episode Reward: 22.0\n",
      "Step 1222 (1972463) @ Episode 3222/10000, loss: 0.0074470890685915957\n",
      "Episode Reward: 28.0\n",
      "Step 701 (1973164) @ Episode 3223/10000, loss: 0.0148915946483612066\n",
      "Episode Reward: 10.0\n",
      "Step 894 (1974058) @ Episode 3224/10000, loss: 0.0106307873502373763\n",
      "Episode Reward: 17.0\n",
      "Step 975 (1975033) @ Episode 3225/10000, loss: 0.0058516673743724825\n",
      "Episode Reward: 16.0\n",
      "Step 874 (1975907) @ Episode 3226/10000, loss: 0.0052207279950380325\n",
      "Episode Reward: 15.0\n",
      "Step 801 (1976708) @ Episode 3227/10000, loss: 0.0225044991821050645\n",
      "Episode Reward: 13.0\n",
      "Step 1030 (1977738) @ Episode 3228/10000, loss: 0.0046725049614906315\n",
      "Episode Reward: 15.0\n",
      "Step 686 (1978424) @ Episode 3229/10000, loss: 0.0044303108006715775\n",
      "Episode Reward: 9.0\n",
      "Step 777 (1979201) @ Episode 3230/10000, loss: 0.0240813381969928744\n",
      "Episode Reward: 15.0\n",
      "Step 798 (1979999) @ Episode 3231/10000, loss: 0.0064891679212450985\n",
      " Copied model parameters to target network\n",
      "Step 834 (1980035) @ Episode 3231/10000, loss: 0.0032619957346469164\n",
      "Episode Reward: 20.0\n",
      "Step 634 (1980669) @ Episode 3232/10000, loss: 0.0072983969002962114\n",
      "Episode Reward: 9.0\n",
      "Step 1263 (1981932) @ Episode 3233/10000, loss: 0.0185827687382698065\n",
      "Episode Reward: 28.0\n",
      "Step 1032 (1982964) @ Episode 3234/10000, loss: 0.0070363963022828136\n",
      "Episode Reward: 18.0\n",
      "Step 774 (1983738) @ Episode 3235/10000, loss: 0.0133911538869142535\n",
      "Episode Reward: 12.0\n",
      "Step 1037 (1984775) @ Episode 3236/10000, loss: 0.0077444794587790973\n",
      "Episode Reward: 30.0\n",
      "Step 715 (1985490) @ Episode 3237/10000, loss: 0.0046651447191834456\n",
      "Episode Reward: 12.0\n",
      "Step 733 (1986223) @ Episode 3238/10000, loss: 0.0063149081543087968\n",
      "Episode Reward: 16.0\n",
      "Step 913 (1987136) @ Episode 3239/10000, loss: 0.0227436348795890827\n",
      "Episode Reward: 25.0\n",
      "Step 657 (1987793) @ Episode 3240/10000, loss: 0.0061072190292179585\n",
      "Episode Reward: 14.0\n",
      "Step 597 (1988390) @ Episode 3241/10000, loss: 0.0203744433820247652\n",
      "Episode Reward: 9.0\n",
      "Step 833 (1989223) @ Episode 3242/10000, loss: 0.0028092109132558107\n",
      "Episode Reward: 13.0\n",
      "Step 642 (1989865) @ Episode 3243/10000, loss: 0.0266171135008335134\n",
      "Episode Reward: 15.0\n",
      "Step 134 (1989999) @ Episode 3244/10000, loss: 0.0066302451305091383\n",
      " Copied model parameters to target network\n",
      "Step 888 (1990753) @ Episode 3244/10000, loss: 0.0026851575821638107\n",
      "Episode Reward: 20.0\n",
      "Step 772 (1991525) @ Episode 3245/10000, loss: 0.0117779755964875224\n",
      "Episode Reward: 12.0\n",
      "Step 712 (1992237) @ Episode 3246/10000, loss: 0.0135154305025935177\n",
      "Episode Reward: 15.0\n",
      "Step 833 (1993070) @ Episode 3247/10000, loss: 0.0097963586449623137\n",
      "Episode Reward: 13.0\n",
      "Step 1228 (1994298) @ Episode 3248/10000, loss: 0.0082863327115774155\n",
      "Episode Reward: 36.0\n",
      "Step 669 (1994967) @ Episode 3249/10000, loss: 0.0049932962283492095\n",
      "Episode Reward: 11.0\n",
      "Step 903 (1995870) @ Episode 3250/10000, loss: 0.0055868532508611686\n",
      "Episode Reward: 16.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 21:47:15,454] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video003250.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1069 (1996939) @ Episode 3251/10000, loss: 0.0074214264750480655\n",
      "Episode Reward: 18.0\n",
      "Step 576 (1997515) @ Episode 3252/10000, loss: 0.0216148104518651963\n",
      "Episode Reward: 9.0\n",
      "Step 981 (1998496) @ Episode 3253/10000, loss: 0.0062355571426451216\n",
      "Episode Reward: 28.0\n",
      "Step 1268 (1999764) @ Episode 3254/10000, loss: 0.0072502172552049165\n",
      "Episode Reward: 27.0\n",
      "Step 235 (1999999) @ Episode 3255/10000, loss: 0.0090202772989869127\n",
      " Copied model parameters to target network\n",
      "Step 876 (2000640) @ Episode 3255/10000, loss: 0.0062454454600811005\n",
      "Episode Reward: 19.0\n",
      "Step 927 (2001567) @ Episode 3256/10000, loss: 0.0037592432927340275\n",
      "Episode Reward: 16.0\n",
      "Step 1023 (2002590) @ Episode 3257/10000, loss: 0.0076982146129012115\n",
      "Episode Reward: 18.0\n",
      "Step 871 (2003461) @ Episode 3258/10000, loss: 0.0056158509105443954\n",
      "Episode Reward: 15.0\n",
      "Step 942 (2004403) @ Episode 3259/10000, loss: 0.0038058252539485693\n",
      "Episode Reward: 20.0\n",
      "Step 1064 (2005467) @ Episode 3260/10000, loss: 0.0126179168000817387\n",
      "Episode Reward: 21.0\n",
      "Step 749 (2006216) @ Episode 3261/10000, loss: 0.0045591918751597404\n",
      "Episode Reward: 12.0\n",
      "Step 817 (2007033) @ Episode 3262/10000, loss: 0.0085542136803269393\n",
      "Episode Reward: 15.0\n",
      "Step 559 (2007592) @ Episode 3263/10000, loss: 0.0092386659234762293\n",
      "Episode Reward: 6.0\n",
      "Step 1024 (2008616) @ Episode 3264/10000, loss: 0.0084774382412433627\n",
      "Episode Reward: 20.0\n",
      "Step 777 (2009393) @ Episode 3265/10000, loss: 0.0047313757240772253\n",
      "Episode Reward: 16.0\n",
      "Step 606 (2009999) @ Episode 3266/10000, loss: 0.0034475335851311684\n",
      " Copied model parameters to target network\n",
      "Step 734 (2010127) @ Episode 3266/10000, loss: 0.0017905455315485597\n",
      "Episode Reward: 12.0\n",
      "Step 451 (2010578) @ Episode 3267/10000, loss: 0.0171371158212423325\n",
      "Episode Reward: 6.0\n",
      "Step 899 (2011477) @ Episode 3268/10000, loss: 0.0086429445073008544\n",
      "Episode Reward: 18.0\n",
      "Step 759 (2012236) @ Episode 3269/10000, loss: 0.0151557736098766333\n",
      "Episode Reward: 11.0\n",
      "Step 780 (2013016) @ Episode 3270/10000, loss: 0.0076745739206671715\n",
      "Episode Reward: 13.0\n",
      "Step 819 (2013835) @ Episode 3271/10000, loss: 0.0137985292822122575\n",
      "Episode Reward: 23.0\n",
      "Step 511 (2014346) @ Episode 3272/10000, loss: 0.0021245577372610574\n",
      "Episode Reward: 8.0\n",
      "Step 862 (2015208) @ Episode 3273/10000, loss: 0.0022039951290935287\n",
      "Episode Reward: 18.0\n",
      "Step 1075 (2016283) @ Episode 3274/10000, loss: 0.0038054999895393855\n",
      "Episode Reward: 16.0\n",
      "Step 912 (2017195) @ Episode 3275/10000, loss: 0.0098015330731868747\n",
      "Episode Reward: 20.0\n",
      "Step 796 (2017991) @ Episode 3276/10000, loss: 0.0057598920539021495\n",
      "Episode Reward: 14.0\n",
      "Step 1322 (2019313) @ Episode 3277/10000, loss: 0.0085598761215806333\n",
      "Episode Reward: 27.0\n",
      "Step 686 (2019999) @ Episode 3278/10000, loss: 0.0142501089721918123\n",
      " Copied model parameters to target network\n",
      "Step 950 (2020263) @ Episode 3278/10000, loss: 0.0042407251894474036\n",
      "Episode Reward: 23.0\n",
      "Step 940 (2021203) @ Episode 3279/10000, loss: 0.0068511627614498145\n",
      "Episode Reward: 21.0\n",
      "Step 591 (2021794) @ Episode 3280/10000, loss: 0.0138893611729145053\n",
      "Episode Reward: 9.0\n",
      "Step 703 (2022497) @ Episode 3281/10000, loss: 0.0165325887501239786\n",
      "Episode Reward: 13.0\n",
      "Step 806 (2023303) @ Episode 3282/10000, loss: 0.0153916608542203936\n",
      "Episode Reward: 16.0\n",
      "Step 497 (2023800) @ Episode 3283/10000, loss: 0.0170683562755584786\n",
      "Episode Reward: 8.0\n",
      "Step 589 (2024389) @ Episode 3284/10000, loss: 0.0119871683418750765\n",
      "Episode Reward: 9.0\n",
      "Step 1021 (2025410) @ Episode 3285/10000, loss: 0.0080730821937322625\n",
      "Episode Reward: 17.0\n",
      "Step 984 (2026394) @ Episode 3286/10000, loss: 0.0102497311308979994\n",
      "Episode Reward: 17.0\n",
      "Step 884 (2027278) @ Episode 3287/10000, loss: 0.0160687379539012975\n",
      "Episode Reward: 16.0\n",
      "Step 1405 (2028683) @ Episode 3288/10000, loss: 0.0090898852795362474\n",
      "Episode Reward: 34.0\n",
      "Step 776 (2029459) @ Episode 3289/10000, loss: 0.0460305884480476414\n",
      "Episode Reward: 11.0\n",
      "Step 540 (2029999) @ Episode 3290/10000, loss: 0.0031514405272901066\n",
      " Copied model parameters to target network\n",
      "Step 1417 (2030876) @ Episode 3290/10000, loss: 0.0037317741662263875\n",
      "Episode Reward: 27.0\n",
      "Step 950 (2031826) @ Episode 3291/10000, loss: 0.0034982629586011175\n",
      "Episode Reward: 22.0\n",
      "Step 789 (2032615) @ Episode 3292/10000, loss: 0.0049141822382807735\n",
      "Episode Reward: 12.0\n",
      "Step 897 (2033512) @ Episode 3293/10000, loss: 0.0031252154149115086\n",
      "Episode Reward: 16.0\n",
      "Step 514 (2034026) @ Episode 3294/10000, loss: 0.0103136524558067326\n",
      "Episode Reward: 12.0\n",
      "Step 771 (2034797) @ Episode 3295/10000, loss: 0.0101789925247430865\n",
      "Episode Reward: 19.0\n",
      "Step 769 (2035566) @ Episode 3296/10000, loss: 0.0075905583798885345\n",
      "Episode Reward: 16.0\n",
      "Step 1193 (2036759) @ Episode 3297/10000, loss: 0.0041280854493379594\n",
      "Episode Reward: 34.0\n",
      "Step 915 (2037674) @ Episode 3298/10000, loss: 0.0087376721203327185\n",
      "Episode Reward: 30.0\n",
      "Step 1281 (2038955) @ Episode 3299/10000, loss: 0.0087286923080682754\n",
      "Episode Reward: 26.0\n",
      "Step 723 (2039678) @ Episode 3300/10000, loss: 0.0054023815318942075\n",
      "Episode Reward: 22.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 21:53:53,959] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video003300.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 321 (2039999) @ Episode 3301/10000, loss: 0.0029571116901934147\n",
      " Copied model parameters to target network\n",
      "Step 678 (2040356) @ Episode 3301/10000, loss: 0.0061438763514161114\n",
      "Episode Reward: 11.0\n",
      "Step 934 (2041290) @ Episode 3302/10000, loss: 0.0214844327419996264\n",
      "Episode Reward: 23.0\n",
      "Step 669 (2041959) @ Episode 3303/10000, loss: 0.0027914545498788357\n",
      "Episode Reward: 13.0\n",
      "Step 937 (2042896) @ Episode 3304/10000, loss: 0.0088263824582099917\n",
      "Episode Reward: 22.0\n",
      "Step 1163 (2044059) @ Episode 3305/10000, loss: 0.0042083780281245716\n",
      "Episode Reward: 28.0\n",
      "Step 781 (2044840) @ Episode 3306/10000, loss: 0.0052173933945596224\n",
      "Episode Reward: 27.0\n",
      "Step 1017 (2045857) @ Episode 3307/10000, loss: 0.0071236896328628064\n",
      "Episode Reward: 22.0\n",
      "Step 1230 (2047087) @ Episode 3308/10000, loss: 0.0079220179468393335\n",
      "Episode Reward: 25.0\n",
      "Step 1074 (2048161) @ Episode 3309/10000, loss: 0.0095526576042175385\n",
      "Episode Reward: 21.0\n",
      "Step 1050 (2049211) @ Episode 3310/10000, loss: 0.0014210459776222706\n",
      "Episode Reward: 28.0\n",
      "Step 788 (2049999) @ Episode 3311/10000, loss: 0.0037298658862710914\n",
      " Copied model parameters to target network\n",
      "Step 1462 (2050673) @ Episode 3311/10000, loss: 0.0042658224701881415\n",
      "Episode Reward: 47.0\n",
      "Step 981 (2051654) @ Episode 3312/10000, loss: 0.0068657631054520613\n",
      "Episode Reward: 24.0\n",
      "Step 1180 (2052834) @ Episode 3313/10000, loss: 0.0107599142938852317\n",
      "Episode Reward: 25.0\n",
      "Step 832 (2053666) @ Episode 3314/10000, loss: 0.0195772796869277952\n",
      "Episode Reward: 14.0\n",
      "Step 916 (2054582) @ Episode 3315/10000, loss: 0.0111669031903147745\n",
      "Episode Reward: 22.0\n",
      "Step 733 (2055315) @ Episode 3316/10000, loss: 0.0158939994871616365\n",
      "Episode Reward: 12.0\n",
      "Step 590 (2055905) @ Episode 3317/10000, loss: 0.0066092349588871495\n",
      "Episode Reward: 11.0\n",
      "Step 554 (2056459) @ Episode 3318/10000, loss: 0.0035758488811552525\n",
      "Episode Reward: 9.0\n",
      "Step 420 (2056879) @ Episode 3319/10000, loss: 0.0068514081649482256\n",
      "Episode Reward: 5.0\n",
      "Step 772 (2057651) @ Episode 3320/10000, loss: 0.0129418289288878444\n",
      "Episode Reward: 15.0\n",
      "Step 911 (2058562) @ Episode 3321/10000, loss: 0.0152751598507165915\n",
      "Episode Reward: 15.0\n",
      "Step 1437 (2059999) @ Episode 3322/10000, loss: 0.0047020716592669495\n",
      " Copied model parameters to target network\n",
      "Step 1538 (2060100) @ Episode 3322/10000, loss: 0.0038881283253431327\n",
      "Episode Reward: 31.0\n",
      "Step 735 (2060835) @ Episode 3323/10000, loss: 0.0547671355307102244\n",
      "Episode Reward: 13.0\n",
      "Step 1513 (2062348) @ Episode 3324/10000, loss: 0.0043531814590096477\n",
      "Episode Reward: 43.0\n",
      "Step 1246 (2063594) @ Episode 3325/10000, loss: 0.0146843390539288525\n",
      "Episode Reward: 27.0\n",
      "Step 754 (2064348) @ Episode 3326/10000, loss: 0.0091144628822803556\n",
      "Episode Reward: 11.0\n",
      "Step 812 (2065160) @ Episode 3327/10000, loss: 0.0063459286466240886\n",
      "Episode Reward: 14.0\n",
      "Step 766 (2065926) @ Episode 3328/10000, loss: 0.0133073404431343085\n",
      "Episode Reward: 14.0\n",
      "Step 988 (2066914) @ Episode 3329/10000, loss: 0.0026748101226985455\n",
      "Episode Reward: 21.0\n",
      "Step 1136 (2068050) @ Episode 3330/10000, loss: 0.0225532464683055885\n",
      "Episode Reward: 22.0\n",
      "Step 895 (2068945) @ Episode 3331/10000, loss: 0.0046587828546762475\n",
      "Episode Reward: 16.0\n",
      "Step 785 (2069730) @ Episode 3332/10000, loss: 0.0067298673093318943\n",
      "Episode Reward: 11.0\n",
      "Step 269 (2069999) @ Episode 3333/10000, loss: 0.0056009110994637015\n",
      " Copied model parameters to target network\n",
      "Step 706 (2070436) @ Episode 3333/10000, loss: 0.0106047140434384353\n",
      "Episode Reward: 11.0\n",
      "Step 800 (2071236) @ Episode 3334/10000, loss: 0.0049450434744358067\n",
      "Episode Reward: 16.0\n",
      "Step 1398 (2072634) @ Episode 3335/10000, loss: 0.0033238157629966736\n",
      "Episode Reward: 26.0\n",
      "Step 885 (2073519) @ Episode 3336/10000, loss: 0.0035902843810617924\n",
      "Episode Reward: 19.0\n",
      "Step 672 (2074191) @ Episode 3337/10000, loss: 0.0175633039325475774\n",
      "Episode Reward: 12.0\n",
      "Step 1046 (2075237) @ Episode 3338/10000, loss: 0.0033481891732662916\n",
      "Episode Reward: 17.0\n",
      "Step 862 (2076099) @ Episode 3339/10000, loss: 0.0029217521660029898\n",
      "Episode Reward: 23.0\n",
      "Step 1179 (2077278) @ Episode 3340/10000, loss: 0.0044328179210424425\n",
      "Episode Reward: 28.0\n",
      "Step 1237 (2078515) @ Episode 3341/10000, loss: 0.0014209146611392498\n",
      "Episode Reward: 32.0\n",
      "Step 1439 (2079954) @ Episode 3342/10000, loss: 0.0062818056903779513\n",
      "Episode Reward: 34.0\n",
      "Step 45 (2079999) @ Episode 3343/10000, loss: 0.0222167894244194034\n",
      " Copied model parameters to target network\n",
      "Step 975 (2080929) @ Episode 3343/10000, loss: 0.0052815787494182592\n",
      "Episode Reward: 15.0\n",
      "Step 842 (2081771) @ Episode 3344/10000, loss: 0.0021182838827371597\n",
      "Episode Reward: 14.0\n",
      "Step 892 (2082663) @ Episode 3345/10000, loss: 0.0057503785938024525\n",
      "Episode Reward: 22.0\n",
      "Step 1552 (2084215) @ Episode 3346/10000, loss: 0.0044301506131887445\n",
      "Episode Reward: 29.0\n",
      "Step 1330 (2085545) @ Episode 3347/10000, loss: 0.0050390926189720635\n",
      "Episode Reward: 33.0\n",
      "Step 858 (2086403) @ Episode 3348/10000, loss: 0.0082479575648903855\n",
      "Episode Reward: 15.0\n",
      "Step 738 (2087141) @ Episode 3349/10000, loss: 0.0057313838042318826\n",
      "Episode Reward: 17.0\n",
      "Step 1337 (2088478) @ Episode 3350/10000, loss: 0.0048788283020257955\n",
      "Episode Reward: 33.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 22:01:17,175] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video003350.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 830 (2089308) @ Episode 3351/10000, loss: 0.0104139540344476755\n",
      "Episode Reward: 14.0\n",
      "Step 691 (2089999) @ Episode 3352/10000, loss: 0.0062800124287605286\n",
      " Copied model parameters to target network\n",
      "Step 813 (2090121) @ Episode 3352/10000, loss: 0.0092752315104007727\n",
      "Episode Reward: 15.0\n",
      "Step 1341 (2091462) @ Episode 3353/10000, loss: 0.0039705475792288784\n",
      "Episode Reward: 35.0\n",
      "Step 584 (2092046) @ Episode 3354/10000, loss: 0.0047994004562497146\n",
      "Episode Reward: 9.0\n",
      "Step 779 (2092825) @ Episode 3355/10000, loss: 0.0414960086345672645\n",
      "Episode Reward: 14.0\n",
      "Step 841 (2093666) @ Episode 3356/10000, loss: 0.0263900961726903935\n",
      "Episode Reward: 12.0\n",
      "Step 1238 (2094904) @ Episode 3357/10000, loss: 0.0036142652388662164\n",
      "Episode Reward: 25.0\n",
      "Step 700 (2095604) @ Episode 3358/10000, loss: 0.0047409208491444595\n",
      "Episode Reward: 10.0\n",
      "Step 872 (2096476) @ Episode 3359/10000, loss: 0.0045513920485973365\n",
      "Episode Reward: 15.0\n",
      "Step 773 (2097249) @ Episode 3360/10000, loss: 0.0136106405407190325\n",
      "Episode Reward: 10.0\n",
      "Step 862 (2098111) @ Episode 3361/10000, loss: 0.0026177708059549337\n",
      "Episode Reward: 14.0\n",
      "Step 699 (2098810) @ Episode 3362/10000, loss: 0.0028171041049063206\n",
      "Episode Reward: 12.0\n",
      "Step 914 (2099724) @ Episode 3363/10000, loss: 0.0063560120761394546\n",
      "Episode Reward: 18.0\n",
      "Step 275 (2099999) @ Episode 3364/10000, loss: 0.0035445224493741995\n",
      " Copied model parameters to target network\n",
      "Step 596 (2100320) @ Episode 3364/10000, loss: 0.0061478335410356525\n",
      "Episode Reward: 12.0\n",
      "Step 1002 (2101322) @ Episode 3365/10000, loss: 0.0149507429450750355\n",
      "Episode Reward: 17.0\n",
      "Step 1600 (2102922) @ Episode 3366/10000, loss: 0.0043687843717634684\n",
      "Episode Reward: 48.0\n",
      "Step 1154 (2104076) @ Episode 3367/10000, loss: 0.0029051310848444736\n",
      "Episode Reward: 28.0\n",
      "Step 1037 (2105113) @ Episode 3368/10000, loss: 0.0147468894720077518\n",
      "Episode Reward: 18.0\n",
      "Step 1240 (2106353) @ Episode 3369/10000, loss: 0.0101472623646259355\n",
      "Episode Reward: 37.0\n",
      "Step 1065 (2107418) @ Episode 3370/10000, loss: 0.0064391121268272457\n",
      "Episode Reward: 22.0\n",
      "Step 631 (2108049) @ Episode 3371/10000, loss: 0.0072695733979344376\n",
      "Episode Reward: 9.0\n",
      "Step 977 (2109026) @ Episode 3372/10000, loss: 0.0100362692028284075\n",
      "Episode Reward: 16.0\n",
      "Step 973 (2109999) @ Episode 3373/10000, loss: 0.0053459703922271732\n",
      " Copied model parameters to target network\n",
      "Step 1216 (2110242) @ Episode 3373/10000, loss: 0.0041868556290864944\n",
      "Episode Reward: 28.0\n",
      "Step 1064 (2111306) @ Episode 3374/10000, loss: 0.0043880185112357146\n",
      "Episode Reward: 21.0\n",
      "Step 791 (2112097) @ Episode 3375/10000, loss: 0.0027031679637730126\n",
      "Episode Reward: 21.0\n",
      "Step 1258 (2113355) @ Episode 3376/10000, loss: 0.0038262982852756977\n",
      "Episode Reward: 35.0\n",
      "Step 678 (2114033) @ Episode 3377/10000, loss: 0.0074087893590331088\n",
      "Episode Reward: 13.0\n",
      "Step 960 (2114993) @ Episode 3378/10000, loss: 0.0062431246042251593\n",
      "Episode Reward: 15.0\n",
      "Step 702 (2115695) @ Episode 3379/10000, loss: 0.0046954713761806492\n",
      "Episode Reward: 14.0\n",
      "Step 546 (2116241) @ Episode 3380/10000, loss: 0.0049141831696033483\n",
      "Episode Reward: 8.0\n",
      "Step 793 (2117034) @ Episode 3381/10000, loss: 0.0051501849666237835\n",
      "Episode Reward: 24.0\n",
      "Step 1409 (2118443) @ Episode 3382/10000, loss: 0.0042309649288654333\n",
      "Episode Reward: 35.0\n",
      "Step 1100 (2119543) @ Episode 3383/10000, loss: 0.0052686929702758794\n",
      "Episode Reward: 19.0\n",
      "Step 456 (2119999) @ Episode 3384/10000, loss: 0.0226645190268754965\n",
      " Copied model parameters to target network\n",
      "Step 768 (2120311) @ Episode 3384/10000, loss: 0.0076868785545229917\n",
      "Episode Reward: 13.0\n",
      "Step 668 (2120979) @ Episode 3385/10000, loss: 0.0593043379485607155\n",
      "Episode Reward: 11.0\n",
      "Step 1193 (2122172) @ Episode 3386/10000, loss: 0.0023329481482505845\n",
      "Episode Reward: 22.0\n",
      "Step 751 (2122923) @ Episode 3387/10000, loss: 0.0054245362989604475\n",
      "Episode Reward: 15.0\n",
      "Step 1132 (2124055) @ Episode 3388/10000, loss: 0.0072529069148004055\n",
      "Episode Reward: 27.0\n",
      "Step 739 (2124794) @ Episode 3389/10000, loss: 0.0057496661320328718\n",
      "Episode Reward: 14.0\n",
      "Step 1056 (2125850) @ Episode 3390/10000, loss: 0.0078647583723068242\n",
      "Episode Reward: 17.0\n",
      "Step 389 (2126239) @ Episode 3391/10000, loss: 0.0060836188495159155\n",
      "Episode Reward: 5.0\n",
      "Step 547 (2126786) @ Episode 3392/10000, loss: 0.0156009178608655935\n",
      "Episode Reward: 8.0\n",
      "Step 816 (2127602) @ Episode 3393/10000, loss: 0.0051869419403374195\n",
      "Episode Reward: 14.0\n",
      "Step 1212 (2128814) @ Episode 3394/10000, loss: 0.0035529253073036674\n",
      "Episode Reward: 25.0\n",
      "Step 716 (2129530) @ Episode 3395/10000, loss: 0.0044911154545843624\n",
      "Episode Reward: 11.0\n",
      "Step 469 (2129999) @ Episode 3396/10000, loss: 0.0054498510435223585\n",
      " Copied model parameters to target network\n",
      "Step 832 (2130362) @ Episode 3396/10000, loss: 0.0082897553220391274\n",
      "Episode Reward: 17.0\n",
      "Step 753 (2131115) @ Episode 3397/10000, loss: 0.0088091101497411736\n",
      "Episode Reward: 16.0\n",
      "Step 1008 (2132123) @ Episode 3398/10000, loss: 0.0085729258134961135\n",
      "Episode Reward: 19.0\n",
      "Step 496 (2132619) @ Episode 3399/10000, loss: 0.0110738100484013568\n",
      "Episode Reward: 10.0\n",
      "Step 456 (2133075) @ Episode 3400/10000, loss: 0.0031445145141333345\n",
      "Episode Reward: 7.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 22:07:58,906] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video003400.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1001 (2134076) @ Episode 3401/10000, loss: 0.005217570811510086\n",
      "Episode Reward: 20.0\n",
      "Step 925 (2135001) @ Episode 3402/10000, loss: 0.0036585964262485504\n",
      "Episode Reward: 19.0\n",
      "Step 1390 (2136391) @ Episode 3403/10000, loss: 0.0044708652421832085\n",
      "Episode Reward: 33.0\n",
      "Step 945 (2137336) @ Episode 3404/10000, loss: 0.0076701072975993164\n",
      "Episode Reward: 19.0\n",
      "Step 829 (2138165) @ Episode 3405/10000, loss: 0.0053251856006681925\n",
      "Episode Reward: 13.0\n",
      "Step 1267 (2139432) @ Episode 3406/10000, loss: 0.0085579985752701764\n",
      "Episode Reward: 21.0\n",
      "Step 567 (2139999) @ Episode 3407/10000, loss: 0.0077065704390406616\n",
      " Copied model parameters to target network\n",
      "Step 670 (2140102) @ Episode 3407/10000, loss: 0.0038708637002855543\n",
      "Episode Reward: 15.0\n",
      "Step 1224 (2141326) @ Episode 3408/10000, loss: 0.0041999812237918384\n",
      "Episode Reward: 25.0\n",
      "Step 1231 (2142557) @ Episode 3409/10000, loss: 0.0056093242019414917\n",
      "Episode Reward: 23.0\n",
      "Step 722 (2143279) @ Episode 3410/10000, loss: 0.0087381843477487566\n",
      "Episode Reward: 17.0\n",
      "Step 944 (2144223) @ Episode 3411/10000, loss: 0.0085333101451396946\n",
      "Episode Reward: 19.0\n",
      "Step 901 (2145124) @ Episode 3412/10000, loss: 0.0084843263030052195\n",
      "Episode Reward: 18.0\n",
      "Step 794 (2145918) @ Episode 3413/10000, loss: 0.0065607102587819175\n",
      "Episode Reward: 13.0\n",
      "Step 676 (2146594) @ Episode 3414/10000, loss: 0.0024100639857351785\n",
      "Episode Reward: 11.0\n",
      "Step 869 (2147463) @ Episode 3415/10000, loss: 0.0278861187398433785\n",
      "Episode Reward: 21.0\n",
      "Step 826 (2148289) @ Episode 3416/10000, loss: 0.0173007883131504064\n",
      "Episode Reward: 16.0\n",
      "Step 733 (2149022) @ Episode 3417/10000, loss: 0.0183004382997751244\n",
      "Episode Reward: 15.0\n",
      "Step 920 (2149942) @ Episode 3418/10000, loss: 0.0051450040191411975\n",
      "Episode Reward: 22.0\n",
      "Step 57 (2149999) @ Episode 3419/10000, loss: 0.0043993741273880005\n",
      " Copied model parameters to target network\n",
      "Step 836 (2150778) @ Episode 3419/10000, loss: 0.0044623166322708138\n",
      "Episode Reward: 12.0\n",
      "Step 465 (2151243) @ Episode 3420/10000, loss: 0.0139255952090024954\n",
      "Episode Reward: 6.0\n",
      "Step 634 (2151877) @ Episode 3421/10000, loss: 0.1212132647633552667\n",
      "Episode Reward: 14.0\n",
      "Step 872 (2152749) @ Episode 3422/10000, loss: 0.0043562874197959943\n",
      "Episode Reward: 14.0\n",
      "Step 1223 (2153972) @ Episode 3423/10000, loss: 0.0025868671946227556\n",
      "Episode Reward: 33.0\n",
      "Step 842 (2154814) @ Episode 3424/10000, loss: 0.0034044848289340734\n",
      "Episode Reward: 14.0\n",
      "Step 677 (2155491) @ Episode 3425/10000, loss: 0.0101633034646511084\n",
      "Episode Reward: 11.0\n",
      "Step 1269 (2156760) @ Episode 3426/10000, loss: 0.0039763404056429868\n",
      "Episode Reward: 37.0\n",
      "Step 1349 (2158109) @ Episode 3427/10000, loss: 0.0082713598385453224\n",
      "Episode Reward: 36.0\n",
      "Step 1306 (2159415) @ Episode 3428/10000, loss: 0.0034695905633270745\n",
      "Episode Reward: 24.0\n",
      "Step 584 (2159999) @ Episode 3429/10000, loss: 0.0114770801737904555\n",
      " Copied model parameters to target network\n",
      "Step 1182 (2160597) @ Episode 3429/10000, loss: 0.0270311366766691254\n",
      "Episode Reward: 29.0\n",
      "Step 677 (2161274) @ Episode 3430/10000, loss: 0.0168776959180831945\n",
      "Episode Reward: 9.0\n",
      "Step 780 (2162054) @ Episode 3431/10000, loss: 0.0062081068754196175\n",
      "Episode Reward: 14.0\n",
      "Step 965 (2163019) @ Episode 3432/10000, loss: 0.0078573804348707257\n",
      "Episode Reward: 20.0\n",
      "Step 1080 (2164099) @ Episode 3433/10000, loss: 0.0045847753062844286\n",
      "Episode Reward: 28.0\n",
      "Step 840 (2164939) @ Episode 3434/10000, loss: 0.0051517207175493247\n",
      "Episode Reward: 27.0\n",
      "Step 617 (2165556) @ Episode 3435/10000, loss: 0.0029176862444728613\n",
      "Episode Reward: 10.0\n",
      "Step 1089 (2166645) @ Episode 3436/10000, loss: 0.0116586843505501752\n",
      "Episode Reward: 20.0\n",
      "Step 1066 (2167711) @ Episode 3437/10000, loss: 0.0375190638005733536\n",
      "Episode Reward: 24.0\n",
      "Step 531 (2168242) @ Episode 3438/10000, loss: 0.0060261795297265055\n",
      "Episode Reward: 7.0\n",
      "Step 1099 (2169341) @ Episode 3439/10000, loss: 0.0064140977337956434\n",
      "Episode Reward: 24.0\n",
      "Step 658 (2169999) @ Episode 3440/10000, loss: 0.0079701859503984456\n",
      " Copied model parameters to target network\n",
      "Step 918 (2170259) @ Episode 3440/10000, loss: 0.0062470315024256713\n",
      "Episode Reward: 19.0\n",
      "Step 1203 (2171462) @ Episode 3441/10000, loss: 0.0073150936514139175\n",
      "Episode Reward: 22.0\n",
      "Step 639 (2172101) @ Episode 3442/10000, loss: 0.0059724366292357445\n",
      "Episode Reward: 10.0\n",
      "Step 545 (2172646) @ Episode 3443/10000, loss: 0.0060768192633986477\n",
      "Episode Reward: 8.0\n",
      "Step 700 (2173346) @ Episode 3444/10000, loss: 0.0045698108151555065\n",
      "Episode Reward: 13.0\n",
      "Step 762 (2174108) @ Episode 3445/10000, loss: 0.0061710258014500145\n",
      "Episode Reward: 13.0\n",
      "Step 707 (2174815) @ Episode 3446/10000, loss: 0.0051652630791068087\n",
      "Episode Reward: 12.0\n",
      "Step 1362 (2176177) @ Episode 3447/10000, loss: 0.0043685664422810087\n",
      "Episode Reward: 39.0\n",
      "Step 724 (2176901) @ Episode 3448/10000, loss: 0.0116282524541020436\n",
      "Episode Reward: 12.0\n",
      "Step 609 (2177510) @ Episode 3449/10000, loss: 0.0056099458597600465\n",
      "Episode Reward: 8.0\n",
      "Step 807 (2178317) @ Episode 3450/10000, loss: 0.0059990095905959616\n",
      "Episode Reward: 12.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 22:14:46,232] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video003450.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1309 (2179626) @ Episode 3451/10000, loss: 0.0038947830908000473\n",
      "Episode Reward: 30.0\n",
      "Step 373 (2179999) @ Episode 3452/10000, loss: 0.0095097860321402556\n",
      " Copied model parameters to target network\n",
      "Step 1413 (2181039) @ Episode 3452/10000, loss: 0.0049258237704634677\n",
      "Episode Reward: 37.0\n",
      "Step 866 (2181905) @ Episode 3453/10000, loss: 0.0077695241197943692\n",
      "Episode Reward: 18.0\n",
      "Step 880 (2182785) @ Episode 3454/10000, loss: 0.0093947276473045353\n",
      "Episode Reward: 15.0\n",
      "Step 766 (2183551) @ Episode 3455/10000, loss: 0.0046170465648174295\n",
      "Episode Reward: 10.0\n",
      "Step 962 (2184513) @ Episode 3456/10000, loss: 0.0134949255734682084\n",
      "Episode Reward: 16.0\n",
      "Step 821 (2185334) @ Episode 3457/10000, loss: 0.0150997042655944825\n",
      "Episode Reward: 13.0\n",
      "Step 1115 (2186449) @ Episode 3458/10000, loss: 0.0079496446996927263\n",
      "Episode Reward: 26.0\n",
      "Step 796 (2187245) @ Episode 3459/10000, loss: 0.0057534137740731245\n",
      "Episode Reward: 19.0\n",
      "Step 668 (2187913) @ Episode 3460/10000, loss: 0.0060651563107967385\n",
      "Episode Reward: 11.0\n",
      "Step 675 (2188588) @ Episode 3461/10000, loss: 0.0082007069140672685\n",
      "Episode Reward: 11.0\n",
      "Step 956 (2189544) @ Episode 3462/10000, loss: 0.0051494222134351735\n",
      "Episode Reward: 21.0\n",
      "Step 455 (2189999) @ Episode 3463/10000, loss: 0.0070126745849847793\n",
      " Copied model parameters to target network\n",
      "Step 664 (2190208) @ Episode 3463/10000, loss: 0.0032850722782313824\n",
      "Episode Reward: 10.0\n",
      "Step 732 (2190940) @ Episode 3464/10000, loss: 0.0069883884862065315\n",
      "Episode Reward: 11.0\n",
      "Step 555 (2191495) @ Episode 3465/10000, loss: 0.0025946188252419233\n",
      "Episode Reward: 6.0\n",
      "Step 596 (2192091) @ Episode 3466/10000, loss: 0.0076879276894032955\n",
      "Episode Reward: 7.0\n",
      "Step 870 (2192961) @ Episode 3467/10000, loss: 0.0058791423216462135\n",
      "Episode Reward: 20.0\n",
      "Step 715 (2193676) @ Episode 3468/10000, loss: 0.0025411141104996204\n",
      "Episode Reward: 15.0\n",
      "Step 789 (2194465) @ Episode 3469/10000, loss: 0.0019381248857825994\n",
      "Episode Reward: 15.0\n",
      "Step 1319 (2195784) @ Episode 3470/10000, loss: 0.0069639608263969427\n",
      "Episode Reward: 33.0\n",
      "Step 908 (2196692) @ Episode 3471/10000, loss: 0.0033430403564125395\n",
      "Episode Reward: 18.0\n",
      "Step 754 (2197446) @ Episode 3472/10000, loss: 0.0035640753339976072\n",
      "Episode Reward: 11.0\n",
      "Step 669 (2198115) @ Episode 3473/10000, loss: 0.0166089273989200676\n",
      "Episode Reward: 9.0\n",
      "Step 1133 (2199248) @ Episode 3474/10000, loss: 0.0152231734246015555\n",
      "Episode Reward: 20.0\n",
      "Step 717 (2199965) @ Episode 3475/10000, loss: 0.0071051530539989478\n",
      "Episode Reward: 11.0\n",
      "Step 34 (2199999) @ Episode 3476/10000, loss: 0.0031691254116594792\n",
      " Copied model parameters to target network\n",
      "Step 785 (2200750) @ Episode 3476/10000, loss: 0.0051165828481316575\n",
      "Episode Reward: 21.0\n",
      "Step 656 (2201406) @ Episode 3477/10000, loss: 0.0112301837652921683\n",
      "Episode Reward: 11.0\n",
      "Step 1032 (2202438) @ Episode 3478/10000, loss: 0.0061199953779578214\n",
      "Episode Reward: 21.0\n",
      "Step 793 (2203231) @ Episode 3479/10000, loss: 0.0066965166479349145\n",
      "Episode Reward: 14.0\n",
      "Step 659 (2203890) @ Episode 3480/10000, loss: 0.0038520821835845715\n",
      "Episode Reward: 10.0\n",
      "Step 860 (2204750) @ Episode 3481/10000, loss: 0.0059860842302441665\n",
      "Episode Reward: 6.0\n",
      "Step 837 (2205587) @ Episode 3482/10000, loss: 0.0042650522664189348\n",
      "Episode Reward: 14.0\n",
      "Step 947 (2206534) @ Episode 3483/10000, loss: 0.0025976956821978092\n",
      "Episode Reward: 17.0\n",
      "Step 566 (2207100) @ Episode 3484/10000, loss: 0.0029253060929477215\n",
      "Episode Reward: 9.0\n",
      "Step 1171 (2208271) @ Episode 3485/10000, loss: 0.0058518433943390855\n",
      "Episode Reward: 21.0\n",
      "Step 1296 (2209567) @ Episode 3486/10000, loss: 0.0047135665081441454\n",
      "Episode Reward: 30.0\n",
      "Step 432 (2209999) @ Episode 3487/10000, loss: 0.0042910547927021984\n",
      " Copied model parameters to target network\n",
      "Step 539 (2210106) @ Episode 3487/10000, loss: 0.0064208135008811954\n",
      "Episode Reward: 9.0\n",
      "Step 716 (2210822) @ Episode 3488/10000, loss: 0.0026732033584266995\n",
      "Episode Reward: 12.0\n",
      "Step 592 (2211414) @ Episode 3489/10000, loss: 0.0026025404222309592\n",
      "Episode Reward: 9.0\n",
      "Step 1012 (2212426) @ Episode 3490/10000, loss: 0.0087959226220846184\n",
      "Episode Reward: 15.0\n",
      "Step 615 (2213041) @ Episode 3491/10000, loss: 0.0073480610735714436\n",
      "Episode Reward: 12.0\n",
      "Step 806 (2213847) @ Episode 3492/10000, loss: 0.0041973693296313295\n",
      "Episode Reward: 16.0\n",
      "Step 612 (2214459) @ Episode 3493/10000, loss: 0.0040997387841343885\n",
      "Episode Reward: 9.0\n",
      "Step 793 (2215252) @ Episode 3494/10000, loss: 0.0124017614871263555\n",
      "Episode Reward: 13.0\n",
      "Step 1264 (2216516) @ Episode 3495/10000, loss: 0.0030739912763237953\n",
      "Episode Reward: 25.0\n",
      "Step 847 (2217363) @ Episode 3496/10000, loss: 0.0030542863532900817\n",
      "Episode Reward: 14.0\n",
      "Step 1277 (2218640) @ Episode 3497/10000, loss: 0.0035294061526656154\n",
      "Episode Reward: 33.0\n",
      "Step 866 (2219506) @ Episode 3498/10000, loss: 0.0056547126732766635\n",
      "Episode Reward: 14.0\n",
      "Step 493 (2219999) @ Episode 3499/10000, loss: 0.0077403238974511626\n",
      " Copied model parameters to target network\n",
      "Step 640 (2220146) @ Episode 3499/10000, loss: 0.0038019833154976376\n",
      "Episode Reward: 10.0\n",
      "Step 660 (2220806) @ Episode 3500/10000, loss: 0.1563399285078048795\n",
      "Episode Reward: 9.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 22:21:14,654] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video003500.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1027 (2221833) @ Episode 3501/10000, loss: 0.0041066044941544536\n",
      "Episode Reward: 23.0\n",
      "Step 786 (2222619) @ Episode 3502/10000, loss: 0.0062259496189653875\n",
      "Episode Reward: 18.0\n",
      "Step 1291 (2223910) @ Episode 3503/10000, loss: 0.0022298051044344975\n",
      "Episode Reward: 20.0\n",
      "Step 642 (2224552) @ Episode 3504/10000, loss: 0.0033983620814979076\n",
      "Episode Reward: 9.0\n",
      "Step 1214 (2225766) @ Episode 3505/10000, loss: 0.0055659632198512555\n",
      "Episode Reward: 27.0\n",
      "Step 1181 (2226947) @ Episode 3506/10000, loss: 0.0923325493931770355\n",
      "Episode Reward: 30.0\n",
      "Step 837 (2227784) @ Episode 3507/10000, loss: 0.0018772834446281195\n",
      "Episode Reward: 22.0\n",
      "Step 728 (2228512) @ Episode 3508/10000, loss: 0.0051669557578861718\n",
      "Episode Reward: 14.0\n",
      "Step 1101 (2229613) @ Episode 3509/10000, loss: 0.0048462059348821646\n",
      "Episode Reward: 24.0\n",
      "Step 386 (2229999) @ Episode 3510/10000, loss: 0.0079190377146005635\n",
      " Copied model parameters to target network\n",
      "Step 677 (2230290) @ Episode 3510/10000, loss: 0.0033201735932379965\n",
      "Episode Reward: 11.0\n",
      "Step 883 (2231173) @ Episode 3511/10000, loss: 0.0023488262668251993\n",
      "Episode Reward: 16.0\n",
      "Step 1060 (2232233) @ Episode 3512/10000, loss: 0.0105334836989641194\n",
      "Episode Reward: 23.0\n",
      "Step 735 (2232968) @ Episode 3513/10000, loss: 0.0082116033881902725\n",
      "Episode Reward: 15.0\n",
      "Step 705 (2233673) @ Episode 3514/10000, loss: 0.0044662859290838245\n",
      "Episode Reward: 12.0\n",
      "Step 759 (2234432) @ Episode 3515/10000, loss: 0.0027377801015973094\n",
      "Episode Reward: 12.0\n",
      "Step 630 (2235062) @ Episode 3516/10000, loss: 0.0044844816438853746\n",
      "Episode Reward: 10.0\n",
      "Step 762 (2235824) @ Episode 3517/10000, loss: 0.0064456984400749217\n",
      "Episode Reward: 8.0\n",
      "Step 493 (2236317) @ Episode 3518/10000, loss: 0.0065765758045017724\n",
      "Episode Reward: 8.0\n",
      "Step 694 (2237011) @ Episode 3519/10000, loss: 0.0089069278910756115\n",
      "Episode Reward: 12.0\n",
      "Step 741 (2237752) @ Episode 3520/10000, loss: 0.0079913269728422165\n",
      "Episode Reward: 10.0\n",
      "Step 647 (2238399) @ Episode 3521/10000, loss: 0.0032751630060374737\n",
      "Episode Reward: 9.0\n",
      "Step 1181 (2239580) @ Episode 3522/10000, loss: 0.0252343267202377325\n",
      "Episode Reward: 30.0\n",
      "Step 419 (2239999) @ Episode 3523/10000, loss: 0.0060531757771968845\n",
      " Copied model parameters to target network\n",
      "Step 1068 (2240648) @ Episode 3523/10000, loss: 0.0026423723902553325\n",
      "Episode Reward: 20.0\n",
      "Step 881 (2241529) @ Episode 3524/10000, loss: 0.0076205804944038395\n",
      "Episode Reward: 17.0\n",
      "Step 894 (2242423) @ Episode 3525/10000, loss: 0.0074852751567959785\n",
      "Episode Reward: 16.0\n",
      "Step 1670 (2244093) @ Episode 3526/10000, loss: 0.0075439037755131725\n",
      "Episode Reward: 46.0\n",
      "Step 695 (2244788) @ Episode 3527/10000, loss: 0.0105175003409385683\n",
      "Episode Reward: 11.0\n",
      "Step 729 (2245517) @ Episode 3528/10000, loss: 0.0027942389715462923\n",
      "Episode Reward: 13.0\n",
      "Step 1372 (2246889) @ Episode 3529/10000, loss: 0.0041958461515605455\n",
      "Episode Reward: 37.0\n",
      "Step 1079 (2247968) @ Episode 3530/10000, loss: 0.0052263112738728526\n",
      "Episode Reward: 27.0\n",
      "Step 759 (2248727) @ Episode 3531/10000, loss: 0.0054800175130367283\n",
      "Episode Reward: 13.0\n",
      "Step 1031 (2249758) @ Episode 3532/10000, loss: 0.0071643376722931865\n",
      "Episode Reward: 22.0\n",
      "Step 241 (2249999) @ Episode 3533/10000, loss: 0.0030570146627724173\n",
      " Copied model parameters to target network\n",
      "Step 1145 (2250903) @ Episode 3533/10000, loss: 0.0219586174935102464\n",
      "Episode Reward: 21.0\n",
      "Step 692 (2251595) @ Episode 3534/10000, loss: 0.0044110622256994254\n",
      "Episode Reward: 11.0\n",
      "Step 781 (2252376) @ Episode 3535/10000, loss: 0.0030918223783373833\n",
      "Episode Reward: 13.0\n",
      "Step 1186 (2253562) @ Episode 3536/10000, loss: 0.0044171903282403956\n",
      "Episode Reward: 28.0\n",
      "Step 665 (2254227) @ Episode 3537/10000, loss: 0.0033194271381944423\n",
      "Episode Reward: 11.0\n",
      "Step 911 (2255138) @ Episode 3538/10000, loss: 0.0123596638441085827\n",
      "Episode Reward: 17.0\n",
      "Step 687 (2255825) @ Episode 3539/10000, loss: 0.0135369114577770234\n",
      "Episode Reward: 12.0\n",
      "Step 744 (2256569) @ Episode 3540/10000, loss: 0.0020303335040807724\n",
      "Episode Reward: 26.0\n",
      "Step 1454 (2258023) @ Episode 3541/10000, loss: 0.0087514435872435577\n",
      "Episode Reward: 44.0\n",
      "Step 750 (2258773) @ Episode 3542/10000, loss: 0.0046548154205083855\n",
      "Episode Reward: 10.0\n",
      "Step 653 (2259426) @ Episode 3543/10000, loss: 0.0073602003976702696\n",
      "Episode Reward: 11.0\n",
      "Step 573 (2259999) @ Episode 3544/10000, loss: 0.0077948179095983505\n",
      " Copied model parameters to target network\n",
      "Step 638 (2260064) @ Episode 3544/10000, loss: 0.0030238553881645203\n",
      "Episode Reward: 13.0\n",
      "Step 1050 (2261114) @ Episode 3545/10000, loss: 0.0030202006455510855\n",
      "Episode Reward: 22.0\n",
      "Step 699 (2261813) @ Episode 3546/10000, loss: 0.0054327156394720083\n",
      "Episode Reward: 11.0\n",
      "Step 776 (2262589) @ Episode 3547/10000, loss: 0.0068884054198861125\n",
      "Episode Reward: 12.0\n",
      "Step 618 (2263207) @ Episode 3548/10000, loss: 0.0048303753137588586\n",
      "Episode Reward: 9.0\n",
      "Step 1031 (2264238) @ Episode 3549/10000, loss: 0.0185035187751054767\n",
      "Episode Reward: 22.0\n",
      "Step 1042 (2265280) @ Episode 3550/10000, loss: 0.0042978096753358842\n",
      "Episode Reward: 24.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 22:27:59,210] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video003550.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 625 (2265905) @ Episode 3551/10000, loss: 0.0086180679500103715\n",
      "Episode Reward: 8.0\n",
      "Step 1013 (2266918) @ Episode 3552/10000, loss: 0.0082675646990537645\n",
      "Episode Reward: 31.0\n",
      "Step 768 (2267686) @ Episode 3553/10000, loss: 0.0062003834173083305\n",
      "Episode Reward: 14.0\n",
      "Step 798 (2268484) @ Episode 3554/10000, loss: 0.0146057633683085445\n",
      "Episode Reward: 14.0\n",
      "Step 510 (2268994) @ Episode 3555/10000, loss: 0.0034407763741910458\n",
      "Episode Reward: 6.0\n",
      "Step 1005 (2269999) @ Episode 3556/10000, loss: 0.011004636064171791\n",
      " Copied model parameters to target network\n",
      "Step 1249 (2270243) @ Episode 3556/10000, loss: 0.0024376832880079746\n",
      "Episode Reward: 27.0\n",
      "Step 810 (2271053) @ Episode 3557/10000, loss: 0.0149131752550601965\n",
      "Episode Reward: 18.0\n",
      "Step 770 (2271823) @ Episode 3558/10000, loss: 0.0060185650363564496\n",
      "Episode Reward: 15.0\n",
      "Step 946 (2272769) @ Episode 3559/10000, loss: 0.0047074612230062485\n",
      "Episode Reward: 21.0\n",
      "Step 1053 (2273822) @ Episode 3560/10000, loss: 0.0046272603794932365\n",
      "Episode Reward: 20.0\n",
      "Step 560 (2274382) @ Episode 3561/10000, loss: 0.0064384825527668537\n",
      "Episode Reward: 8.0\n",
      "Step 890 (2275272) @ Episode 3562/10000, loss: 0.0071326550096273425\n",
      "Episode Reward: 14.0\n",
      "Step 1190 (2276462) @ Episode 3563/10000, loss: 0.0059828795492649086\n",
      "Episode Reward: 19.0\n",
      "Step 971 (2277433) @ Episode 3564/10000, loss: 0.0030947185587137938\n",
      "Episode Reward: 17.0\n",
      "Step 952 (2278385) @ Episode 3565/10000, loss: 0.0043623996898531913\n",
      "Episode Reward: 17.0\n",
      "Step 1048 (2279433) @ Episode 3566/10000, loss: 0.0045169480144977576\n",
      "Episode Reward: 28.0\n",
      "Step 566 (2279999) @ Episode 3567/10000, loss: 0.0086820349097251955\n",
      " Copied model parameters to target network\n",
      "Step 602 (2280035) @ Episode 3567/10000, loss: 0.0059012072160840034\n",
      "Episode Reward: 10.0\n",
      "Step 975 (2281010) @ Episode 3568/10000, loss: 0.0155730666592717175\n",
      "Episode Reward: 27.0\n",
      "Step 470 (2281480) @ Episode 3569/10000, loss: 0.0086871422827243823\n",
      "Episode Reward: 10.0\n",
      "Step 925 (2282405) @ Episode 3570/10000, loss: 0.0056864735670387745\n",
      "Episode Reward: 19.0\n",
      "Step 887 (2283292) @ Episode 3571/10000, loss: 0.0148577531799674036\n",
      "Episode Reward: 15.0\n",
      "Step 638 (2283930) @ Episode 3572/10000, loss: 0.0052007031626999386\n",
      "Episode Reward: 15.0\n",
      "Step 745 (2284675) @ Episode 3573/10000, loss: 0.0040490357205271725\n",
      "Episode Reward: 16.0\n",
      "Step 770 (2285445) @ Episode 3574/10000, loss: 0.0052597885951399893\n",
      "Episode Reward: 13.0\n",
      "Step 1316 (2286761) @ Episode 3575/10000, loss: 0.0172079727053642276\n",
      "Episode Reward: 31.0\n",
      "Step 1317 (2288078) @ Episode 3576/10000, loss: 0.0159007646143436433\n",
      "Episode Reward: 26.0\n",
      "Step 897 (2288975) @ Episode 3577/10000, loss: 0.0067436257377266883\n",
      "Episode Reward: 19.0\n",
      "Step 1024 (2289999) @ Episode 3578/10000, loss: 0.0300926100462675163\n",
      " Copied model parameters to target network\n",
      "Step 1693 (2290668) @ Episode 3578/10000, loss: 0.0057114632800221444\n",
      "Episode Reward: 39.0\n",
      "Step 901 (2291569) @ Episode 3579/10000, loss: 0.0040584811940789225\n",
      "Episode Reward: 20.0\n",
      "Step 1303 (2292872) @ Episode 3580/10000, loss: 0.0035591823980212214\n",
      "Episode Reward: 33.0\n",
      "Step 1272 (2294144) @ Episode 3581/10000, loss: 0.0054831178858876236\n",
      "Episode Reward: 27.0\n",
      "Step 750 (2294894) @ Episode 3582/10000, loss: 0.0034059504978358746\n",
      "Episode Reward: 11.0\n",
      "Step 1104 (2295998) @ Episode 3583/10000, loss: 0.0259632393717765896\n",
      "Episode Reward: 27.0\n",
      "Step 829 (2296827) @ Episode 3584/10000, loss: 0.0041508330032229424\n",
      "Episode Reward: 14.0\n",
      "Step 1105 (2297932) @ Episode 3585/10000, loss: 0.0040287207812070856\n",
      "Episode Reward: 26.0\n",
      "Step 712 (2298644) @ Episode 3586/10000, loss: 0.0048133148811757565\n",
      "Episode Reward: 10.0\n",
      "Step 838 (2299482) @ Episode 3587/10000, loss: 0.0093375565484166155\n",
      "Episode Reward: 13.0\n",
      "Step 517 (2299999) @ Episode 3588/10000, loss: 0.0087416265159845357\n",
      " Copied model parameters to target network\n",
      "Step 998 (2300480) @ Episode 3588/10000, loss: 0.0085751898586750034\n",
      "Episode Reward: 18.0\n",
      "Step 896 (2301376) @ Episode 3589/10000, loss: 0.0026444280520081525\n",
      "Episode Reward: 15.0\n",
      "Step 1121 (2302497) @ Episode 3590/10000, loss: 0.0016124048270285135\n",
      "Episode Reward: 33.0\n",
      "Step 615 (2303112) @ Episode 3591/10000, loss: 0.0060125645250082025\n",
      "Episode Reward: 11.0\n",
      "Step 1277 (2304389) @ Episode 3592/10000, loss: 0.0065080784261226657\n",
      "Episode Reward: 19.0\n",
      "Step 1014 (2305403) @ Episode 3593/10000, loss: 0.0091116391122341165\n",
      "Episode Reward: 20.0\n",
      "Step 688 (2306091) @ Episode 3594/10000, loss: 0.0063497228547930725\n",
      "Episode Reward: 14.0\n",
      "Step 1215 (2307306) @ Episode 3595/10000, loss: 0.0039270948618650445\n",
      "Episode Reward: 27.0\n",
      "Step 721 (2308027) @ Episode 3596/10000, loss: 0.0136774480342864996\n",
      "Episode Reward: 13.0\n",
      "Step 1002 (2309029) @ Episode 3597/10000, loss: 0.012039514258503914\n",
      "Episode Reward: 24.0\n",
      "Step 789 (2309818) @ Episode 3598/10000, loss: 0.0109744416549801835\n",
      "Episode Reward: 16.0\n",
      "Step 181 (2309999) @ Episode 3599/10000, loss: 0.0029187945183366537\n",
      " Copied model parameters to target network\n",
      "Step 828 (2310646) @ Episode 3599/10000, loss: 0.0093882177025079736\n",
      "Episode Reward: 16.0\n",
      "Step 1170 (2311816) @ Episode 3600/10000, loss: 0.0055298535153269776\n",
      "Episode Reward: 31.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 22:34:57,044] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video003600.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 969 (2312785) @ Episode 3601/10000, loss: 0.0039388593286275866\n",
      "Episode Reward: 26.0\n",
      "Step 622 (2313407) @ Episode 3602/10000, loss: 0.0129813170060515453\n",
      "Episode Reward: 11.0\n",
      "Step 788 (2314195) @ Episode 3603/10000, loss: 0.0034447226207703352\n",
      "Episode Reward: 20.0\n",
      "Step 564 (2314759) @ Episode 3604/10000, loss: 0.0054498147219419485\n",
      "Episode Reward: 7.0\n",
      "Step 1448 (2316207) @ Episode 3605/10000, loss: 0.0044047534465789795\n",
      "Episode Reward: 24.0\n",
      "Step 1194 (2317401) @ Episode 3606/10000, loss: 0.0036614201962947845\n",
      "Episode Reward: 20.0\n",
      "Step 609 (2318010) @ Episode 3607/10000, loss: 0.0111525012180209165\n",
      "Episode Reward: 8.0\n",
      "Step 838 (2318848) @ Episode 3608/10000, loss: 0.0030771275050938137\n",
      "Episode Reward: 14.0\n",
      "Step 941 (2319789) @ Episode 3609/10000, loss: 0.0053087119013071065\n",
      "Episode Reward: 16.0\n",
      "Step 210 (2319999) @ Episode 3610/10000, loss: 0.0087680574506521225\n",
      " Copied model parameters to target network\n",
      "Step 950 (2320739) @ Episode 3610/10000, loss: 0.0159120075404644514\n",
      "Episode Reward: 19.0\n",
      "Step 825 (2321564) @ Episode 3611/10000, loss: 0.0041801393963396555\n",
      "Episode Reward: 13.0\n",
      "Step 1217 (2322781) @ Episode 3612/10000, loss: 0.0071407957002520566\n",
      "Episode Reward: 34.0\n",
      "Step 524 (2323305) @ Episode 3613/10000, loss: 0.0097524225711822512\n",
      "Episode Reward: 4.0\n",
      "Step 1068 (2324373) @ Episode 3614/10000, loss: 0.0064025791361927995\n",
      "Episode Reward: 23.0\n",
      "Step 742 (2325115) @ Episode 3615/10000, loss: 0.0031425035558640957\n",
      "Episode Reward: 17.0\n",
      "Step 866 (2325981) @ Episode 3616/10000, loss: 0.0048636738210916526\n",
      "Episode Reward: 11.0\n",
      "Step 1103 (2327084) @ Episode 3617/10000, loss: 0.0169574450701475146\n",
      "Episode Reward: 20.0\n",
      "Step 541 (2327625) @ Episode 3618/10000, loss: 0.0084606539458036426\n",
      "Episode Reward: 7.0\n",
      "Step 1099 (2328724) @ Episode 3619/10000, loss: 0.0057607181370258333\n",
      "Episode Reward: 18.0\n",
      "Step 881 (2329605) @ Episode 3620/10000, loss: 0.0090704616159200675\n",
      "Episode Reward: 14.0\n",
      "Step 394 (2329999) @ Episode 3621/10000, loss: 0.0046081924811005597\n",
      " Copied model parameters to target network\n",
      "Step 925 (2330530) @ Episode 3621/10000, loss: 0.0041050221771001823\n",
      "Episode Reward: 16.0\n",
      "Step 504 (2331034) @ Episode 3622/10000, loss: 0.0040229661390185365\n",
      "Episode Reward: 7.0\n",
      "Step 1036 (2332070) @ Episode 3623/10000, loss: 0.0092201065272092826\n",
      "Episode Reward: 18.0\n",
      "Step 709 (2332779) @ Episode 3624/10000, loss: 0.0030045709572732455\n",
      "Episode Reward: 11.0\n",
      "Step 1287 (2334066) @ Episode 3625/10000, loss: 0.0065221949480473995\n",
      "Episode Reward: 31.0\n",
      "Step 526 (2334592) @ Episode 3626/10000, loss: 0.0057135284878313544\n",
      "Episode Reward: 8.0\n",
      "Step 831 (2335423) @ Episode 3627/10000, loss: 0.0119009492918849044\n",
      "Episode Reward: 14.0\n",
      "Step 760 (2336183) @ Episode 3628/10000, loss: 0.0077948179095983505\n",
      "Episode Reward: 12.0\n",
      "Step 796 (2336979) @ Episode 3629/10000, loss: 0.0049271131865680225\n",
      "Episode Reward: 13.0\n",
      "Step 825 (2337804) @ Episode 3630/10000, loss: 0.0048570986837148675\n",
      "Episode Reward: 11.0\n",
      "Step 1063 (2338867) @ Episode 3631/10000, loss: 0.0129475975409150127\n",
      "Episode Reward: 19.0\n",
      "Step 1097 (2339964) @ Episode 3632/10000, loss: 0.1127005293965339725\n",
      "Episode Reward: 17.0\n",
      "Step 35 (2339999) @ Episode 3633/10000, loss: 0.0076630837284028536\n",
      " Copied model parameters to target network\n",
      "Step 614 (2340578) @ Episode 3633/10000, loss: 0.0061697470955550675\n",
      "Episode Reward: 9.0\n",
      "Step 1223 (2341801) @ Episode 3634/10000, loss: 0.0042669088579714394\n",
      "Episode Reward: 26.0\n",
      "Step 815 (2342616) @ Episode 3635/10000, loss: 0.0100848563015460973\n",
      "Episode Reward: 16.0\n",
      "Step 697 (2343313) @ Episode 3636/10000, loss: 0.0032993217464536432\n",
      "Episode Reward: 15.0\n",
      "Step 666 (2343979) @ Episode 3637/10000, loss: 0.0019066368695348501\n",
      "Episode Reward: 9.0\n",
      "Step 961 (2344940) @ Episode 3638/10000, loss: 0.0063571454957127573\n",
      "Episode Reward: 17.0\n",
      "Step 957 (2345897) @ Episode 3639/10000, loss: 0.0044543724507093435\n",
      "Episode Reward: 17.0\n",
      "Step 1341 (2347238) @ Episode 3640/10000, loss: 0.0027857790701091293\n",
      "Episode Reward: 19.0\n",
      "Step 651 (2347889) @ Episode 3641/10000, loss: 0.0067604379728436477\n",
      "Episode Reward: 11.0\n",
      "Step 708 (2348597) @ Episode 3642/10000, loss: 0.0051865493878722193\n",
      "Episode Reward: 15.0\n",
      "Step 972 (2349569) @ Episode 3643/10000, loss: 0.0075876330956816675\n",
      "Episode Reward: 20.0\n",
      "Step 430 (2349999) @ Episode 3644/10000, loss: 0.0036683403886854656\n",
      " Copied model parameters to target network\n",
      "Step 776 (2350345) @ Episode 3644/10000, loss: 0.0066747441887855535\n",
      "Episode Reward: 17.0\n",
      "Step 1228 (2351573) @ Episode 3645/10000, loss: 0.0022334847599267968\n",
      "Episode Reward: 23.0\n",
      "Step 1704 (2353277) @ Episode 3646/10000, loss: 0.0039342045783996583\n",
      "Episode Reward: 45.0\n",
      "Step 1232 (2354509) @ Episode 3647/10000, loss: 0.0097327847033739094\n",
      "Episode Reward: 33.0\n",
      "Step 760 (2355269) @ Episode 3648/10000, loss: 0.0050334753468632774\n",
      "Episode Reward: 12.0\n",
      "Step 715 (2355984) @ Episode 3649/10000, loss: 0.0058399243280291565\n",
      "Episode Reward: 11.0\n",
      "Step 579 (2356563) @ Episode 3650/10000, loss: 0.0047195400111377242\n",
      "Episode Reward: 10.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 22:41:42,652] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video003650.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1022 (2357585) @ Episode 3651/10000, loss: 0.0099806329235434534\n",
      "Episode Reward: 18.0\n",
      "Step 679 (2358264) @ Episode 3652/10000, loss: 0.0041180332191288477\n",
      "Episode Reward: 23.0\n",
      "Step 1522 (2359786) @ Episode 3653/10000, loss: 0.0055464478209614754\n",
      "Episode Reward: 36.0\n",
      "Step 213 (2359999) @ Episode 3654/10000, loss: 0.0027823164127767086\n",
      " Copied model parameters to target network\n",
      "Step 1506 (2361292) @ Episode 3654/10000, loss: 0.0115285310894250875\n",
      "Episode Reward: 32.0\n",
      "Step 905 (2362197) @ Episode 3655/10000, loss: 0.0080298958346247675\n",
      "Episode Reward: 14.0\n",
      "Step 1199 (2363396) @ Episode 3656/10000, loss: 0.0045375693589448934\n",
      "Episode Reward: 27.0\n",
      "Step 1210 (2364606) @ Episode 3657/10000, loss: 0.0024529765360057354\n",
      "Episode Reward: 25.0\n",
      "Step 999 (2365605) @ Episode 3658/10000, loss: 0.0073962789028882983\n",
      "Episode Reward: 20.0\n",
      "Step 988 (2366593) @ Episode 3659/10000, loss: 0.0060328375548124315\n",
      "Episode Reward: 20.0\n",
      "Step 1139 (2367732) @ Episode 3660/10000, loss: 0.0029084472917020325\n",
      "Episode Reward: 20.0\n",
      "Step 1258 (2368990) @ Episode 3661/10000, loss: 0.0102677009999752045\n",
      "Episode Reward: 21.0\n",
      "Step 902 (2369892) @ Episode 3662/10000, loss: 0.0032988192979246385\n",
      "Episode Reward: 26.0\n",
      "Step 107 (2369999) @ Episode 3663/10000, loss: 0.002310279756784439\n",
      " Copied model parameters to target network\n",
      "Step 1186 (2371078) @ Episode 3663/10000, loss: 0.0107800103724002846\n",
      "Episode Reward: 22.0\n",
      "Step 656 (2371734) @ Episode 3664/10000, loss: 0.0223217532038688665\n",
      "Episode Reward: 10.0\n",
      "Step 891 (2372625) @ Episode 3665/10000, loss: 0.0167733412235975275\n",
      "Episode Reward: 15.0\n",
      "Step 1512 (2374137) @ Episode 3666/10000, loss: 0.0103326337411999794\n",
      "Episode Reward: 45.0\n",
      "Step 1033 (2375170) @ Episode 3667/10000, loss: 0.0034940447658300435\n",
      "Episode Reward: 22.0\n",
      "Step 1462 (2376632) @ Episode 3668/10000, loss: 0.0146286878734827047\n",
      "Episode Reward: 36.0\n",
      "Step 646 (2377278) @ Episode 3669/10000, loss: 0.0059402417391538626\n",
      "Episode Reward: 15.0\n",
      "Step 1017 (2378295) @ Episode 3670/10000, loss: 0.0039486442692577842\n",
      "Episode Reward: 20.0\n",
      "Step 769 (2379064) @ Episode 3671/10000, loss: 0.0040847398340702067\n",
      "Episode Reward: 10.0\n",
      "Step 935 (2379999) @ Episode 3672/10000, loss: 0.0029659387655556278\n",
      " Copied model parameters to target network\n",
      "Step 1230 (2380294) @ Episode 3672/10000, loss: 0.0026458953507244587\n",
      "Episode Reward: 30.0\n",
      "Step 850 (2381144) @ Episode 3673/10000, loss: 0.0070023676380515186\n",
      "Episode Reward: 13.0\n",
      "Step 835 (2381979) @ Episode 3674/10000, loss: 0.0061687054112553634\n",
      "Episode Reward: 12.0\n",
      "Step 1044 (2383023) @ Episode 3675/10000, loss: 0.0085949385538697245\n",
      "Episode Reward: 21.0\n",
      "Step 697 (2383720) @ Episode 3676/10000, loss: 0.0048367227427661425\n",
      "Episode Reward: 11.0\n",
      "Step 783 (2384503) @ Episode 3677/10000, loss: 0.0063897920772433287\n",
      "Episode Reward: 13.0\n",
      "Step 691 (2385194) @ Episode 3678/10000, loss: 0.0058600297197699554\n",
      "Episode Reward: 11.0\n",
      "Step 1368 (2386562) @ Episode 3679/10000, loss: 0.0081711150705814365\n",
      "Episode Reward: 32.0\n",
      "Step 1272 (2387834) @ Episode 3680/10000, loss: 0.0039776107296347625\n",
      "Episode Reward: 30.0\n",
      "Step 670 (2388504) @ Episode 3681/10000, loss: 0.0091922488063573843\n",
      "Episode Reward: 9.0\n",
      "Step 1136 (2389640) @ Episode 3682/10000, loss: 0.0047035100869834425\n",
      "Episode Reward: 16.0\n",
      "Step 359 (2389999) @ Episode 3683/10000, loss: 0.0038418124895542867\n",
      " Copied model parameters to target network\n",
      "Step 1562 (2391202) @ Episode 3683/10000, loss: 0.0181606691330671357\n",
      "Episode Reward: 39.0\n",
      "Step 808 (2392010) @ Episode 3684/10000, loss: 0.0093409465625882156\n",
      "Episode Reward: 16.0\n",
      "Step 1047 (2393057) @ Episode 3685/10000, loss: 0.0096446713432669645\n",
      "Episode Reward: 25.0\n",
      "Step 931 (2393988) @ Episode 3686/10000, loss: 0.0102613652125000955\n",
      "Episode Reward: 18.0\n",
      "Step 1143 (2395131) @ Episode 3687/10000, loss: 0.0052200267091393474\n",
      "Episode Reward: 23.0\n",
      "Step 1346 (2396477) @ Episode 3688/10000, loss: 0.0090939812362194065\n",
      "Episode Reward: 33.0\n",
      "Step 1544 (2398021) @ Episode 3689/10000, loss: 0.0056897434405982494\n",
      "Episode Reward: 43.0\n",
      "Step 961 (2398982) @ Episode 3690/10000, loss: 0.0485920161008834843\n",
      "Episode Reward: 22.0\n",
      "Step 1017 (2399999) @ Episode 3691/10000, loss: 0.0065018339082598692\n",
      " Copied model parameters to target network\n",
      "Step 1326 (2400308) @ Episode 3691/10000, loss: 0.0058448845520615584\n",
      "Episode Reward: 38.0\n",
      "Step 1467 (2401775) @ Episode 3692/10000, loss: 0.0022718990221619606\n",
      "Episode Reward: 36.0\n",
      "Step 804 (2402579) @ Episode 3693/10000, loss: 0.0105974450707435695\n",
      "Episode Reward: 14.0\n",
      "Step 900 (2403479) @ Episode 3694/10000, loss: 0.0043024104088544846\n",
      "Episode Reward: 14.0\n",
      "Step 992 (2404471) @ Episode 3695/10000, loss: 0.0190192013978958135\n",
      "Episode Reward: 17.0\n",
      "Step 632 (2405103) @ Episode 3696/10000, loss: 0.0018887224141508345\n",
      "Episode Reward: 20.0\n",
      "Step 661 (2405764) @ Episode 3697/10000, loss: 0.0062204198911786085\n",
      "Episode Reward: 20.0\n",
      "Step 681 (2406445) @ Episode 3698/10000, loss: 0.0043239770457148555\n",
      "Episode Reward: 10.0\n",
      "Step 889 (2407334) @ Episode 3699/10000, loss: 0.0097022270783782292\n",
      "Episode Reward: 19.0\n",
      "Step 644 (2407978) @ Episode 3700/10000, loss: 0.0231082364916801454\n",
      "Episode Reward: 12.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 22:49:24,482] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video003700.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1095 (2409073) @ Episode 3701/10000, loss: 0.0041571687906980515\n",
      "Episode Reward: 23.0\n",
      "Step 926 (2409999) @ Episode 3702/10000, loss: 0.0096454815939068843\n",
      " Copied model parameters to target network\n",
      "Step 963 (2410036) @ Episode 3702/10000, loss: 0.0028505166992545135\n",
      "Episode Reward: 21.0\n",
      "Step 1061 (2411097) @ Episode 3703/10000, loss: 0.0050529381260275844\n",
      "Episode Reward: 20.0\n",
      "Step 724 (2411821) @ Episode 3704/10000, loss: 0.0090387053787708286\n",
      "Episode Reward: 25.0\n",
      "Step 1495 (2413316) @ Episode 3705/10000, loss: 0.0029056514613330364\n",
      "Episode Reward: 40.0\n",
      "Step 1312 (2414628) @ Episode 3706/10000, loss: 0.0053353845141828062\n",
      "Episode Reward: 27.0\n",
      "Step 1289 (2415917) @ Episode 3707/10000, loss: 0.0095447525382041936\n",
      "Episode Reward: 30.0\n",
      "Step 995 (2416912) @ Episode 3708/10000, loss: 0.0031645623967051506\n",
      "Episode Reward: 21.0\n",
      "Step 872 (2417784) @ Episode 3709/10000, loss: 0.0052982205525040632\n",
      "Episode Reward: 19.0\n",
      "Step 975 (2418759) @ Episode 3710/10000, loss: 0.0025360337458550935\n",
      "Episode Reward: 21.0\n",
      "Step 1107 (2419866) @ Episode 3711/10000, loss: 0.0022565494291484356\n",
      "Episode Reward: 25.0\n",
      "Step 133 (2419999) @ Episode 3712/10000, loss: 0.0047428938560187826\n",
      " Copied model parameters to target network\n",
      "Step 803 (2420669) @ Episode 3712/10000, loss: 0.0058479653671383865\n",
      "Episode Reward: 13.0\n",
      "Step 915 (2421584) @ Episode 3713/10000, loss: 0.0059118727222085565\n",
      "Episode Reward: 17.0\n",
      "Step 1002 (2422586) @ Episode 3714/10000, loss: 0.0038973421324044466\n",
      "Episode Reward: 20.0\n",
      "Step 996 (2423582) @ Episode 3715/10000, loss: 0.0654899626970291134\n",
      "Episode Reward: 20.0\n",
      "Step 750 (2424332) @ Episode 3716/10000, loss: 0.0055870278738439082\n",
      "Episode Reward: 12.0\n",
      "Step 1380 (2425712) @ Episode 3717/10000, loss: 0.0069450265727937225\n",
      "Episode Reward: 29.0\n",
      "Step 810 (2426522) @ Episode 3718/10000, loss: 0.0231244154274463654\n",
      "Episode Reward: 13.0\n",
      "Step 1165 (2427687) @ Episode 3719/10000, loss: 0.0124915121123194717\n",
      "Episode Reward: 20.0\n",
      "Step 924 (2428611) @ Episode 3720/10000, loss: 0.0044382913038134575\n",
      "Episode Reward: 19.0\n",
      "Step 990 (2429601) @ Episode 3721/10000, loss: 0.0051076211966574195\n",
      "Episode Reward: 23.0\n",
      "Step 398 (2429999) @ Episode 3722/10000, loss: 0.0035840841010212987\n",
      " Copied model parameters to target network\n",
      "Step 1196 (2430797) @ Episode 3722/10000, loss: 0.0049257604405283935\n",
      "Episode Reward: 21.0\n",
      "Step 1043 (2431840) @ Episode 3723/10000, loss: 0.0072058085352182394\n",
      "Episode Reward: 34.0\n",
      "Step 778 (2432618) @ Episode 3724/10000, loss: 0.0269762724637985235\n",
      "Episode Reward: 17.0\n",
      "Step 991 (2433609) @ Episode 3725/10000, loss: 0.0065908594988286495\n",
      "Episode Reward: 16.0\n",
      "Step 1099 (2434708) @ Episode 3726/10000, loss: 0.0127279292792081834\n",
      "Episode Reward: 25.0\n",
      "Step 675 (2435383) @ Episode 3727/10000, loss: 0.0058501120656728745\n",
      "Episode Reward: 12.0\n",
      "Step 1318 (2436701) @ Episode 3728/10000, loss: 0.0077675888314843183\n",
      "Episode Reward: 31.0\n",
      "Step 850 (2437551) @ Episode 3729/10000, loss: 0.0058243665844202046\n",
      "Episode Reward: 16.0\n",
      "Step 1339 (2438890) @ Episode 3730/10000, loss: 0.0082850400358438564\n",
      "Episode Reward: 22.0\n",
      "Step 1009 (2439899) @ Episode 3731/10000, loss: 0.0123070999979972845\n",
      "Episode Reward: 21.0\n",
      "Step 100 (2439999) @ Episode 3732/10000, loss: 0.008086727000772953\n",
      " Copied model parameters to target network\n",
      "Step 1191 (2441090) @ Episode 3732/10000, loss: 0.0093620605766773226\n",
      "Episode Reward: 35.0\n",
      "Step 776 (2441866) @ Episode 3733/10000, loss: 0.0076460684649646287\n",
      "Episode Reward: 20.0\n",
      "Step 1050 (2442916) @ Episode 3734/10000, loss: 0.0061285654082894325\n",
      "Episode Reward: 19.0\n",
      "Step 718 (2443634) @ Episode 3735/10000, loss: 0.0373571179807186125\n",
      "Episode Reward: 11.0\n",
      "Step 1125 (2444759) @ Episode 3736/10000, loss: 0.0046308035962283615\n",
      "Episode Reward: 26.0\n",
      "Step 660 (2445419) @ Episode 3737/10000, loss: 0.0147439911961555484\n",
      "Episode Reward: 10.0\n",
      "Step 1306 (2446725) @ Episode 3738/10000, loss: 0.0054015088826417923\n",
      "Episode Reward: 30.0\n",
      "Step 1044 (2447769) @ Episode 3739/10000, loss: 0.0025424507912248373\n",
      "Episode Reward: 18.0\n",
      "Step 1160 (2448929) @ Episode 3740/10000, loss: 0.0046451883390545845\n",
      "Episode Reward: 31.0\n",
      "Step 1070 (2449999) @ Episode 3741/10000, loss: 0.0294759217649698265\n",
      " Copied model parameters to target network\n",
      "Step 1502 (2450431) @ Episode 3741/10000, loss: 0.0035199250560253865\n",
      "Episode Reward: 49.0\n",
      "Step 932 (2451363) @ Episode 3742/10000, loss: 0.0048694796860218056\n",
      "Episode Reward: 33.0\n",
      "Step 1179 (2452542) @ Episode 3743/10000, loss: 0.0035930981393903494\n",
      "Episode Reward: 23.0\n",
      "Step 830 (2453372) @ Episode 3744/10000, loss: 0.0061379177495837214\n",
      "Episode Reward: 20.0\n",
      "Step 792 (2454164) @ Episode 3745/10000, loss: 0.0030568980146199465\n",
      "Episode Reward: 10.0\n",
      "Step 829 (2454993) @ Episode 3746/10000, loss: 0.0064169401302933695\n",
      "Episode Reward: 16.0\n",
      "Step 1018 (2456011) @ Episode 3747/10000, loss: 0.0040147630497813225\n",
      "Episode Reward: 18.0\n",
      "Step 1044 (2457055) @ Episode 3748/10000, loss: 0.0055487686768174176\n",
      "Episode Reward: 18.0\n",
      "Step 1118 (2458173) @ Episode 3749/10000, loss: 0.0056946501135826115\n",
      "Episode Reward: 27.0\n",
      "Step 1058 (2459231) @ Episode 3750/10000, loss: 0.0033136727288365364\n",
      "Episode Reward: 22.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 22:57:07,461] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video003750.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 768 (2459999) @ Episode 3751/10000, loss: 0.0049056624993681917\n",
      " Copied model parameters to target network\n",
      "Step 991 (2460222) @ Episode 3751/10000, loss: 0.0463016815483570115\n",
      "Episode Reward: 24.0\n",
      "Step 1321 (2461543) @ Episode 3752/10000, loss: 0.0168913155794143684\n",
      "Episode Reward: 27.0\n",
      "Step 921 (2462464) @ Episode 3753/10000, loss: 0.0036743560340255595\n",
      "Episode Reward: 18.0\n",
      "Step 1387 (2463851) @ Episode 3754/10000, loss: 0.0082584088668227236\n",
      "Episode Reward: 36.0\n",
      "Step 1141 (2464992) @ Episode 3755/10000, loss: 0.0116741368547081955\n",
      "Episode Reward: 25.0\n",
      "Step 1080 (2466072) @ Episode 3756/10000, loss: 0.0099801728501915935\n",
      "Episode Reward: 29.0\n",
      "Step 924 (2466996) @ Episode 3757/10000, loss: 0.0080991275608539586\n",
      "Episode Reward: 16.0\n",
      "Step 1239 (2468235) @ Episode 3758/10000, loss: 0.0073043415322899825\n",
      "Episode Reward: 26.0\n",
      "Step 1406 (2469641) @ Episode 3759/10000, loss: 0.0087204333394765855\n",
      "Episode Reward: 30.0\n",
      "Step 358 (2469999) @ Episode 3760/10000, loss: 0.0073854662477970125\n",
      " Copied model parameters to target network\n",
      "Step 1010 (2470651) @ Episode 3760/10000, loss: 0.0046587819233536723\n",
      "Episode Reward: 16.0\n",
      "Step 1102 (2471753) @ Episode 3761/10000, loss: 0.0062216976657509897\n",
      "Episode Reward: 22.0\n",
      "Step 863 (2472616) @ Episode 3762/10000, loss: 0.0092430394142866135\n",
      "Episode Reward: 14.0\n",
      "Step 994 (2473610) @ Episode 3763/10000, loss: 0.0042731733992695815\n",
      "Episode Reward: 17.0\n",
      "Step 932 (2474542) @ Episode 3764/10000, loss: 0.0039852093905210495\n",
      "Episode Reward: 17.0\n",
      "Step 1072 (2475614) @ Episode 3765/10000, loss: 0.0094350120052695272\n",
      "Episode Reward: 17.0\n",
      "Step 900 (2476514) @ Episode 3766/10000, loss: 0.0107800764963030826\n",
      "Episode Reward: 14.0\n",
      "Step 790 (2477304) @ Episode 3767/10000, loss: 0.0093696955591440285\n",
      "Episode Reward: 15.0\n",
      "Step 1014 (2478318) @ Episode 3768/10000, loss: 0.0029253924731165175\n",
      "Episode Reward: 27.0\n",
      "Step 1268 (2479586) @ Episode 3769/10000, loss: 0.0051099103875458243\n",
      "Episode Reward: 20.0\n",
      "Step 413 (2479999) @ Episode 3770/10000, loss: 0.0064784856513142595\n",
      " Copied model parameters to target network\n",
      "Step 550 (2480136) @ Episode 3770/10000, loss: 0.0047993008047342387\n",
      "Episode Reward: 8.0\n",
      "Step 810 (2480946) @ Episode 3771/10000, loss: 0.0033262525685131554\n",
      "Episode Reward: 20.0\n",
      "Step 812 (2481758) @ Episode 3772/10000, loss: 0.0037348994519561535\n",
      "Episode Reward: 13.0\n",
      "Step 1091 (2482849) @ Episode 3773/10000, loss: 0.0117573598399758344\n",
      "Episode Reward: 25.0\n",
      "Step 1002 (2483851) @ Episode 3774/10000, loss: 0.020116142928600314\n",
      "Episode Reward: 15.0\n",
      "Step 1093 (2484944) @ Episode 3775/10000, loss: 0.0036340756341814995\n",
      "Episode Reward: 28.0\n",
      "Step 803 (2485747) @ Episode 3776/10000, loss: 0.0050207097083330154\n",
      "Episode Reward: 13.0\n",
      "Step 1397 (2487144) @ Episode 3777/10000, loss: 0.0024755119811743594\n",
      "Episode Reward: 23.0\n",
      "Step 924 (2488068) @ Episode 3778/10000, loss: 0.0066401036456227345\n",
      "Episode Reward: 20.0\n",
      "Step 1054 (2489122) @ Episode 3779/10000, loss: 0.0028582224622368813\n",
      "Episode Reward: 19.0\n",
      "Step 841 (2489963) @ Episode 3780/10000, loss: 0.0038825538940727715\n",
      "Episode Reward: 15.0\n",
      "Step 36 (2489999) @ Episode 3781/10000, loss: 0.0063052438199520113\n",
      " Copied model parameters to target network\n",
      "Step 738 (2490701) @ Episode 3781/10000, loss: 0.0022012707777321345\n",
      "Episode Reward: 12.0\n",
      "Step 987 (2491688) @ Episode 3782/10000, loss: 0.0068652066402137285\n",
      "Episode Reward: 16.0\n",
      "Step 762 (2492450) @ Episode 3783/10000, loss: 0.0058011822402477264\n",
      "Episode Reward: 13.0\n",
      "Step 1143 (2493593) @ Episode 3784/10000, loss: 0.0035164621658623224\n",
      "Episode Reward: 27.0\n",
      "Step 1163 (2494756) @ Episode 3785/10000, loss: 0.0029785498045384884\n",
      "Episode Reward: 23.0\n",
      "Step 1105 (2495861) @ Episode 3786/10000, loss: 0.0029904600232839584\n",
      "Episode Reward: 21.0\n",
      "Step 495 (2496356) @ Episode 3787/10000, loss: 0.0022112624719738965\n",
      "Episode Reward: 7.0\n",
      "Step 1186 (2497542) @ Episode 3788/10000, loss: 0.0019460562616586685\n",
      "Episode Reward: 24.0\n",
      "Step 1003 (2498545) @ Episode 3789/10000, loss: 0.008108599111437798\n",
      "Episode Reward: 19.0\n",
      "Step 599 (2499144) @ Episode 3790/10000, loss: 0.0125955939292907716\n",
      "Episode Reward: 8.0\n",
      "Step 855 (2499999) @ Episode 3791/10000, loss: 0.0045797512866556644\n",
      " Copied model parameters to target network\n",
      "Step 966 (2500110) @ Episode 3791/10000, loss: 0.0083510410040616997\n",
      "Episode Reward: 21.0\n",
      "Step 923 (2501033) @ Episode 3792/10000, loss: 0.0119236372411251075\n",
      "Episode Reward: 15.0\n",
      "Step 558 (2501591) @ Episode 3793/10000, loss: 0.0689248144626617425\n",
      "Episode Reward: 9.0\n",
      "Step 793 (2502384) @ Episode 3794/10000, loss: 0.0079293716698884963\n",
      "Episode Reward: 12.0\n",
      "Step 827 (2503211) @ Episode 3795/10000, loss: 0.0057960739359259605\n",
      "Episode Reward: 14.0\n",
      "Step 774 (2503985) @ Episode 3796/10000, loss: 0.0180682316422462466\n",
      "Episode Reward: 12.0\n",
      "Step 1663 (2505648) @ Episode 3797/10000, loss: 0.0039706528186798135\n",
      "Episode Reward: 44.0\n",
      "Step 777 (2506425) @ Episode 3798/10000, loss: 0.0063473731279373175\n",
      "Episode Reward: 13.0\n",
      "Step 961 (2507386) @ Episode 3799/10000, loss: 0.0067125568166375163\n",
      "Episode Reward: 21.0\n",
      "Step 789 (2508175) @ Episode 3800/10000, loss: 0.0045843753032386324\n",
      "Episode Reward: 12.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 23:04:32,288] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video003800.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 845 (2509020) @ Episode 3801/10000, loss: 0.0056404932402074345\n",
      "Episode Reward: 18.0\n",
      "Step 861 (2509881) @ Episode 3802/10000, loss: 0.0068033938296139246\n",
      "Episode Reward: 14.0\n",
      "Step 118 (2509999) @ Episode 3803/10000, loss: 0.0048647476360201836\n",
      " Copied model parameters to target network\n",
      "Step 973 (2510854) @ Episode 3803/10000, loss: 0.0056703700684010985\n",
      "Episode Reward: 21.0\n",
      "Step 1105 (2511959) @ Episode 3804/10000, loss: 0.0082243783399462785\n",
      "Episode Reward: 22.0\n",
      "Step 1317 (2513276) @ Episode 3805/10000, loss: 0.0025155090261250734\n",
      "Episode Reward: 26.0\n",
      "Step 1124 (2514400) @ Episode 3806/10000, loss: 0.0090188272297382355\n",
      "Episode Reward: 22.0\n",
      "Step 1126 (2515526) @ Episode 3807/10000, loss: 0.0295910220593214046\n",
      "Episode Reward: 19.0\n",
      "Step 1140 (2516666) @ Episode 3808/10000, loss: 0.0110694672912359247\n",
      "Episode Reward: 28.0\n",
      "Step 1023 (2517689) @ Episode 3809/10000, loss: 0.0034080811310559515\n",
      "Episode Reward: 20.0\n",
      "Step 446 (2518135) @ Episode 3810/10000, loss: 0.0054033193737268455\n",
      "Episode Reward: 6.0\n",
      "Step 959 (2519094) @ Episode 3811/10000, loss: 0.0063085351139307025\n",
      "Episode Reward: 18.0\n",
      "Step 544 (2519638) @ Episode 3812/10000, loss: 0.0066867009736597545\n",
      "Episode Reward: 8.0\n",
      "Step 361 (2519999) @ Episode 3813/10000, loss: 0.0225088000297546425\n",
      " Copied model parameters to target network\n",
      "Step 732 (2520370) @ Episode 3813/10000, loss: 0.0031975277233868837\n",
      "Episode Reward: 13.0\n",
      "Step 1113 (2521483) @ Episode 3814/10000, loss: 0.0123950559645891195\n",
      "Episode Reward: 22.0\n",
      "Step 979 (2522462) @ Episode 3815/10000, loss: 0.0075167175382375725\n",
      "Episode Reward: 21.0\n",
      "Step 918 (2523380) @ Episode 3816/10000, loss: 0.0110025983303785322\n",
      "Episode Reward: 15.0\n",
      "Step 795 (2524175) @ Episode 3817/10000, loss: 0.0082131912931799893\n",
      "Episode Reward: 12.0\n",
      "Step 954 (2525129) @ Episode 3818/10000, loss: 0.0059636943042278295\n",
      "Episode Reward: 23.0\n",
      "Step 1010 (2526139) @ Episode 3819/10000, loss: 0.0036777816712856293\n",
      "Episode Reward: 20.0\n",
      "Step 972 (2527111) @ Episode 3820/10000, loss: 0.0063496977090835574\n",
      "Episode Reward: 21.0\n",
      "Step 983 (2528094) @ Episode 3821/10000, loss: 0.0053156502544879914\n",
      "Episode Reward: 26.0\n",
      "Step 837 (2528931) @ Episode 3822/10000, loss: 0.0044001527130603795\n",
      "Episode Reward: 16.0\n",
      "Step 1068 (2529999) @ Episode 3823/10000, loss: 0.0074198972433805475\n",
      " Copied model parameters to target network\n",
      "Step 1148 (2530079) @ Episode 3823/10000, loss: 0.0022557079792022705\n",
      "Episode Reward: 30.0\n",
      "Step 640 (2530719) @ Episode 3824/10000, loss: 0.0038754029665142298\n",
      "Episode Reward: 13.0\n",
      "Step 1340 (2532059) @ Episode 3825/10000, loss: 0.0035406227689236403\n",
      "Episode Reward: 40.0\n",
      "Step 871 (2532930) @ Episode 3826/10000, loss: 0.0077469614334404474\n",
      "Episode Reward: 14.0\n",
      "Step 1040 (2533970) @ Episode 3827/10000, loss: 0.0048354286700487145\n",
      "Episode Reward: 23.0\n",
      "Step 1274 (2535244) @ Episode 3828/10000, loss: 0.0045520737767219544\n",
      "Episode Reward: 32.0\n",
      "Step 1035 (2536279) @ Episode 3829/10000, loss: 0.0076831229962408546\n",
      "Episode Reward: 21.0\n",
      "Step 761 (2537040) @ Episode 3830/10000, loss: 0.0044014016166329386\n",
      "Episode Reward: 12.0\n",
      "Step 959 (2537999) @ Episode 3831/10000, loss: 0.0092257494106888778\n",
      "Episode Reward: 17.0\n",
      "Step 585 (2538584) @ Episode 3832/10000, loss: 0.0037025040946900845\n",
      "Episode Reward: 8.0\n",
      "Step 1337 (2539921) @ Episode 3833/10000, loss: 0.0071624182164669044\n",
      "Episode Reward: 33.0\n",
      "Step 78 (2539999) @ Episode 3834/10000, loss: 0.0039311642758548263\n",
      " Copied model parameters to target network\n",
      "Step 1316 (2541237) @ Episode 3834/10000, loss: 0.0025115914177149534\n",
      "Episode Reward: 24.0\n",
      "Step 639 (2541876) @ Episode 3835/10000, loss: 0.0058859018608927736\n",
      "Episode Reward: 10.0\n",
      "Step 830 (2542706) @ Episode 3836/10000, loss: 0.0034885581117123365\n",
      "Episode Reward: 20.0\n",
      "Step 1242 (2543948) @ Episode 3837/10000, loss: 0.0025539204943925142\n",
      "Episode Reward: 24.0\n",
      "Step 976 (2544924) @ Episode 3838/10000, loss: 0.0048271175473928456\n",
      "Episode Reward: 20.0\n",
      "Step 799 (2545723) @ Episode 3839/10000, loss: 0.0052227838896214965\n",
      "Episode Reward: 16.0\n",
      "Step 1302 (2547025) @ Episode 3840/10000, loss: 0.0020125801675021657\n",
      "Episode Reward: 43.0\n",
      "Step 991 (2548016) @ Episode 3841/10000, loss: 0.0074809268116950997\n",
      "Episode Reward: 25.0\n",
      "Step 718 (2548734) @ Episode 3842/10000, loss: 0.0052270940504968175\n",
      "Episode Reward: 16.0\n",
      "Step 781 (2549515) @ Episode 3843/10000, loss: 0.0087715052068233495\n",
      "Episode Reward: 20.0\n",
      "Step 484 (2549999) @ Episode 3844/10000, loss: 0.0022485887166112662\n",
      " Copied model parameters to target network\n",
      "Step 1201 (2550716) @ Episode 3844/10000, loss: 0.0161355435848236155\n",
      "Episode Reward: 24.0\n",
      "Step 814 (2551530) @ Episode 3845/10000, loss: 0.0043434142135083675\n",
      "Episode Reward: 13.0\n",
      "Step 775 (2552305) @ Episode 3846/10000, loss: 0.0051649343222379684\n",
      "Episode Reward: 12.0\n",
      "Step 1346 (2553651) @ Episode 3847/10000, loss: 0.1551042795181274422\n",
      "Episode Reward: 25.0\n",
      "Step 999 (2554650) @ Episode 3848/10000, loss: 0.0043282853439450265\n",
      "Episode Reward: 18.0\n",
      "Step 761 (2555411) @ Episode 3849/10000, loss: 0.0044388961978256735\n",
      "Episode Reward: 11.0\n",
      "Step 929 (2556340) @ Episode 3850/10000, loss: 0.0080463932827115065\n",
      "Episode Reward: 17.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 23:11:48,607] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video003850.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1018 (2557358) @ Episode 3851/10000, loss: 0.0055718235671520237\n",
      "Episode Reward: 29.0\n",
      "Step 969 (2558327) @ Episode 3852/10000, loss: 0.0233659110963344573\n",
      "Episode Reward: 24.0\n",
      "Step 1199 (2559526) @ Episode 3853/10000, loss: 0.0421963632106781157\n",
      "Episode Reward: 26.0\n",
      "Step 473 (2559999) @ Episode 3854/10000, loss: 0.0028666029684245586\n",
      " Copied model parameters to target network\n",
      "Step 725 (2560251) @ Episode 3854/10000, loss: 0.0045820972882211213\n",
      "Episode Reward: 11.0\n",
      "Step 895 (2561146) @ Episode 3855/10000, loss: 0.0083382036536932913\n",
      "Episode Reward: 23.0\n",
      "Step 545 (2561691) @ Episode 3856/10000, loss: 0.0059192078188061716\n",
      "Episode Reward: 8.0\n",
      "Step 730 (2562421) @ Episode 3857/10000, loss: 0.0062800943851470955\n",
      "Episode Reward: 12.0\n",
      "Step 852 (2563273) @ Episode 3858/10000, loss: 0.0030073397792875767\n",
      "Episode Reward: 11.0\n",
      "Step 1206 (2564479) @ Episode 3859/10000, loss: 0.0150855826213955887\n",
      "Episode Reward: 17.0\n",
      "Step 1578 (2566057) @ Episode 3860/10000, loss: 0.0085098128765821463\n",
      "Episode Reward: 37.0\n",
      "Step 992 (2567049) @ Episode 3861/10000, loss: 0.0093452101573348054\n",
      "Episode Reward: 19.0\n",
      "Step 964 (2568013) @ Episode 3862/10000, loss: 0.0180113874375820163\n",
      "Episode Reward: 17.0\n",
      "Step 979 (2568992) @ Episode 3863/10000, loss: 0.0025962004438042647\n",
      "Episode Reward: 20.0\n",
      "Step 1007 (2569999) @ Episode 3864/10000, loss: 0.0023961360566318035\n",
      " Copied model parameters to target network\n",
      "Step 1013 (2570005) @ Episode 3864/10000, loss: 0.0036767716519534591\n",
      "Episode Reward: 18.0\n",
      "Step 916 (2570921) @ Episode 3865/10000, loss: 0.0051762983202934265\n",
      "Episode Reward: 23.0\n",
      "Step 1024 (2571945) @ Episode 3866/10000, loss: 0.0053621390834450725\n",
      "Episode Reward: 21.0\n",
      "Step 1465 (2573410) @ Episode 3867/10000, loss: 0.0040943883359432226\n",
      "Episode Reward: 39.0\n",
      "Step 787 (2574197) @ Episode 3868/10000, loss: 0.0159535128623247154\n",
      "Episode Reward: 14.0\n",
      "Step 1155 (2575352) @ Episode 3869/10000, loss: 0.0050393044948577887\n",
      "Episode Reward: 35.0\n",
      "Step 1067 (2576419) @ Episode 3870/10000, loss: 0.0028550694696605206\n",
      "Episode Reward: 19.0\n",
      "Step 1126 (2577545) @ Episode 3871/10000, loss: 0.0083251129835844044\n",
      "Episode Reward: 20.0\n",
      "Step 1082 (2578627) @ Episode 3872/10000, loss: 0.0173261277377605443\n",
      "Episode Reward: 17.0\n",
      "Step 837 (2579464) @ Episode 3873/10000, loss: 0.0828263163566589487\n",
      "Episode Reward: 16.0\n",
      "Step 535 (2579999) @ Episode 3874/10000, loss: 0.0073670055717229845\n",
      " Copied model parameters to target network\n",
      "Step 1004 (2580468) @ Episode 3874/10000, loss: 0.004715456627309322\n",
      "Episode Reward: 18.0\n",
      "Step 525 (2580993) @ Episode 3875/10000, loss: 0.0059692054055631162\n",
      "Episode Reward: 7.0\n",
      "Step 912 (2581905) @ Episode 3876/10000, loss: 0.0082616414874792133\n",
      "Episode Reward: 16.0\n",
      "Step 1057 (2582962) @ Episode 3877/10000, loss: 0.0061495043337345122\n",
      "Episode Reward: 24.0\n",
      "Step 934 (2583896) @ Episode 3878/10000, loss: 0.0102586057037115135\n",
      "Episode Reward: 19.0\n",
      "Step 962 (2584858) @ Episode 3879/10000, loss: 0.0103252157568931583\n",
      "Episode Reward: 21.0\n",
      "Step 836 (2585694) @ Episode 3880/10000, loss: 0.0190585106611251836\n",
      "Episode Reward: 14.0\n",
      "Step 542 (2586236) @ Episode 3881/10000, loss: 0.0084817940369248395\n",
      "Episode Reward: 6.0\n",
      "Step 966 (2587202) @ Episode 3882/10000, loss: 0.0097097922116518027\n",
      "Episode Reward: 12.0\n",
      "Step 813 (2588015) @ Episode 3883/10000, loss: 0.0032235935796052217\n",
      "Episode Reward: 12.0\n",
      "Step 1019 (2589034) @ Episode 3884/10000, loss: 0.0089000714942812927\n",
      "Episode Reward: 21.0\n",
      "Step 825 (2589859) @ Episode 3885/10000, loss: 0.0049746981821954258\n",
      "Episode Reward: 14.0\n",
      "Step 140 (2589999) @ Episode 3886/10000, loss: 0.0118146967142820366\n",
      " Copied model parameters to target network\n",
      "Step 910 (2590769) @ Episode 3886/10000, loss: 0.0052687805145978936\n",
      "Episode Reward: 16.0\n",
      "Step 863 (2591632) @ Episode 3887/10000, loss: 0.0060711996629834175\n",
      "Episode Reward: 21.0\n",
      "Step 1002 (2592634) @ Episode 3888/10000, loss: 0.002286411589011552\n",
      "Episode Reward: 25.0\n",
      "Step 1480 (2594114) @ Episode 3889/10000, loss: 0.0183362588286399846\n",
      "Episode Reward: 27.0\n",
      "Step 811 (2594925) @ Episode 3890/10000, loss: 0.0055030826479196556\n",
      "Episode Reward: 11.0\n",
      "Step 800 (2595725) @ Episode 3891/10000, loss: 0.0049263606779277325\n",
      "Episode Reward: 13.0\n",
      "Step 924 (2596649) @ Episode 3892/10000, loss: 0.0043282127007842065\n",
      "Episode Reward: 15.0\n",
      "Step 912 (2597561) @ Episode 3893/10000, loss: 0.0079169953241944315\n",
      "Episode Reward: 16.0\n",
      "Step 781 (2598342) @ Episode 3894/10000, loss: 0.0028062397614121437\n",
      "Episode Reward: 13.0\n",
      "Step 819 (2599161) @ Episode 3895/10000, loss: 0.0053700264543294912\n",
      "Episode Reward: 16.0\n",
      "Step 838 (2599999) @ Episode 3896/10000, loss: 0.0049401735886931426\n",
      " Copied model parameters to target network\n",
      "Step 877 (2600038) @ Episode 3896/10000, loss: 0.0051970165222883224\n",
      "Episode Reward: 17.0\n",
      "Step 1296 (2601334) @ Episode 3897/10000, loss: 0.0027554435655474663\n",
      "Episode Reward: 30.0\n",
      "Step 643 (2601977) @ Episode 3898/10000, loss: 0.0110268630087375647\n",
      "Episode Reward: 13.0\n",
      "Step 576 (2602553) @ Episode 3899/10000, loss: 0.0716096609830856325\n",
      "Episode Reward: 9.0\n",
      "Step 803 (2603356) @ Episode 3900/10000, loss: 0.0050263078883290296\n",
      "Episode Reward: 21.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 23:18:57,233] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video003900.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1352 (2604708) @ Episode 3901/10000, loss: 0.0079751303419470795\n",
      "Episode Reward: 33.0\n",
      "Step 1035 (2605743) @ Episode 3902/10000, loss: 0.0020810174755752087\n",
      "Episode Reward: 24.0\n",
      "Step 1230 (2606973) @ Episode 3903/10000, loss: 0.0057910326868295676\n",
      "Episode Reward: 31.0\n",
      "Step 1689 (2608662) @ Episode 3904/10000, loss: 0.0754794627428054814\n",
      "Episode Reward: 47.0\n",
      "Step 773 (2609435) @ Episode 3905/10000, loss: 0.0163189768791198736\n",
      "Episode Reward: 17.0\n",
      "Step 564 (2609999) @ Episode 3906/10000, loss: 0.0028109543491154913\n",
      " Copied model parameters to target network\n",
      "Step 977 (2610412) @ Episode 3906/10000, loss: 0.0124367196112871173\n",
      "Episode Reward: 19.0\n",
      "Step 1111 (2611523) @ Episode 3907/10000, loss: 0.0082467384636402134\n",
      "Episode Reward: 22.0\n",
      "Step 747 (2612270) @ Episode 3908/10000, loss: 0.0051909266039729124\n",
      "Episode Reward: 19.0\n",
      "Step 592 (2612862) @ Episode 3909/10000, loss: 0.0080769546329975137\n",
      "Episode Reward: 10.0\n",
      "Step 1004 (2613866) @ Episode 3910/10000, loss: 0.0092839645221829415\n",
      "Episode Reward: 11.0\n",
      "Step 780 (2614646) @ Episode 3911/10000, loss: 0.0086272247135639195\n",
      "Episode Reward: 11.0\n",
      "Step 1087 (2615733) @ Episode 3912/10000, loss: 0.0057962965220212945\n",
      "Episode Reward: 18.0\n",
      "Step 1042 (2616775) @ Episode 3913/10000, loss: 0.0158857107162475617\n",
      "Episode Reward: 17.0\n",
      "Step 1576 (2618351) @ Episode 3914/10000, loss: 0.0060187019407749183\n",
      "Episode Reward: 33.0\n",
      "Step 983 (2619334) @ Episode 3915/10000, loss: 0.0021337172947824063\n",
      "Episode Reward: 17.0\n",
      "Step 665 (2619999) @ Episode 3916/10000, loss: 0.0035853800363838673\n",
      " Copied model parameters to target network\n",
      "Step 795 (2620129) @ Episode 3916/10000, loss: 0.0589280351996421866\n",
      "Episode Reward: 12.0\n",
      "Step 735 (2620864) @ Episode 3917/10000, loss: 0.0096387295052409175\n",
      "Episode Reward: 13.0\n",
      "Step 810 (2621674) @ Episode 3918/10000, loss: 0.0056142243556678295\n",
      "Episode Reward: 14.0\n",
      "Step 1467 (2623141) @ Episode 3919/10000, loss: 0.0268609914928674763\n",
      "Episode Reward: 28.0\n",
      "Step 911 (2624052) @ Episode 3920/10000, loss: 0.0129932370036840447\n",
      "Episode Reward: 25.0\n",
      "Step 949 (2625001) @ Episode 3921/10000, loss: 0.0097361579537391666\n",
      "Episode Reward: 16.0\n",
      "Step 898 (2625899) @ Episode 3922/10000, loss: 0.0034256929066032175\n",
      "Episode Reward: 17.0\n",
      "Step 722 (2626621) @ Episode 3923/10000, loss: 0.0065675424411892895\n",
      "Episode Reward: 19.0\n",
      "Step 969 (2627590) @ Episode 3924/10000, loss: 0.0049287504516541964\n",
      "Episode Reward: 15.0\n",
      "Step 1115 (2628705) @ Episode 3925/10000, loss: 0.0033288737758994102\n",
      "Episode Reward: 22.0\n",
      "Step 835 (2629540) @ Episode 3926/10000, loss: 0.0028689331375062466\n",
      "Episode Reward: 15.0\n",
      "Step 459 (2629999) @ Episode 3927/10000, loss: 0.0053532463498413566\n",
      " Copied model parameters to target network\n",
      "Step 1060 (2630600) @ Episode 3927/10000, loss: 0.0028281300328671932\n",
      "Episode Reward: 16.0\n",
      "Step 649 (2631249) @ Episode 3928/10000, loss: 0.0032664125319570303\n",
      "Episode Reward: 10.0\n",
      "Step 774 (2632023) @ Episode 3929/10000, loss: 0.0040497030131518845\n",
      "Episode Reward: 14.0\n",
      "Step 654 (2632677) @ Episode 3930/10000, loss: 0.0040079560130834586\n",
      "Episode Reward: 10.0\n",
      "Step 973 (2633650) @ Episode 3931/10000, loss: 0.0215387195348739627\n",
      "Episode Reward: 16.0\n",
      "Step 525 (2634175) @ Episode 3932/10000, loss: 0.0028933216817677025\n",
      "Episode Reward: 8.0\n",
      "Step 845 (2635020) @ Episode 3933/10000, loss: 0.0034741954877972603\n",
      "Episode Reward: 13.0\n",
      "Step 1003 (2636023) @ Episode 3934/10000, loss: 0.0086241457611322415\n",
      "Episode Reward: 17.0\n",
      "Step 1294 (2637317) @ Episode 3935/10000, loss: 0.0051726098172366622\n",
      "Episode Reward: 42.0\n",
      "Step 654 (2637971) @ Episode 3936/10000, loss: 0.0608172304928302765\n",
      "Episode Reward: 9.0\n",
      "Step 1007 (2638978) @ Episode 3937/10000, loss: 0.0051349028944969186\n",
      "Episode Reward: 17.0\n",
      "Step 1021 (2639999) @ Episode 3938/10000, loss: 0.0064379340037703516\n",
      " Copied model parameters to target network\n",
      "Step 1481 (2640459) @ Episode 3938/10000, loss: 0.0085936784744262734\n",
      "Episode Reward: 29.0\n",
      "Step 820 (2641279) @ Episode 3939/10000, loss: 0.0207220055162906655\n",
      "Episode Reward: 16.0\n",
      "Step 739 (2642018) @ Episode 3940/10000, loss: 0.0123535608872771268\n",
      "Episode Reward: 12.0\n",
      "Step 664 (2642682) @ Episode 3941/10000, loss: 0.0047094188630580969\n",
      "Episode Reward: 11.0\n",
      "Step 1403 (2644085) @ Episode 3942/10000, loss: 0.0094771366566419615\n",
      "Episode Reward: 29.0\n",
      "Step 1522 (2645607) @ Episode 3943/10000, loss: 0.0448171384632587495\n",
      "Episode Reward: 35.0\n",
      "Step 1310 (2646917) @ Episode 3944/10000, loss: 0.0145194754004478454\n",
      "Episode Reward: 29.0\n",
      "Step 1343 (2648260) @ Episode 3945/10000, loss: 0.0038059221114963293\n",
      "Episode Reward: 26.0\n",
      "Step 809 (2649069) @ Episode 3946/10000, loss: 0.0072617554105818275\n",
      "Episode Reward: 18.0\n",
      "Step 728 (2649797) @ Episode 3947/10000, loss: 0.0054187001660466194\n",
      "Episode Reward: 12.0\n",
      "Step 202 (2649999) @ Episode 3948/10000, loss: 0.0078982012346386916\n",
      " Copied model parameters to target network\n",
      "Step 971 (2650768) @ Episode 3948/10000, loss: 0.0074069444090127945\n",
      "Episode Reward: 16.0\n",
      "Step 801 (2651569) @ Episode 3949/10000, loss: 0.0040602297522127635\n",
      "Episode Reward: 18.0\n",
      "Step 851 (2652420) @ Episode 3950/10000, loss: 0.0027444704901427034\n",
      "Episode Reward: 13.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 23:26:23,967] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video003950.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 936 (2653356) @ Episode 3951/10000, loss: 0.0047600725665688515\n",
      "Episode Reward: 16.0\n",
      "Step 1133 (2654489) @ Episode 3952/10000, loss: 0.0059916656464338375\n",
      "Episode Reward: 29.0\n",
      "Step 1157 (2655646) @ Episode 3953/10000, loss: 0.0041461884975433357\n",
      "Episode Reward: 30.0\n",
      "Step 1276 (2656922) @ Episode 3954/10000, loss: 0.0039778500795364385\n",
      "Episode Reward: 29.0\n",
      "Step 1222 (2658144) @ Episode 3955/10000, loss: 0.0065138922072947025\n",
      "Episode Reward: 18.0\n",
      "Step 711 (2658855) @ Episode 3956/10000, loss: 0.0066333203576505187\n",
      "Episode Reward: 14.0\n",
      "Step 938 (2659793) @ Episode 3957/10000, loss: 0.0085784466937184336\n",
      "Episode Reward: 15.0\n",
      "Step 206 (2659999) @ Episode 3958/10000, loss: 0.0049524749629199505\n",
      " Copied model parameters to target network\n",
      "Step 843 (2660636) @ Episode 3958/10000, loss: 0.0096740871667861945\n",
      "Episode Reward: 14.0\n",
      "Step 690 (2661326) @ Episode 3959/10000, loss: 0.0074196169152855878\n",
      "Episode Reward: 13.0\n",
      "Step 868 (2662194) @ Episode 3960/10000, loss: 0.0044904039241373544\n",
      "Episode Reward: 17.0\n",
      "Step 743 (2662937) @ Episode 3961/10000, loss: 0.0167034044861793525\n",
      "Episode Reward: 12.0\n",
      "Step 925 (2663862) @ Episode 3962/10000, loss: 0.0063009783625602725\n",
      "Episode Reward: 13.0\n",
      "Step 814 (2664676) @ Episode 3963/10000, loss: 0.0057172700762748725\n",
      "Episode Reward: 13.0\n",
      "Step 979 (2665655) @ Episode 3964/10000, loss: 0.0051822438836097725\n",
      "Episode Reward: 35.0\n",
      "Step 1196 (2666851) @ Episode 3965/10000, loss: 0.0055420640856027664\n",
      "Episode Reward: 29.0\n",
      "Step 1100 (2667951) @ Episode 3966/10000, loss: 0.0034823655150830746\n",
      "Episode Reward: 24.0\n",
      "Step 579 (2668530) @ Episode 3967/10000, loss: 0.0061269141733646392\n",
      "Episode Reward: 16.0\n",
      "Step 1085 (2669615) @ Episode 3968/10000, loss: 0.0162358768284320834\n",
      "Episode Reward: 29.0\n",
      "Step 384 (2669999) @ Episode 3969/10000, loss: 0.0038240230642259125\n",
      " Copied model parameters to target network\n",
      "Step 1243 (2670858) @ Episode 3969/10000, loss: 0.0150070041418075565\n",
      "Episode Reward: 28.0\n",
      "Step 1033 (2671891) @ Episode 3970/10000, loss: 0.0061883088201284413\n",
      "Episode Reward: 17.0\n",
      "Step 1194 (2673085) @ Episode 3971/10000, loss: 0.0098128914833068855\n",
      "Episode Reward: 24.0\n",
      "Step 1357 (2674442) @ Episode 3972/10000, loss: 0.0025250536855310276\n",
      "Episode Reward: 38.0\n",
      "Step 919 (2675361) @ Episode 3973/10000, loss: 0.0164061151444911965\n",
      "Episode Reward: 19.0\n",
      "Step 800 (2676161) @ Episode 3974/10000, loss: 0.0061402977444231515\n",
      "Episode Reward: 17.0\n",
      "Step 1251 (2677412) @ Episode 3975/10000, loss: 0.0082021513953804975\n",
      "Episode Reward: 25.0\n",
      "Step 861 (2678273) @ Episode 3976/10000, loss: 0.0077254469506442554\n",
      "Episode Reward: 14.0\n",
      "Step 1026 (2679299) @ Episode 3977/10000, loss: 0.0064761992543935786\n",
      "Episode Reward: 23.0\n",
      "Step 700 (2679999) @ Episode 3978/10000, loss: 0.0072870408184826373\n",
      " Copied model parameters to target network\n",
      "Step 1344 (2680643) @ Episode 3978/10000, loss: 0.0445373021066188882\n",
      "Episode Reward: 28.0\n",
      "Step 1365 (2682008) @ Episode 3979/10000, loss: 0.0077060721814632425\n",
      "Episode Reward: 34.0\n",
      "Step 969 (2682977) @ Episode 3980/10000, loss: 0.0074776774272322655\n",
      "Episode Reward: 16.0\n",
      "Step 1676 (2684653) @ Episode 3981/10000, loss: 0.0062160370871424675\n",
      "Episode Reward: 44.0\n",
      "Step 769 (2685422) @ Episode 3982/10000, loss: 0.0073581617325544366\n",
      "Episode Reward: 14.0\n",
      "Step 961 (2686383) @ Episode 3983/10000, loss: 0.0082783810794353496\n",
      "Episode Reward: 16.0\n",
      "Step 1115 (2687498) @ Episode 3984/10000, loss: 0.0053839031606912612\n",
      "Episode Reward: 22.0\n",
      "Step 1245 (2688743) @ Episode 3985/10000, loss: 0.0059030512347817427\n",
      "Episode Reward: 24.0\n",
      "Step 973 (2689716) @ Episode 3986/10000, loss: 0.0079339221119880685\n",
      "Episode Reward: 14.0\n",
      "Step 283 (2689999) @ Episode 3987/10000, loss: 0.0060457894578576095\n",
      " Copied model parameters to target network\n",
      "Step 926 (2690642) @ Episode 3987/10000, loss: 0.0036238045431673527\n",
      "Episode Reward: 17.0\n",
      "Step 1004 (2691646) @ Episode 3988/10000, loss: 0.0073696556501090534\n",
      "Episode Reward: 20.0\n",
      "Step 1018 (2692664) @ Episode 3989/10000, loss: 0.0035559877287596464\n",
      "Episode Reward: 26.0\n",
      "Step 801 (2693465) @ Episode 3990/10000, loss: 0.0166328996419906625\n",
      "Episode Reward: 12.0\n",
      "Step 739 (2694204) @ Episode 3991/10000, loss: 0.0041969483718276023\n",
      "Episode Reward: 9.0\n",
      "Step 1224 (2695428) @ Episode 3992/10000, loss: 0.0077155227772891525\n",
      "Episode Reward: 18.0\n",
      "Step 959 (2696387) @ Episode 3993/10000, loss: 0.0071642268449068076\n",
      "Episode Reward: 16.0\n",
      "Step 1089 (2697476) @ Episode 3994/10000, loss: 0.0189026538282632836\n",
      "Episode Reward: 20.0\n",
      "Step 1312 (2698788) @ Episode 3995/10000, loss: 0.0093692895025014885\n",
      "Episode Reward: 35.0\n",
      "Step 1211 (2699999) @ Episode 3996/10000, loss: 0.0049210507422685627\n",
      " Copied model parameters to target network\n",
      "Step 1368 (2700156) @ Episode 3996/10000, loss: 0.0025141905061900616\n",
      "Episode Reward: 30.0\n",
      "Step 1429 (2701585) @ Episode 3997/10000, loss: 0.0056082429364323625\n",
      "Episode Reward: 33.0\n",
      "Step 986 (2702571) @ Episode 3998/10000, loss: 0.0056056110188364985\n",
      "Episode Reward: 20.0\n",
      "Step 1020 (2703591) @ Episode 3999/10000, loss: 0.0174920000135898626\n",
      "Episode Reward: 18.0\n",
      "Step 848 (2704439) @ Episode 4000/10000, loss: 0.0022848146036267283\n",
      "Episode Reward: 17.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 23:34:13,690] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video004000.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 713 (2705152) @ Episode 4001/10000, loss: 0.0119478106498718265\n",
      "Episode Reward: 15.0\n",
      "Step 765 (2705917) @ Episode 4002/10000, loss: 0.0128281544893980033\n",
      "Episode Reward: 14.0\n",
      "Step 770 (2706687) @ Episode 4003/10000, loss: 0.0229922924190759665\n",
      "Episode Reward: 15.0\n",
      "Step 1284 (2707971) @ Episode 4004/10000, loss: 0.0075572468340396886\n",
      "Episode Reward: 25.0\n",
      "Step 1317 (2709288) @ Episode 4005/10000, loss: 0.0075698643922805793\n",
      "Episode Reward: 26.0\n",
      "Step 711 (2709999) @ Episode 4006/10000, loss: 0.0253122970461845486\n",
      " Copied model parameters to target network\n",
      "Step 728 (2710016) @ Episode 4006/10000, loss: 0.0029948907904326916\n",
      "Episode Reward: 12.0\n",
      "Step 1011 (2711027) @ Episode 4007/10000, loss: 0.0093925446271896362\n",
      "Episode Reward: 20.0\n",
      "Step 1125 (2712152) @ Episode 4008/10000, loss: 0.0039376378990709785\n",
      "Episode Reward: 29.0\n",
      "Step 992 (2713144) @ Episode 4009/10000, loss: 0.0211144350469112493\n",
      "Episode Reward: 14.0\n",
      "Step 753 (2713897) @ Episode 4010/10000, loss: 0.0049317963421344766\n",
      "Episode Reward: 15.0\n",
      "Step 894 (2714791) @ Episode 4011/10000, loss: 0.0323971696197986635\n",
      "Episode Reward: 16.0\n",
      "Step 1479 (2716270) @ Episode 4012/10000, loss: 0.0036783087998628616\n",
      "Episode Reward: 30.0\n",
      "Step 873 (2717143) @ Episode 4013/10000, loss: 0.0485347695648670285\n",
      "Episode Reward: 27.0\n",
      "Step 666 (2717809) @ Episode 4014/10000, loss: 0.0026643543969839813\n",
      "Episode Reward: 7.0\n",
      "Step 1236 (2719045) @ Episode 4015/10000, loss: 0.0080469110980629926\n",
      "Episode Reward: 21.0\n",
      "Step 562 (2719607) @ Episode 4016/10000, loss: 0.0055125262588262565\n",
      "Episode Reward: 12.0\n",
      "Step 392 (2719999) @ Episode 4017/10000, loss: 0.0698794275522232645\n",
      " Copied model parameters to target network\n",
      "Step 817 (2720424) @ Episode 4017/10000, loss: 0.0072578596882522115\n",
      "Episode Reward: 17.0\n",
      "Step 820 (2721244) @ Episode 4018/10000, loss: 0.0066206641495227815\n",
      "Episode Reward: 19.0\n",
      "Step 510 (2721754) @ Episode 4019/10000, loss: 0.0040863426402211194\n",
      "Episode Reward: 8.0\n",
      "Step 670 (2722424) @ Episode 4020/10000, loss: 0.0079652154818177225\n",
      "Episode Reward: 16.0\n",
      "Step 619 (2723043) @ Episode 4021/10000, loss: 0.0071342280134558686\n",
      "Episode Reward: 8.0\n",
      "Step 739 (2723782) @ Episode 4022/10000, loss: 0.0024114667903631926\n",
      "Episode Reward: 13.0\n",
      "Step 679 (2724461) @ Episode 4023/10000, loss: 0.0067166909575462343\n",
      "Episode Reward: 9.0\n",
      "Step 704 (2725165) @ Episode 4024/10000, loss: 0.0861550942063331624\n",
      "Episode Reward: 15.0\n",
      "Step 862 (2726027) @ Episode 4025/10000, loss: 0.0118433125317096714\n",
      "Episode Reward: 12.0\n",
      "Step 1121 (2727148) @ Episode 4026/10000, loss: 0.0068016448058187963\n",
      "Episode Reward: 18.0\n",
      "Step 652 (2727800) @ Episode 4027/10000, loss: 0.0150683000683784486\n",
      "Episode Reward: 9.0\n",
      "Step 645 (2728445) @ Episode 4028/10000, loss: 0.0550169348716735845\n",
      "Episode Reward: 9.0\n",
      "Step 993 (2729438) @ Episode 4029/10000, loss: 0.0034629320725798607\n",
      "Episode Reward: 20.0\n",
      "Step 561 (2729999) @ Episode 4030/10000, loss: 0.1538930386304855335\n",
      " Copied model parameters to target network\n",
      "Step 825 (2730263) @ Episode 4030/10000, loss: 0.0084889195859432222\n",
      "Episode Reward: 15.0\n",
      "Step 772 (2731035) @ Episode 4031/10000, loss: 0.0071206158027052883\n",
      "Episode Reward: 18.0\n",
      "Step 1152 (2732187) @ Episode 4032/10000, loss: 0.0076497644186019976\n",
      "Episode Reward: 26.0\n",
      "Step 599 (2732786) @ Episode 4033/10000, loss: 0.0027524195611476986\n",
      "Episode Reward: 9.0\n",
      "Step 797 (2733583) @ Episode 4034/10000, loss: 0.0067298114299774175\n",
      "Episode Reward: 15.0\n",
      "Step 724 (2734307) @ Episode 4035/10000, loss: 0.0055579338222742085\n",
      "Episode Reward: 12.0\n",
      "Step 978 (2735285) @ Episode 4036/10000, loss: 0.0062885507941246035\n",
      "Episode Reward: 22.0\n",
      "Step 1010 (2736295) @ Episode 4037/10000, loss: 0.0051213800907135016\n",
      "Episode Reward: 23.0\n",
      "Step 632 (2736927) @ Episode 4038/10000, loss: 0.0075821038335561755\n",
      "Episode Reward: 9.0\n",
      "Step 711 (2737638) @ Episode 4039/10000, loss: 0.0022472897544503218\n",
      "Episode Reward: 12.0\n",
      "Step 674 (2738312) @ Episode 4040/10000, loss: 0.0116992034018039733\n",
      "Episode Reward: 15.0\n",
      "Step 845 (2739157) @ Episode 4041/10000, loss: 0.0076240869238972664\n",
      "Episode Reward: 12.0\n",
      "Step 842 (2739999) @ Episode 4042/10000, loss: 0.0070029124617576625\n",
      " Copied model parameters to target network\n",
      "Step 894 (2740051) @ Episode 4042/10000, loss: 0.0031332192011177546\n",
      "Episode Reward: 15.0\n",
      "Step 1228 (2741279) @ Episode 4043/10000, loss: 0.0051776589825749435\n",
      "Episode Reward: 27.0\n",
      "Step 926 (2742205) @ Episode 4044/10000, loss: 0.0104176141321659093\n",
      "Episode Reward: 21.0\n",
      "Step 632 (2742837) @ Episode 4045/10000, loss: 0.0066991727799177176\n",
      "Episode Reward: 9.0\n",
      "Step 821 (2743658) @ Episode 4046/10000, loss: 0.0055201216600835328\n",
      "Episode Reward: 13.0\n",
      "Step 1053 (2744711) @ Episode 4047/10000, loss: 0.0055300579406321057\n",
      "Episode Reward: 25.0\n",
      "Step 853 (2745564) @ Episode 4048/10000, loss: 0.0026936703361570835\n",
      "Episode Reward: 14.0\n",
      "Step 1006 (2746570) @ Episode 4049/10000, loss: 0.0057095196098089227\n",
      "Episode Reward: 18.0\n",
      "Step 884 (2747454) @ Episode 4050/10000, loss: 0.0072731771506369112\n",
      "Episode Reward: 16.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 23:40:46,113] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video004050.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 676 (2748130) @ Episode 4051/10000, loss: 0.0028472696430981165\n",
      "Episode Reward: 11.0\n",
      "Step 961 (2749091) @ Episode 4052/10000, loss: 0.0070286481641232976\n",
      "Episode Reward: 19.0\n",
      "Step 852 (2749943) @ Episode 4053/10000, loss: 0.0049339169636368754\n",
      "Episode Reward: 14.0\n",
      "Step 56 (2749999) @ Episode 4054/10000, loss: 0.0195538457483053248\n",
      " Copied model parameters to target network\n",
      "Step 1059 (2751002) @ Episode 4054/10000, loss: 0.0047551658935844905\n",
      "Episode Reward: 21.0\n",
      "Step 998 (2752000) @ Episode 4055/10000, loss: 0.0056117251515388497\n",
      "Episode Reward: 18.0\n",
      "Step 562 (2752562) @ Episode 4056/10000, loss: 0.0113815851509571085\n",
      "Episode Reward: 9.0\n",
      "Step 1334 (2753896) @ Episode 4057/10000, loss: 0.0047502936795353896\n",
      "Episode Reward: 33.0\n",
      "Step 818 (2754714) @ Episode 4058/10000, loss: 0.0096859242767095577\n",
      "Episode Reward: 13.0\n",
      "Step 942 (2755656) @ Episode 4059/10000, loss: 0.0086049120873212815\n",
      "Episode Reward: 19.0\n",
      "Step 1207 (2756863) @ Episode 4060/10000, loss: 0.0081306742504239085\n",
      "Episode Reward: 25.0\n",
      "Step 600 (2757463) @ Episode 4061/10000, loss: 0.0086423968896269854\n",
      "Episode Reward: 8.0\n",
      "Step 777 (2758240) @ Episode 4062/10000, loss: 0.0048516592942178252\n",
      "Episode Reward: 13.0\n",
      "Step 1229 (2759469) @ Episode 4063/10000, loss: 0.0018512654351070523\n",
      "Episode Reward: 24.0\n",
      "Step 530 (2759999) @ Episode 4064/10000, loss: 0.0119573986157774936\n",
      " Copied model parameters to target network\n",
      "Step 835 (2760304) @ Episode 4064/10000, loss: 0.0146104320883750926\n",
      "Episode Reward: 15.0\n",
      "Step 1098 (2761402) @ Episode 4065/10000, loss: 0.0054243318736553196\n",
      "Episode Reward: 22.0\n",
      "Step 1133 (2762535) @ Episode 4066/10000, loss: 0.0090657146647572527\n",
      "Episode Reward: 20.0\n",
      "Step 993 (2763528) @ Episode 4067/10000, loss: 0.0047641908749938016\n",
      "Episode Reward: 18.0\n",
      "Step 1015 (2764543) @ Episode 4068/10000, loss: 0.0187274701893329623\n",
      "Episode Reward: 25.0\n",
      "Step 753 (2765296) @ Episode 4069/10000, loss: 0.0069196154363453395\n",
      "Episode Reward: 12.0\n",
      "Step 610 (2765906) @ Episode 4070/10000, loss: 0.0026242693420499563\n",
      "Episode Reward: 8.0\n",
      "Step 679 (2766585) @ Episode 4071/10000, loss: 0.0053171520121395593\n",
      "Episode Reward: 11.0\n",
      "Step 1066 (2767651) @ Episode 4072/10000, loss: 0.0222548060119152075\n",
      "Episode Reward: 25.0\n",
      "Step 895 (2768546) @ Episode 4073/10000, loss: 0.0079017281532287658\n",
      "Episode Reward: 19.0\n",
      "Step 955 (2769501) @ Episode 4074/10000, loss: 0.0063182371668517597\n",
      "Episode Reward: 26.0\n",
      "Step 498 (2769999) @ Episode 4075/10000, loss: 0.0065213665366172795\n",
      " Copied model parameters to target network\n",
      "Step 629 (2770130) @ Episode 4075/10000, loss: 0.0031027165241539486\n",
      "Episode Reward: 10.0\n",
      "Step 949 (2771079) @ Episode 4076/10000, loss: 0.0070227137766778475\n",
      "Episode Reward: 24.0\n",
      "Step 1272 (2772351) @ Episode 4077/10000, loss: 0.0070143654011189948\n",
      "Episode Reward: 26.0\n",
      "Step 614 (2772965) @ Episode 4078/10000, loss: 0.0046713496558368216\n",
      "Episode Reward: 10.0\n",
      "Step 845 (2773810) @ Episode 4079/10000, loss: 0.0017220430308952928\n",
      "Episode Reward: 16.0\n",
      "Step 1034 (2774844) @ Episode 4080/10000, loss: 0.0198596417903900155\n",
      "Episode Reward: 21.0\n",
      "Step 1079 (2775923) @ Episode 4081/10000, loss: 0.0086753219366073645\n",
      "Episode Reward: 26.0\n",
      "Step 965 (2776888) @ Episode 4082/10000, loss: 0.0069641713052988056\n",
      "Episode Reward: 17.0\n",
      "Step 1327 (2778215) @ Episode 4083/10000, loss: 0.0057127880863845354\n",
      "Episode Reward: 41.0\n",
      "Step 1193 (2779408) @ Episode 4084/10000, loss: 0.0073534050025045875\n",
      "Episode Reward: 21.0\n",
      "Step 591 (2779999) @ Episode 4085/10000, loss: 0.0029922886751592164\n",
      " Copied model parameters to target network\n",
      "Step 1116 (2780524) @ Episode 4085/10000, loss: 0.0018824439030140638\n",
      "Episode Reward: 26.0\n",
      "Step 641 (2781165) @ Episode 4086/10000, loss: 0.0082187410444021227\n",
      "Episode Reward: 17.0\n",
      "Step 1070 (2782235) @ Episode 4087/10000, loss: 0.0031954376026988033\n",
      "Episode Reward: 22.0\n",
      "Step 764 (2782999) @ Episode 4088/10000, loss: 0.0028299980331212282\n",
      "Episode Reward: 17.0\n",
      "Step 1463 (2784462) @ Episode 4089/10000, loss: 0.0049456134438514715\n",
      "Episode Reward: 36.0\n",
      "Step 823 (2785285) @ Episode 4090/10000, loss: 0.0065973903983831406\n",
      "Episode Reward: 10.0\n",
      "Step 920 (2786205) @ Episode 4091/10000, loss: 0.0027795699425041676\n",
      "Episode Reward: 17.0\n",
      "Step 622 (2786827) @ Episode 4092/10000, loss: 0.0030775479972362525\n",
      "Episode Reward: 9.0\n",
      "Step 1265 (2788092) @ Episode 4093/10000, loss: 0.0057485005818307454\n",
      "Episode Reward: 27.0\n",
      "Step 917 (2789009) @ Episode 4094/10000, loss: 0.0054338062182068825\n",
      "Episode Reward: 13.0\n",
      "Step 990 (2789999) @ Episode 4095/10000, loss: 0.0062334463000297555\n",
      " Copied model parameters to target network\n",
      "Step 1300 (2790309) @ Episode 4095/10000, loss: 0.0061199311167001725\n",
      "Episode Reward: 24.0\n",
      "Step 1190 (2791499) @ Episode 4096/10000, loss: 0.0044399295002222066\n",
      "Episode Reward: 28.0\n",
      "Step 1032 (2792531) @ Episode 4097/10000, loss: 0.0047446051612496382\n",
      "Episode Reward: 20.0\n",
      "Step 1373 (2793904) @ Episode 4098/10000, loss: 0.0045253681018948555\n",
      "Episode Reward: 35.0\n",
      "Step 773 (2794677) @ Episode 4099/10000, loss: 0.0052031339146196845\n",
      "Episode Reward: 14.0\n",
      "Step 1446 (2796123) @ Episode 4100/10000, loss: 0.0181308239698410036\n",
      "Episode Reward: 28.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 23:48:06,609] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video004100.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 912 (2797035) @ Episode 4101/10000, loss: 0.0106944208964705475\n",
      "Episode Reward: 18.0\n",
      "Step 747 (2797782) @ Episode 4102/10000, loss: 0.0072958124801516535\n",
      "Episode Reward: 18.0\n",
      "Step 697 (2798479) @ Episode 4103/10000, loss: 0.0054861176759004596\n",
      "Episode Reward: 14.0\n",
      "Step 683 (2799162) @ Episode 4104/10000, loss: 0.0038774483837187296\n",
      "Episode Reward: 14.0\n",
      "Step 837 (2799999) @ Episode 4105/10000, loss: 0.0046816682443022737\n",
      " Copied model parameters to target network\n",
      "Step 840 (2800002) @ Episode 4105/10000, loss: 0.0037915417924523354\n",
      "Episode Reward: 15.0\n",
      "Step 586 (2800588) @ Episode 4106/10000, loss: 0.0027743065729737284\n",
      "Episode Reward: 9.0\n",
      "Step 482 (2801070) @ Episode 4107/10000, loss: 0.0046471073292195815\n",
      "Episode Reward: 7.0\n",
      "Step 1296 (2802366) @ Episode 4108/10000, loss: 0.0107557065784931186\n",
      "Episode Reward: 28.0\n",
      "Step 986 (2803352) @ Episode 4109/10000, loss: 0.0087998555973172194\n",
      "Episode Reward: 14.0\n",
      "Step 538 (2803890) @ Episode 4110/10000, loss: 0.0050619696266949185\n",
      "Episode Reward: 8.0\n",
      "Step 1040 (2804930) @ Episode 4111/10000, loss: 0.0060858922079205515\n",
      "Episode Reward: 18.0\n",
      "Step 764 (2805694) @ Episode 4112/10000, loss: 0.0115111637860536585\n",
      "Episode Reward: 15.0\n",
      "Step 978 (2806672) @ Episode 4113/10000, loss: 0.0053268987685441975\n",
      "Episode Reward: 21.0\n",
      "Step 595 (2807267) @ Episode 4114/10000, loss: 0.0083817830309271815\n",
      "Episode Reward: 8.0\n",
      "Step 539 (2807806) @ Episode 4115/10000, loss: 0.0047878948971629146\n",
      "Episode Reward: 7.0\n",
      "Step 603 (2808409) @ Episode 4116/10000, loss: 0.0106782354414463044\n",
      "Episode Reward: 8.0\n",
      "Step 724 (2809133) @ Episode 4117/10000, loss: 0.0063786217942833964\n",
      "Episode Reward: 10.0\n",
      "Step 866 (2809999) @ Episode 4118/10000, loss: 0.0043710637837648394\n",
      " Copied model parameters to target network\n",
      "Step 1061 (2810194) @ Episode 4118/10000, loss: 0.0099020721390843455\n",
      "Episode Reward: 22.0\n",
      "Step 384 (2810578) @ Episode 4119/10000, loss: 0.0090395109727978764\n",
      "Episode Reward: 4.0\n",
      "Step 670 (2811248) @ Episode 4120/10000, loss: 0.0045499540865421295\n",
      "Episode Reward: 9.0\n",
      "Step 802 (2812050) @ Episode 4121/10000, loss: 0.0075432364828884627\n",
      "Episode Reward: 12.0\n",
      "Step 595 (2812645) @ Episode 4122/10000, loss: 0.0130139952525496487\n",
      "Episode Reward: 8.0\n",
      "Step 800 (2813445) @ Episode 4123/10000, loss: 0.0042975237593054775\n",
      "Episode Reward: 7.0\n",
      "Step 659 (2814104) @ Episode 4124/10000, loss: 0.0065900878980755812\n",
      "Episode Reward: 9.0\n",
      "Step 820 (2814924) @ Episode 4125/10000, loss: 0.0020762700587511063\n",
      "Episode Reward: 11.0\n",
      "Step 1183 (2816107) @ Episode 4126/10000, loss: 0.0052654291503131396\n",
      "Episode Reward: 32.0\n",
      "Step 625 (2816732) @ Episode 4127/10000, loss: 0.0022514197044074535\n",
      "Episode Reward: 9.0\n",
      "Step 618 (2817350) @ Episode 4128/10000, loss: 0.0064962282776832585\n",
      "Episode Reward: 14.0\n",
      "Step 790 (2818140) @ Episode 4129/10000, loss: 0.0057225218042731285\n",
      "Episode Reward: 14.0\n",
      "Step 1022 (2819162) @ Episode 4130/10000, loss: 0.0049628773704171187\n",
      "Episode Reward: 21.0\n",
      "Step 625 (2819787) @ Episode 4131/10000, loss: 0.0075847925618290953\n",
      "Episode Reward: 14.0\n",
      "Step 212 (2819999) @ Episode 4132/10000, loss: 0.0052759787067770962\n",
      " Copied model parameters to target network\n",
      "Step 964 (2820751) @ Episode 4132/10000, loss: 0.0029359282925724983\n",
      "Episode Reward: 21.0\n",
      "Step 558 (2821309) @ Episode 4133/10000, loss: 0.0079255383461713793\n",
      "Episode Reward: 8.0\n",
      "Step 1030 (2822339) @ Episode 4134/10000, loss: 0.0096286246553063466\n",
      "Episode Reward: 20.0\n",
      "Step 1147 (2823486) @ Episode 4135/10000, loss: 0.0073379352688789375\n",
      "Episode Reward: 18.0\n",
      "Step 689 (2824175) @ Episode 4136/10000, loss: 0.0061898306012153625\n",
      "Episode Reward: 14.0\n",
      "Step 1168 (2825343) @ Episode 4137/10000, loss: 0.0071121612563729297\n",
      "Episode Reward: 18.0\n",
      "Step 903 (2826246) @ Episode 4138/10000, loss: 0.0054271323606371888\n",
      "Episode Reward: 17.0\n",
      "Step 920 (2827166) @ Episode 4139/10000, loss: 0.0046888347715139395\n",
      "Episode Reward: 23.0\n",
      "Step 972 (2828138) @ Episode 4140/10000, loss: 0.0035908669233322144\n",
      "Episode Reward: 23.0\n",
      "Step 1227 (2829365) @ Episode 4141/10000, loss: 0.0096404263749718674\n",
      "Episode Reward: 27.0\n",
      "Step 552 (2829917) @ Episode 4142/10000, loss: 0.0025774047244340186\n",
      "Episode Reward: 8.0\n",
      "Step 82 (2829999) @ Episode 4143/10000, loss: 0.0116206426173448564\n",
      " Copied model parameters to target network\n",
      "Step 1227 (2831144) @ Episode 4143/10000, loss: 0.0111473258584737787\n",
      "Episode Reward: 24.0\n",
      "Step 887 (2832031) @ Episode 4144/10000, loss: 0.0086787827312946325\n",
      "Episode Reward: 18.0\n",
      "Step 1191 (2833222) @ Episode 4145/10000, loss: 0.0078883562237024326\n",
      "Episode Reward: 27.0\n",
      "Step 915 (2834137) @ Episode 4146/10000, loss: 0.0083800833672285087\n",
      "Episode Reward: 26.0\n",
      "Step 903 (2835040) @ Episode 4147/10000, loss: 0.0035067566204816103\n",
      "Episode Reward: 22.0\n",
      "Step 555 (2835595) @ Episode 4148/10000, loss: 0.0092151388525962833\n",
      "Episode Reward: 8.0\n",
      "Step 454 (2836049) @ Episode 4149/10000, loss: 0.0099405515938997279\n",
      "Episode Reward: 6.0\n",
      "Step 1630 (2837679) @ Episode 4150/10000, loss: 0.0061080353334546096\n",
      "Episode Reward: 37.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-04 23:54:26,224] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video004150.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 868 (2838547) @ Episode 4151/10000, loss: 0.0055150827392935755\n",
      "Episode Reward: 16.0\n",
      "Step 812 (2839359) @ Episode 4152/10000, loss: 0.0114527456462383275\n",
      "Episode Reward: 15.0\n",
      "Step 640 (2839999) @ Episode 4153/10000, loss: 0.0049302112311124832\n",
      " Copied model parameters to target network\n",
      "Step 737 (2840096) @ Episode 4153/10000, loss: 0.0057383487001061445\n",
      "Episode Reward: 12.0\n",
      "Step 827 (2840923) @ Episode 4154/10000, loss: 0.0057196905836462975\n",
      "Episode Reward: 17.0\n",
      "Step 694 (2841617) @ Episode 4155/10000, loss: 0.0463741347193717968\n",
      "Episode Reward: 11.0\n",
      "Step 992 (2842609) @ Episode 4156/10000, loss: 0.0135514363646507264\n",
      "Episode Reward: 21.0\n",
      "Step 982 (2843591) @ Episode 4157/10000, loss: 0.0083414614200592045\n",
      "Episode Reward: 21.0\n",
      "Step 880 (2844471) @ Episode 4158/10000, loss: 0.0203036479651927955\n",
      "Episode Reward: 20.0\n",
      "Step 508 (2844979) @ Episode 4159/10000, loss: 0.0043074721470475273\n",
      "Episode Reward: 8.0\n",
      "Step 1151 (2846130) @ Episode 4160/10000, loss: 0.0145377349108457575\n",
      "Episode Reward: 27.0\n",
      "Step 937 (2847067) @ Episode 4161/10000, loss: 0.0871127694845199627\n",
      "Episode Reward: 16.0\n",
      "Step 739 (2847806) @ Episode 4162/10000, loss: 0.0771447494626045264\n",
      "Episode Reward: 16.0\n",
      "Step 633 (2848439) @ Episode 4163/10000, loss: 0.0054036471992731094\n",
      "Episode Reward: 14.0\n",
      "Step 836 (2849275) @ Episode 4164/10000, loss: 0.0288032144308090285\n",
      "Episode Reward: 24.0\n",
      "Step 724 (2849999) @ Episode 4165/10000, loss: 0.0022849189117550855\n",
      " Copied model parameters to target network\n",
      "Step 1214 (2850489) @ Episode 4165/10000, loss: 0.0044116033241152766\n",
      "Episode Reward: 24.0\n",
      "Step 1334 (2851823) @ Episode 4166/10000, loss: 0.0055702719837427145\n",
      "Episode Reward: 32.0\n",
      "Step 897 (2852720) @ Episode 4167/10000, loss: 0.0031341256108134985\n",
      "Episode Reward: 19.0\n",
      "Step 759 (2853479) @ Episode 4168/10000, loss: 0.0027470779605209827\n",
      "Episode Reward: 13.0\n",
      "Step 973 (2854452) @ Episode 4169/10000, loss: 0.0048031099140644074\n",
      "Episode Reward: 18.0\n",
      "Step 1061 (2855513) @ Episode 4170/10000, loss: 0.0047474913299083716\n",
      "Episode Reward: 20.0\n",
      "Step 581 (2856094) @ Episode 4171/10000, loss: 0.0031711256597191095\n",
      "Episode Reward: 14.0\n",
      "Step 1170 (2857264) @ Episode 4172/10000, loss: 0.0042298482730984698\n",
      "Episode Reward: 28.0\n",
      "Step 994 (2858258) @ Episode 4173/10000, loss: 0.0046914909034967427\n",
      "Episode Reward: 18.0\n",
      "Step 1486 (2859744) @ Episode 4174/10000, loss: 0.0062906658276915555\n",
      "Episode Reward: 34.0\n",
      "Step 255 (2859999) @ Episode 4175/10000, loss: 0.0096114678308367736\n",
      " Copied model parameters to target network\n",
      "Step 794 (2860538) @ Episode 4175/10000, loss: 0.0064572291448712355\n",
      "Episode Reward: 19.0\n",
      "Step 751 (2861289) @ Episode 4176/10000, loss: 0.0037300155963748693\n",
      "Episode Reward: 25.0\n",
      "Step 808 (2862097) @ Episode 4177/10000, loss: 0.0387784838676452645\n",
      "Episode Reward: 12.0\n",
      "Step 1270 (2863367) @ Episode 4178/10000, loss: 0.0133256139233708382\n",
      "Episode Reward: 28.0\n",
      "Step 944 (2864311) @ Episode 4179/10000, loss: 0.0099455658346414575\n",
      "Episode Reward: 20.0\n",
      "Step 945 (2865256) @ Episode 4180/10000, loss: 0.0031449859961867332\n",
      "Episode Reward: 17.0\n",
      "Step 884 (2866140) @ Episode 4181/10000, loss: 0.0128552420064806944\n",
      "Episode Reward: 21.0\n",
      "Step 776 (2866916) @ Episode 4182/10000, loss: 0.0043500512838363654\n",
      "Episode Reward: 12.0\n",
      "Step 1125 (2868041) @ Episode 4183/10000, loss: 0.0042714555747807038\n",
      "Episode Reward: 24.0\n",
      "Step 912 (2868953) @ Episode 4184/10000, loss: 0.0014974721707403667\n",
      "Episode Reward: 19.0\n",
      "Step 910 (2869863) @ Episode 4185/10000, loss: 0.0069085992872715217\n",
      "Episode Reward: 16.0\n",
      "Step 136 (2869999) @ Episode 4186/10000, loss: 0.0045426590368151665\n",
      " Copied model parameters to target network\n",
      "Step 1049 (2870912) @ Episode 4186/10000, loss: 0.0038639847189188004\n",
      "Episode Reward: 17.0\n",
      "Step 580 (2871492) @ Episode 4187/10000, loss: 0.0142043065279722215\n",
      "Episode Reward: 8.0\n",
      "Step 512 (2872004) @ Episode 4188/10000, loss: 0.0339234322309494255\n",
      "Episode Reward: 7.0\n",
      "Step 748 (2872752) @ Episode 4189/10000, loss: 0.0052337134256958965\n",
      "Episode Reward: 12.0\n",
      "Step 776 (2873528) @ Episode 4190/10000, loss: 0.0048357876949012283\n",
      "Episode Reward: 12.0\n",
      "Step 1047 (2874575) @ Episode 4191/10000, loss: 0.0067336983047425755\n",
      "Episode Reward: 20.0\n",
      "Step 844 (2875419) @ Episode 4192/10000, loss: 0.0053652622736990455\n",
      "Episode Reward: 24.0\n",
      "Step 595 (2876014) @ Episode 4193/10000, loss: 0.0020433655008673676\n",
      "Episode Reward: 10.0\n",
      "Step 752 (2876766) @ Episode 4194/10000, loss: 0.0029835472814738757\n",
      "Episode Reward: 13.0\n",
      "Step 1172 (2877938) @ Episode 4195/10000, loss: 0.0028497418388724327\n",
      "Episode Reward: 24.0\n",
      "Step 612 (2878550) @ Episode 4196/10000, loss: 0.0094406781718134888\n",
      "Episode Reward: 9.0\n",
      "Step 888 (2879438) @ Episode 4197/10000, loss: 0.0106975827366113665\n",
      "Episode Reward: 13.0\n",
      "Step 561 (2879999) @ Episode 4198/10000, loss: 0.0066845975816249858\n",
      " Copied model parameters to target network\n",
      "Step 965 (2880403) @ Episode 4198/10000, loss: 0.0041727055795490742\n",
      "Episode Reward: 12.0\n",
      "Step 788 (2881191) @ Episode 4199/10000, loss: 0.0066707399673759943\n",
      "Episode Reward: 14.0\n",
      "Step 675 (2881866) @ Episode 4200/10000, loss: 0.0115070715546607975\n",
      "Episode Reward: 11.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 00:01:05,352] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video004200.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 947 (2882813) @ Episode 4201/10000, loss: 0.0066718780435621742\n",
      "Episode Reward: 16.0\n",
      "Step 961 (2883774) @ Episode 4202/10000, loss: 0.0077313417568802836\n",
      "Episode Reward: 22.0\n",
      "Step 677 (2884451) @ Episode 4203/10000, loss: 0.1214024946093559317\n",
      "Episode Reward: 10.0\n",
      "Step 698 (2885149) @ Episode 4204/10000, loss: 0.0046627791598439224\n",
      "Episode Reward: 13.0\n",
      "Step 907 (2886056) @ Episode 4205/10000, loss: 0.0032351464033126836\n",
      "Episode Reward: 22.0\n",
      "Step 752 (2886808) @ Episode 4206/10000, loss: 0.0094775678589940077\n",
      "Episode Reward: 13.0\n",
      "Step 633 (2887441) @ Episode 4207/10000, loss: 0.0056731244549155235\n",
      "Episode Reward: 11.0\n",
      "Step 555 (2887996) @ Episode 4208/10000, loss: 0.0037733013741672042\n",
      "Episode Reward: 9.0\n",
      "Step 552 (2888548) @ Episode 4209/10000, loss: 0.0109168495982885365\n",
      "Episode Reward: 7.0\n",
      "Step 1287 (2889835) @ Episode 4210/10000, loss: 0.0039848382584750655\n",
      "Episode Reward: 29.0\n",
      "Step 164 (2889999) @ Episode 4211/10000, loss: 0.0043803281150758274\n",
      " Copied model parameters to target network\n",
      "Step 1023 (2890858) @ Episode 4211/10000, loss: 0.0137711055576801314\n",
      "Episode Reward: 23.0\n",
      "Step 808 (2891666) @ Episode 4212/10000, loss: 0.0047988882288336757\n",
      "Episode Reward: 14.0\n",
      "Step 894 (2892560) @ Episode 4213/10000, loss: 0.0115853445604443553\n",
      "Episode Reward: 18.0\n",
      "Step 836 (2893396) @ Episode 4214/10000, loss: 0.0027504051104187965\n",
      "Episode Reward: 13.0\n",
      "Step 1228 (2894624) @ Episode 4215/10000, loss: 0.0028811898082494736\n",
      "Episode Reward: 31.0\n",
      "Step 1339 (2895963) @ Episode 4216/10000, loss: 0.0042177657596766955\n",
      "Episode Reward: 36.0\n",
      "Step 950 (2896913) @ Episode 4217/10000, loss: 0.0055454098619520665\n",
      "Episode Reward: 18.0\n",
      "Step 692 (2897605) @ Episode 4218/10000, loss: 0.0135262534022331243\n",
      "Episode Reward: 19.0\n",
      "Step 880 (2898485) @ Episode 4219/10000, loss: 0.0035499124787747867\n",
      "Episode Reward: 15.0\n",
      "Step 952 (2899437) @ Episode 4220/10000, loss: 0.0070847081951797016\n",
      "Episode Reward: 16.0\n",
      "Step 562 (2899999) @ Episode 4221/10000, loss: 0.0043813572265207776\n",
      " Copied model parameters to target network\n",
      "Step 756 (2900193) @ Episode 4221/10000, loss: 0.0020293039269745354\n",
      "Episode Reward: 13.0\n",
      "Step 677 (2900870) @ Episode 4222/10000, loss: 0.0052029835060238844\n",
      "Episode Reward: 11.0\n",
      "Step 895 (2901765) @ Episode 4223/10000, loss: 0.0041271429508924486\n",
      "Episode Reward: 16.0\n",
      "Step 794 (2902559) @ Episode 4224/10000, loss: 0.0069050835445523265\n",
      "Episode Reward: 14.0\n",
      "Step 1112 (2903671) @ Episode 4225/10000, loss: 0.0037189680151641375\n",
      "Episode Reward: 20.0\n",
      "Step 1252 (2904923) @ Episode 4226/10000, loss: 0.0047527323476970205\n",
      "Episode Reward: 40.0\n",
      "Step 867 (2905790) @ Episode 4227/10000, loss: 0.0037321601994335655\n",
      "Episode Reward: 14.0\n",
      "Step 1000 (2906790) @ Episode 4228/10000, loss: 0.012377463281154633\n",
      "Episode Reward: 16.0\n",
      "Step 897 (2907687) @ Episode 4229/10000, loss: 0.0036440864205360413\n",
      "Episode Reward: 14.0\n",
      "Step 912 (2908599) @ Episode 4230/10000, loss: 0.0037404149770736694\n",
      "Episode Reward: 19.0\n",
      "Step 1400 (2909999) @ Episode 4231/10000, loss: 0.0871414989233017254\n",
      " Copied model parameters to target network\n",
      "Step 1586 (2910185) @ Episode 4231/10000, loss: 0.0051667168736457825\n",
      "Episode Reward: 38.0\n",
      "Step 794 (2910979) @ Episode 4232/10000, loss: 0.0058300117962062365\n",
      "Episode Reward: 13.0\n",
      "Step 1013 (2911992) @ Episode 4233/10000, loss: 0.0067049236968159676\n",
      "Episode Reward: 18.0\n",
      "Step 762 (2912754) @ Episode 4234/10000, loss: 0.0041850307025015357\n",
      "Episode Reward: 19.0\n",
      "Step 1031 (2913785) @ Episode 4235/10000, loss: 0.0054427329450845723\n",
      "Episode Reward: 28.0\n",
      "Step 582 (2914367) @ Episode 4236/10000, loss: 0.0026456874329596766\n",
      "Episode Reward: 8.0\n",
      "Step 1568 (2915935) @ Episode 4237/10000, loss: 0.0083195464685559274\n",
      "Episode Reward: 45.0\n",
      "Step 783 (2916718) @ Episode 4238/10000, loss: 0.0250002685934305237\n",
      "Episode Reward: 33.0\n",
      "Step 929 (2917647) @ Episode 4239/10000, loss: 0.0040533477440476426\n",
      "Episode Reward: 16.0\n",
      "Step 813 (2918460) @ Episode 4240/10000, loss: 0.0082869902253150944\n",
      "Episode Reward: 17.0\n",
      "Step 764 (2919224) @ Episode 4241/10000, loss: 0.0049234125763177876\n",
      "Episode Reward: 12.0\n",
      "Step 775 (2919999) @ Episode 4242/10000, loss: 0.0036222189664840714\n",
      " Copied model parameters to target network\n",
      "Step 925 (2920149) @ Episode 4242/10000, loss: 0.0066390228457748894\n",
      "Episode Reward: 16.0\n",
      "Step 1391 (2921540) @ Episode 4243/10000, loss: 0.0036367124412208796\n",
      "Episode Reward: 35.0\n",
      "Step 1212 (2922752) @ Episode 4244/10000, loss: 0.0066913487389683724\n",
      "Episode Reward: 24.0\n",
      "Step 1402 (2924154) @ Episode 4245/10000, loss: 0.0043790442869067196\n",
      "Episode Reward: 37.0\n",
      "Step 1591 (2925745) @ Episode 4246/10000, loss: 0.0036324672400951385\n",
      "Episode Reward: 48.0\n",
      "Step 977 (2926722) @ Episode 4247/10000, loss: 0.0033952305093407636\n",
      "Episode Reward: 20.0\n",
      "Step 872 (2927594) @ Episode 4248/10000, loss: 0.0075154975056648254\n",
      "Episode Reward: 16.0\n",
      "Step 1142 (2928736) @ Episode 4249/10000, loss: 0.0054620746523141865\n",
      "Episode Reward: 27.0\n",
      "Step 1079 (2929815) @ Episode 4250/10000, loss: 0.0016964016249403358\n",
      "Episode Reward: 18.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 00:08:19,499] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video004250.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 184 (2929999) @ Episode 4251/10000, loss: 0.0327764749526977547\n",
      " Copied model parameters to target network\n",
      "Step 1468 (2931283) @ Episode 4251/10000, loss: 0.0865284353494644268\n",
      "Episode Reward: 43.0\n",
      "Step 829 (2932112) @ Episode 4252/10000, loss: 0.0109792277216911328\n",
      "Episode Reward: 14.0\n",
      "Step 732 (2932844) @ Episode 4253/10000, loss: 0.0136492094025015836\n",
      "Episode Reward: 15.0\n",
      "Step 576 (2933420) @ Episode 4254/10000, loss: 0.0025953124277293685\n",
      "Episode Reward: 8.0\n",
      "Step 1219 (2934639) @ Episode 4255/10000, loss: 0.0026163749862462282\n",
      "Episode Reward: 35.0\n",
      "Step 1259 (2935898) @ Episode 4256/10000, loss: 0.0039999126456677915\n",
      "Episode Reward: 24.0\n",
      "Step 1201 (2937099) @ Episode 4257/10000, loss: 0.0045733395963907245\n",
      "Episode Reward: 27.0\n",
      "Step 907 (2938006) @ Episode 4258/10000, loss: 0.0071564549580216415\n",
      "Episode Reward: 23.0\n",
      "Step 1051 (2939057) @ Episode 4259/10000, loss: 0.0060557280667126183\n",
      "Episode Reward: 24.0\n",
      "Step 942 (2939999) @ Episode 4260/10000, loss: 0.0063729314133524895\n",
      " Copied model parameters to target network\n",
      "Step 1066 (2940123) @ Episode 4260/10000, loss: 0.0042426623404026034\n",
      "Episode Reward: 29.0\n",
      "Step 1316 (2941439) @ Episode 4261/10000, loss: 0.0020916708745062356\n",
      "Episode Reward: 24.0\n",
      "Step 1102 (2942541) @ Episode 4262/10000, loss: 0.0045488574542105261\n",
      "Episode Reward: 27.0\n",
      "Step 1057 (2943598) @ Episode 4263/10000, loss: 0.1871235966682434994\n",
      "Episode Reward: 20.0\n",
      "Step 852 (2944450) @ Episode 4264/10000, loss: 0.0049276058562099937\n",
      "Episode Reward: 15.0\n",
      "Step 1020 (2945470) @ Episode 4265/10000, loss: 0.0153449550271034245\n",
      "Episode Reward: 33.0\n",
      "Step 741 (2946211) @ Episode 4266/10000, loss: 0.0101418690755963334\n",
      "Episode Reward: 15.0\n",
      "Step 895 (2947106) @ Episode 4267/10000, loss: 0.0041835419833660137\n",
      "Episode Reward: 16.0\n",
      "Step 756 (2947862) @ Episode 4268/10000, loss: 0.0081537617370486267\n",
      "Episode Reward: 12.0\n",
      "Step 763 (2948625) @ Episode 4269/10000, loss: 0.0063350731506943727\n",
      "Episode Reward: 19.0\n",
      "Step 957 (2949582) @ Episode 4270/10000, loss: 0.0102997887879610063\n",
      "Episode Reward: 16.0\n",
      "Step 417 (2949999) @ Episode 4271/10000, loss: 0.0020835308823734525\n",
      " Copied model parameters to target network\n",
      "Step 865 (2950447) @ Episode 4271/10000, loss: 0.0037336708046495914\n",
      "Episode Reward: 16.0\n",
      "Step 418 (2950865) @ Episode 4272/10000, loss: 0.0041133691556751735\n",
      "Episode Reward: 6.0\n",
      "Step 508 (2951373) @ Episode 4273/10000, loss: 0.0251914914697408682\n",
      "Episode Reward: 6.0\n",
      "Step 901 (2952274) @ Episode 4274/10000, loss: 0.0161017272621393255\n",
      "Episode Reward: 14.0\n",
      "Step 966 (2953240) @ Episode 4275/10000, loss: 0.0120980190113186846\n",
      "Episode Reward: 20.0\n",
      "Step 699 (2953939) @ Episode 4276/10000, loss: 0.0054322374053299433\n",
      "Episode Reward: 11.0\n",
      "Step 732 (2954671) @ Episode 4277/10000, loss: 0.0031270671170204886\n",
      "Episode Reward: 12.0\n",
      "Step 560 (2955231) @ Episode 4278/10000, loss: 0.0031250701285898685\n",
      "Episode Reward: 10.0\n",
      "Step 1406 (2956637) @ Episode 4279/10000, loss: 0.0047353515401482584\n",
      "Episode Reward: 39.0\n",
      "Step 811 (2957448) @ Episode 4280/10000, loss: 0.0079578012228012085\n",
      "Episode Reward: 20.0\n",
      "Step 1039 (2958487) @ Episode 4281/10000, loss: 0.0058483136817812927\n",
      "Episode Reward: 21.0\n",
      "Step 1169 (2959656) @ Episode 4282/10000, loss: 0.0061278929933905675\n",
      "Episode Reward: 22.0\n",
      "Step 343 (2959999) @ Episode 4283/10000, loss: 0.0026616067625582223\n",
      " Copied model parameters to target network\n",
      "Step 971 (2960627) @ Episode 4283/10000, loss: 0.0125009929761290556\n",
      "Episode Reward: 17.0\n",
      "Step 1052 (2961679) @ Episode 4284/10000, loss: 0.0085831899195909533\n",
      "Episode Reward: 19.0\n",
      "Step 801 (2962480) @ Episode 4285/10000, loss: 0.0056387749500572687\n",
      "Episode Reward: 20.0\n",
      "Step 1026 (2963506) @ Episode 4286/10000, loss: 0.0039294664748013023\n",
      "Episode Reward: 23.0\n",
      "Step 844 (2964350) @ Episode 4287/10000, loss: 0.0024544468615204096\n",
      "Episode Reward: 14.0\n",
      "Step 883 (2965233) @ Episode 4288/10000, loss: 0.0135543011128902447\n",
      "Episode Reward: 14.0\n",
      "Step 606 (2965839) @ Episode 4289/10000, loss: 0.0026268414221704006\n",
      "Episode Reward: 9.0\n",
      "Step 787 (2966626) @ Episode 4290/10000, loss: 0.0080989114940166476\n",
      "Episode Reward: 10.0\n",
      "Step 543 (2967169) @ Episode 4291/10000, loss: 0.0074460208415985114\n",
      "Episode Reward: 9.0\n",
      "Step 1210 (2968379) @ Episode 4292/10000, loss: 0.0028835793491452932\n",
      "Episode Reward: 38.0\n",
      "Step 1058 (2969437) @ Episode 4293/10000, loss: 0.0044609345495700847\n",
      "Episode Reward: 18.0\n",
      "Step 562 (2969999) @ Episode 4294/10000, loss: 0.0052295415662229063\n",
      " Copied model parameters to target network\n",
      "Step 871 (2970308) @ Episode 4294/10000, loss: 0.0050822226330637934\n",
      "Episode Reward: 13.0\n",
      "Step 830 (2971138) @ Episode 4295/10000, loss: 0.0101826163008809095\n",
      "Episode Reward: 17.0\n",
      "Step 629 (2971767) @ Episode 4296/10000, loss: 0.0070619136095047715\n",
      "Episode Reward: 10.0\n",
      "Step 1152 (2972919) @ Episode 4297/10000, loss: 0.0065363156609237192\n",
      "Episode Reward: 28.0\n",
      "Step 668 (2973587) @ Episode 4298/10000, loss: 0.0038916459307074547\n",
      "Episode Reward: 11.0\n",
      "Step 878 (2974465) @ Episode 4299/10000, loss: 0.0085795652121305473\n",
      "Episode Reward: 23.0\n",
      "Step 793 (2975258) @ Episode 4300/10000, loss: 0.0143802007660269746\n",
      "Episode Reward: 17.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 00:15:14,676] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video004300.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 662 (2975920) @ Episode 4301/10000, loss: 0.0069519216194748888\n",
      "Episode Reward: 10.0\n",
      "Step 1027 (2976947) @ Episode 4302/10000, loss: 0.0046449052169919015\n",
      "Episode Reward: 20.0\n",
      "Step 622 (2977569) @ Episode 4303/10000, loss: 0.0081717781722545625\n",
      "Episode Reward: 12.0\n",
      "Step 832 (2978401) @ Episode 4304/10000, loss: 0.1644851416349411565\n",
      "Episode Reward: 22.0\n",
      "Step 919 (2979320) @ Episode 4305/10000, loss: 0.0041511491872370245\n",
      "Episode Reward: 20.0\n",
      "Step 679 (2979999) @ Episode 4306/10000, loss: 0.0101522821933031082\n",
      " Copied model parameters to target network\n",
      "Step 1035 (2980355) @ Episode 4306/10000, loss: 0.0071360412985086443\n",
      "Episode Reward: 21.0\n",
      "Step 757 (2981112) @ Episode 4307/10000, loss: 0.0052183927036821843\n",
      "Episode Reward: 11.0\n",
      "Step 838 (2981950) @ Episode 4308/10000, loss: 0.0031731347553431988\n",
      "Episode Reward: 12.0\n",
      "Step 685 (2982635) @ Episode 4309/10000, loss: 0.0064557278528809554\n",
      "Episode Reward: 12.0\n",
      "Step 1425 (2984060) @ Episode 4310/10000, loss: 0.0059472341090440755\n",
      "Episode Reward: 34.0\n",
      "Step 968 (2985028) @ Episode 4311/10000, loss: 0.0052379970438778455\n",
      "Episode Reward: 18.0\n",
      "Step 948 (2985976) @ Episode 4312/10000, loss: 0.0070565007627010345\n",
      "Episode Reward: 14.0\n",
      "Step 1156 (2987132) @ Episode 4313/10000, loss: 0.0072122174315154553\n",
      "Episode Reward: 31.0\n",
      "Step 1290 (2988422) @ Episode 4314/10000, loss: 0.0044674482196569445\n",
      "Episode Reward: 31.0\n",
      "Step 763 (2989185) @ Episode 4315/10000, loss: 0.0242727287113666533\n",
      "Episode Reward: 13.0\n",
      "Step 814 (2989999) @ Episode 4316/10000, loss: 0.0327602773904800436\n",
      " Copied model parameters to target network\n",
      "Step 1341 (2990526) @ Episode 4316/10000, loss: 0.0039517763070762167\n",
      "Episode Reward: 30.0\n",
      "Step 874 (2991400) @ Episode 4317/10000, loss: 0.0094157690182328227\n",
      "Episode Reward: 13.0\n",
      "Step 741 (2992141) @ Episode 4318/10000, loss: 0.0121871307492256167\n",
      "Episode Reward: 11.0\n",
      "Step 928 (2993069) @ Episode 4319/10000, loss: 0.0026269040536135435\n",
      "Episode Reward: 21.0\n",
      "Step 654 (2993723) @ Episode 4320/10000, loss: 0.0316240377724170787\n",
      "Episode Reward: 9.0\n",
      "Step 625 (2994348) @ Episode 4321/10000, loss: 0.0478936210274696356\n",
      "Episode Reward: 10.0\n",
      "Step 517 (2994865) @ Episode 4322/10000, loss: 0.0230910982936620736\n",
      "Episode Reward: 8.0\n",
      "Step 1140 (2996005) @ Episode 4323/10000, loss: 0.0109557276591658603\n",
      "Episode Reward: 22.0\n",
      "Step 1036 (2997041) @ Episode 4324/10000, loss: 0.0033454806543886666\n",
      "Episode Reward: 18.0\n",
      "Step 773 (2997814) @ Episode 4325/10000, loss: 0.0068510295823216443\n",
      "Episode Reward: 12.0\n",
      "Step 749 (2998563) @ Episode 4326/10000, loss: 0.0029156194068491462\n",
      "Episode Reward: 15.0\n",
      "Step 1395 (2999958) @ Episode 4327/10000, loss: 0.0064865648746490484\n",
      "Episode Reward: 23.0\n",
      "Step 41 (2999999) @ Episode 4328/10000, loss: 0.0068862745538353925\n",
      " Copied model parameters to target network\n",
      "Step 1084 (3001042) @ Episode 4328/10000, loss: 0.0091213816776871683\n",
      "Episode Reward: 27.0\n",
      "Step 921 (3001963) @ Episode 4329/10000, loss: 0.0082608992233872417\n",
      "Episode Reward: 18.0\n",
      "Step 679 (3002642) @ Episode 4330/10000, loss: 0.0036168855149298906\n",
      "Episode Reward: 9.0\n",
      "Step 1057 (3003699) @ Episode 4331/10000, loss: 0.0048537622205913075\n",
      "Episode Reward: 24.0\n",
      "Step 961 (3004660) @ Episode 4332/10000, loss: 0.0029333340935409077\n",
      "Episode Reward: 28.0\n",
      "Step 908 (3005568) @ Episode 4333/10000, loss: 0.0034798230044543743\n",
      "Episode Reward: 12.0\n",
      "Step 911 (3006479) @ Episode 4334/10000, loss: 0.0027138767763972282\n",
      "Episode Reward: 20.0\n",
      "Step 551 (3007030) @ Episode 4335/10000, loss: 0.0180700495839118965\n",
      "Episode Reward: 8.0\n",
      "Step 1048 (3008078) @ Episode 4336/10000, loss: 0.0033854073844850063\n",
      "Episode Reward: 26.0\n",
      "Step 1060 (3009138) @ Episode 4337/10000, loss: 0.0044679027050733575\n",
      "Episode Reward: 26.0\n",
      "Step 631 (3009769) @ Episode 4338/10000, loss: 0.0092329271137714396\n",
      "Episode Reward: 9.0\n",
      "Step 230 (3009999) @ Episode 4339/10000, loss: 0.0045155021362006666\n",
      " Copied model parameters to target network\n",
      "Step 1424 (3011193) @ Episode 4339/10000, loss: 0.0091490354388952266\n",
      "Episode Reward: 40.0\n",
      "Step 924 (3012117) @ Episode 4340/10000, loss: 0.0037041343748569494\n",
      "Episode Reward: 15.0\n",
      "Step 1009 (3013126) @ Episode 4341/10000, loss: 0.006848642602562904\n",
      "Episode Reward: 23.0\n",
      "Step 437 (3013563) @ Episode 4342/10000, loss: 0.0032624781597405676\n",
      "Episode Reward: 5.0\n",
      "Step 578 (3014141) @ Episode 4343/10000, loss: 0.0067978580482304144\n",
      "Episode Reward: 9.0\n",
      "Step 1181 (3015322) @ Episode 4344/10000, loss: 0.0047459136694669726\n",
      "Episode Reward: 30.0\n",
      "Step 846 (3016168) @ Episode 4345/10000, loss: 0.0120566952973604265\n",
      "Episode Reward: 17.0\n",
      "Step 832 (3017000) @ Episode 4346/10000, loss: 0.0042943544685840613\n",
      "Episode Reward: 13.0\n",
      "Step 824 (3017824) @ Episode 4347/10000, loss: 0.0145822409540414814\n",
      "Episode Reward: 15.0\n",
      "Step 741 (3018565) @ Episode 4348/10000, loss: 0.0026098818052560095\n",
      "Episode Reward: 10.0\n",
      "Step 908 (3019473) @ Episode 4349/10000, loss: 0.0669230967760086646\n",
      "Episode Reward: 17.0\n",
      "Step 526 (3019999) @ Episode 4350/10000, loss: 0.0054719299077987674\n",
      " Copied model parameters to target network\n",
      "Step 835 (3020308) @ Episode 4350/10000, loss: 0.0050367303192615517\n",
      "Episode Reward: 12.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 00:22:05,437] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video004350.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 632 (3020940) @ Episode 4351/10000, loss: 0.0071354615502059462\n",
      "Episode Reward: 9.0\n",
      "Step 543 (3021483) @ Episode 4352/10000, loss: 0.0047277957201004037\n",
      "Episode Reward: 8.0\n",
      "Step 1239 (3022722) @ Episode 4353/10000, loss: 0.0081134065985679635\n",
      "Episode Reward: 27.0\n",
      "Step 927 (3023649) @ Episode 4354/10000, loss: 0.0112232407554984146\n",
      "Episode Reward: 17.0\n",
      "Step 1128 (3024777) @ Episode 4355/10000, loss: 0.0109114469960331926\n",
      "Episode Reward: 19.0\n",
      "Step 1384 (3026161) @ Episode 4356/10000, loss: 0.0037200555671006443\n",
      "Episode Reward: 26.0\n",
      "Step 654 (3026815) @ Episode 4357/10000, loss: 0.0242052879184484485\n",
      "Episode Reward: 14.0\n",
      "Step 793 (3027608) @ Episode 4358/10000, loss: 0.0092623345553874974\n",
      "Episode Reward: 14.0\n",
      "Step 915 (3028523) @ Episode 4359/10000, loss: 0.0038855210877954965\n",
      "Episode Reward: 16.0\n",
      "Step 895 (3029418) @ Episode 4360/10000, loss: 0.0126545606181025526\n",
      "Episode Reward: 18.0\n",
      "Step 581 (3029999) @ Episode 4361/10000, loss: 0.0031660175882279873\n",
      " Copied model parameters to target network\n",
      "Step 1062 (3030480) @ Episode 4361/10000, loss: 0.0084340581670403488\n",
      "Episode Reward: 17.0\n",
      "Step 949 (3031429) @ Episode 4362/10000, loss: 0.0107940891757607463\n",
      "Episode Reward: 15.0\n",
      "Step 1138 (3032567) @ Episode 4363/10000, loss: 0.0080863069742918016\n",
      "Episode Reward: 33.0\n",
      "Step 484 (3033051) @ Episode 4364/10000, loss: 0.0051982700824737554\n",
      "Episode Reward: 6.0\n",
      "Step 1021 (3034072) @ Episode 4365/10000, loss: 0.0049639935605227956\n",
      "Episode Reward: 23.0\n",
      "Step 1276 (3035348) @ Episode 4366/10000, loss: 0.0063618319109082226\n",
      "Episode Reward: 25.0\n",
      "Step 783 (3036131) @ Episode 4367/10000, loss: 0.0137757398188114175\n",
      "Episode Reward: 20.0\n",
      "Step 855 (3036986) @ Episode 4368/10000, loss: 0.0019549145363271236\n",
      "Episode Reward: 14.0\n",
      "Step 770 (3037756) @ Episode 4369/10000, loss: 0.0072800018824636943\n",
      "Episode Reward: 17.0\n",
      "Step 723 (3038479) @ Episode 4370/10000, loss: 0.0081575401127338415\n",
      "Episode Reward: 14.0\n",
      "Step 1047 (3039526) @ Episode 4371/10000, loss: 0.0097078885883092885\n",
      "Episode Reward: 26.0\n",
      "Step 473 (3039999) @ Episode 4372/10000, loss: 0.0137069411575794224\n",
      " Copied model parameters to target network\n",
      "Step 702 (3040228) @ Episode 4372/10000, loss: 0.0034393710084259514\n",
      "Episode Reward: 15.0\n",
      "Step 1085 (3041313) @ Episode 4373/10000, loss: 0.0058413846418261535\n",
      "Episode Reward: 21.0\n",
      "Step 1114 (3042427) @ Episode 4374/10000, loss: 0.0112874954938888554\n",
      "Episode Reward: 17.0\n",
      "Step 820 (3043247) @ Episode 4375/10000, loss: 0.0068319058045744915\n",
      "Episode Reward: 14.0\n",
      "Step 695 (3043942) @ Episode 4376/10000, loss: 0.0051942989230155945\n",
      "Episode Reward: 15.0\n",
      "Step 1005 (3044947) @ Episode 4377/10000, loss: 0.0036789500154554844\n",
      "Episode Reward: 23.0\n",
      "Step 1343 (3046290) @ Episode 4378/10000, loss: 0.0087826289236545565\n",
      "Episode Reward: 33.0\n",
      "Step 899 (3047189) @ Episode 4379/10000, loss: 0.0086444998160004626\n",
      "Episode Reward: 18.0\n",
      "Step 868 (3048057) @ Episode 4380/10000, loss: 0.0046566678211092954\n",
      "Episode Reward: 17.0\n",
      "Step 800 (3048857) @ Episode 4381/10000, loss: 0.0025410270318388946\n",
      "Episode Reward: 16.0\n",
      "Step 1142 (3049999) @ Episode 4382/10000, loss: 0.0084325009956955914\n",
      " Copied model parameters to target network\n",
      "Step 1269 (3050126) @ Episode 4382/10000, loss: 0.0039354939945042137\n",
      "Episode Reward: 24.0\n",
      "Step 1203 (3051329) @ Episode 4383/10000, loss: 0.0162166431546211244\n",
      "Episode Reward: 27.0\n",
      "Step 581 (3051910) @ Episode 4384/10000, loss: 0.0043621249496936836\n",
      "Episode Reward: 8.0\n",
      "Step 885 (3052795) @ Episode 4385/10000, loss: 0.0051693627610802655\n",
      "Episode Reward: 13.0\n",
      "Step 931 (3053726) @ Episode 4386/10000, loss: 0.0118757635354995736\n",
      "Episode Reward: 20.0\n",
      "Step 1127 (3054853) @ Episode 4387/10000, loss: 0.0094494819641113284\n",
      "Episode Reward: 27.0\n",
      "Step 819 (3055672) @ Episode 4388/10000, loss: 0.0036661252379417425\n",
      "Episode Reward: 11.0\n",
      "Step 988 (3056660) @ Episode 4389/10000, loss: 0.0026064231060445315\n",
      "Episode Reward: 16.0\n",
      "Step 553 (3057213) @ Episode 4390/10000, loss: 0.0033600339666008955\n",
      "Episode Reward: 9.0\n",
      "Step 1318 (3058531) @ Episode 4391/10000, loss: 0.0067933746613562115\n",
      "Episode Reward: 30.0\n",
      "Step 842 (3059373) @ Episode 4392/10000, loss: 0.0038136621005833155\n",
      "Episode Reward: 12.0\n",
      "Step 626 (3059999) @ Episode 4393/10000, loss: 0.0066154934465885165\n",
      " Copied model parameters to target network\n",
      "Step 943 (3060316) @ Episode 4393/10000, loss: 0.0122058298438787465\n",
      "Episode Reward: 14.0\n",
      "Step 775 (3061091) @ Episode 4394/10000, loss: 0.1951791793107986533\n",
      "Episode Reward: 12.0\n",
      "Step 1489 (3062580) @ Episode 4395/10000, loss: 0.0037181470543146133\n",
      "Episode Reward: 33.0\n",
      "Step 1171 (3063751) @ Episode 4396/10000, loss: 0.0107135204598307615\n",
      "Episode Reward: 21.0\n",
      "Step 757 (3064508) @ Episode 4397/10000, loss: 0.0523851551115512857\n",
      "Episode Reward: 11.0\n",
      "Step 919 (3065427) @ Episode 4398/10000, loss: 0.0053816176950931555\n",
      "Episode Reward: 20.0\n",
      "Step 1077 (3066504) @ Episode 4399/10000, loss: 0.0109859621152281765\n",
      "Episode Reward: 25.0\n",
      "Step 922 (3067426) @ Episode 4400/10000, loss: 0.0022396601270884275\n",
      "Episode Reward: 23.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 00:29:18,959] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video004400.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 886 (3068312) @ Episode 4401/10000, loss: 0.0072049824520945556\n",
      "Episode Reward: 14.0\n",
      "Step 1075 (3069387) @ Episode 4402/10000, loss: 0.0062614353373646744\n",
      "Episode Reward: 22.0\n",
      "Step 447 (3069834) @ Episode 4403/10000, loss: 0.0053820968605577953\n",
      "Episode Reward: 6.0\n",
      "Step 165 (3069999) @ Episode 4404/10000, loss: 0.0164051372557878548\n",
      " Copied model parameters to target network\n",
      "Step 1191 (3071025) @ Episode 4404/10000, loss: 0.0107612740248441785\n",
      "Episode Reward: 28.0\n",
      "Step 922 (3071947) @ Episode 4405/10000, loss: 0.0027933889068663124\n",
      "Episode Reward: 16.0\n",
      "Step 895 (3072842) @ Episode 4406/10000, loss: 0.0097898617386817936\n",
      "Episode Reward: 18.0\n",
      "Step 987 (3073829) @ Episode 4407/10000, loss: 0.0036593698896467686\n",
      "Episode Reward: 25.0\n",
      "Step 1203 (3075032) @ Episode 4408/10000, loss: 0.0039973277598619463\n",
      "Episode Reward: 22.0\n",
      "Step 856 (3075888) @ Episode 4409/10000, loss: 0.0137908235192298896\n",
      "Episode Reward: 14.0\n",
      "Step 1078 (3076966) @ Episode 4410/10000, loss: 0.0028469446115195755\n",
      "Episode Reward: 25.0\n",
      "Step 892 (3077858) @ Episode 4411/10000, loss: 0.0019478728063404564\n",
      "Episode Reward: 10.0\n",
      "Step 1274 (3079132) @ Episode 4412/10000, loss: 0.0124705880880355837\n",
      "Episode Reward: 28.0\n",
      "Step 867 (3079999) @ Episode 4413/10000, loss: 0.0028311258647590876\n",
      " Copied model parameters to target network\n",
      "Step 929 (3080061) @ Episode 4413/10000, loss: 0.0139024788513779645\n",
      "Episode Reward: 25.0\n",
      "Step 710 (3080771) @ Episode 4414/10000, loss: 0.0068038972094655045\n",
      "Episode Reward: 12.0\n",
      "Step 919 (3081690) @ Episode 4415/10000, loss: 0.0075352555140852934\n",
      "Episode Reward: 26.0\n",
      "Step 791 (3082481) @ Episode 4416/10000, loss: 0.0071055958978831775\n",
      "Episode Reward: 17.0\n",
      "Step 1059 (3083540) @ Episode 4417/10000, loss: 0.0012738995719701052\n",
      "Episode Reward: 31.0\n",
      "Step 818 (3084358) @ Episode 4418/10000, loss: 0.0098380688577890474\n",
      "Episode Reward: 18.0\n",
      "Step 1135 (3085493) @ Episode 4419/10000, loss: 0.0068770092912018313\n",
      "Episode Reward: 23.0\n",
      "Step 845 (3086338) @ Episode 4420/10000, loss: 0.0099799372255802155\n",
      "Episode Reward: 12.0\n",
      "Step 1053 (3087391) @ Episode 4421/10000, loss: 0.0029276418499648575\n",
      "Episode Reward: 24.0\n",
      "Step 696 (3088087) @ Episode 4422/10000, loss: 0.0034979232586920264\n",
      "Episode Reward: 12.0\n",
      "Step 1053 (3089140) @ Episode 4423/10000, loss: 0.0113772880285978323\n",
      "Episode Reward: 17.0\n",
      "Step 859 (3089999) @ Episode 4424/10000, loss: 0.0114715863019227985\n",
      " Copied model parameters to target network\n",
      "Step 915 (3090055) @ Episode 4424/10000, loss: 0.0059683076106011877\n",
      "Episode Reward: 16.0\n",
      "Step 793 (3090848) @ Episode 4425/10000, loss: 0.0049222973175346855\n",
      "Episode Reward: 20.0\n",
      "Step 1063 (3091911) @ Episode 4426/10000, loss: 0.0071629080921411514\n",
      "Episode Reward: 20.0\n",
      "Step 852 (3092763) @ Episode 4427/10000, loss: 0.0057224398478865625\n",
      "Episode Reward: 18.0\n",
      "Step 697 (3093460) @ Episode 4428/10000, loss: 0.0019299169071018696\n",
      "Episode Reward: 15.0\n",
      "Step 1241 (3094701) @ Episode 4429/10000, loss: 0.0077249645255506044\n",
      "Episode Reward: 33.0\n",
      "Step 331 (3095032) @ Episode 4430/10000, loss: 0.0057548121549189095\n",
      "Episode Reward: 3.0\n",
      "Step 832 (3095864) @ Episode 4431/10000, loss: 0.0072891120798885826\n",
      "Episode Reward: 14.0\n",
      "Step 817 (3096681) @ Episode 4432/10000, loss: 0.0084421392530202877\n",
      "Episode Reward: 17.0\n",
      "Step 728 (3097409) @ Episode 4433/10000, loss: 0.0081811044365167623\n",
      "Episode Reward: 16.0\n",
      "Step 743 (3098152) @ Episode 4434/10000, loss: 0.0095745082944631585\n",
      "Episode Reward: 12.0\n",
      "Step 1012 (3099164) @ Episode 4435/10000, loss: 0.0143045866861939436\n",
      "Episode Reward: 15.0\n",
      "Step 577 (3099741) @ Episode 4436/10000, loss: 0.0045067444443702795\n",
      "Episode Reward: 9.0\n",
      "Step 258 (3099999) @ Episode 4437/10000, loss: 0.0031509664840996265\n",
      " Copied model parameters to target network\n",
      "Step 1148 (3100889) @ Episode 4437/10000, loss: 0.0052217952907085425\n",
      "Episode Reward: 24.0\n",
      "Step 945 (3101834) @ Episode 4438/10000, loss: 0.0060081779956817638\n",
      "Episode Reward: 19.0\n",
      "Step 1246 (3103080) @ Episode 4439/10000, loss: 0.0061316713690757755\n",
      "Episode Reward: 35.0\n",
      "Step 676 (3103756) @ Episode 4440/10000, loss: 0.0068138921633362774\n",
      "Episode Reward: 18.0\n",
      "Step 1015 (3104771) @ Episode 4441/10000, loss: 0.0021454482339322567\n",
      "Episode Reward: 17.0\n",
      "Step 1340 (3106111) @ Episode 4442/10000, loss: 0.0126577857881784445\n",
      "Episode Reward: 32.0\n",
      "Step 684 (3106795) @ Episode 4443/10000, loss: 0.0050804633647203445\n",
      "Episode Reward: 10.0\n",
      "Step 977 (3107772) @ Episode 4444/10000, loss: 0.0131531571969389925\n",
      "Episode Reward: 27.0\n",
      "Step 953 (3108725) @ Episode 4445/10000, loss: 0.0127517692744731945\n",
      "Episode Reward: 22.0\n",
      "Step 729 (3109454) @ Episode 4446/10000, loss: 0.0028624327387660747\n",
      "Episode Reward: 13.0\n",
      "Step 545 (3109999) @ Episode 4447/10000, loss: 0.0209615826606750515\n",
      " Copied model parameters to target network\n",
      "Step 993 (3110447) @ Episode 4447/10000, loss: 0.0045830709859728813\n",
      "Episode Reward: 19.0\n",
      "Step 526 (3110973) @ Episode 4448/10000, loss: 0.0041247261688113213\n",
      "Episode Reward: 9.0\n",
      "Step 968 (3111941) @ Episode 4449/10000, loss: 0.0075052357278764255\n",
      "Episode Reward: 19.0\n",
      "Step 1257 (3113198) @ Episode 4450/10000, loss: 0.0054217753931886566\n",
      "Episode Reward: 24.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 00:36:19,087] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video004450.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 668 (3113866) @ Episode 4451/10000, loss: 0.0050742039456963547\n",
      "Episode Reward: 11.0\n",
      "Step 557 (3114423) @ Episode 4452/10000, loss: 0.0036111830268055285\n",
      "Episode Reward: 8.0\n",
      "Step 710 (3115133) @ Episode 4453/10000, loss: 0.0032271030358970165\n",
      "Episode Reward: 18.0\n",
      "Step 602 (3115735) @ Episode 4454/10000, loss: 0.0369162298738956453\n",
      "Episode Reward: 11.0\n",
      "Step 871 (3116606) @ Episode 4455/10000, loss: 0.0101516554132103922\n",
      "Episode Reward: 14.0\n",
      "Step 466 (3117072) @ Episode 4456/10000, loss: 0.0181560255587101047\n",
      "Episode Reward: 7.0\n",
      "Step 1045 (3118117) @ Episode 4457/10000, loss: 0.0031378250569105155\n",
      "Episode Reward: 21.0\n",
      "Step 718 (3118835) @ Episode 4458/10000, loss: 0.0054811863228678788\n",
      "Episode Reward: 23.0\n",
      "Step 791 (3119626) @ Episode 4459/10000, loss: 0.0086852144449949267\n",
      "Episode Reward: 18.0\n",
      "Step 373 (3119999) @ Episode 4460/10000, loss: 0.0105005847290158275\n",
      " Copied model parameters to target network\n",
      "Step 696 (3120322) @ Episode 4460/10000, loss: 0.0015097993891686201\n",
      "Episode Reward: 11.0\n",
      "Step 1008 (3121330) @ Episode 4461/10000, loss: 0.0060838591307401666\n",
      "Episode Reward: 20.0\n",
      "Step 758 (3122088) @ Episode 4462/10000, loss: 0.0034567825496196747\n",
      "Episode Reward: 13.0\n",
      "Step 667 (3122755) @ Episode 4463/10000, loss: 0.0181689951568841936\n",
      "Episode Reward: 10.0\n",
      "Step 1101 (3123856) @ Episode 4464/10000, loss: 0.0070392265915870676\n",
      "Episode Reward: 20.0\n",
      "Step 943 (3124799) @ Episode 4465/10000, loss: 0.0062506794929504395\n",
      "Episode Reward: 15.0\n",
      "Step 959 (3125758) @ Episode 4466/10000, loss: 0.0017482568509876728\n",
      "Episode Reward: 16.0\n",
      "Step 946 (3126704) @ Episode 4467/10000, loss: 0.0095649883151054388\n",
      "Episode Reward: 17.0\n",
      "Step 704 (3127408) @ Episode 4468/10000, loss: 0.0030647851526737213\n",
      "Episode Reward: 11.0\n",
      "Step 513 (3127921) @ Episode 4469/10000, loss: 0.0032157464884221554\n",
      "Episode Reward: 8.0\n",
      "Step 635 (3128556) @ Episode 4470/10000, loss: 0.0094675533473491679\n",
      "Episode Reward: 7.0\n",
      "Step 763 (3129319) @ Episode 4471/10000, loss: 0.0064627719111740596\n",
      "Episode Reward: 13.0\n",
      "Step 680 (3129999) @ Episode 4472/10000, loss: 0.0050463732331991252\n",
      " Copied model parameters to target network\n",
      "Step 1184 (3130503) @ Episode 4472/10000, loss: 0.0061595607548952133\n",
      "Episode Reward: 22.0\n",
      "Step 934 (3131437) @ Episode 4473/10000, loss: 0.0084137432277202614\n",
      "Episode Reward: 17.0\n",
      "Step 848 (3132285) @ Episode 4474/10000, loss: 0.0043686800636351116\n",
      "Episode Reward: 14.0\n",
      "Step 729 (3133014) @ Episode 4475/10000, loss: 0.0041135456413030624\n",
      "Episode Reward: 17.0\n",
      "Step 505 (3133519) @ Episode 4476/10000, loss: 0.0043262927792966376\n",
      "Episode Reward: 7.0\n",
      "Step 881 (3134400) @ Episode 4477/10000, loss: 0.0077071441337466243\n",
      "Episode Reward: 12.0\n",
      "Step 757 (3135157) @ Episode 4478/10000, loss: 0.0067009408958256245\n",
      "Episode Reward: 11.0\n",
      "Step 784 (3135941) @ Episode 4479/10000, loss: 0.0066422279924154287\n",
      "Episode Reward: 11.0\n",
      "Step 893 (3136834) @ Episode 4480/10000, loss: 0.0101330354809761056\n",
      "Episode Reward: 17.0\n",
      "Step 1287 (3138121) @ Episode 4481/10000, loss: 0.0100984694436192515\n",
      "Episode Reward: 31.0\n",
      "Step 1026 (3139147) @ Episode 4482/10000, loss: 0.0071561522781848914\n",
      "Episode Reward: 13.0\n",
      "Step 852 (3139999) @ Episode 4483/10000, loss: 0.0033242218196392063\n",
      " Copied model parameters to target network\n",
      "Step 962 (3140109) @ Episode 4483/10000, loss: 0.0076183858327567583\n",
      "Episode Reward: 19.0\n",
      "Step 852 (3140961) @ Episode 4484/10000, loss: 0.0080309621989727025\n",
      "Episode Reward: 19.0\n",
      "Step 664 (3141625) @ Episode 4485/10000, loss: 0.0044624265283346185\n",
      "Episode Reward: 9.0\n",
      "Step 1271 (3142896) @ Episode 4486/10000, loss: 0.0063810297288000583\n",
      "Episode Reward: 24.0\n",
      "Step 997 (3143893) @ Episode 4487/10000, loss: 0.0072573265060782437\n",
      "Episode Reward: 22.0\n",
      "Step 591 (3144484) @ Episode 4488/10000, loss: 0.0035446370020508766\n",
      "Episode Reward: 8.0\n",
      "Step 750 (3145234) @ Episode 4489/10000, loss: 0.0734110474586486895\n",
      "Episode Reward: 10.0\n",
      "Step 819 (3146053) @ Episode 4490/10000, loss: 0.0038644191808998585\n",
      "Episode Reward: 18.0\n",
      "Step 846 (3146899) @ Episode 4491/10000, loss: 0.0042422767728567125\n",
      "Episode Reward: 15.0\n",
      "Step 915 (3147814) @ Episode 4492/10000, loss: 0.0115195121616125114\n",
      "Episode Reward: 16.0\n",
      "Step 478 (3148292) @ Episode 4493/10000, loss: 0.0113687673583626758\n",
      "Episode Reward: 6.0\n",
      "Step 666 (3148958) @ Episode 4494/10000, loss: 0.0035994322970509534\n",
      "Episode Reward: 11.0\n",
      "Step 1041 (3149999) @ Episode 4495/10000, loss: 0.0123783443123102196\n",
      " Copied model parameters to target network\n",
      "Step 1152 (3150110) @ Episode 4495/10000, loss: 0.0057944795116782195\n",
      "Episode Reward: 21.0\n",
      "Step 1511 (3151621) @ Episode 4496/10000, loss: 0.0056774909608066085\n",
      "Episode Reward: 32.0\n",
      "Step 778 (3152399) @ Episode 4497/10000, loss: 0.0087781893089413647\n",
      "Episode Reward: 12.0\n",
      "Step 1190 (3153589) @ Episode 4498/10000, loss: 0.0045296689495444365\n",
      "Episode Reward: 21.0\n",
      "Step 683 (3154272) @ Episode 4499/10000, loss: 0.0061313100159168244\n",
      "Episode Reward: 10.0\n",
      "Step 1022 (3155294) @ Episode 4500/10000, loss: 0.0105259176343679433\n",
      "Episode Reward: 18.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 00:42:48,039] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video004500.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 890 (3156184) @ Episode 4501/10000, loss: 0.0037877373397350315\n",
      "Episode Reward: 15.0\n",
      "Step 1428 (3157612) @ Episode 4502/10000, loss: 0.0085489936172962194\n",
      "Episode Reward: 30.0\n",
      "Step 805 (3158417) @ Episode 4503/10000, loss: 0.0065747769549489025\n",
      "Episode Reward: 16.0\n",
      "Step 1106 (3159523) @ Episode 4504/10000, loss: 0.0037599888164550066\n",
      "Episode Reward: 18.0\n",
      "Step 476 (3159999) @ Episode 4505/10000, loss: 0.0065967985428869725\n",
      " Copied model parameters to target network\n",
      "Step 586 (3160109) @ Episode 4505/10000, loss: 0.0047121183015406136\n",
      "Episode Reward: 9.0\n",
      "Step 714 (3160823) @ Episode 4506/10000, loss: 0.0037704727146774533\n",
      "Episode Reward: 10.0\n",
      "Step 755 (3161578) @ Episode 4507/10000, loss: 0.0072699873708188534\n",
      "Episode Reward: 12.0\n",
      "Step 1090 (3162668) @ Episode 4508/10000, loss: 0.0035210489295423036\n",
      "Episode Reward: 24.0\n",
      "Step 755 (3163423) @ Episode 4509/10000, loss: 0.0029100179672241215\n",
      "Episode Reward: 12.0\n",
      "Step 945 (3164368) @ Episode 4510/10000, loss: 0.0102842543274164285\n",
      "Episode Reward: 15.0\n",
      "Step 1189 (3165557) @ Episode 4511/10000, loss: 0.0059350058436393747\n",
      "Episode Reward: 27.0\n",
      "Step 626 (3166183) @ Episode 4512/10000, loss: 0.0033231915440410376\n",
      "Episode Reward: 9.0\n",
      "Step 944 (3167127) @ Episode 4513/10000, loss: 0.0036654735449701548\n",
      "Episode Reward: 16.0\n",
      "Step 792 (3167919) @ Episode 4514/10000, loss: 0.0053723296150565154\n",
      "Episode Reward: 12.0\n",
      "Step 919 (3168838) @ Episode 4515/10000, loss: 0.0080352984368801125\n",
      "Episode Reward: 23.0\n",
      "Step 750 (3169588) @ Episode 4516/10000, loss: 0.0030592214316129684\n",
      "Episode Reward: 19.0\n",
      "Step 411 (3169999) @ Episode 4517/10000, loss: 0.0044671939685940743\n",
      " Copied model parameters to target network\n",
      "Step 826 (3170414) @ Episode 4517/10000, loss: 0.0064223329536616884\n",
      "Episode Reward: 19.0\n",
      "Step 983 (3171397) @ Episode 4518/10000, loss: 0.1631961166858673715\n",
      "Episode Reward: 16.0\n",
      "Step 709 (3172106) @ Episode 4519/10000, loss: 0.0091656688600778584\n",
      "Episode Reward: 17.0\n",
      "Step 563 (3172669) @ Episode 4520/10000, loss: 0.0059775868430733686\n",
      "Episode Reward: 9.0\n",
      "Step 811 (3173480) @ Episode 4521/10000, loss: 0.0149616515263915068\n",
      "Episode Reward: 13.0\n",
      "Step 981 (3174461) @ Episode 4522/10000, loss: 0.0141498558223247537\n",
      "Episode Reward: 19.0\n",
      "Step 808 (3175269) @ Episode 4523/10000, loss: 0.0058810650371015075\n",
      "Episode Reward: 17.0\n",
      "Step 762 (3176031) @ Episode 4524/10000, loss: 0.0048545817844569682\n",
      "Episode Reward: 11.0\n",
      "Step 505 (3176536) @ Episode 4525/10000, loss: 0.0029774720314890146\n",
      "Episode Reward: 10.0\n",
      "Step 674 (3177210) @ Episode 4526/10000, loss: 0.0168585982173681264\n",
      "Episode Reward: 11.0\n",
      "Step 858 (3178068) @ Episode 4527/10000, loss: 0.0036093890666961674\n",
      "Episode Reward: 14.0\n",
      "Step 635 (3178703) @ Episode 4528/10000, loss: 0.0144954659044742588\n",
      "Episode Reward: 12.0\n",
      "Step 788 (3179491) @ Episode 4529/10000, loss: 0.0055565675720572474\n",
      "Episode Reward: 19.0\n",
      "Step 481 (3179972) @ Episode 4530/10000, loss: 0.0100839324295520786\n",
      "Episode Reward: 6.0\n",
      "Step 27 (3179999) @ Episode 4531/10000, loss: 0.0048814397305250177\n",
      " Copied model parameters to target network\n",
      "Step 951 (3180923) @ Episode 4531/10000, loss: 0.0051350006833672523\n",
      "Episode Reward: 23.0\n",
      "Step 995 (3181918) @ Episode 4532/10000, loss: 0.0070106806233525283\n",
      "Episode Reward: 27.0\n",
      "Step 735 (3182653) @ Episode 4533/10000, loss: 0.0050424011424183846\n",
      "Episode Reward: 13.0\n",
      "Step 864 (3183517) @ Episode 4534/10000, loss: 0.0031462321057915688\n",
      "Episode Reward: 13.0\n",
      "Step 1098 (3184615) @ Episode 4535/10000, loss: 0.0057957805693149575\n",
      "Episode Reward: 18.0\n",
      "Step 1130 (3185745) @ Episode 4536/10000, loss: 0.0057680383324623112\n",
      "Episode Reward: 19.0\n",
      "Step 794 (3186539) @ Episode 4537/10000, loss: 0.0027482975274324417\n",
      "Episode Reward: 12.0\n",
      "Step 749 (3187288) @ Episode 4538/10000, loss: 0.0197063535451889044\n",
      "Episode Reward: 11.0\n",
      "Step 990 (3188278) @ Episode 4539/10000, loss: 0.0059071816504001625\n",
      "Episode Reward: 17.0\n",
      "Step 898 (3189176) @ Episode 4540/10000, loss: 0.0055095595307648185\n",
      "Episode Reward: 15.0\n",
      "Step 823 (3189999) @ Episode 4541/10000, loss: 0.0048532336950302123\n",
      " Copied model parameters to target network\n",
      "Step 877 (3190053) @ Episode 4541/10000, loss: 0.0048647518269717695\n",
      "Episode Reward: 16.0\n",
      "Step 932 (3190985) @ Episode 4542/10000, loss: 0.0123374126851558695\n",
      "Episode Reward: 20.0\n",
      "Step 552 (3191537) @ Episode 4543/10000, loss: 0.0067953355610370646\n",
      "Episode Reward: 8.0\n",
      "Step 988 (3192525) @ Episode 4544/10000, loss: 0.0064656483009457596\n",
      "Episode Reward: 14.0\n",
      "Step 1056 (3193581) @ Episode 4545/10000, loss: 0.0070911245420575146\n",
      "Episode Reward: 21.0\n",
      "Step 1082 (3194663) @ Episode 4546/10000, loss: 0.0039519667625427254\n",
      "Episode Reward: 17.0\n",
      "Step 929 (3195592) @ Episode 4547/10000, loss: 0.0034286268055438995\n",
      "Episode Reward: 12.0\n",
      "Step 830 (3196422) @ Episode 4548/10000, loss: 0.0034212383907288313\n",
      "Episode Reward: 16.0\n",
      "Step 1082 (3197504) @ Episode 4549/10000, loss: 0.0026634503155946735\n",
      "Episode Reward: 22.0\n",
      "Step 565 (3198069) @ Episode 4550/10000, loss: 0.0021774109918624163\n",
      "Episode Reward: 10.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 00:49:21,896] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video004550.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 746 (3198815) @ Episode 4551/10000, loss: 0.0040406500920653345\n",
      "Episode Reward: 10.0\n",
      "Step 757 (3199572) @ Episode 4552/10000, loss: 0.0017781867645680904\n",
      "Episode Reward: 11.0\n",
      "Step 427 (3199999) @ Episode 4553/10000, loss: 0.0046573672443628313\n",
      " Copied model parameters to target network\n",
      "Step 845 (3200417) @ Episode 4553/10000, loss: 0.0048586772754788446\n",
      "Episode Reward: 24.0\n",
      "Step 772 (3201189) @ Episode 4554/10000, loss: 0.0040827877819538127\n",
      "Episode Reward: 13.0\n",
      "Step 800 (3201989) @ Episode 4555/10000, loss: 0.0057769492268562323\n",
      "Episode Reward: 10.0\n",
      "Step 889 (3202878) @ Episode 4556/10000, loss: 0.0045190542005002524\n",
      "Episode Reward: 14.0\n",
      "Step 1031 (3203909) @ Episode 4557/10000, loss: 0.0045210518874228045\n",
      "Episode Reward: 21.0\n",
      "Step 1055 (3204964) @ Episode 4558/10000, loss: 0.0047396896407008173\n",
      "Episode Reward: 20.0\n",
      "Step 682 (3205646) @ Episode 4559/10000, loss: 0.0071044210344552994\n",
      "Episode Reward: 12.0\n",
      "Step 917 (3206563) @ Episode 4560/10000, loss: 0.0074238115921616554\n",
      "Episode Reward: 18.0\n",
      "Step 604 (3207167) @ Episode 4561/10000, loss: 0.0037541487254202366\n",
      "Episode Reward: 14.0\n",
      "Step 866 (3208033) @ Episode 4562/10000, loss: 0.0069526955485343936\n",
      "Episode Reward: 14.0\n",
      "Step 740 (3208773) @ Episode 4563/10000, loss: 0.0280122570693492997\n",
      "Episode Reward: 17.0\n",
      "Step 890 (3209663) @ Episode 4564/10000, loss: 0.0112004177644848823\n",
      "Episode Reward: 16.0\n",
      "Step 336 (3209999) @ Episode 4565/10000, loss: 0.0048195687122642998\n",
      " Copied model parameters to target network\n",
      "Step 837 (3210500) @ Episode 4565/10000, loss: 0.0096692051738500615\n",
      "Episode Reward: 13.0\n",
      "Step 1016 (3211516) @ Episode 4566/10000, loss: 0.0031442446634173393\n",
      "Episode Reward: 12.0\n",
      "Step 839 (3212355) @ Episode 4567/10000, loss: 0.0213499236851930625\n",
      "Episode Reward: 13.0\n",
      "Step 1255 (3213610) @ Episode 4568/10000, loss: 0.0113567560911178593\n",
      "Episode Reward: 29.0\n",
      "Step 1144 (3214754) @ Episode 4569/10000, loss: 0.0058458484709262855\n",
      "Episode Reward: 26.0\n",
      "Step 1238 (3215992) @ Episode 4570/10000, loss: 0.0047316355630755424\n",
      "Episode Reward: 30.0\n",
      "Step 1308 (3217300) @ Episode 4571/10000, loss: 0.0093065639957785654\n",
      "Episode Reward: 31.0\n",
      "Step 940 (3218240) @ Episode 4572/10000, loss: 0.0102210426703095443\n",
      "Episode Reward: 15.0\n",
      "Step 979 (3219219) @ Episode 4573/10000, loss: 0.0034081949852406986\n",
      "Episode Reward: 31.0\n",
      "Step 780 (3219999) @ Episode 4574/10000, loss: 0.0068060476332902915\n",
      " Copied model parameters to target network\n",
      "Step 839 (3220058) @ Episode 4574/10000, loss: 0.0039014047943055637\n",
      "Episode Reward: 10.0\n",
      "Step 595 (3220653) @ Episode 4575/10000, loss: 0.0091964136809110643\n",
      "Episode Reward: 8.0\n",
      "Step 839 (3221492) @ Episode 4576/10000, loss: 0.0042743515223264694\n",
      "Episode Reward: 14.0\n",
      "Step 557 (3222049) @ Episode 4577/10000, loss: 0.0031401976011693478\n",
      "Episode Reward: 12.0\n",
      "Step 989 (3223038) @ Episode 4578/10000, loss: 0.0054444260895252235\n",
      "Episode Reward: 18.0\n",
      "Step 864 (3223902) @ Episode 4579/10000, loss: 0.0029734664130955935\n",
      "Episode Reward: 15.0\n",
      "Step 1004 (3224906) @ Episode 4580/10000, loss: 0.012671393342316151\n",
      "Episode Reward: 17.0\n",
      "Step 919 (3225825) @ Episode 4581/10000, loss: 0.0055228015407919885\n",
      "Episode Reward: 16.0\n",
      "Step 611 (3226436) @ Episode 4582/10000, loss: 0.0058792526833713055\n",
      "Episode Reward: 7.0\n",
      "Step 1144 (3227580) @ Episode 4583/10000, loss: 0.0065903603099286565\n",
      "Episode Reward: 21.0\n",
      "Step 666 (3228246) @ Episode 4584/10000, loss: 0.0040808189660310745\n",
      "Episode Reward: 11.0\n",
      "Step 483 (3228729) @ Episode 4585/10000, loss: 0.0048271096311509615\n",
      "Episode Reward: 7.0\n",
      "Step 937 (3229666) @ Episode 4586/10000, loss: 0.0148339709267020235\n",
      "Episode Reward: 17.0\n",
      "Step 333 (3229999) @ Episode 4587/10000, loss: 0.0043583614751696595\n",
      " Copied model parameters to target network\n",
      "Step 1059 (3230725) @ Episode 4587/10000, loss: 0.0042582433670759253\n",
      "Episode Reward: 22.0\n",
      "Step 1125 (3231850) @ Episode 4588/10000, loss: 0.0033326488919556145\n",
      "Episode Reward: 22.0\n",
      "Step 758 (3232608) @ Episode 4589/10000, loss: 0.0060443780384957797\n",
      "Episode Reward: 17.0\n",
      "Step 665 (3233273) @ Episode 4590/10000, loss: 0.0073682353831827647\n",
      "Episode Reward: 10.0\n",
      "Step 839 (3234112) @ Episode 4591/10000, loss: 0.0086067328229546552\n",
      "Episode Reward: 13.0\n",
      "Step 656 (3234768) @ Episode 4592/10000, loss: 0.0057033281773328783\n",
      "Episode Reward: 10.0\n",
      "Step 1006 (3235774) @ Episode 4593/10000, loss: 0.0081663047894835473\n",
      "Episode Reward: 19.0\n",
      "Step 1401 (3237175) @ Episode 4594/10000, loss: 0.0034166071563959127\n",
      "Episode Reward: 33.0\n",
      "Step 594 (3237769) @ Episode 4595/10000, loss: 0.0052236597985029228\n",
      "Episode Reward: 13.0\n",
      "Step 929 (3238698) @ Episode 4596/10000, loss: 0.0114871822297573095\n",
      "Episode Reward: 23.0\n",
      "Step 838 (3239536) @ Episode 4597/10000, loss: 0.0094326613470911985\n",
      "Episode Reward: 18.0\n",
      "Step 463 (3239999) @ Episode 4598/10000, loss: 0.0039314548484981065\n",
      " Copied model parameters to target network\n",
      "Step 1398 (3240934) @ Episode 4598/10000, loss: 0.0099315186962485314\n",
      "Episode Reward: 34.0\n",
      "Step 823 (3241757) @ Episode 4599/10000, loss: 0.0129674058407545095\n",
      "Episode Reward: 18.0\n",
      "Step 938 (3242695) @ Episode 4600/10000, loss: 0.0367587246000766755\n",
      "Episode Reward: 15.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 00:56:12,667] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video004600.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 546 (3243241) @ Episode 4601/10000, loss: 0.0026261648163199425\n",
      "Episode Reward: 8.0\n",
      "Step 864 (3244105) @ Episode 4602/10000, loss: 0.1121790930628776664\n",
      "Episode Reward: 11.0\n",
      "Step 600 (3244705) @ Episode 4603/10000, loss: 0.0077686472795903685\n",
      "Episode Reward: 7.0\n",
      "Step 970 (3245675) @ Episode 4604/10000, loss: 0.0082212733104825025\n",
      "Episode Reward: 15.0\n",
      "Step 685 (3246360) @ Episode 4605/10000, loss: 0.0041526891291141516\n",
      "Episode Reward: 11.0\n",
      "Step 559 (3246919) @ Episode 4606/10000, loss: 0.0032960220705717872\n",
      "Episode Reward: 8.0\n",
      "Step 1107 (3248026) @ Episode 4607/10000, loss: 0.0045260712504386933\n",
      "Episode Reward: 24.0\n",
      "Step 787 (3248813) @ Episode 4608/10000, loss: 0.0076571637764573178\n",
      "Episode Reward: 13.0\n",
      "Step 764 (3249577) @ Episode 4609/10000, loss: 0.0035341051407158375\n",
      "Episode Reward: 12.0\n",
      "Step 422 (3249999) @ Episode 4610/10000, loss: 0.0029641110450029373\n",
      " Copied model parameters to target network\n",
      "Step 1232 (3250809) @ Episode 4610/10000, loss: 0.0038998313248157514\n",
      "Episode Reward: 25.0\n",
      "Step 667 (3251476) @ Episode 4611/10000, loss: 0.0086126308888196956\n",
      "Episode Reward: 7.0\n",
      "Step 1064 (3252540) @ Episode 4612/10000, loss: 0.0066124764271080494\n",
      "Episode Reward: 23.0\n",
      "Step 1074 (3253614) @ Episode 4613/10000, loss: 0.0129931895062327384\n",
      "Episode Reward: 21.0\n",
      "Step 817 (3254431) @ Episode 4614/10000, loss: 0.0091268960386514665\n",
      "Episode Reward: 14.0\n",
      "Step 880 (3255311) @ Episode 4615/10000, loss: 0.0036343815736472607\n",
      "Episode Reward: 15.0\n",
      "Step 1194 (3256505) @ Episode 4616/10000, loss: 0.0152965132147073756\n",
      "Episode Reward: 22.0\n",
      "Step 663 (3257168) @ Episode 4617/10000, loss: 0.0024823988787829876\n",
      "Episode Reward: 10.0\n",
      "Step 464 (3257632) @ Episode 4618/10000, loss: 0.0260306037962436683\n",
      "Episode Reward: 6.0\n",
      "Step 662 (3258294) @ Episode 4619/10000, loss: 0.0068143410608172425\n",
      "Episode Reward: 7.0\n",
      "Step 694 (3258988) @ Episode 4620/10000, loss: 0.0083240177482366563\n",
      "Episode Reward: 11.0\n",
      "Step 753 (3259741) @ Episode 4621/10000, loss: 0.0744730085134506269\n",
      "Episode Reward: 16.0\n",
      "Step 258 (3259999) @ Episode 4622/10000, loss: 0.0024163895286619663\n",
      " Copied model parameters to target network\n",
      "Step 1143 (3260884) @ Episode 4622/10000, loss: 0.0041020670905709276\n",
      "Episode Reward: 22.0\n",
      "Step 802 (3261686) @ Episode 4623/10000, loss: 0.0215915292501449636\n",
      "Episode Reward: 14.0\n",
      "Step 879 (3262565) @ Episode 4624/10000, loss: 0.0138839287683367734\n",
      "Episode Reward: 15.0\n",
      "Step 988 (3263553) @ Episode 4625/10000, loss: 0.0051973331719636924\n",
      "Episode Reward: 21.0\n",
      "Step 729 (3264282) @ Episode 4626/10000, loss: 0.0080427955836057665\n",
      "Episode Reward: 12.0\n",
      "Step 893 (3265175) @ Episode 4627/10000, loss: 0.0053616669028997427\n",
      "Episode Reward: 22.0\n",
      "Step 934 (3266109) @ Episode 4628/10000, loss: 0.0053191902115941055\n",
      "Episode Reward: 18.0\n",
      "Step 905 (3267014) @ Episode 4629/10000, loss: 0.0084464438259601615\n",
      "Episode Reward: 12.0\n",
      "Step 886 (3267900) @ Episode 4630/10000, loss: 0.0043911151587963175\n",
      "Episode Reward: 17.0\n",
      "Step 527 (3268427) @ Episode 4631/10000, loss: 0.0149348750710487374\n",
      "Episode Reward: 8.0\n",
      "Step 1145 (3269572) @ Episode 4632/10000, loss: 0.0051262555643916135\n",
      "Episode Reward: 20.0\n",
      "Step 427 (3269999) @ Episode 4633/10000, loss: 0.0031202845275402076\n",
      " Copied model parameters to target network\n",
      "Step 1281 (3270853) @ Episode 4633/10000, loss: 0.0046932082623243335\n",
      "Episode Reward: 21.0\n",
      "Step 901 (3271754) @ Episode 4634/10000, loss: 0.0021695699542760853\n",
      "Episode Reward: 20.0\n",
      "Step 1063 (3272817) @ Episode 4635/10000, loss: 0.0110166016966104534\n",
      "Episode Reward: 28.0\n",
      "Step 776 (3273593) @ Episode 4636/10000, loss: 0.0122504588216543243\n",
      "Episode Reward: 12.0\n",
      "Step 1221 (3274814) @ Episode 4637/10000, loss: 0.0074927075766026975\n",
      "Episode Reward: 21.0\n",
      "Step 975 (3275789) @ Episode 4638/10000, loss: 0.0104411141946911815\n",
      "Episode Reward: 19.0\n",
      "Step 850 (3276639) @ Episode 4639/10000, loss: 0.0030524651519954205\n",
      "Episode Reward: 16.0\n",
      "Step 775 (3277414) @ Episode 4640/10000, loss: 0.0078444406390190127\n",
      "Episode Reward: 11.0\n",
      "Step 893 (3278307) @ Episode 4641/10000, loss: 0.0084441425278782844\n",
      "Episode Reward: 24.0\n",
      "Step 1043 (3279350) @ Episode 4642/10000, loss: 0.0026592474896460775\n",
      "Episode Reward: 29.0\n",
      "Step 649 (3279999) @ Episode 4643/10000, loss: 0.0029340763576328754\n",
      " Copied model parameters to target network\n",
      "Step 877 (3280227) @ Episode 4643/10000, loss: 0.0030033607035875325\n",
      "Episode Reward: 15.0\n",
      "Step 1455 (3281682) @ Episode 4644/10000, loss: 0.0045175421983003625\n",
      "Episode Reward: 36.0\n",
      "Step 681 (3282363) @ Episode 4645/10000, loss: 0.0047060120850801476\n",
      "Episode Reward: 17.0\n",
      "Step 861 (3283224) @ Episode 4646/10000, loss: 0.0091011663898825652\n",
      "Episode Reward: 15.0\n",
      "Step 1181 (3284405) @ Episode 4647/10000, loss: 0.0028548287227749825\n",
      "Episode Reward: 24.0\n",
      "Step 754 (3285159) @ Episode 4648/10000, loss: 0.0121361007913947135\n",
      "Episode Reward: 13.0\n",
      "Step 990 (3286149) @ Episode 4649/10000, loss: 0.0075072851032018666\n",
      "Episode Reward: 19.0\n",
      "Step 1161 (3287310) @ Episode 4650/10000, loss: 0.0036537770647555593\n",
      "Episode Reward: 24.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 01:03:01,510] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video004650.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 917 (3288227) @ Episode 4651/10000, loss: 0.0126978028565645227\n",
      "Episode Reward: 15.0\n",
      "Step 690 (3288917) @ Episode 4652/10000, loss: 0.0057542305439710624\n",
      "Episode Reward: 12.0\n",
      "Step 1082 (3289999) @ Episode 4653/10000, loss: 0.0047280164435505872\n",
      " Copied model parameters to target network\n",
      "Step 1329 (3290246) @ Episode 4653/10000, loss: 0.0043719066306948664\n",
      "Episode Reward: 27.0\n",
      "Step 852 (3291098) @ Episode 4654/10000, loss: 0.0035820775665342808\n",
      "Episode Reward: 19.0\n",
      "Step 1033 (3292131) @ Episode 4655/10000, loss: 0.0098064821213483815\n",
      "Episode Reward: 19.0\n",
      "Step 869 (3293000) @ Episode 4656/10000, loss: 0.0105135701596736987\n",
      "Episode Reward: 17.0\n",
      "Step 741 (3293741) @ Episode 4657/10000, loss: 0.0053770220838487153\n",
      "Episode Reward: 12.0\n",
      "Step 432 (3294173) @ Episode 4658/10000, loss: 0.0049831909127533445\n",
      "Episode Reward: 5.0\n",
      "Step 1066 (3295239) @ Episode 4659/10000, loss: 0.0015734690241515636\n",
      "Episode Reward: 23.0\n",
      "Step 846 (3296085) @ Episode 4660/10000, loss: 0.0049627870321273865\n",
      "Episode Reward: 14.0\n",
      "Step 909 (3296994) @ Episode 4661/10000, loss: 0.0083017777651548395\n",
      "Episode Reward: 15.0\n",
      "Step 700 (3297694) @ Episode 4662/10000, loss: 0.0066623231396079065\n",
      "Episode Reward: 14.0\n",
      "Step 1107 (3298801) @ Episode 4663/10000, loss: 0.0048092952929437162\n",
      "Episode Reward: 25.0\n",
      "Step 747 (3299548) @ Episode 4664/10000, loss: 0.0074033616110682497\n",
      "Episode Reward: 13.0\n",
      "Step 451 (3299999) @ Episode 4665/10000, loss: 0.0072425678372383125\n",
      " Copied model parameters to target network\n",
      "Step 608 (3300156) @ Episode 4665/10000, loss: 0.0044434741139411935\n",
      "Episode Reward: 10.0\n",
      "Step 763 (3300919) @ Episode 4666/10000, loss: 0.0090521331876516345\n",
      "Episode Reward: 12.0\n",
      "Step 861 (3301780) @ Episode 4667/10000, loss: 0.0061535616405308255\n",
      "Episode Reward: 12.0\n",
      "Step 794 (3302574) @ Episode 4668/10000, loss: 0.0126715945079922684\n",
      "Episode Reward: 18.0\n",
      "Step 477 (3303051) @ Episode 4669/10000, loss: 0.0073267319239676553\n",
      "Episode Reward: 13.0\n",
      "Step 1508 (3304559) @ Episode 4670/10000, loss: 0.0018721589585766196\n",
      "Episode Reward: 40.0\n",
      "Step 994 (3305553) @ Episode 4671/10000, loss: 0.0048230597749352455\n",
      "Episode Reward: 20.0\n",
      "Step 1286 (3306839) @ Episode 4672/10000, loss: 0.0025255561340600258\n",
      "Episode Reward: 35.0\n",
      "Step 1431 (3308270) @ Episode 4673/10000, loss: 0.0029857954941689977\n",
      "Episode Reward: 25.0\n",
      "Step 1255 (3309525) @ Episode 4674/10000, loss: 0.0049816798418760365\n",
      "Episode Reward: 19.0\n",
      "Step 474 (3309999) @ Episode 4675/10000, loss: 0.0054080057889223153\n",
      " Copied model parameters to target network\n",
      "Step 1068 (3310593) @ Episode 4675/10000, loss: 0.0099401623010635387\n",
      "Episode Reward: 23.0\n",
      "Step 874 (3311467) @ Episode 4676/10000, loss: 0.0065308157354593282\n",
      "Episode Reward: 15.0\n",
      "Step 790 (3312257) @ Episode 4677/10000, loss: 0.0084537407383322725\n",
      "Episode Reward: 12.0\n",
      "Step 842 (3313099) @ Episode 4678/10000, loss: 0.0035901428200304517\n",
      "Episode Reward: 14.0\n",
      "Step 900 (3313999) @ Episode 4679/10000, loss: 0.0123842228204011926\n",
      "Episode Reward: 19.0\n",
      "Step 891 (3314890) @ Episode 4680/10000, loss: 0.0083089666441082953\n",
      "Episode Reward: 12.0\n",
      "Step 803 (3315693) @ Episode 4681/10000, loss: 0.0046471259556710727\n",
      "Episode Reward: 15.0\n",
      "Step 410 (3316103) @ Episode 4682/10000, loss: 0.0042089298367500305\n",
      "Episode Reward: 5.0\n",
      "Step 1051 (3317154) @ Episode 4683/10000, loss: 0.0083800600841641433\n",
      "Episode Reward: 27.0\n",
      "Step 850 (3318004) @ Episode 4684/10000, loss: 0.0050346083007752895\n",
      "Episode Reward: 15.0\n",
      "Step 823 (3318827) @ Episode 4685/10000, loss: 0.0075389845296740538\n",
      "Episode Reward: 17.0\n",
      "Step 867 (3319694) @ Episode 4686/10000, loss: 0.0429260730743408245\n",
      "Episode Reward: 18.0\n",
      "Step 305 (3319999) @ Episode 4687/10000, loss: 0.0102132251486182217\n",
      " Copied model parameters to target network\n",
      "Step 962 (3320656) @ Episode 4687/10000, loss: 0.0035872333683073527\n",
      "Episode Reward: 15.0\n",
      "Step 967 (3321623) @ Episode 4688/10000, loss: 0.0040358733385801315\n",
      "Episode Reward: 24.0\n",
      "Step 590 (3322213) @ Episode 4689/10000, loss: 0.0078857494518160825\n",
      "Episode Reward: 7.0\n",
      "Step 523 (3322736) @ Episode 4690/10000, loss: 0.0092237656936049465\n",
      "Episode Reward: 7.0\n",
      "Step 947 (3323683) @ Episode 4691/10000, loss: 0.0159033965319395075\n",
      "Episode Reward: 13.0\n",
      "Step 866 (3324549) @ Episode 4692/10000, loss: 0.0036062537692487246\n",
      "Episode Reward: 14.0\n",
      "Step 817 (3325366) @ Episode 4693/10000, loss: 0.0030930202919989824\n",
      "Episode Reward: 20.0\n",
      "Step 882 (3326248) @ Episode 4694/10000, loss: 0.0160756185650825587\n",
      "Episode Reward: 16.0\n",
      "Step 679 (3326927) @ Episode 4695/10000, loss: 0.0142873600125312896\n",
      "Episode Reward: 11.0\n",
      "Step 823 (3327750) @ Episode 4696/10000, loss: 0.0071231294423341754\n",
      "Episode Reward: 12.0\n",
      "Step 700 (3328450) @ Episode 4697/10000, loss: 0.0102013060823082925\n",
      "Episode Reward: 12.0\n",
      "Step 1064 (3329514) @ Episode 4698/10000, loss: 0.0063896244391798974\n",
      "Episode Reward: 21.0\n",
      "Step 485 (3329999) @ Episode 4699/10000, loss: 0.0073438072577118875\n",
      " Copied model parameters to target network\n",
      "Step 587 (3330101) @ Episode 4699/10000, loss: 0.0064672403968870644\n",
      "Episode Reward: 8.0\n",
      "Step 951 (3331052) @ Episode 4700/10000, loss: 0.0080536240711808286\n",
      "Episode Reward: 23.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 01:09:42,552] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video004700.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 944 (3331996) @ Episode 4701/10000, loss: 0.0856983438134193424\n",
      "Episode Reward: 20.0\n",
      "Step 1211 (3333207) @ Episode 4702/10000, loss: 0.0078174285590648655\n",
      "Episode Reward: 26.0\n",
      "Step 853 (3334060) @ Episode 4703/10000, loss: 0.0043853898532688626\n",
      "Episode Reward: 18.0\n",
      "Step 1405 (3335465) @ Episode 4704/10000, loss: 0.0059275575913488865\n",
      "Episode Reward: 31.0\n",
      "Step 602 (3336067) @ Episode 4705/10000, loss: 0.0092843966558575635\n",
      "Episode Reward: 10.0\n",
      "Step 748 (3336815) @ Episode 4706/10000, loss: 0.0208736117929220224\n",
      "Episode Reward: 12.0\n",
      "Step 659 (3337474) @ Episode 4707/10000, loss: 0.0054217232391238216\n",
      "Episode Reward: 11.0\n",
      "Step 923 (3338397) @ Episode 4708/10000, loss: 0.0064464099705219274\n",
      "Episode Reward: 19.0\n",
      "Step 830 (3339227) @ Episode 4709/10000, loss: 0.0966412425041198763\n",
      "Episode Reward: 20.0\n",
      "Step 772 (3339999) @ Episode 4710/10000, loss: 0.0058375522494316133\n",
      " Copied model parameters to target network\n",
      "Step 1465 (3340692) @ Episode 4710/10000, loss: 0.0084984879940748214\n",
      "Episode Reward: 32.0\n",
      "Step 840 (3341532) @ Episode 4711/10000, loss: 0.0153607502579689037\n",
      "Episode Reward: 13.0\n",
      "Step 607 (3342139) @ Episode 4712/10000, loss: 0.0020241586025804284\n",
      "Episode Reward: 10.0\n",
      "Step 1230 (3343369) @ Episode 4713/10000, loss: 0.0056613013148307863\n",
      "Episode Reward: 28.0\n",
      "Step 684 (3344053) @ Episode 4714/10000, loss: 0.0143105927854776384\n",
      "Episode Reward: 12.0\n",
      "Step 957 (3345010) @ Episode 4715/10000, loss: 0.0068020271137356765\n",
      "Episode Reward: 17.0\n",
      "Step 939 (3345949) @ Episode 4716/10000, loss: 0.0032829120755195618\n",
      "Episode Reward: 16.0\n",
      "Step 1042 (3346991) @ Episode 4717/10000, loss: 0.0131201492622494786\n",
      "Episode Reward: 17.0\n",
      "Step 617 (3347608) @ Episode 4718/10000, loss: 0.0059473458677530294\n",
      "Episode Reward: 12.0\n",
      "Step 1028 (3348636) @ Episode 4719/10000, loss: 0.0099890604615211494\n",
      "Episode Reward: 18.0\n",
      "Step 881 (3349517) @ Episode 4720/10000, loss: 0.0099155772477388383\n",
      "Episode Reward: 26.0\n",
      "Step 482 (3349999) @ Episode 4721/10000, loss: 0.0039702840149402624\n",
      " Copied model parameters to target network\n",
      "Step 550 (3350067) @ Episode 4721/10000, loss: 0.0051490929909050465\n",
      "Episode Reward: 9.0\n",
      "Step 1030 (3351097) @ Episode 4722/10000, loss: 0.0078961970284581185\n",
      "Episode Reward: 24.0\n",
      "Step 998 (3352095) @ Episode 4723/10000, loss: 0.0045303744263947015\n",
      "Episode Reward: 21.0\n",
      "Step 701 (3352796) @ Episode 4724/10000, loss: 0.0072646210901439193\n",
      "Episode Reward: 13.0\n",
      "Step 628 (3353424) @ Episode 4725/10000, loss: 0.0037697691004723316\n",
      "Episode Reward: 12.0\n",
      "Step 1176 (3354600) @ Episode 4726/10000, loss: 0.0044711721129715445\n",
      "Episode Reward: 19.0\n",
      "Step 933 (3355533) @ Episode 4727/10000, loss: 0.0055661816149950033\n",
      "Episode Reward: 25.0\n",
      "Step 1271 (3356804) @ Episode 4728/10000, loss: 0.0052643632516264915\n",
      "Episode Reward: 27.0\n",
      "Step 1045 (3357849) @ Episode 4729/10000, loss: 0.0072523308917880065\n",
      "Episode Reward: 24.0\n",
      "Step 1140 (3358989) @ Episode 4730/10000, loss: 0.0054675471037626275\n",
      "Episode Reward: 23.0\n",
      "Step 769 (3359758) @ Episode 4731/10000, loss: 0.0069805718958377847\n",
      "Episode Reward: 16.0\n",
      "Step 241 (3359999) @ Episode 4732/10000, loss: 0.0027998995501548055\n",
      " Copied model parameters to target network\n",
      "Step 753 (3360511) @ Episode 4732/10000, loss: 0.0104025732725858695\n",
      "Episode Reward: 11.0\n",
      "Step 1066 (3361577) @ Episode 4733/10000, loss: 0.0234232824295759243\n",
      "Episode Reward: 26.0\n",
      "Step 827 (3362404) @ Episode 4734/10000, loss: 0.0045597823336720473\n",
      "Episode Reward: 14.0\n",
      "Step 931 (3363335) @ Episode 4735/10000, loss: 0.0047715362161397934\n",
      "Episode Reward: 28.0\n",
      "Step 1160 (3364495) @ Episode 4736/10000, loss: 0.0104583483189344446\n",
      "Episode Reward: 30.0\n",
      "Step 1127 (3365622) @ Episode 4737/10000, loss: 0.0076730088330805363\n",
      "Episode Reward: 26.0\n",
      "Step 991 (3366613) @ Episode 4738/10000, loss: 0.0245775412768125536\n",
      "Episode Reward: 23.0\n",
      "Step 864 (3367477) @ Episode 4739/10000, loss: 0.0050401203334331516\n",
      "Episode Reward: 16.0\n",
      "Step 812 (3368289) @ Episode 4740/10000, loss: 0.0072633279487490654\n",
      "Episode Reward: 16.0\n",
      "Step 1038 (3369327) @ Episode 4741/10000, loss: 0.0068074418231844913\n",
      "Episode Reward: 16.0\n",
      "Step 672 (3369999) @ Episode 4742/10000, loss: 0.0071948440745472916\n",
      " Copied model parameters to target network\n",
      "Step 1083 (3370410) @ Episode 4742/10000, loss: 0.0087159983813762663\n",
      "Episode Reward: 22.0\n",
      "Step 1135 (3371545) @ Episode 4743/10000, loss: 0.0036436696536839014\n",
      "Episode Reward: 23.0\n",
      "Step 584 (3372129) @ Episode 4744/10000, loss: 0.0140357427299022674\n",
      "Episode Reward: 9.0\n",
      "Step 954 (3373083) @ Episode 4745/10000, loss: 0.0045981723815202718\n",
      "Episode Reward: 21.0\n",
      "Step 862 (3373945) @ Episode 4746/10000, loss: 0.0069697261787950996\n",
      "Episode Reward: 14.0\n",
      "Step 620 (3374565) @ Episode 4747/10000, loss: 0.0047251442447304726\n",
      "Episode Reward: 12.0\n",
      "Step 733 (3375298) @ Episode 4748/10000, loss: 0.0055296160280704546\n",
      "Episode Reward: 12.0\n",
      "Step 613 (3375911) @ Episode 4749/10000, loss: 0.0034444257616996765\n",
      "Episode Reward: 10.0\n",
      "Step 947 (3376858) @ Episode 4750/10000, loss: 0.0172934401780366945\n",
      "Episode Reward: 13.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 01:16:41,912] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video004750.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 714 (3377572) @ Episode 4751/10000, loss: 0.0136211225762963365\n",
      "Episode Reward: 11.0\n",
      "Step 1244 (3378816) @ Episode 4752/10000, loss: 0.0053493352606892595\n",
      "Episode Reward: 30.0\n",
      "Step 611 (3379427) @ Episode 4753/10000, loss: 0.0096414070576429375\n",
      "Episode Reward: 17.0\n",
      "Step 572 (3379999) @ Episode 4754/10000, loss: 0.0036446489393711095\n",
      " Copied model parameters to target network\n",
      "Step 1154 (3380581) @ Episode 4754/10000, loss: 0.0032158941030502326\n",
      "Episode Reward: 28.0\n",
      "Step 1125 (3381706) @ Episode 4755/10000, loss: 0.0094891907647252084\n",
      "Episode Reward: 26.0\n",
      "Step 1067 (3382773) @ Episode 4756/10000, loss: 0.0045582824386656284\n",
      "Episode Reward: 33.0\n",
      "Step 803 (3383576) @ Episode 4757/10000, loss: 0.0040214699693024163\n",
      "Episode Reward: 18.0\n",
      "Step 785 (3384361) @ Episode 4758/10000, loss: 0.1109403818845748944\n",
      "Episode Reward: 14.0\n",
      "Step 1010 (3385371) @ Episode 4759/10000, loss: 0.0047047901898622513\n",
      "Episode Reward: 23.0\n",
      "Step 732 (3386103) @ Episode 4760/10000, loss: 0.0033607003279030323\n",
      "Episode Reward: 15.0\n",
      "Step 1021 (3387124) @ Episode 4761/10000, loss: 0.0043640150688588623\n",
      "Episode Reward: 18.0\n",
      "Step 974 (3388098) @ Episode 4762/10000, loss: 0.0043751569464802743\n",
      "Episode Reward: 17.0\n",
      "Step 834 (3388932) @ Episode 4763/10000, loss: 0.0085298772901296625\n",
      "Episode Reward: 14.0\n",
      "Step 705 (3389637) @ Episode 4764/10000, loss: 0.0026696231216192245\n",
      "Episode Reward: 12.0\n",
      "Step 362 (3389999) @ Episode 4765/10000, loss: 0.0052378345280885735\n",
      " Copied model parameters to target network\n",
      "Step 620 (3390257) @ Episode 4765/10000, loss: 0.0031587928533554077\n",
      "Episode Reward: 14.0\n",
      "Step 662 (3390919) @ Episode 4766/10000, loss: 0.0045266775414347654\n",
      "Episode Reward: 10.0\n",
      "Step 899 (3391818) @ Episode 4767/10000, loss: 0.0052231056615710266\n",
      "Episode Reward: 22.0\n",
      "Step 1138 (3392956) @ Episode 4768/10000, loss: 0.0026322868652641773\n",
      "Episode Reward: 24.0\n",
      "Step 873 (3393829) @ Episode 4769/10000, loss: 0.0050090071745216857\n",
      "Episode Reward: 13.0\n",
      "Step 901 (3394730) @ Episode 4770/10000, loss: 0.0085318209603428844\n",
      "Episode Reward: 15.0\n",
      "Step 712 (3395442) @ Episode 4771/10000, loss: 0.0026048938743770123\n",
      "Episode Reward: 9.0\n",
      "Step 634 (3396076) @ Episode 4772/10000, loss: 0.0087020434439182285\n",
      "Episode Reward: 11.0\n",
      "Step 874 (3396950) @ Episode 4773/10000, loss: 0.0030080676078796387\n",
      "Episode Reward: 19.0\n",
      "Step 870 (3397820) @ Episode 4774/10000, loss: 0.0056315381079912197\n",
      "Episode Reward: 15.0\n",
      "Step 890 (3398710) @ Episode 4775/10000, loss: 0.0058797504752874374\n",
      "Episode Reward: 21.0\n",
      "Step 732 (3399442) @ Episode 4776/10000, loss: 0.0060632918030023575\n",
      "Episode Reward: 15.0\n",
      "Step 557 (3399999) @ Episode 4777/10000, loss: 0.0028930027037858963\n",
      " Copied model parameters to target network\n",
      "Step 780 (3400222) @ Episode 4777/10000, loss: 0.1001692861318588346\n",
      "Episode Reward: 15.0\n",
      "Step 815 (3401037) @ Episode 4778/10000, loss: 0.0032882646191865206\n",
      "Episode Reward: 17.0\n",
      "Step 748 (3401785) @ Episode 4779/10000, loss: 0.0045067612081766134\n",
      "Episode Reward: 13.0\n",
      "Step 617 (3402402) @ Episode 4780/10000, loss: 0.0061804046854376793\n",
      "Episode Reward: 10.0\n",
      "Step 728 (3403130) @ Episode 4781/10000, loss: 0.0022358270362019544\n",
      "Episode Reward: 13.0\n",
      "Step 870 (3404000) @ Episode 4782/10000, loss: 0.0033969818614423275\n",
      "Episode Reward: 15.0\n",
      "Step 598 (3404598) @ Episode 4783/10000, loss: 0.0089697679504752165\n",
      "Episode Reward: 10.0\n",
      "Step 667 (3405265) @ Episode 4784/10000, loss: 0.0044817132875323296\n",
      "Episode Reward: 9.0\n",
      "Step 938 (3406203) @ Episode 4785/10000, loss: 0.0021087508648633957\n",
      "Episode Reward: 17.0\n",
      "Step 1228 (3407431) @ Episode 4786/10000, loss: 0.0070579526945948696\n",
      "Episode Reward: 19.0\n",
      "Step 1092 (3408523) @ Episode 4787/10000, loss: 0.0062756817787885676\n",
      "Episode Reward: 16.0\n",
      "Step 781 (3409304) @ Episode 4788/10000, loss: 0.0105189289897680284\n",
      "Episode Reward: 13.0\n",
      "Step 600 (3409904) @ Episode 4789/10000, loss: 0.0038725463673472404\n",
      "Episode Reward: 7.0\n",
      "Step 95 (3409999) @ Episode 4790/10000, loss: 0.0033561172895133495\n",
      " Copied model parameters to target network\n",
      "Step 616 (3410520) @ Episode 4790/10000, loss: 0.0573856495320797944\n",
      "Episode Reward: 9.0\n",
      "Step 1046 (3411566) @ Episode 4791/10000, loss: 0.0058854427188634877\n",
      "Episode Reward: 16.0\n",
      "Step 906 (3412472) @ Episode 4792/10000, loss: 0.0042028734460473063\n",
      "Episode Reward: 15.0\n",
      "Step 846 (3413318) @ Episode 4793/10000, loss: 0.0067122802138328553\n",
      "Episode Reward: 15.0\n",
      "Step 1013 (3414331) @ Episode 4794/10000, loss: 0.0030214516445994377\n",
      "Episode Reward: 26.0\n",
      "Step 851 (3415182) @ Episode 4795/10000, loss: 0.0022847021464258432\n",
      "Episode Reward: 15.0\n",
      "Step 637 (3415819) @ Episode 4796/10000, loss: 0.0073737856000661855\n",
      "Episode Reward: 9.0\n",
      "Step 894 (3416713) @ Episode 4797/10000, loss: 0.0028933119028806686\n",
      "Episode Reward: 17.0\n",
      "Step 1010 (3417723) @ Episode 4798/10000, loss: 0.0178116690367460254\n",
      "Episode Reward: 23.0\n",
      "Step 638 (3418361) @ Episode 4799/10000, loss: 0.0047355243004858493\n",
      "Episode Reward: 9.0\n",
      "Step 834 (3419195) @ Episode 4800/10000, loss: 0.0035181599669158465\n",
      "Episode Reward: 18.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 01:23:12,233] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video004800.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 758 (3419953) @ Episode 4801/10000, loss: 0.0079093929380178455\n",
      "Episode Reward: 12.0\n",
      "Step 46 (3419999) @ Episode 4802/10000, loss: 0.0058533409610390667\n",
      " Copied model parameters to target network\n",
      "Step 935 (3420888) @ Episode 4802/10000, loss: 0.0057163243182003545\n",
      "Episode Reward: 19.0\n",
      "Step 855 (3421743) @ Episode 4803/10000, loss: 0.0076935868710279465\n",
      "Episode Reward: 17.0\n",
      "Step 1046 (3422789) @ Episode 4804/10000, loss: 0.0062126349657773975\n",
      "Episode Reward: 18.0\n",
      "Step 824 (3423613) @ Episode 4805/10000, loss: 0.0325613692402839666\n",
      "Episode Reward: 14.0\n",
      "Step 1095 (3424708) @ Episode 4806/10000, loss: 0.0039358944632112985\n",
      "Episode Reward: 18.0\n",
      "Step 1231 (3425939) @ Episode 4807/10000, loss: 0.0055104284547269343\n",
      "Episode Reward: 33.0\n",
      "Step 873 (3426812) @ Episode 4808/10000, loss: 0.0086929593235254295\n",
      "Episode Reward: 25.0\n",
      "Step 770 (3427582) @ Episode 4809/10000, loss: 0.0057324441149830825\n",
      "Episode Reward: 22.0\n",
      "Step 877 (3428459) @ Episode 4810/10000, loss: 0.0055967690423130995\n",
      "Episode Reward: 17.0\n",
      "Step 738 (3429197) @ Episode 4811/10000, loss: 0.0072351596318185335\n",
      "Episode Reward: 10.0\n",
      "Step 578 (3429775) @ Episode 4812/10000, loss: 0.0041345963254570966\n",
      "Episode Reward: 10.0\n",
      "Step 224 (3429999) @ Episode 4813/10000, loss: 0.0034037788864225156\n",
      " Copied model parameters to target network\n",
      "Step 1162 (3430937) @ Episode 4813/10000, loss: 0.0061223730444908146\n",
      "Episode Reward: 20.0\n",
      "Step 689 (3431626) @ Episode 4814/10000, loss: 0.0039763175882399086\n",
      "Episode Reward: 10.0\n",
      "Step 917 (3432543) @ Episode 4815/10000, loss: 0.0026600719429552555\n",
      "Episode Reward: 24.0\n",
      "Step 703 (3433246) @ Episode 4816/10000, loss: 0.0047193020582199146\n",
      "Episode Reward: 16.0\n",
      "Step 614 (3433860) @ Episode 4817/10000, loss: 0.0031353114172816277\n",
      "Episode Reward: 10.0\n",
      "Step 746 (3434606) @ Episode 4818/10000, loss: 0.0060250512324273594\n",
      "Episode Reward: 14.0\n",
      "Step 716 (3435322) @ Episode 4819/10000, loss: 0.0093003278598189354\n",
      "Episode Reward: 11.0\n",
      "Step 754 (3436076) @ Episode 4820/10000, loss: 0.0060981679707765586\n",
      "Episode Reward: 15.0\n",
      "Step 787 (3436863) @ Episode 4821/10000, loss: 0.0057064387947320945\n",
      "Episode Reward: 15.0\n",
      "Step 1030 (3437893) @ Episode 4822/10000, loss: 0.0052771321497857575\n",
      "Episode Reward: 18.0\n",
      "Step 737 (3438630) @ Episode 4823/10000, loss: 0.0081393439322710044\n",
      "Episode Reward: 17.0\n",
      "Step 553 (3439183) @ Episode 4824/10000, loss: 0.0144556509330868725\n",
      "Episode Reward: 9.0\n",
      "Step 703 (3439886) @ Episode 4825/10000, loss: 0.0027707032859325414\n",
      "Episode Reward: 12.0\n",
      "Step 113 (3439999) @ Episode 4826/10000, loss: 0.004745909944176674\n",
      " Copied model parameters to target network\n",
      "Step 408 (3440294) @ Episode 4826/10000, loss: 0.0027079873252660036\n",
      "Episode Reward: 6.0\n",
      "Step 742 (3441036) @ Episode 4827/10000, loss: 0.0059391208924353125\n",
      "Episode Reward: 13.0\n",
      "Step 913 (3441949) @ Episode 4828/10000, loss: 0.0049387449398636825\n",
      "Episode Reward: 15.0\n",
      "Step 828 (3442777) @ Episode 4829/10000, loss: 0.0039061051793396473\n",
      "Episode Reward: 15.0\n",
      "Step 788 (3443565) @ Episode 4830/10000, loss: 0.0026907422579824924\n",
      "Episode Reward: 12.0\n",
      "Step 1087 (3444652) @ Episode 4831/10000, loss: 0.0028371787630021574\n",
      "Episode Reward: 17.0\n",
      "Step 946 (3445598) @ Episode 4832/10000, loss: 0.0050253383815288545\n",
      "Episode Reward: 20.0\n",
      "Step 879 (3446477) @ Episode 4833/10000, loss: 0.0138356219977140435\n",
      "Episode Reward: 19.0\n",
      "Step 1210 (3447687) @ Episode 4834/10000, loss: 0.0043771648779511455\n",
      "Episode Reward: 29.0\n",
      "Step 910 (3448597) @ Episode 4835/10000, loss: 0.0039171697571873665\n",
      "Episode Reward: 19.0\n",
      "Step 899 (3449496) @ Episode 4836/10000, loss: 0.0041283559985458853\n",
      "Episode Reward: 19.0\n",
      "Step 503 (3449999) @ Episode 4837/10000, loss: 0.0051648314110934734\n",
      " Copied model parameters to target network\n",
      "Step 955 (3450451) @ Episode 4837/10000, loss: 0.0031375132966786623\n",
      "Episode Reward: 22.0\n",
      "Step 1210 (3451661) @ Episode 4838/10000, loss: 0.0017745658988133073\n",
      "Episode Reward: 23.0\n",
      "Step 1378 (3453039) @ Episode 4839/10000, loss: 0.0053456453606486322\n",
      "Episode Reward: 29.0\n",
      "Step 674 (3453713) @ Episode 4840/10000, loss: 0.0409800522029399933\n",
      "Episode Reward: 11.0\n",
      "Step 993 (3454706) @ Episode 4841/10000, loss: 0.0023644242901355037\n",
      "Episode Reward: 18.0\n",
      "Step 845 (3455551) @ Episode 4842/10000, loss: 0.0050055743195116524\n",
      "Episode Reward: 15.0\n",
      "Step 654 (3456205) @ Episode 4843/10000, loss: 0.0082825897261500365\n",
      "Episode Reward: 9.0\n",
      "Step 875 (3457080) @ Episode 4844/10000, loss: 0.0050385147333145148\n",
      "Episode Reward: 15.0\n",
      "Step 973 (3458053) @ Episode 4845/10000, loss: 0.0053567104041576385\n",
      "Episode Reward: 17.0\n",
      "Step 604 (3458657) @ Episode 4846/10000, loss: 0.0043486505746841435\n",
      "Episode Reward: 9.0\n",
      "Step 1055 (3459712) @ Episode 4847/10000, loss: 0.0016663577407598495\n",
      "Episode Reward: 18.0\n",
      "Step 287 (3459999) @ Episode 4848/10000, loss: 0.0024716421030461795\n",
      " Copied model parameters to target network\n",
      "Step 855 (3460567) @ Episode 4848/10000, loss: 0.0074459882453083995\n",
      "Episode Reward: 16.0\n",
      "Step 1038 (3461605) @ Episode 4849/10000, loss: 0.0070244846865534786\n",
      "Episode Reward: 21.0\n",
      "Step 973 (3462578) @ Episode 4850/10000, loss: 0.0043321507982909686\n",
      "Episode Reward: 20.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 01:29:51,408] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video004850.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1530 (3464108) @ Episode 4851/10000, loss: 0.0027279183268547063\n",
      "Episode Reward: 38.0\n",
      "Step 962 (3465070) @ Episode 4852/10000, loss: 0.0040634805336594586\n",
      "Episode Reward: 27.0\n",
      "Step 815 (3465885) @ Episode 4853/10000, loss: 0.0026025734841823586\n",
      "Episode Reward: 18.0\n",
      "Step 920 (3466805) @ Episode 4854/10000, loss: 0.0074241757392883354\n",
      "Episode Reward: 14.0\n",
      "Step 1449 (3468254) @ Episode 4855/10000, loss: 0.0065182615071535116\n",
      "Episode Reward: 30.0\n",
      "Step 1036 (3469290) @ Episode 4856/10000, loss: 0.0087145371362566956\n",
      "Episode Reward: 21.0\n",
      "Step 709 (3469999) @ Episode 4857/10000, loss: 0.0032121108379215325\n",
      " Copied model parameters to target network\n",
      "Step 1101 (3470391) @ Episode 4857/10000, loss: 0.0049596750177443038\n",
      "Episode Reward: 26.0\n",
      "Step 663 (3471054) @ Episode 4858/10000, loss: 0.0045052464120090015\n",
      "Episode Reward: 13.0\n",
      "Step 638 (3471692) @ Episode 4859/10000, loss: 0.0132223386317491535\n",
      "Episode Reward: 10.0\n",
      "Step 907 (3472599) @ Episode 4860/10000, loss: 0.0034774558153003454\n",
      "Episode Reward: 17.0\n",
      "Step 1118 (3473717) @ Episode 4861/10000, loss: 0.0052668284624814996\n",
      "Episode Reward: 31.0\n",
      "Step 983 (3474700) @ Episode 4862/10000, loss: 0.0052687884308397773\n",
      "Episode Reward: 19.0\n",
      "Step 1139 (3475839) @ Episode 4863/10000, loss: 0.0069668106734752655\n",
      "Episode Reward: 20.0\n",
      "Step 706 (3476545) @ Episode 4864/10000, loss: 0.0075003742240369326\n",
      "Episode Reward: 15.0\n",
      "Step 716 (3477261) @ Episode 4865/10000, loss: 0.0062576485797762875\n",
      "Episode Reward: 12.0\n",
      "Step 969 (3478230) @ Episode 4866/10000, loss: 0.0033989571966230875\n",
      "Episode Reward: 18.0\n",
      "Step 1228 (3479458) @ Episode 4867/10000, loss: 0.0048883715644478865\n",
      "Episode Reward: 26.0\n",
      "Step 541 (3479999) @ Episode 4868/10000, loss: 0.0097037767991423616\n",
      " Copied model parameters to target network\n",
      "Step 1142 (3480600) @ Episode 4868/10000, loss: 0.0038623437285423286\n",
      "Episode Reward: 28.0\n",
      "Step 924 (3481524) @ Episode 4869/10000, loss: 0.0222275406122207644\n",
      "Episode Reward: 16.0\n",
      "Step 899 (3482423) @ Episode 4870/10000, loss: 0.0188802480697631845\n",
      "Episode Reward: 15.0\n",
      "Step 1067 (3483490) @ Episode 4871/10000, loss: 0.0103210993111133585\n",
      "Episode Reward: 21.0\n",
      "Step 977 (3484467) @ Episode 4872/10000, loss: 0.0049694040790200238\n",
      "Episode Reward: 20.0\n",
      "Step 855 (3485322) @ Episode 4873/10000, loss: 0.0065860608592629434\n",
      "Episode Reward: 19.0\n",
      "Step 755 (3486077) @ Episode 4874/10000, loss: 0.0062599759548902515\n",
      "Episode Reward: 11.0\n",
      "Step 845 (3486922) @ Episode 4875/10000, loss: 0.0064477231353521354\n",
      "Episode Reward: 26.0\n",
      "Step 883 (3487805) @ Episode 4876/10000, loss: 0.0056900344789028172\n",
      "Episode Reward: 22.0\n",
      "Step 963 (3488768) @ Episode 4877/10000, loss: 0.0039583593606948853\n",
      "Episode Reward: 19.0\n",
      "Step 854 (3489622) @ Episode 4878/10000, loss: 0.0056836521252989776\n",
      "Episode Reward: 21.0\n",
      "Step 377 (3489999) @ Episode 4879/10000, loss: 0.0053642028942704277\n",
      " Copied model parameters to target network\n",
      "Step 1009 (3490631) @ Episode 4879/10000, loss: 0.0097034098580479624\n",
      "Episode Reward: 20.0\n",
      "Step 818 (3491449) @ Episode 4880/10000, loss: 0.0140091329813003545\n",
      "Episode Reward: 17.0\n",
      "Step 815 (3492264) @ Episode 4881/10000, loss: 0.0015502453316003084\n",
      "Episode Reward: 21.0\n",
      "Step 1016 (3493280) @ Episode 4882/10000, loss: 0.0048037813976407053\n",
      "Episode Reward: 28.0\n",
      "Step 1082 (3494362) @ Episode 4883/10000, loss: 0.0042111948132514955\n",
      "Episode Reward: 23.0\n",
      "Step 781 (3495143) @ Episode 4884/10000, loss: 0.0123124020174145744\n",
      "Episode Reward: 12.0\n",
      "Step 1100 (3496243) @ Episode 4885/10000, loss: 0.0144643336534500123\n",
      "Episode Reward: 22.0\n",
      "Step 907 (3497150) @ Episode 4886/10000, loss: 0.0267401449382305153\n",
      "Episode Reward: 15.0\n",
      "Step 1406 (3498556) @ Episode 4887/10000, loss: 0.0093252742663025866\n",
      "Episode Reward: 35.0\n",
      "Step 864 (3499420) @ Episode 4888/10000, loss: 0.0050107343122363095\n",
      "Episode Reward: 24.0\n",
      "Step 579 (3499999) @ Episode 4889/10000, loss: 0.0186338238418102265\n",
      " Copied model parameters to target network\n",
      "Step 993 (3500413) @ Episode 4889/10000, loss: 0.0033244844526052475\n",
      "Episode Reward: 19.0\n",
      "Step 943 (3501356) @ Episode 4890/10000, loss: 0.0106571372598409658\n",
      "Episode Reward: 17.0\n",
      "Step 922 (3502278) @ Episode 4891/10000, loss: 0.0061177974566817285\n",
      "Episode Reward: 22.0\n",
      "Step 783 (3503061) @ Episode 4892/10000, loss: 0.0036203260533511648\n",
      "Episode Reward: 16.0\n",
      "Step 1311 (3504372) @ Episode 4893/10000, loss: 0.0130293900147080425\n",
      "Episode Reward: 30.0\n",
      "Step 896 (3505268) @ Episode 4894/10000, loss: 0.0126323401927948054\n",
      "Episode Reward: 16.0\n",
      "Step 1050 (3506318) @ Episode 4895/10000, loss: 0.0109705161303281788\n",
      "Episode Reward: 24.0\n",
      "Step 1265 (3507583) @ Episode 4896/10000, loss: 0.0027647735550999645\n",
      "Episode Reward: 28.0\n",
      "Step 787 (3508370) @ Episode 4897/10000, loss: 0.0038200966082513332\n",
      "Episode Reward: 15.0\n",
      "Step 993 (3509363) @ Episode 4898/10000, loss: 0.0051478482782840735\n",
      "Episode Reward: 17.0\n",
      "Step 636 (3509999) @ Episode 4899/10000, loss: 0.0067166988737881185\n",
      " Copied model parameters to target network\n",
      "Step 867 (3510230) @ Episode 4899/10000, loss: 0.0029199866112321615\n",
      "Episode Reward: 17.0\n",
      "Step 985 (3511215) @ Episode 4900/10000, loss: 0.0030651048291474584\n",
      "Episode Reward: 15.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 01:37:18,614] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video004900.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 940 (3512155) @ Episode 4901/10000, loss: 0.0124096889048814774\n",
      "Episode Reward: 14.0\n",
      "Step 645 (3512800) @ Episode 4902/10000, loss: 0.0067613767459988593\n",
      "Episode Reward: 13.0\n",
      "Step 972 (3513772) @ Episode 4903/10000, loss: 0.0037252353504300117\n",
      "Episode Reward: 18.0\n",
      "Step 1242 (3515014) @ Episode 4904/10000, loss: 0.0098483096808195117\n",
      "Episode Reward: 30.0\n",
      "Step 960 (3515974) @ Episode 4905/10000, loss: 0.0030966354534029967\n",
      "Episode Reward: 23.0\n",
      "Step 1132 (3517106) @ Episode 4906/10000, loss: 0.0038012354634702206\n",
      "Episode Reward: 25.0\n",
      "Step 858 (3517964) @ Episode 4907/10000, loss: 0.0032436405308544636\n",
      "Episode Reward: 22.0\n",
      "Step 1128 (3519092) @ Episode 4908/10000, loss: 0.0027447282336652286\n",
      "Episode Reward: 27.0\n",
      "Step 639 (3519731) @ Episode 4909/10000, loss: 0.0064612627029418945\n",
      "Episode Reward: 10.0\n",
      "Step 268 (3519999) @ Episode 4910/10000, loss: 0.0110574569553136834\n",
      " Copied model parameters to target network\n",
      "Step 1214 (3520945) @ Episode 4910/10000, loss: 0.0055650305002927785\n",
      "Episode Reward: 26.0\n",
      "Step 1103 (3522048) @ Episode 4911/10000, loss: 0.0088872546330094345\n",
      "Episode Reward: 24.0\n",
      "Step 1141 (3523189) @ Episode 4912/10000, loss: 0.0070303748361766344\n",
      "Episode Reward: 22.0\n",
      "Step 1210 (3524399) @ Episode 4913/10000, loss: 0.0069481050595641144\n",
      "Episode Reward: 24.0\n",
      "Step 1035 (3525434) @ Episode 4914/10000, loss: 0.0071814819239079953\n",
      "Episode Reward: 19.0\n",
      "Step 627 (3526061) @ Episode 4915/10000, loss: 0.0289386771619319994\n",
      "Episode Reward: 9.0\n",
      "Step 732 (3526793) @ Episode 4916/10000, loss: 0.0035339035093784332\n",
      "Episode Reward: 13.0\n",
      "Step 1141 (3527934) @ Episode 4917/10000, loss: 0.0025536576285958294\n",
      "Episode Reward: 30.0\n",
      "Step 759 (3528693) @ Episode 4918/10000, loss: 0.0057290317490696911\n",
      "Episode Reward: 13.0\n",
      "Step 1066 (3529759) @ Episode 4919/10000, loss: 0.0032413487788289785\n",
      "Episode Reward: 15.0\n",
      "Step 240 (3529999) @ Episode 4920/10000, loss: 0.0110708223655819974\n",
      " Copied model parameters to target network\n",
      "Step 945 (3530704) @ Episode 4920/10000, loss: 0.0063184602186083795\n",
      "Episode Reward: 16.0\n",
      "Step 1210 (3531914) @ Episode 4921/10000, loss: 0.0143678691238164935\n",
      "Episode Reward: 29.0\n",
      "Step 1455 (3533369) @ Episode 4922/10000, loss: 0.0057348278351128116\n",
      "Episode Reward: 38.0\n",
      "Step 986 (3534355) @ Episode 4923/10000, loss: 0.0091125005856156355\n",
      "Episode Reward: 20.0\n",
      "Step 1003 (3535358) @ Episode 4924/10000, loss: 0.006750474218279123\n",
      "Episode Reward: 18.0\n",
      "Step 741 (3536099) @ Episode 4925/10000, loss: 0.0102263949811458596\n",
      "Episode Reward: 13.0\n",
      "Step 760 (3536859) @ Episode 4926/10000, loss: 0.0067672617733478556\n",
      "Episode Reward: 17.0\n",
      "Step 1108 (3537967) @ Episode 4927/10000, loss: 0.0102585786953568466\n",
      "Episode Reward: 20.0\n",
      "Step 903 (3538870) @ Episode 4928/10000, loss: 0.0043594697490334512\n",
      "Episode Reward: 19.0\n",
      "Step 1129 (3539999) @ Episode 4929/10000, loss: 0.0050482102669775496\n",
      " Copied model parameters to target network\n",
      "Step 1225 (3540095) @ Episode 4929/10000, loss: 0.0067456527613103396\n",
      "Episode Reward: 35.0\n",
      "Step 1074 (3541169) @ Episode 4930/10000, loss: 0.0057082423008978372\n",
      "Episode Reward: 18.0\n",
      "Step 746 (3541915) @ Episode 4931/10000, loss: 0.0035911549348384149\n",
      "Episode Reward: 17.0\n",
      "Step 939 (3542854) @ Episode 4932/10000, loss: 0.0113452635705471046\n",
      "Episode Reward: 17.0\n",
      "Step 759 (3543613) @ Episode 4933/10000, loss: 0.0064799031242728235\n",
      "Episode Reward: 14.0\n",
      "Step 1049 (3544662) @ Episode 4934/10000, loss: 0.0096002491191029556\n",
      "Episode Reward: 25.0\n",
      "Step 1593 (3546255) @ Episode 4935/10000, loss: 0.0038656708784401417\n",
      "Episode Reward: 42.0\n",
      "Step 904 (3547159) @ Episode 4936/10000, loss: 0.0112004140391945844\n",
      "Episode Reward: 22.0\n",
      "Step 1138 (3548297) @ Episode 4937/10000, loss: 0.0054046469740569595\n",
      "Episode Reward: 26.0\n",
      "Step 1222 (3549519) @ Episode 4938/10000, loss: 0.0067073567770421505\n",
      "Episode Reward: 22.0\n",
      "Step 480 (3549999) @ Episode 4939/10000, loss: 0.0030766376294195653\n",
      " Copied model parameters to target network\n",
      "Step 750 (3550269) @ Episode 4939/10000, loss: 0.0029566902667284014\n",
      "Episode Reward: 16.0\n",
      "Step 897 (3551166) @ Episode 4940/10000, loss: 0.0027789431624114513\n",
      "Episode Reward: 22.0\n",
      "Step 957 (3552123) @ Episode 4941/10000, loss: 0.0019855576101690535\n",
      "Episode Reward: 20.0\n",
      "Step 1074 (3553197) @ Episode 4942/10000, loss: 0.0053254803642630585\n",
      "Episode Reward: 21.0\n",
      "Step 925 (3554122) @ Episode 4943/10000, loss: 0.0031969337724149227\n",
      "Episode Reward: 12.0\n",
      "Step 939 (3555061) @ Episode 4944/10000, loss: 0.0041172932833433155\n",
      "Episode Reward: 14.0\n",
      "Step 1073 (3556134) @ Episode 4945/10000, loss: 0.0063294055871665485\n",
      "Episode Reward: 18.0\n",
      "Step 1127 (3557261) @ Episode 4946/10000, loss: 0.0087697692215442665\n",
      "Episode Reward: 22.0\n",
      "Step 908 (3558169) @ Episode 4947/10000, loss: 0.0060742553323507317\n",
      "Episode Reward: 19.0\n",
      "Step 885 (3559054) @ Episode 4948/10000, loss: 0.0095550548285245975\n",
      "Episode Reward: 18.0\n",
      "Step 476 (3559530) @ Episode 4949/10000, loss: 0.0042605046182870865\n",
      "Episode Reward: 7.0\n",
      "Step 469 (3559999) @ Episode 4950/10000, loss: 0.0028408211655914783\n",
      " Copied model parameters to target network\n",
      "Step 646 (3560176) @ Episode 4950/10000, loss: 0.0022562029771506786\n",
      "Episode Reward: 21.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 01:44:44,030] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video004950.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1411 (3561587) @ Episode 4951/10000, loss: 0.0037722894921898844\n",
      "Episode Reward: 32.0\n",
      "Step 1003 (3562590) @ Episode 4952/10000, loss: 0.011667391285300255\n",
      "Episode Reward: 19.0\n",
      "Step 1008 (3563598) @ Episode 4953/10000, loss: 0.0052613853476941586\n",
      "Episode Reward: 21.0\n",
      "Step 1617 (3565215) @ Episode 4954/10000, loss: 0.0041079991497099473\n",
      "Episode Reward: 42.0\n",
      "Step 1600 (3566815) @ Episode 4955/10000, loss: 0.0024711419828236103\n",
      "Episode Reward: 46.0\n",
      "Step 1101 (3567916) @ Episode 4956/10000, loss: 0.0104466043412685423\n",
      "Episode Reward: 27.0\n",
      "Step 678 (3568594) @ Episode 4957/10000, loss: 0.0142748905345797545\n",
      "Episode Reward: 12.0\n",
      "Step 1045 (3569639) @ Episode 4958/10000, loss: 0.0047679007984697825\n",
      "Episode Reward: 26.0\n",
      "Step 360 (3569999) @ Episode 4959/10000, loss: 0.0264683868736028673\n",
      " Copied model parameters to target network\n",
      "Step 959 (3570598) @ Episode 4959/10000, loss: 0.0039914809167385154\n",
      "Episode Reward: 18.0\n",
      "Step 920 (3571518) @ Episode 4960/10000, loss: 0.0122329909354448325\n",
      "Episode Reward: 22.0\n",
      "Step 940 (3572458) @ Episode 4961/10000, loss: 0.0098781995475292235\n",
      "Episode Reward: 19.0\n",
      "Step 862 (3573320) @ Episode 4962/10000, loss: 0.0040634372271597385\n",
      "Episode Reward: 14.0\n",
      "Step 827 (3574147) @ Episode 4963/10000, loss: 0.0029014265164732933\n",
      "Episode Reward: 14.0\n",
      "Step 1443 (3575590) @ Episode 4964/10000, loss: 0.0142471930012106937\n",
      "Episode Reward: 36.0\n",
      "Step 551 (3576141) @ Episode 4965/10000, loss: 0.0065377340652048593\n",
      "Episode Reward: 8.0\n",
      "Step 1339 (3577480) @ Episode 4966/10000, loss: 0.0128617342561483385\n",
      "Episode Reward: 25.0\n",
      "Step 923 (3578403) @ Episode 4967/10000, loss: 0.0054892655462026652\n",
      "Episode Reward: 19.0\n",
      "Step 937 (3579340) @ Episode 4968/10000, loss: 0.0069638947024941444\n",
      "Episode Reward: 16.0\n",
      "Step 659 (3579999) @ Episode 4969/10000, loss: 0.0026101993862539534\n",
      " Copied model parameters to target network\n",
      "Step 803 (3580143) @ Episode 4969/10000, loss: 0.0049615311436355113\n",
      "Episode Reward: 13.0\n",
      "Step 745 (3580888) @ Episode 4970/10000, loss: 0.0046253167092800145\n",
      "Episode Reward: 12.0\n",
      "Step 981 (3581869) @ Episode 4971/10000, loss: 0.0042033558711409578\n",
      "Episode Reward: 15.0\n",
      "Step 624 (3582493) @ Episode 4972/10000, loss: 0.0067337774671614174\n",
      "Episode Reward: 10.0\n",
      "Step 960 (3583453) @ Episode 4973/10000, loss: 0.0048636216670274734\n",
      "Episode Reward: 19.0\n",
      "Step 795 (3584248) @ Episode 4974/10000, loss: 0.0098617440089583416\n",
      "Episode Reward: 14.0\n",
      "Step 1056 (3585304) @ Episode 4975/10000, loss: 0.0089420890435576442\n",
      "Episode Reward: 24.0\n",
      "Step 1098 (3586402) @ Episode 4976/10000, loss: 0.0042579942382872105\n",
      "Episode Reward: 18.0\n",
      "Step 459 (3586861) @ Episode 4977/10000, loss: 0.0064636170864105225\n",
      "Episode Reward: 8.0\n",
      "Step 708 (3587569) @ Episode 4978/10000, loss: 0.0076256003230810165\n",
      "Episode Reward: 9.0\n",
      "Step 902 (3588471) @ Episode 4979/10000, loss: 0.0111700985580682755\n",
      "Episode Reward: 16.0\n",
      "Step 725 (3589196) @ Episode 4980/10000, loss: 0.0048102606087923052\n",
      "Episode Reward: 12.0\n",
      "Step 803 (3589999) @ Episode 4981/10000, loss: 0.0058992886915802956\n",
      " Copied model parameters to target network\n",
      "Step 1497 (3590693) @ Episode 4981/10000, loss: 0.0050308192148804665\n",
      "Episode Reward: 42.0\n",
      "Step 855 (3591548) @ Episode 4982/10000, loss: 0.0032650402281433344\n",
      "Episode Reward: 29.0\n",
      "Step 857 (3592405) @ Episode 4983/10000, loss: 0.0026043346151709557\n",
      "Episode Reward: 16.0\n",
      "Step 1454 (3593859) @ Episode 4984/10000, loss: 0.0097779948264360435\n",
      "Episode Reward: 36.0\n",
      "Step 931 (3594790) @ Episode 4985/10000, loss: 0.0064496267586946497\n",
      "Episode Reward: 18.0\n",
      "Step 962 (3595752) @ Episode 4986/10000, loss: 0.0177090913057327276\n",
      "Episode Reward: 22.0\n",
      "Step 483 (3596235) @ Episode 4987/10000, loss: 0.0034345933236181736\n",
      "Episode Reward: 6.0\n",
      "Step 1127 (3597362) @ Episode 4988/10000, loss: 0.0065312571823596954\n",
      "Episode Reward: 23.0\n",
      "Step 1061 (3598423) @ Episode 4989/10000, loss: 0.0073099718429148247\n",
      "Episode Reward: 26.0\n",
      "Step 901 (3599324) @ Episode 4990/10000, loss: 0.0045238686725497254\n",
      "Episode Reward: 18.0\n",
      "Step 675 (3599999) @ Episode 4991/10000, loss: 0.0055066021159291275\n",
      " Copied model parameters to target network\n",
      "Step 821 (3600145) @ Episode 4991/10000, loss: 0.0024140824098147945\n",
      "Episode Reward: 20.0\n",
      "Step 526 (3600671) @ Episode 4992/10000, loss: 0.0015457535628229386\n",
      "Episode Reward: 7.0\n",
      "Step 1168 (3601839) @ Episode 4993/10000, loss: 0.0047204489819705494\n",
      "Episode Reward: 26.0\n",
      "Step 1256 (3603095) @ Episode 4994/10000, loss: 0.0083013456314802175\n",
      "Episode Reward: 25.0\n",
      "Step 954 (3604049) @ Episode 4995/10000, loss: 0.0053012976422905926\n",
      "Episode Reward: 16.0\n",
      "Step 1302 (3605351) @ Episode 4996/10000, loss: 0.0041038240306079395\n",
      "Episode Reward: 33.0\n",
      "Step 1311 (3606662) @ Episode 4997/10000, loss: 0.0044328300282359125\n",
      "Episode Reward: 34.0\n",
      "Step 924 (3607586) @ Episode 4998/10000, loss: 0.0049125589430332184\n",
      "Episode Reward: 23.0\n",
      "Step 581 (3608167) @ Episode 4999/10000, loss: 0.0059262751601636415\n",
      "Episode Reward: 9.0\n",
      "Step 830 (3608997) @ Episode 5000/10000, loss: 0.0060237692669034974\n",
      "Episode Reward: 15.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 01:52:12,786] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video005000.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 754 (3609751) @ Episode 5001/10000, loss: 0.0074268230237066754\n",
      "Episode Reward: 16.0\n",
      "Step 248 (3609999) @ Episode 5002/10000, loss: 0.0042750081047415736\n",
      " Copied model parameters to target network\n",
      "Step 899 (3610650) @ Episode 5002/10000, loss: 0.0070833940990269186\n",
      "Episode Reward: 19.0\n",
      "Step 920 (3611570) @ Episode 5003/10000, loss: 0.0074823815375566484\n",
      "Episode Reward: 15.0\n",
      "Step 872 (3612442) @ Episode 5004/10000, loss: 0.0032549514435231686\n",
      "Episode Reward: 17.0\n",
      "Step 1314 (3613756) @ Episode 5005/10000, loss: 0.0056465510278940265\n",
      "Episode Reward: 28.0\n",
      "Step 816 (3614572) @ Episode 5006/10000, loss: 0.0096681490540504464\n",
      "Episode Reward: 14.0\n",
      "Step 1026 (3615598) @ Episode 5007/10000, loss: 0.0034931940026581287\n",
      "Episode Reward: 19.0\n",
      "Step 959 (3616557) @ Episode 5008/10000, loss: 0.0058498829603195195\n",
      "Episode Reward: 18.0\n",
      "Step 1161 (3617718) @ Episode 5009/10000, loss: 0.0041315993294119835\n",
      "Episode Reward: 31.0\n",
      "Step 685 (3618403) @ Episode 5010/10000, loss: 0.0075337509624660015\n",
      "Episode Reward: 10.0\n",
      "Step 820 (3619223) @ Episode 5011/10000, loss: 0.0046627046540379528\n",
      "Episode Reward: 14.0\n",
      "Step 776 (3619999) @ Episode 5012/10000, loss: 0.0038121414836496115\n",
      " Copied model parameters to target network\n",
      "Step 798 (3620021) @ Episode 5012/10000, loss: 0.1017806679010391268\n",
      "Episode Reward: 13.0\n",
      "Step 744 (3620765) @ Episode 5013/10000, loss: 0.0080004818737506874\n",
      "Episode Reward: 11.0\n",
      "Step 1068 (3621833) @ Episode 5014/10000, loss: 0.0070442082360386855\n",
      "Episode Reward: 18.0\n",
      "Step 923 (3622756) @ Episode 5015/10000, loss: 0.0086925243958830835\n",
      "Episode Reward: 16.0\n",
      "Step 1032 (3623788) @ Episode 5016/10000, loss: 0.0050728204660117636\n",
      "Episode Reward: 20.0\n",
      "Step 677 (3624465) @ Episode 5017/10000, loss: 0.0067654214799404143\n",
      "Episode Reward: 10.0\n",
      "Step 1006 (3625471) @ Episode 5018/10000, loss: 0.0018561086617410183\n",
      "Episode Reward: 26.0\n",
      "Step 1193 (3626664) @ Episode 5019/10000, loss: 0.0030724802054464817\n",
      "Episode Reward: 23.0\n",
      "Step 978 (3627642) @ Episode 5020/10000, loss: 0.0160282254219055185\n",
      "Episode Reward: 23.0\n",
      "Step 902 (3628544) @ Episode 5021/10000, loss: 0.0046831751242280014\n",
      "Episode Reward: 21.0\n",
      "Step 1373 (3629917) @ Episode 5022/10000, loss: 0.0076703331433236636\n",
      "Episode Reward: 40.0\n",
      "Step 82 (3629999) @ Episode 5023/10000, loss: 0.0029405520763248205\n",
      " Copied model parameters to target network\n",
      "Step 641 (3630558) @ Episode 5023/10000, loss: 0.0020342296920716763\n",
      "Episode Reward: 13.0\n",
      "Step 796 (3631354) @ Episode 5024/10000, loss: 0.0083622988313436577\n",
      "Episode Reward: 12.0\n",
      "Step 1183 (3632537) @ Episode 5025/10000, loss: 0.0049239941872656345\n",
      "Episode Reward: 29.0\n",
      "Step 1271 (3633808) @ Episode 5026/10000, loss: 0.0091077601537108425\n",
      "Episode Reward: 26.0\n",
      "Step 1296 (3635104) @ Episode 5027/10000, loss: 0.0327790752053260815\n",
      "Episode Reward: 22.0\n",
      "Step 471 (3635575) @ Episode 5028/10000, loss: 0.0045991512015461926\n",
      "Episode Reward: 8.0\n",
      "Step 802 (3636377) @ Episode 5029/10000, loss: 0.0084405206143856055\n",
      "Episode Reward: 12.0\n",
      "Step 547 (3636924) @ Episode 5030/10000, loss: 0.0144535163417458533\n",
      "Episode Reward: 9.0\n",
      "Step 1612 (3638536) @ Episode 5031/10000, loss: 0.0057930694893002516\n",
      "Episode Reward: 46.0\n",
      "Step 670 (3639206) @ Episode 5032/10000, loss: 0.0057446416467428215\n",
      "Episode Reward: 12.0\n",
      "Step 793 (3639999) @ Episode 5033/10000, loss: 0.0101230014115571987\n",
      " Copied model parameters to target network\n",
      "Step 1026 (3640232) @ Episode 5033/10000, loss: 0.0059410328976809985\n",
      "Episode Reward: 33.0\n",
      "Step 1102 (3641334) @ Episode 5034/10000, loss: 0.0067180870100855834\n",
      "Episode Reward: 23.0\n",
      "Step 954 (3642288) @ Episode 5035/10000, loss: 0.0037255831994116306\n",
      "Episode Reward: 26.0\n",
      "Step 738 (3643026) @ Episode 5036/10000, loss: 0.0043228645808994774\n",
      "Episode Reward: 12.0\n",
      "Step 896 (3643922) @ Episode 5037/10000, loss: 0.0081380112096667297\n",
      "Episode Reward: 18.0\n",
      "Step 806 (3644728) @ Episode 5038/10000, loss: 0.0108301267027854926\n",
      "Episode Reward: 14.0\n",
      "Step 732 (3645460) @ Episode 5039/10000, loss: 0.0025745783932507045\n",
      "Episode Reward: 15.0\n",
      "Step 769 (3646229) @ Episode 5040/10000, loss: 0.0118238814175128944\n",
      "Episode Reward: 13.0\n",
      "Step 830 (3647059) @ Episode 5041/10000, loss: 0.0045647984370589263\n",
      "Episode Reward: 18.0\n",
      "Step 1184 (3648243) @ Episode 5042/10000, loss: 0.0052506392821669585\n",
      "Episode Reward: 24.0\n",
      "Step 1215 (3649458) @ Episode 5043/10000, loss: 0.0051633492112159734\n",
      "Episode Reward: 37.0\n",
      "Step 541 (3649999) @ Episode 5044/10000, loss: 0.0066157020628452327\n",
      " Copied model parameters to target network\n",
      "Step 902 (3650360) @ Episode 5044/10000, loss: 0.0034525971859693527\n",
      "Episode Reward: 16.0\n",
      "Step 683 (3651043) @ Episode 5045/10000, loss: 0.0070803686976432828\n",
      "Episode Reward: 12.0\n",
      "Step 1160 (3652203) @ Episode 5046/10000, loss: 0.0050971647724509243\n",
      "Episode Reward: 25.0\n",
      "Step 1166 (3653369) @ Episode 5047/10000, loss: 0.0082930885255336765\n",
      "Episode Reward: 29.0\n",
      "Step 1123 (3654492) @ Episode 5048/10000, loss: 0.0054642241448163996\n",
      "Episode Reward: 24.0\n",
      "Step 1098 (3655590) @ Episode 5049/10000, loss: 0.0045547410845756535\n",
      "Episode Reward: 20.0\n",
      "Step 1170 (3656760) @ Episode 5050/10000, loss: 0.0064668594859540464\n",
      "Episode Reward: 30.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 01:59:32,588] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video005050.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1241 (3658001) @ Episode 5051/10000, loss: 0.0030776574276387693\n",
      "Episode Reward: 27.0\n",
      "Step 407 (3658408) @ Episode 5052/10000, loss: 0.0064678983762860325\n",
      "Episode Reward: 3.0\n",
      "Step 1056 (3659464) @ Episode 5053/10000, loss: 0.0048323660157620915\n",
      "Episode Reward: 19.0\n",
      "Step 535 (3659999) @ Episode 5054/10000, loss: 0.0046084020286798487\n",
      " Copied model parameters to target network\n",
      "Step 936 (3660400) @ Episode 5054/10000, loss: 0.0263595040887594222\n",
      "Episode Reward: 16.0\n",
      "Step 860 (3661260) @ Episode 5055/10000, loss: 0.0059431772679090516\n",
      "Episode Reward: 17.0\n",
      "Step 1330 (3662590) @ Episode 5056/10000, loss: 0.0076811565086245546\n",
      "Episode Reward: 25.0\n",
      "Step 866 (3663456) @ Episode 5057/10000, loss: 0.0103743467479944234\n",
      "Episode Reward: 20.0\n",
      "Step 901 (3664357) @ Episode 5058/10000, loss: 0.0083541981875896455\n",
      "Episode Reward: 19.0\n",
      "Step 1096 (3665453) @ Episode 5059/10000, loss: 0.0124233737587928775\n",
      "Episode Reward: 30.0\n",
      "Step 945 (3666398) @ Episode 5060/10000, loss: 0.0126612372696399694\n",
      "Episode Reward: 18.0\n",
      "Step 718 (3667116) @ Episode 5061/10000, loss: 0.0034763342700898647\n",
      "Episode Reward: 11.0\n",
      "Step 1142 (3668258) @ Episode 5062/10000, loss: 0.0046788109466433525\n",
      "Episode Reward: 24.0\n",
      "Step 690 (3668948) @ Episode 5063/10000, loss: 0.0029470436275005345\n",
      "Episode Reward: 11.0\n",
      "Step 1051 (3669999) @ Episode 5064/10000, loss: 0.0150182805955417766\n",
      " Copied model parameters to target network\n",
      "Step 1074 (3670022) @ Episode 5064/10000, loss: 0.0036378414370119577\n",
      "Episode Reward: 29.0\n",
      "Step 1008 (3671030) @ Episode 5065/10000, loss: 0.008756197988986969\n",
      "Episode Reward: 18.0\n",
      "Step 907 (3671937) @ Episode 5066/10000, loss: 0.0155869778245687485\n",
      "Episode Reward: 16.0\n",
      "Step 908 (3672845) @ Episode 5067/10000, loss: 0.0032797537278383974\n",
      "Episode Reward: 17.0\n",
      "Step 988 (3673833) @ Episode 5068/10000, loss: 0.0015680766664445443\n",
      "Episode Reward: 20.0\n",
      "Step 1158 (3674991) @ Episode 5069/10000, loss: 0.0077333203516900545\n",
      "Episode Reward: 27.0\n",
      "Step 810 (3675801) @ Episode 5070/10000, loss: 0.0080239567905664445\n",
      "Episode Reward: 13.0\n",
      "Step 1127 (3676928) @ Episode 5071/10000, loss: 0.0111198592931032185\n",
      "Episode Reward: 17.0\n",
      "Step 902 (3677830) @ Episode 5072/10000, loss: 0.0024769171141088015\n",
      "Episode Reward: 15.0\n",
      "Step 1047 (3678877) @ Episode 5073/10000, loss: 0.0044624004513025285\n",
      "Episode Reward: 20.0\n",
      "Step 1122 (3679999) @ Episode 5074/10000, loss: 0.0124501278623938565\n",
      " Copied model parameters to target network\n",
      "Step 1158 (3680035) @ Episode 5074/10000, loss: 0.0036625275388360023\n",
      "Episode Reward: 22.0\n",
      "Step 945 (3680980) @ Episode 5075/10000, loss: 0.0737015008926391605\n",
      "Episode Reward: 18.0\n",
      "Step 910 (3681890) @ Episode 5076/10000, loss: 0.0035568133462220434\n",
      "Episode Reward: 22.0\n",
      "Step 628 (3682518) @ Episode 5077/10000, loss: 0.0042858682572841643\n",
      "Episode Reward: 11.0\n",
      "Step 1376 (3683894) @ Episode 5078/10000, loss: 0.0061095058917999273\n",
      "Episode Reward: 35.0\n",
      "Step 1012 (3684906) @ Episode 5079/10000, loss: 0.0060894247144460687\n",
      "Episode Reward: 17.0\n",
      "Step 1233 (3686139) @ Episode 5080/10000, loss: 0.0166171193122863773\n",
      "Episode Reward: 33.0\n",
      "Step 1386 (3687525) @ Episode 5081/10000, loss: 0.0071707656607031826\n",
      "Episode Reward: 32.0\n",
      "Step 1238 (3688763) @ Episode 5082/10000, loss: 0.0045499345287680635\n",
      "Episode Reward: 28.0\n",
      "Step 1160 (3689923) @ Episode 5083/10000, loss: 0.0051923948340117935\n",
      "Episode Reward: 26.0\n",
      "Step 76 (3689999) @ Episode 5084/10000, loss: 0.0109903030097484592\n",
      " Copied model parameters to target network\n",
      "Step 901 (3690824) @ Episode 5084/10000, loss: 0.0073126200586557393\n",
      "Episode Reward: 19.0\n",
      "Step 603 (3691427) @ Episode 5085/10000, loss: 0.0084879416972398767\n",
      "Episode Reward: 10.0\n",
      "Step 721 (3692148) @ Episode 5086/10000, loss: 0.0269074421375989903\n",
      "Episode Reward: 11.0\n",
      "Step 1340 (3693488) @ Episode 5087/10000, loss: 0.0126746324822306635\n",
      "Episode Reward: 28.0\n",
      "Step 1013 (3694501) @ Episode 5088/10000, loss: 0.0044822427444159985\n",
      "Episode Reward: 23.0\n",
      "Step 623 (3695124) @ Episode 5089/10000, loss: 0.2485753148794174277\n",
      "Episode Reward: 10.0\n",
      "Step 726 (3695850) @ Episode 5090/10000, loss: 0.0044724373146891596\n",
      "Episode Reward: 13.0\n",
      "Step 633 (3696483) @ Episode 5091/10000, loss: 0.0061712889000773432\n",
      "Episode Reward: 11.0\n",
      "Step 1139 (3697622) @ Episode 5092/10000, loss: 0.0050224233418703084\n",
      "Episode Reward: 21.0\n",
      "Step 1012 (3698634) @ Episode 5093/10000, loss: 0.0065939845517277727\n",
      "Episode Reward: 17.0\n",
      "Step 760 (3699394) @ Episode 5094/10000, loss: 0.0187260285019874577\n",
      "Episode Reward: 12.0\n",
      "Step 605 (3699999) @ Episode 5095/10000, loss: 0.0038081191014498472\n",
      " Copied model parameters to target network\n",
      "Step 985 (3700379) @ Episode 5095/10000, loss: 0.0046710683964192873\n",
      "Episode Reward: 18.0\n",
      "Step 1189 (3701568) @ Episode 5096/10000, loss: 0.0106742195785045625\n",
      "Episode Reward: 23.0\n",
      "Step 465 (3702033) @ Episode 5097/10000, loss: 0.0032005168031901125\n",
      "Episode Reward: 10.0\n",
      "Step 1519 (3703552) @ Episode 5098/10000, loss: 0.0056252754293382177\n",
      "Episode Reward: 48.0\n",
      "Step 663 (3704215) @ Episode 5099/10000, loss: 0.0047534671612083916\n",
      "Episode Reward: 14.0\n",
      "Step 886 (3705101) @ Episode 5100/10000, loss: 0.0108744446188211446\n",
      "Episode Reward: 16.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 02:06:53,963] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video005100.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 758 (3705859) @ Episode 5101/10000, loss: 0.0057040196843445373\n",
      "Episode Reward: 13.0\n",
      "Step 1171 (3707030) @ Episode 5102/10000, loss: 0.0042838240042328835\n",
      "Episode Reward: 22.0\n",
      "Step 1137 (3708167) @ Episode 5103/10000, loss: 0.0062057031318545345\n",
      "Episode Reward: 33.0\n",
      "Step 944 (3709111) @ Episode 5104/10000, loss: 0.0068149613216519367\n",
      "Episode Reward: 21.0\n",
      "Step 888 (3709999) @ Episode 5105/10000, loss: 0.0049479734152555475\n",
      " Copied model parameters to target network\n",
      "Step 1134 (3710245) @ Episode 5105/10000, loss: 0.0065275849774479875\n",
      "Episode Reward: 24.0\n",
      "Step 780 (3711025) @ Episode 5106/10000, loss: 0.0065417485311627394\n",
      "Episode Reward: 13.0\n",
      "Step 991 (3712016) @ Episode 5107/10000, loss: 0.0031167806591838632\n",
      "Episode Reward: 19.0\n",
      "Step 921 (3712937) @ Episode 5108/10000, loss: 0.0145417284220457085\n",
      "Episode Reward: 19.0\n",
      "Step 921 (3713858) @ Episode 5109/10000, loss: 0.0058174808509647856\n",
      "Episode Reward: 15.0\n",
      "Step 825 (3714683) @ Episode 5110/10000, loss: 0.0046426095068454743\n",
      "Episode Reward: 16.0\n",
      "Step 841 (3715524) @ Episode 5111/10000, loss: 0.0029436468612402678\n",
      "Episode Reward: 17.0\n",
      "Step 974 (3716498) @ Episode 5112/10000, loss: 0.0058669606223702435\n",
      "Episode Reward: 24.0\n",
      "Step 1121 (3717619) @ Episode 5113/10000, loss: 0.0035255148541182285\n",
      "Episode Reward: 24.0\n",
      "Step 906 (3718525) @ Episode 5114/10000, loss: 0.0040877442806959153\n",
      "Episode Reward: 16.0\n",
      "Step 686 (3719211) @ Episode 5115/10000, loss: 0.0054430626332759863\n",
      "Episode Reward: 11.0\n",
      "Step 788 (3719999) @ Episode 5116/10000, loss: 0.0066891396418213843\n",
      " Copied model parameters to target network\n",
      "Step 798 (3720009) @ Episode 5116/10000, loss: 0.0022863647900521755\n",
      "Episode Reward: 13.0\n",
      "Step 648 (3720657) @ Episode 5117/10000, loss: 0.0027516060508787633\n",
      "Episode Reward: 10.0\n",
      "Step 1507 (3722164) @ Episode 5118/10000, loss: 0.0022981984075158834\n",
      "Episode Reward: 40.0\n",
      "Step 1515 (3723679) @ Episode 5119/10000, loss: 0.0066898744553327565\n",
      "Episode Reward: 38.0\n",
      "Step 1295 (3724974) @ Episode 5120/10000, loss: 0.0079337460920214656\n",
      "Episode Reward: 30.0\n",
      "Step 753 (3725727) @ Episode 5121/10000, loss: 0.0035445510875433683\n",
      "Episode Reward: 13.0\n",
      "Step 1123 (3726850) @ Episode 5122/10000, loss: 0.0058453017845749855\n",
      "Episode Reward: 21.0\n",
      "Step 634 (3727484) @ Episode 5123/10000, loss: 0.0025054116267710924\n",
      "Episode Reward: 13.0\n",
      "Step 901 (3728385) @ Episode 5124/10000, loss: 0.0053697787225246435\n",
      "Episode Reward: 13.0\n",
      "Step 1124 (3729509) @ Episode 5125/10000, loss: 0.0040738186798989778\n",
      "Episode Reward: 29.0\n",
      "Step 490 (3729999) @ Episode 5126/10000, loss: 0.0047949356958270075\n",
      " Copied model parameters to target network\n",
      "Step 673 (3730182) @ Episode 5126/10000, loss: 0.0085774865001440054\n",
      "Episode Reward: 10.0\n",
      "Step 848 (3731030) @ Episode 5127/10000, loss: 0.0060901017859578133\n",
      "Episode Reward: 15.0\n",
      "Step 624 (3731654) @ Episode 5128/10000, loss: 0.0233258903026580855\n",
      "Episode Reward: 9.0\n",
      "Step 753 (3732407) @ Episode 5129/10000, loss: 0.0062021929770708085\n",
      "Episode Reward: 13.0\n",
      "Step 932 (3733339) @ Episode 5130/10000, loss: 0.0106349140405654986\n",
      "Episode Reward: 14.0\n",
      "Step 1146 (3734485) @ Episode 5131/10000, loss: 0.0072636436671018685\n",
      "Episode Reward: 30.0\n",
      "Step 799 (3735284) @ Episode 5132/10000, loss: 0.0032012984156608585\n",
      "Episode Reward: 17.0\n",
      "Step 1070 (3736354) @ Episode 5133/10000, loss: 0.0701955780386924765\n",
      "Episode Reward: 24.0\n",
      "Step 843 (3737197) @ Episode 5134/10000, loss: 0.0131279807537794115\n",
      "Episode Reward: 17.0\n",
      "Step 1059 (3738256) @ Episode 5135/10000, loss: 0.0035733566619455814\n",
      "Episode Reward: 28.0\n",
      "Step 824 (3739080) @ Episode 5136/10000, loss: 0.0070058708079159267\n",
      "Episode Reward: 22.0\n",
      "Step 919 (3739999) @ Episode 5137/10000, loss: 0.0140083692967891716\n",
      " Copied model parameters to target network\n",
      "Step 1589 (3740669) @ Episode 5137/10000, loss: 0.0034290701150894165\n",
      "Episode Reward: 41.0\n",
      "Step 924 (3741593) @ Episode 5138/10000, loss: 0.0078980764374136925\n",
      "Episode Reward: 23.0\n",
      "Step 816 (3742409) @ Episode 5139/10000, loss: 0.0027409929316490892\n",
      "Episode Reward: 14.0\n",
      "Step 679 (3743088) @ Episode 5140/10000, loss: 0.0028783041052520275\n",
      "Episode Reward: 12.0\n",
      "Step 581 (3743669) @ Episode 5141/10000, loss: 0.0028053526766598225\n",
      "Episode Reward: 12.0\n",
      "Step 1011 (3744680) @ Episode 5142/10000, loss: 0.0206247139722108843\n",
      "Episode Reward: 22.0\n",
      "Step 701 (3745381) @ Episode 5143/10000, loss: 0.0071462579071521765\n",
      "Episode Reward: 15.0\n",
      "Step 1120 (3746501) @ Episode 5144/10000, loss: 0.0078428303822875025\n",
      "Episode Reward: 23.0\n",
      "Step 1089 (3747590) @ Episode 5145/10000, loss: 0.0049556135199964055\n",
      "Episode Reward: 22.0\n",
      "Step 782 (3748372) @ Episode 5146/10000, loss: 0.0069905077107250696\n",
      "Episode Reward: 12.0\n",
      "Step 882 (3749254) @ Episode 5147/10000, loss: 0.0031622149981558323\n",
      "Episode Reward: 19.0\n",
      "Step 745 (3749999) @ Episode 5148/10000, loss: 0.0022328072227537635\n",
      " Copied model parameters to target network\n",
      "Step 1026 (3750280) @ Episode 5148/10000, loss: 0.0046374057419598148\n",
      "Episode Reward: 19.0\n",
      "Step 560 (3750840) @ Episode 5149/10000, loss: 0.0070765670388937775\n",
      "Episode Reward: 12.0\n",
      "Step 1183 (3752023) @ Episode 5150/10000, loss: 0.0039213853888213634\n",
      "Episode Reward: 36.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 02:14:02,094] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video005150.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 862 (3752885) @ Episode 5151/10000, loss: 0.0095980446785688476\n",
      "Episode Reward: 22.0\n",
      "Step 1076 (3753961) @ Episode 5152/10000, loss: 0.0042181639000773437\n",
      "Episode Reward: 34.0\n",
      "Step 1446 (3755407) @ Episode 5153/10000, loss: 0.0031025847420096397\n",
      "Episode Reward: 35.0\n",
      "Step 515 (3755922) @ Episode 5154/10000, loss: 0.0166304614394903255\n",
      "Episode Reward: 8.0\n",
      "Step 1009 (3756931) @ Episode 5155/10000, loss: 0.0080030225217342387\n",
      "Episode Reward: 25.0\n",
      "Step 1213 (3758144) @ Episode 5156/10000, loss: 0.0036768619902431965\n",
      "Episode Reward: 32.0\n",
      "Step 891 (3759035) @ Episode 5157/10000, loss: 0.0325465723872184755\n",
      "Episode Reward: 19.0\n",
      "Step 828 (3759863) @ Episode 5158/10000, loss: 0.0107528679072856964\n",
      "Episode Reward: 17.0\n",
      "Step 136 (3759999) @ Episode 5159/10000, loss: 0.0023369155824184418\n",
      " Copied model parameters to target network\n",
      "Step 1060 (3760923) @ Episode 5159/10000, loss: 0.0034258496016263963\n",
      "Episode Reward: 23.0\n",
      "Step 438 (3761361) @ Episode 5160/10000, loss: 0.0053683705627918244\n",
      "Episode Reward: 6.0\n",
      "Step 511 (3761872) @ Episode 5161/10000, loss: 0.0074472194537520413\n",
      "Episode Reward: 7.0\n",
      "Step 1101 (3762973) @ Episode 5162/10000, loss: 0.0048074154183268557\n",
      "Episode Reward: 26.0\n",
      "Step 522 (3763495) @ Episode 5163/10000, loss: 0.0062634251080453483\n",
      "Episode Reward: 7.0\n",
      "Step 792 (3764287) @ Episode 5164/10000, loss: 0.0045830439776182175\n",
      "Episode Reward: 14.0\n",
      "Step 1261 (3765548) @ Episode 5165/10000, loss: 0.0049558943137526513\n",
      "Episode Reward: 29.0\n",
      "Step 1254 (3766802) @ Episode 5166/10000, loss: 0.0061063528992235663\n",
      "Episode Reward: 29.0\n",
      "Step 898 (3767700) @ Episode 5167/10000, loss: 0.0207013133913278583\n",
      "Episode Reward: 17.0\n",
      "Step 717 (3768417) @ Episode 5168/10000, loss: 0.0061508608050644456\n",
      "Episode Reward: 11.0\n",
      "Step 1324 (3769741) @ Episode 5169/10000, loss: 0.0084147714078426365\n",
      "Episode Reward: 36.0\n",
      "Step 258 (3769999) @ Episode 5170/10000, loss: 0.0067499647848308095\n",
      " Copied model parameters to target network\n",
      "Step 603 (3770344) @ Episode 5170/10000, loss: 0.0054529262706637383\n",
      "Episode Reward: 9.0\n",
      "Step 1409 (3771753) @ Episode 5171/10000, loss: 0.0031856519635766745\n",
      "Episode Reward: 33.0\n",
      "Step 1048 (3772801) @ Episode 5172/10000, loss: 0.0027471997309476137\n",
      "Episode Reward: 24.0\n",
      "Step 895 (3773696) @ Episode 5173/10000, loss: 0.0034185997210443025\n",
      "Episode Reward: 17.0\n",
      "Step 1076 (3774772) @ Episode 5174/10000, loss: 0.0083231125026941384\n",
      "Episode Reward: 18.0\n",
      "Step 843 (3775615) @ Episode 5175/10000, loss: 0.0029360579792410135\n",
      "Episode Reward: 14.0\n",
      "Step 879 (3776494) @ Episode 5176/10000, loss: 0.0076340758241713055\n",
      "Episode Reward: 17.0\n",
      "Step 1060 (3777554) @ Episode 5177/10000, loss: 0.0051435125060379505\n",
      "Episode Reward: 25.0\n",
      "Step 377 (3777931) @ Episode 5178/10000, loss: 0.0016862185439094901\n",
      "Episode Reward: 4.0\n",
      "Step 1521 (3779452) @ Episode 5179/10000, loss: 0.0061247954145073895\n",
      "Episode Reward: 40.0\n",
      "Step 547 (3779999) @ Episode 5180/10000, loss: 0.0206405259668827064\n",
      " Copied model parameters to target network\n",
      "Step 873 (3780325) @ Episode 5180/10000, loss: 0.0100392885506153157\n",
      "Episode Reward: 16.0\n",
      "Step 670 (3780995) @ Episode 5181/10000, loss: 0.0068304920569062235\n",
      "Episode Reward: 10.0\n",
      "Step 801 (3781796) @ Episode 5182/10000, loss: 0.0060331784188747415\n",
      "Episode Reward: 12.0\n",
      "Step 1167 (3782963) @ Episode 5183/10000, loss: 0.0020665689371526246\n",
      "Episode Reward: 32.0\n",
      "Step 1023 (3783986) @ Episode 5184/10000, loss: 0.0029146256856620314\n",
      "Episode Reward: 17.0\n",
      "Step 1050 (3785036) @ Episode 5185/10000, loss: 0.0105199404060840697\n",
      "Episode Reward: 23.0\n",
      "Step 939 (3785975) @ Episode 5186/10000, loss: 0.0056828744709491735\n",
      "Episode Reward: 24.0\n",
      "Step 939 (3786914) @ Episode 5187/10000, loss: 0.0097637921571731575\n",
      "Episode Reward: 21.0\n",
      "Step 1076 (3787990) @ Episode 5188/10000, loss: 0.0067515978589653974\n",
      "Episode Reward: 22.0\n",
      "Step 598 (3788588) @ Episode 5189/10000, loss: 0.0058699720539152624\n",
      "Episode Reward: 10.0\n",
      "Step 820 (3789408) @ Episode 5190/10000, loss: 0.0063464860431849963\n",
      "Episode Reward: 14.0\n",
      "Step 583 (3789991) @ Episode 5191/10000, loss: 0.0061283092945814137\n",
      "Episode Reward: 9.0\n",
      "Step 8 (3789999) @ Episode 5192/10000, loss: 0.0051624570041894914\n",
      " Copied model parameters to target network\n",
      "Step 999 (3790990) @ Episode 5192/10000, loss: 0.0421720519661903464\n",
      "Episode Reward: 16.0\n",
      "Step 894 (3791884) @ Episode 5193/10000, loss: 0.0088140871375799185\n",
      "Episode Reward: 16.0\n",
      "Step 854 (3792738) @ Episode 5194/10000, loss: 0.0078501626849174512\n",
      "Episode Reward: 15.0\n",
      "Step 732 (3793470) @ Episode 5195/10000, loss: 0.0087551120668649676\n",
      "Episode Reward: 13.0\n",
      "Step 891 (3794361) @ Episode 5196/10000, loss: 0.0038283781614154577\n",
      "Episode Reward: 12.0\n",
      "Step 835 (3795196) @ Episode 5197/10000, loss: 0.0037321399431675673\n",
      "Episode Reward: 15.0\n",
      "Step 1133 (3796329) @ Episode 5198/10000, loss: 0.0076445718295872214\n",
      "Episode Reward: 27.0\n",
      "Step 733 (3797062) @ Episode 5199/10000, loss: 0.0035810014232993126\n",
      "Episode Reward: 18.0\n",
      "Step 594 (3797656) @ Episode 5200/10000, loss: 0.0063413991592824463\n",
      "Episode Reward: 7.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 02:21:02,428] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video005200.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1035 (3798691) @ Episode 5201/10000, loss: 0.0024959535803645855\n",
      "Episode Reward: 19.0\n",
      "Step 888 (3799579) @ Episode 5202/10000, loss: 0.0053439657203853136\n",
      "Episode Reward: 19.0\n",
      "Step 420 (3799999) @ Episode 5203/10000, loss: 0.0030149640515446663\n",
      " Copied model parameters to target network\n",
      "Step 968 (3800547) @ Episode 5203/10000, loss: 0.0226519517600536354\n",
      "Episode Reward: 25.0\n",
      "Step 870 (3801417) @ Episode 5204/10000, loss: 0.0104493508115410822\n",
      "Episode Reward: 17.0\n",
      "Step 755 (3802172) @ Episode 5205/10000, loss: 0.0059305555187165745\n",
      "Episode Reward: 11.0\n",
      "Step 907 (3803079) @ Episode 5206/10000, loss: 0.0031339928973466164\n",
      "Episode Reward: 23.0\n",
      "Step 902 (3803981) @ Episode 5207/10000, loss: 0.0090850237756967544\n",
      "Episode Reward: 16.0\n",
      "Step 409 (3804390) @ Episode 5208/10000, loss: 0.0064667426049709325\n",
      "Episode Reward: 5.0\n",
      "Step 932 (3805322) @ Episode 5209/10000, loss: 0.0030733775347471237\n",
      "Episode Reward: 28.0\n",
      "Step 753 (3806075) @ Episode 5210/10000, loss: 0.0066201025620102887\n",
      "Episode Reward: 12.0\n",
      "Step 725 (3806800) @ Episode 5211/10000, loss: 0.0069900704547762875\n",
      "Episode Reward: 12.0\n",
      "Step 797 (3807597) @ Episode 5212/10000, loss: 0.0035745874047279365\n",
      "Episode Reward: 19.0\n",
      "Step 1001 (3808598) @ Episode 5213/10000, loss: 0.011916939169168472\n",
      "Episode Reward: 23.0\n",
      "Step 604 (3809202) @ Episode 5214/10000, loss: 0.0039556929841637613\n",
      "Episode Reward: 11.0\n",
      "Step 797 (3809999) @ Episode 5215/10000, loss: 0.0053602382540702825\n",
      " Copied model parameters to target network\n",
      "Step 1141 (3810343) @ Episode 5215/10000, loss: 0.0057976315729320057\n",
      "Episode Reward: 23.0\n",
      "Step 626 (3810969) @ Episode 5216/10000, loss: 0.0044833407737314794\n",
      "Episode Reward: 9.0\n",
      "Step 726 (3811695) @ Episode 5217/10000, loss: 0.0017705342033877969\n",
      "Episode Reward: 13.0\n",
      "Step 1432 (3813127) @ Episode 5218/10000, loss: 0.0085080321878194815\n",
      "Episode Reward: 36.0\n",
      "Step 1058 (3814185) @ Episode 5219/10000, loss: 0.0055677001364529134\n",
      "Episode Reward: 18.0\n",
      "Step 777 (3814962) @ Episode 5220/10000, loss: 0.0043412866070866585\n",
      "Episode Reward: 17.0\n",
      "Step 844 (3815806) @ Episode 5221/10000, loss: 0.0046352995559573173\n",
      "Episode Reward: 17.0\n",
      "Step 1253 (3817059) @ Episode 5222/10000, loss: 0.0044706352055072784\n",
      "Episode Reward: 30.0\n",
      "Step 885 (3817944) @ Episode 5223/10000, loss: 0.0069194496609270575\n",
      "Episode Reward: 17.0\n",
      "Step 896 (3818840) @ Episode 5224/10000, loss: 0.0029351783450692893\n",
      "Episode Reward: 19.0\n",
      "Step 992 (3819832) @ Episode 5225/10000, loss: 0.0047690914943814286\n",
      "Episode Reward: 18.0\n",
      "Step 167 (3819999) @ Episode 5226/10000, loss: 0.0042229555547237498\n",
      " Copied model parameters to target network\n",
      "Step 928 (3820760) @ Episode 5226/10000, loss: 0.0031037756707519293\n",
      "Episode Reward: 25.0\n",
      "Step 1074 (3821834) @ Episode 5227/10000, loss: 0.0038567429874092343\n",
      "Episode Reward: 20.0\n",
      "Step 918 (3822752) @ Episode 5228/10000, loss: 0.0048956288956105715\n",
      "Episode Reward: 24.0\n",
      "Step 871 (3823623) @ Episode 5229/10000, loss: 0.0025249319151043893\n",
      "Episode Reward: 16.0\n",
      "Step 743 (3824366) @ Episode 5230/10000, loss: 0.0120098162442445765\n",
      "Episode Reward: 12.0\n",
      "Step 880 (3825246) @ Episode 5231/10000, loss: 0.0034456681460142136\n",
      "Episode Reward: 14.0\n",
      "Step 1030 (3826276) @ Episode 5232/10000, loss: 0.0038585395086556673\n",
      "Episode Reward: 26.0\n",
      "Step 1167 (3827443) @ Episode 5233/10000, loss: 0.0031773673836141825\n",
      "Episode Reward: 29.0\n",
      "Step 1073 (3828516) @ Episode 5234/10000, loss: 0.0050995266065001496\n",
      "Episode Reward: 23.0\n",
      "Step 802 (3829318) @ Episode 5235/10000, loss: 0.0083185639232397088\n",
      "Episode Reward: 21.0\n",
      "Step 681 (3829999) @ Episode 5236/10000, loss: 0.0071707246825098993\n",
      " Copied model parameters to target network\n",
      "Step 930 (3830248) @ Episode 5236/10000, loss: 0.0068648480810225018\n",
      "Episode Reward: 22.0\n",
      "Step 934 (3831182) @ Episode 5237/10000, loss: 0.0046234726905822755\n",
      "Episode Reward: 16.0\n",
      "Step 1364 (3832546) @ Episode 5238/10000, loss: 0.0065211476758122443\n",
      "Episode Reward: 29.0\n",
      "Step 862 (3833408) @ Episode 5239/10000, loss: 0.0157730933278799068\n",
      "Episode Reward: 22.0\n",
      "Step 1212 (3834620) @ Episode 5240/10000, loss: 0.0046150283887982375\n",
      "Episode Reward: 19.0\n",
      "Step 766 (3835386) @ Episode 5241/10000, loss: 0.0048399181105196485\n",
      "Episode Reward: 11.0\n",
      "Step 1193 (3836579) @ Episode 5242/10000, loss: 0.0063140308484435084\n",
      "Episode Reward: 21.0\n",
      "Step 1374 (3837953) @ Episode 5243/10000, loss: 0.0069869644939899445\n",
      "Episode Reward: 30.0\n",
      "Step 853 (3838806) @ Episode 5244/10000, loss: 0.0032385843805968765\n",
      "Episode Reward: 16.0\n",
      "Step 664 (3839470) @ Episode 5245/10000, loss: 0.0120107997208833784\n",
      "Episode Reward: 11.0\n",
      "Step 529 (3839999) @ Episode 5246/10000, loss: 0.0038915828336030245\n",
      " Copied model parameters to target network\n",
      "Step 936 (3840406) @ Episode 5246/10000, loss: 0.0055045010522007945\n",
      "Episode Reward: 17.0\n",
      "Step 1129 (3841535) @ Episode 5247/10000, loss: 0.0294824428856372833\n",
      "Episode Reward: 22.0\n",
      "Step 1404 (3842939) @ Episode 5248/10000, loss: 0.0040939394384622576\n",
      "Episode Reward: 33.0\n",
      "Step 926 (3843865) @ Episode 5249/10000, loss: 0.0035049326252192265\n",
      "Episode Reward: 24.0\n",
      "Step 876 (3844741) @ Episode 5250/10000, loss: 0.0140350051224231726\n",
      "Episode Reward: 15.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 02:28:11,341] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video005250.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 704 (3845445) @ Episode 5251/10000, loss: 0.0070788888260722165\n",
      "Episode Reward: 14.0\n",
      "Step 514 (3845959) @ Episode 5252/10000, loss: 0.0046291979961097244\n",
      "Episode Reward: 10.0\n",
      "Step 631 (3846590) @ Episode 5253/10000, loss: 0.0051542762666940694\n",
      "Episode Reward: 10.0\n",
      "Step 955 (3847545) @ Episode 5254/10000, loss: 0.0073549253866076475\n",
      "Episode Reward: 14.0\n",
      "Step 1111 (3848656) @ Episode 5255/10000, loss: 0.0207237266004085545\n",
      "Episode Reward: 21.0\n",
      "Step 475 (3849131) @ Episode 5256/10000, loss: 0.0082999160513281824\n",
      "Episode Reward: 7.0\n",
      "Step 868 (3849999) @ Episode 5257/10000, loss: 0.0077492133714258673\n",
      " Copied model parameters to target network\n",
      "Step 1116 (3850247) @ Episode 5257/10000, loss: 0.0194765180349349988\n",
      "Episode Reward: 22.0\n",
      "Step 909 (3851156) @ Episode 5258/10000, loss: 0.0122771225869655615\n",
      "Episode Reward: 19.0\n",
      "Step 1353 (3852509) @ Episode 5259/10000, loss: 0.0071510178968310363\n",
      "Episode Reward: 49.0\n",
      "Step 526 (3853035) @ Episode 5260/10000, loss: 0.0022637136280536657\n",
      "Episode Reward: 7.0\n",
      "Step 809 (3853844) @ Episode 5261/10000, loss: 0.0078687891364097646\n",
      "Episode Reward: 13.0\n",
      "Step 736 (3854580) @ Episode 5262/10000, loss: 0.0039709648117423067\n",
      "Episode Reward: 12.0\n",
      "Step 1181 (3855761) @ Episode 5263/10000, loss: 0.0024020685814321045\n",
      "Episode Reward: 22.0\n",
      "Step 916 (3856677) @ Episode 5264/10000, loss: 0.0052812281064689167\n",
      "Episode Reward: 16.0\n",
      "Step 926 (3857603) @ Episode 5265/10000, loss: 0.0471781119704246556\n",
      "Episode Reward: 15.0\n",
      "Step 717 (3858320) @ Episode 5266/10000, loss: 0.0086872410029172937\n",
      "Episode Reward: 12.0\n",
      "Step 835 (3859155) @ Episode 5267/10000, loss: 0.0562024079263210336\n",
      "Episode Reward: 18.0\n",
      "Step 844 (3859999) @ Episode 5268/10000, loss: 0.0115883983671665242\n",
      " Copied model parameters to target network\n",
      "Step 943 (3860098) @ Episode 5268/10000, loss: 0.0064847012981772425\n",
      "Episode Reward: 17.0\n",
      "Step 513 (3860611) @ Episode 5269/10000, loss: 0.0052110059186816216\n",
      "Episode Reward: 7.0\n",
      "Step 958 (3861569) @ Episode 5270/10000, loss: 0.0033602870535105467\n",
      "Episode Reward: 17.0\n",
      "Step 1018 (3862587) @ Episode 5271/10000, loss: 0.0041777524165809155\n",
      "Episode Reward: 18.0\n",
      "Step 942 (3863529) @ Episode 5272/10000, loss: 0.0157864168286323552\n",
      "Episode Reward: 20.0\n",
      "Step 935 (3864464) @ Episode 5273/10000, loss: 0.0318985134363174445\n",
      "Episode Reward: 24.0\n",
      "Step 883 (3865347) @ Episode 5274/10000, loss: 0.0133834425359964376\n",
      "Episode Reward: 19.0\n",
      "Step 885 (3866232) @ Episode 5275/10000, loss: 0.1103977635502815284\n",
      "Episode Reward: 21.0\n",
      "Step 673 (3866905) @ Episode 5276/10000, loss: 0.0074876928701996894\n",
      "Episode Reward: 13.0\n",
      "Step 729 (3867634) @ Episode 5277/10000, loss: 0.0054385093972086915\n",
      "Episode Reward: 16.0\n",
      "Step 579 (3868213) @ Episode 5278/10000, loss: 0.0055415318347513684\n",
      "Episode Reward: 16.0\n",
      "Step 786 (3868999) @ Episode 5279/10000, loss: 0.0032916669733822346\n",
      "Episode Reward: 14.0\n",
      "Step 671 (3869670) @ Episode 5280/10000, loss: 0.0032193176448345184\n",
      "Episode Reward: 11.0\n",
      "Step 329 (3869999) @ Episode 5281/10000, loss: 0.0049003046005964287\n",
      " Copied model parameters to target network\n",
      "Step 1844 (3871514) @ Episode 5281/10000, loss: 0.0036336313933134086\n",
      "Episode Reward: 60.0\n",
      "Step 709 (3872223) @ Episode 5282/10000, loss: 0.0075740851461887368\n",
      "Episode Reward: 12.0\n",
      "Step 926 (3873149) @ Episode 5283/10000, loss: 0.0112231569364666948\n",
      "Episode Reward: 19.0\n",
      "Step 1265 (3874414) @ Episode 5284/10000, loss: 0.0050747198984026914\n",
      "Episode Reward: 28.0\n",
      "Step 718 (3875132) @ Episode 5285/10000, loss: 0.0203291494399309166\n",
      "Episode Reward: 11.0\n",
      "Step 1068 (3876200) @ Episode 5286/10000, loss: 0.0047402377240359784\n",
      "Episode Reward: 28.0\n",
      "Step 782 (3876982) @ Episode 5287/10000, loss: 0.0058184443041682246\n",
      "Episode Reward: 16.0\n",
      "Step 1001 (3877983) @ Episode 5288/10000, loss: 0.0028239735402166843\n",
      "Episode Reward: 21.0\n",
      "Step 856 (3878839) @ Episode 5289/10000, loss: 0.0018081188900396228\n",
      "Episode Reward: 16.0\n",
      "Step 1160 (3879999) @ Episode 5290/10000, loss: 0.0074939662590622985\n",
      " Copied model parameters to target network\n",
      "Step 1169 (3880008) @ Episode 5290/10000, loss: 0.0042836330831050875\n",
      "Episode Reward: 21.0\n",
      "Step 709 (3880717) @ Episode 5291/10000, loss: 0.0097422422841191327\n",
      "Episode Reward: 15.0\n",
      "Step 793 (3881510) @ Episode 5292/10000, loss: 0.0029501819517463446\n",
      "Episode Reward: 14.0\n",
      "Step 752 (3882262) @ Episode 5293/10000, loss: 0.0245618987828493125\n",
      "Episode Reward: 11.0\n",
      "Step 830 (3883092) @ Episode 5294/10000, loss: 0.0062758941203355797\n",
      "Episode Reward: 13.0\n",
      "Step 620 (3883712) @ Episode 5295/10000, loss: 0.0036001647822558884\n",
      "Episode Reward: 10.0\n",
      "Step 685 (3884397) @ Episode 5296/10000, loss: 0.0033811077009886503\n",
      "Episode Reward: 9.0\n",
      "Step 633 (3885030) @ Episode 5297/10000, loss: 0.0049506817013025288\n",
      "Episode Reward: 8.0\n",
      "Step 715 (3885745) @ Episode 5298/10000, loss: 0.0062756221741437913\n",
      "Episode Reward: 17.0\n",
      "Step 999 (3886744) @ Episode 5299/10000, loss: 0.0145323872566223148\n",
      "Episode Reward: 20.0\n",
      "Step 703 (3887447) @ Episode 5300/10000, loss: 0.0067917509004473693\n",
      "Episode Reward: 12.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 02:34:45,977] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video005300.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1365 (3888812) @ Episode 5301/10000, loss: 0.0118780145421624184\n",
      "Episode Reward: 44.0\n",
      "Step 1006 (3889818) @ Episode 5302/10000, loss: 0.0100554572418332175\n",
      "Episode Reward: 21.0\n",
      "Step 181 (3889999) @ Episode 5303/10000, loss: 0.0035717007704079158\n",
      " Copied model parameters to target network\n",
      "Step 628 (3890446) @ Episode 5303/10000, loss: 0.0030445882584899664\n",
      "Episode Reward: 16.0\n",
      "Step 913 (3891359) @ Episode 5304/10000, loss: 0.0056231245398521426\n",
      "Episode Reward: 18.0\n",
      "Step 796 (3892155) @ Episode 5305/10000, loss: 0.0114003419876098635\n",
      "Episode Reward: 14.0\n",
      "Step 1144 (3893299) @ Episode 5306/10000, loss: 0.0071263662539422515\n",
      "Episode Reward: 30.0\n",
      "Step 1711 (3895010) @ Episode 5307/10000, loss: 0.0157013460993766858\n",
      "Episode Reward: 35.0\n",
      "Step 1046 (3896056) @ Episode 5308/10000, loss: 0.0064951376989483836\n",
      "Episode Reward: 22.0\n",
      "Step 859 (3896915) @ Episode 5309/10000, loss: 0.0023048743605613718\n",
      "Episode Reward: 14.0\n",
      "Step 646 (3897561) @ Episode 5310/10000, loss: 0.0029691169038414955\n",
      "Episode Reward: 10.0\n",
      "Step 684 (3898245) @ Episode 5311/10000, loss: 0.0069370269775390625\n",
      "Episode Reward: 14.0\n",
      "Step 883 (3899128) @ Episode 5312/10000, loss: 0.0069177350960671974\n",
      "Episode Reward: 14.0\n",
      "Step 635 (3899763) @ Episode 5313/10000, loss: 0.0031340646091848616\n",
      "Episode Reward: 12.0\n",
      "Step 236 (3899999) @ Episode 5314/10000, loss: 0.0044254059903323655\n",
      " Copied model parameters to target network\n",
      "Step 630 (3900393) @ Episode 5314/10000, loss: 0.0032254299148917253\n",
      "Episode Reward: 8.0\n",
      "Step 1235 (3901628) @ Episode 5315/10000, loss: 0.0071319374255836016\n",
      "Episode Reward: 29.0\n",
      "Step 1032 (3902660) @ Episode 5316/10000, loss: 0.0043260790407657623\n",
      "Episode Reward: 24.0\n",
      "Step 1169 (3903829) @ Episode 5317/10000, loss: 0.0024812500923871994\n",
      "Episode Reward: 19.0\n",
      "Step 866 (3904695) @ Episode 5318/10000, loss: 0.0256002377718687063\n",
      "Episode Reward: 13.0\n",
      "Step 771 (3905466) @ Episode 5319/10000, loss: 0.0050994371995329866\n",
      "Episode Reward: 15.0\n",
      "Step 822 (3906288) @ Episode 5320/10000, loss: 0.0059770727530121846\n",
      "Episode Reward: 17.0\n",
      "Step 1035 (3907323) @ Episode 5321/10000, loss: 0.0072876047343015677\n",
      "Episode Reward: 29.0\n",
      "Step 887 (3908210) @ Episode 5322/10000, loss: 0.0094628185033798223\n",
      "Episode Reward: 14.0\n",
      "Step 821 (3909031) @ Episode 5323/10000, loss: 0.0019458237802609801\n",
      "Episode Reward: 15.0\n",
      "Step 968 (3909999) @ Episode 5324/10000, loss: 0.0024354688357561827\n",
      " Copied model parameters to target network\n",
      "Step 971 (3910002) @ Episode 5324/10000, loss: 0.0026179777923971415\n",
      "Episode Reward: 17.0\n",
      "Step 606 (3910608) @ Episode 5325/10000, loss: 0.0022310302592813971\n",
      "Episode Reward: 10.0\n",
      "Step 752 (3911360) @ Episode 5326/10000, loss: 0.0433569774031639187\n",
      "Episode Reward: 16.0\n",
      "Step 1026 (3912386) @ Episode 5327/10000, loss: 0.0186763294041156773\n",
      "Episode Reward: 18.0\n",
      "Step 795 (3913181) @ Episode 5328/10000, loss: 0.0090232565999031072\n",
      "Episode Reward: 13.0\n",
      "Step 458 (3913639) @ Episode 5329/10000, loss: 0.0094475494697690012\n",
      "Episode Reward: 6.0\n",
      "Step 842 (3914481) @ Episode 5330/10000, loss: 0.0054315901361405854\n",
      "Episode Reward: 13.0\n",
      "Step 971 (3915452) @ Episode 5331/10000, loss: 0.0076269628480076796\n",
      "Episode Reward: 23.0\n",
      "Step 794 (3916246) @ Episode 5332/10000, loss: 0.0047277444973587993\n",
      "Episode Reward: 19.0\n",
      "Step 1029 (3917275) @ Episode 5333/10000, loss: 0.0070807286538183694\n",
      "Episode Reward: 18.0\n",
      "Step 860 (3918135) @ Episode 5334/10000, loss: 0.0059227906167507179\n",
      "Episode Reward: 14.0\n",
      "Step 984 (3919119) @ Episode 5335/10000, loss: 0.0030183931812644005\n",
      "Episode Reward: 18.0\n",
      "Step 722 (3919841) @ Episode 5336/10000, loss: 0.0084663424640893945\n",
      "Episode Reward: 12.0\n",
      "Step 158 (3919999) @ Episode 5337/10000, loss: 0.0029399739578366286\n",
      " Copied model parameters to target network\n",
      "Step 895 (3920736) @ Episode 5337/10000, loss: 0.0052347737364470965\n",
      "Episode Reward: 18.0\n",
      "Step 1002 (3921738) @ Episode 5338/10000, loss: 0.003949708305299282\n",
      "Episode Reward: 20.0\n",
      "Step 829 (3922567) @ Episode 5339/10000, loss: 0.0054904744029045105\n",
      "Episode Reward: 16.0\n",
      "Step 1232 (3923799) @ Episode 5340/10000, loss: 0.0032222203444689512\n",
      "Episode Reward: 23.0\n",
      "Step 848 (3924647) @ Episode 5341/10000, loss: 0.0022108326666057115\n",
      "Episode Reward: 17.0\n",
      "Step 730 (3925377) @ Episode 5342/10000, loss: 0.0046405643224716195\n",
      "Episode Reward: 12.0\n",
      "Step 685 (3926062) @ Episode 5343/10000, loss: 0.0041876994073390965\n",
      "Episode Reward: 9.0\n",
      "Step 1113 (3927175) @ Episode 5344/10000, loss: 0.0054811867885291583\n",
      "Episode Reward: 23.0\n",
      "Step 800 (3927975) @ Episode 5345/10000, loss: 0.0101681621745228773\n",
      "Episode Reward: 10.0\n",
      "Step 891 (3928866) @ Episode 5346/10000, loss: 0.0092005077749490745\n",
      "Episode Reward: 17.0\n",
      "Step 884 (3929750) @ Episode 5347/10000, loss: 0.0031300818081945187\n",
      "Episode Reward: 16.0\n",
      "Step 249 (3929999) @ Episode 5348/10000, loss: 0.0076206251978874214\n",
      " Copied model parameters to target network\n",
      "Step 832 (3930582) @ Episode 5348/10000, loss: 0.0072033377364277844\n",
      "Episode Reward: 15.0\n",
      "Step 827 (3931409) @ Episode 5349/10000, loss: 0.0046397531405091298\n",
      "Episode Reward: 14.0\n",
      "Step 864 (3932273) @ Episode 5350/10000, loss: 0.0085982335731387147\n",
      "Episode Reward: 16.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 02:41:37,606] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video005350.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 729 (3933002) @ Episode 5351/10000, loss: 0.0050270697101950645\n",
      "Episode Reward: 12.0\n",
      "Step 1116 (3934118) @ Episode 5352/10000, loss: 0.0120861176401376725\n",
      "Episode Reward: 20.0\n",
      "Step 871 (3934989) @ Episode 5353/10000, loss: 0.0082487398758530625\n",
      "Episode Reward: 22.0\n",
      "Step 815 (3935804) @ Episode 5354/10000, loss: 0.0044122235849499737\n",
      "Episode Reward: 15.0\n",
      "Step 874 (3936678) @ Episode 5355/10000, loss: 0.0041626105085015337\n",
      "Episode Reward: 15.0\n",
      "Step 673 (3937351) @ Episode 5356/10000, loss: 0.0064616678282618525\n",
      "Episode Reward: 12.0\n",
      "Step 970 (3938321) @ Episode 5357/10000, loss: 0.0062870783731341362\n",
      "Episode Reward: 15.0\n",
      "Step 1158 (3939479) @ Episode 5358/10000, loss: 0.0076029477640986445\n",
      "Episode Reward: 21.0\n",
      "Step 520 (3939999) @ Episode 5359/10000, loss: 0.0066256234422326093\n",
      " Copied model parameters to target network\n",
      "Step 1116 (3940595) @ Episode 5359/10000, loss: 0.0022290660999715334\n",
      "Episode Reward: 21.0\n",
      "Step 988 (3941583) @ Episode 5360/10000, loss: 0.0031833469402045013\n",
      "Episode Reward: 23.0\n",
      "Step 882 (3942465) @ Episode 5361/10000, loss: 0.0060465354472398764\n",
      "Episode Reward: 18.0\n",
      "Step 661 (3943126) @ Episode 5362/10000, loss: 0.0030389407183974982\n",
      "Episode Reward: 8.0\n",
      "Step 932 (3944058) @ Episode 5363/10000, loss: 0.0020881001837551594\n",
      "Episode Reward: 15.0\n",
      "Step 744 (3944802) @ Episode 5364/10000, loss: 0.0031320096459239724\n",
      "Episode Reward: 14.0\n",
      "Step 953 (3945755) @ Episode 5365/10000, loss: 0.0163334533572196964\n",
      "Episode Reward: 16.0\n",
      "Step 798 (3946553) @ Episode 5366/10000, loss: 0.0061599179171025756\n",
      "Episode Reward: 13.0\n",
      "Step 1122 (3947675) @ Episode 5367/10000, loss: 0.0042638462036848076\n",
      "Episode Reward: 25.0\n",
      "Step 694 (3948369) @ Episode 5368/10000, loss: 0.0018584199715405703\n",
      "Episode Reward: 9.0\n",
      "Step 894 (3949263) @ Episode 5369/10000, loss: 0.0082340817898511897\n",
      "Episode Reward: 14.0\n",
      "Step 736 (3949999) @ Episode 5370/10000, loss: 0.0075763300992548477\n",
      " Copied model parameters to target network\n",
      "Step 927 (3950190) @ Episode 5370/10000, loss: 0.0050552599132061005\n",
      "Episode Reward: 18.0\n",
      "Step 755 (3950945) @ Episode 5371/10000, loss: 0.0163390748202800758\n",
      "Episode Reward: 13.0\n",
      "Step 981 (3951926) @ Episode 5372/10000, loss: 0.0030390243045985764\n",
      "Episode Reward: 24.0\n",
      "Step 787 (3952713) @ Episode 5373/10000, loss: 0.0066959988325834276\n",
      "Episode Reward: 14.0\n",
      "Step 799 (3953512) @ Episode 5374/10000, loss: 0.0027068159542977816\n",
      "Episode Reward: 12.0\n",
      "Step 732 (3954244) @ Episode 5375/10000, loss: 0.0022299992851912975\n",
      "Episode Reward: 10.0\n",
      "Step 476 (3954720) @ Episode 5376/10000, loss: 0.0120890028774738315\n",
      "Episode Reward: 7.0\n",
      "Step 1359 (3956079) @ Episode 5377/10000, loss: 0.0051957461982965472\n",
      "Episode Reward: 32.0\n",
      "Step 655 (3956734) @ Episode 5378/10000, loss: 0.0054239397868514066\n",
      "Episode Reward: 11.0\n",
      "Step 850 (3957584) @ Episode 5379/10000, loss: 0.0049982685595750815\n",
      "Episode Reward: 23.0\n",
      "Step 1044 (3958628) @ Episode 5380/10000, loss: 0.0028753788210451603\n",
      "Episode Reward: 17.0\n",
      "Step 722 (3959350) @ Episode 5381/10000, loss: 0.0046882200986146934\n",
      "Episode Reward: 11.0\n",
      "Step 649 (3959999) @ Episode 5382/10000, loss: 0.0031026811338961124\n",
      " Copied model parameters to target network\n",
      "Step 717 (3960067) @ Episode 5382/10000, loss: 0.0055380491539835934\n",
      "Episode Reward: 12.0\n",
      "Step 953 (3961020) @ Episode 5383/10000, loss: 0.0120851816609501846\n",
      "Episode Reward: 19.0\n",
      "Step 828 (3961848) @ Episode 5384/10000, loss: 0.0028322762809693813\n",
      "Episode Reward: 10.0\n",
      "Step 725 (3962573) @ Episode 5385/10000, loss: 0.0020758039318025115\n",
      "Episode Reward: 19.0\n",
      "Step 896 (3963469) @ Episode 5386/10000, loss: 0.0022944069933146245\n",
      "Episode Reward: 19.0\n",
      "Step 590 (3964059) @ Episode 5387/10000, loss: 0.0058974758721888065\n",
      "Episode Reward: 5.0\n",
      "Step 783 (3964842) @ Episode 5388/10000, loss: 0.0076145110651850765\n",
      "Episode Reward: 11.0\n",
      "Step 868 (3965710) @ Episode 5389/10000, loss: 0.0035024869721382856\n",
      "Episode Reward: 16.0\n",
      "Step 1047 (3966757) @ Episode 5390/10000, loss: 0.0044791842810809616\n",
      "Episode Reward: 22.0\n",
      "Step 515 (3967272) @ Episode 5391/10000, loss: 0.0040969392284750947\n",
      "Episode Reward: 8.0\n",
      "Step 1221 (3968493) @ Episode 5392/10000, loss: 0.0047777337022125725\n",
      "Episode Reward: 21.0\n",
      "Step 1114 (3969607) @ Episode 5393/10000, loss: 0.0176052227616310124\n",
      "Episode Reward: 33.0\n",
      "Step 392 (3969999) @ Episode 5394/10000, loss: 0.0041238125413656235\n",
      " Copied model parameters to target network\n",
      "Step 1049 (3970656) @ Episode 5394/10000, loss: 0.0161639358848333365\n",
      "Episode Reward: 26.0\n",
      "Step 754 (3971410) @ Episode 5395/10000, loss: 0.0160762201994657576\n",
      "Episode Reward: 17.0\n",
      "Step 1198 (3972608) @ Episode 5396/10000, loss: 0.0104514267295598985\n",
      "Episode Reward: 23.0\n",
      "Step 642 (3973250) @ Episode 5397/10000, loss: 0.0040352325886487964\n",
      "Episode Reward: 9.0\n",
      "Step 631 (3973881) @ Episode 5398/10000, loss: 0.0184024460613727575\n",
      "Episode Reward: 13.0\n",
      "Step 962 (3974843) @ Episode 5399/10000, loss: 0.0043888567015528685\n",
      "Episode Reward: 15.0\n",
      "Step 1390 (3976233) @ Episode 5400/10000, loss: 0.0313671156764030464\n",
      "Episode Reward: 32.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 02:48:24,320] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video005400.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 930 (3977163) @ Episode 5401/10000, loss: 0.0065893647260963927\n",
      "Episode Reward: 20.0\n",
      "Step 824 (3977987) @ Episode 5402/10000, loss: 0.0099755162373185165\n",
      "Episode Reward: 14.0\n",
      "Step 953 (3978940) @ Episode 5403/10000, loss: 0.0020123920403420925\n",
      "Episode Reward: 16.0\n",
      "Step 987 (3979927) @ Episode 5404/10000, loss: 0.0076381498947739638\n",
      "Episode Reward: 24.0\n",
      "Step 72 (3979999) @ Episode 5405/10000, loss: 0.0078515652567148256\n",
      " Copied model parameters to target network\n",
      "Step 889 (3980816) @ Episode 5405/10000, loss: 0.0155056230723857882\n",
      "Episode Reward: 26.0\n",
      "Step 790 (3981606) @ Episode 5406/10000, loss: 0.0045356038026511675\n",
      "Episode Reward: 12.0\n",
      "Step 1423 (3983029) @ Episode 5407/10000, loss: 0.0093366093933582393\n",
      "Episode Reward: 36.0\n",
      "Step 968 (3983997) @ Episode 5408/10000, loss: 0.0134377731010317875\n",
      "Episode Reward: 20.0\n",
      "Step 480 (3984477) @ Episode 5409/10000, loss: 0.0022824869956821203\n",
      "Episode Reward: 7.0\n",
      "Step 680 (3985157) @ Episode 5410/10000, loss: 0.0029110063333064318\n",
      "Episode Reward: 11.0\n",
      "Step 718 (3985875) @ Episode 5411/10000, loss: 0.0066558099351823336\n",
      "Episode Reward: 12.0\n",
      "Step 885 (3986760) @ Episode 5412/10000, loss: 0.0036537526175379753\n",
      "Episode Reward: 17.0\n",
      "Step 615 (3987375) @ Episode 5413/10000, loss: 0.0071900468319654465\n",
      "Episode Reward: 9.0\n",
      "Step 723 (3988098) @ Episode 5414/10000, loss: 0.0019146142294630408\n",
      "Episode Reward: 12.0\n",
      "Step 1102 (3989200) @ Episode 5415/10000, loss: 0.0116380602121353154\n",
      "Episode Reward: 19.0\n",
      "Step 653 (3989853) @ Episode 5416/10000, loss: 0.0036014816723763943\n",
      "Episode Reward: 11.0\n",
      "Step 146 (3989999) @ Episode 5417/10000, loss: 0.0081466725096106535\n",
      " Copied model parameters to target network\n",
      "Step 871 (3990724) @ Episode 5417/10000, loss: 0.0040873475372791295\n",
      "Episode Reward: 15.0\n",
      "Step 565 (3991289) @ Episode 5418/10000, loss: 0.0111272428184747744\n",
      "Episode Reward: 9.0\n",
      "Step 1232 (3992521) @ Episode 5419/10000, loss: 0.0047700884751975543\n",
      "Episode Reward: 24.0\n",
      "Step 1007 (3993528) @ Episode 5420/10000, loss: 0.008209513500332832\n",
      "Episode Reward: 19.0\n",
      "Step 759 (3994287) @ Episode 5421/10000, loss: 0.0062196003273129466\n",
      "Episode Reward: 12.0\n",
      "Step 1005 (3995292) @ Episode 5422/10000, loss: 0.0061517800204455854\n",
      "Episode Reward: 14.0\n",
      "Step 832 (3996124) @ Episode 5423/10000, loss: 0.0049298908561468124\n",
      "Episode Reward: 13.0\n",
      "Step 900 (3997024) @ Episode 5424/10000, loss: 0.0061855530366301545\n",
      "Episode Reward: 16.0\n",
      "Step 733 (3997757) @ Episode 5425/10000, loss: 0.0034700646065175533\n",
      "Episode Reward: 13.0\n",
      "Step 893 (3998650) @ Episode 5426/10000, loss: 0.0069668754003942015\n",
      "Episode Reward: 15.0\n",
      "Step 1024 (3999674) @ Episode 5427/10000, loss: 0.0074376007542014124\n",
      "Episode Reward: 17.0\n",
      "Step 325 (3999999) @ Episode 5428/10000, loss: 0.0054536266252398494\n",
      " Copied model parameters to target network\n",
      "Step 774 (4000448) @ Episode 5428/10000, loss: 0.0056160665117204193\n",
      "Episode Reward: 18.0\n",
      "Step 708 (4001156) @ Episode 5429/10000, loss: 0.0059542758390307437\n",
      "Episode Reward: 14.0\n",
      "Step 841 (4001997) @ Episode 5430/10000, loss: 0.0037318635731935564\n",
      "Episode Reward: 18.0\n",
      "Step 664 (4002661) @ Episode 5431/10000, loss: 0.0052990783005952835\n",
      "Episode Reward: 6.0\n",
      "Step 795 (4003456) @ Episode 5432/10000, loss: 0.0033832795452326536\n",
      "Episode Reward: 17.0\n",
      "Step 563 (4004019) @ Episode 5433/10000, loss: 0.0051117585971951485\n",
      "Episode Reward: 7.0\n",
      "Step 1058 (4005077) @ Episode 5434/10000, loss: 0.0046602818183600974\n",
      "Episode Reward: 21.0\n",
      "Step 969 (4006046) @ Episode 5435/10000, loss: 0.0047181076370179657\n",
      "Episode Reward: 20.0\n",
      "Step 680 (4006726) @ Episode 5436/10000, loss: 0.0046536410227417953\n",
      "Episode Reward: 13.0\n",
      "Step 743 (4007469) @ Episode 5437/10000, loss: 0.0102444402873516086\n",
      "Episode Reward: 15.0\n",
      "Step 865 (4008334) @ Episode 5438/10000, loss: 0.0048468420282006263\n",
      "Episode Reward: 22.0\n",
      "Step 576 (4008910) @ Episode 5439/10000, loss: 0.0049261357635259633\n",
      "Episode Reward: 7.0\n",
      "Step 830 (4009740) @ Episode 5440/10000, loss: 0.0067278794012963776\n",
      "Episode Reward: 17.0\n",
      "Step 259 (4009999) @ Episode 5441/10000, loss: 0.0050739012658596044\n",
      " Copied model parameters to target network\n",
      "Step 907 (4010647) @ Episode 5441/10000, loss: 0.0061741834506392488\n",
      "Episode Reward: 15.0\n",
      "Step 845 (4011492) @ Episode 5442/10000, loss: 0.0027777524664998055\n",
      "Episode Reward: 14.0\n",
      "Step 1315 (4012807) @ Episode 5443/10000, loss: 0.0023346871603280306\n",
      "Episode Reward: 26.0\n",
      "Step 750 (4013557) @ Episode 5444/10000, loss: 0.0043119429610669613\n",
      "Episode Reward: 16.0\n",
      "Step 646 (4014203) @ Episode 5445/10000, loss: 0.0102170361205935486\n",
      "Episode Reward: 10.0\n",
      "Step 891 (4015094) @ Episode 5446/10000, loss: 0.0019725123420357704\n",
      "Episode Reward: 13.0\n",
      "Step 936 (4016030) @ Episode 5447/10000, loss: 0.0061850720085203655\n",
      "Episode Reward: 16.0\n",
      "Step 954 (4016984) @ Episode 5448/10000, loss: 0.0049398280680179636\n",
      "Episode Reward: 17.0\n",
      "Step 565 (4017549) @ Episode 5449/10000, loss: 0.0068561905063688755\n",
      "Episode Reward: 8.0\n",
      "Step 783 (4018332) @ Episode 5450/10000, loss: 0.0073968106880784035\n",
      "Episode Reward: 14.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 02:54:53,337] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video005450.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 644 (4018976) @ Episode 5451/10000, loss: 0.0032406440004706383\n",
      "Episode Reward: 9.0\n",
      "Step 543 (4019519) @ Episode 5452/10000, loss: 0.0062524504028260714\n",
      "Episode Reward: 9.0\n",
      "Step 480 (4019999) @ Episode 5453/10000, loss: 0.0487636066973209435\n",
      " Copied model parameters to target network\n",
      "Step 705 (4020224) @ Episode 5453/10000, loss: 0.0016233341302722692\n",
      "Episode Reward: 14.0\n",
      "Step 829 (4021053) @ Episode 5454/10000, loss: 0.0026154723018407825\n",
      "Episode Reward: 15.0\n",
      "Step 916 (4021969) @ Episode 5455/10000, loss: 0.0019842712208628654\n",
      "Episode Reward: 21.0\n",
      "Step 617 (4022586) @ Episode 5456/10000, loss: 0.0091768288984894755\n",
      "Episode Reward: 10.0\n",
      "Step 759 (4023345) @ Episode 5457/10000, loss: 0.0020847404375672343\n",
      "Episode Reward: 25.0\n",
      "Step 956 (4024301) @ Episode 5458/10000, loss: 0.0034558004699647427\n",
      "Episode Reward: 21.0\n",
      "Step 520 (4024821) @ Episode 5459/10000, loss: 0.0056828921660780917\n",
      "Episode Reward: 8.0\n",
      "Step 1226 (4026047) @ Episode 5460/10000, loss: 0.0071272784844040877\n",
      "Episode Reward: 24.0\n",
      "Step 924 (4026971) @ Episode 5461/10000, loss: 0.0032454463653266437\n",
      "Episode Reward: 22.0\n",
      "Step 525 (4027496) @ Episode 5462/10000, loss: 0.0025755378883332014\n",
      "Episode Reward: 8.0\n",
      "Step 916 (4028412) @ Episode 5463/10000, loss: 0.0034677754156291485\n",
      "Episode Reward: 15.0\n",
      "Step 504 (4028916) @ Episode 5464/10000, loss: 0.0053520421497523785\n",
      "Episode Reward: 6.0\n",
      "Step 929 (4029845) @ Episode 5465/10000, loss: 0.0074744978919625285\n",
      "Episode Reward: 21.0\n",
      "Step 154 (4029999) @ Episode 5466/10000, loss: 0.0092712566256523137\n",
      " Copied model parameters to target network\n",
      "Step 1058 (4030903) @ Episode 5466/10000, loss: 0.0047502168454229835\n",
      "Episode Reward: 22.0\n",
      "Step 651 (4031554) @ Episode 5467/10000, loss: 0.0049300417304039245\n",
      "Episode Reward: 13.0\n",
      "Step 946 (4032500) @ Episode 5468/10000, loss: 0.0056292838416993625\n",
      "Episode Reward: 18.0\n",
      "Step 754 (4033254) @ Episode 5469/10000, loss: 0.0056732175871729858\n",
      "Episode Reward: 15.0\n",
      "Step 868 (4034122) @ Episode 5470/10000, loss: 0.0098501639440655784\n",
      "Episode Reward: 14.0\n",
      "Step 820 (4034942) @ Episode 5471/10000, loss: 0.0049454653635621077\n",
      "Episode Reward: 19.0\n",
      "Step 930 (4035872) @ Episode 5472/10000, loss: 0.0058888685889542164\n",
      "Episode Reward: 20.0\n",
      "Step 839 (4036711) @ Episode 5473/10000, loss: 0.0076517248526215555\n",
      "Episode Reward: 20.0\n",
      "Step 656 (4037367) @ Episode 5474/10000, loss: 0.0050833863206207756\n",
      "Episode Reward: 17.0\n",
      "Step 789 (4038156) @ Episode 5475/10000, loss: 0.0062120510265231136\n",
      "Episode Reward: 15.0\n",
      "Step 578 (4038734) @ Episode 5476/10000, loss: 0.0039097443222999577\n",
      "Episode Reward: 8.0\n",
      "Step 908 (4039642) @ Episode 5477/10000, loss: 0.0127015579491853714\n",
      "Episode Reward: 17.0\n",
      "Step 357 (4039999) @ Episode 5478/10000, loss: 0.0028025384526699784\n",
      " Copied model parameters to target network\n",
      "Step 896 (4040538) @ Episode 5478/10000, loss: 0.0050609298050403595\n",
      "Episode Reward: 15.0\n",
      "Step 1029 (4041567) @ Episode 5479/10000, loss: 0.0037947827950119972\n",
      "Episode Reward: 21.0\n",
      "Step 957 (4042524) @ Episode 5480/10000, loss: 0.0092651117593052073\n",
      "Episode Reward: 23.0\n",
      "Step 717 (4043241) @ Episode 5481/10000, loss: 0.0081336526200175298\n",
      "Episode Reward: 11.0\n",
      "Step 983 (4044224) @ Episode 5482/10000, loss: 0.0037254313938319683\n",
      "Episode Reward: 16.0\n",
      "Step 602 (4044826) @ Episode 5483/10000, loss: 0.0053095761686563494\n",
      "Episode Reward: 9.0\n",
      "Step 583 (4045409) @ Episode 5484/10000, loss: 0.0108282845467329037\n",
      "Episode Reward: 12.0\n",
      "Step 611 (4046020) @ Episode 5485/10000, loss: 0.0036837493535131216\n",
      "Episode Reward: 9.0\n",
      "Step 943 (4046963) @ Episode 5486/10000, loss: 0.0033588795922696599\n",
      "Episode Reward: 17.0\n",
      "Step 597 (4047560) @ Episode 5487/10000, loss: 0.0066372617147862915\n",
      "Episode Reward: 9.0\n",
      "Step 872 (4048432) @ Episode 5488/10000, loss: 0.0068212579935789113\n",
      "Episode Reward: 15.0\n",
      "Step 1045 (4049477) @ Episode 5489/10000, loss: 0.0068517345935106285\n",
      "Episode Reward: 23.0\n",
      "Step 512 (4049989) @ Episode 5490/10000, loss: 0.0084184240549802785\n",
      "Episode Reward: 8.0\n",
      "Step 10 (4049999) @ Episode 5491/10000, loss: 0.006522866897284985\n",
      " Copied model parameters to target network\n",
      "Step 928 (4050917) @ Episode 5491/10000, loss: 0.0041470332071185115\n",
      "Episode Reward: 22.0\n",
      "Step 616 (4051533) @ Episode 5492/10000, loss: 0.0023357914760708812\n",
      "Episode Reward: 8.0\n",
      "Step 799 (4052332) @ Episode 5493/10000, loss: 0.0023120522964745765\n",
      "Episode Reward: 12.0\n",
      "Step 534 (4052866) @ Episode 5494/10000, loss: 0.0047849896363914014\n",
      "Episode Reward: 8.0\n",
      "Step 697 (4053563) @ Episode 5495/10000, loss: 0.0082727484405040746\n",
      "Episode Reward: 15.0\n",
      "Step 793 (4054356) @ Episode 5496/10000, loss: 0.0014173166127875447\n",
      "Episode Reward: 11.0\n",
      "Step 676 (4055032) @ Episode 5497/10000, loss: 0.0039946227334439754\n",
      "Episode Reward: 14.0\n",
      "Step 1572 (4056604) @ Episode 5498/10000, loss: 0.0038637788966298103\n",
      "Episode Reward: 34.0\n",
      "Step 660 (4057264) @ Episode 5499/10000, loss: 0.0025960602797567844\n",
      "Episode Reward: 11.0\n",
      "Step 1183 (4058447) @ Episode 5500/10000, loss: 0.0090534761548042384\n",
      "Episode Reward: 20.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 03:01:06,189] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video005500.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1027 (4059474) @ Episode 5501/10000, loss: 0.0024860822595655923\n",
      "Episode Reward: 15.0\n",
      "Step 525 (4059999) @ Episode 5502/10000, loss: 0.0057395990006625653\n",
      " Copied model parameters to target network\n",
      "Step 870 (4060344) @ Episode 5502/10000, loss: 0.0100746713578701026\n",
      "Episode Reward: 13.0\n",
      "Step 792 (4061136) @ Episode 5503/10000, loss: 0.0042018312960863113\n",
      "Episode Reward: 20.0\n",
      "Step 1065 (4062201) @ Episode 5504/10000, loss: 0.0038977819494903088\n",
      "Episode Reward: 18.0\n",
      "Step 513 (4062714) @ Episode 5505/10000, loss: 0.0281266383826732647\n",
      "Episode Reward: 8.0\n",
      "Step 1048 (4063762) @ Episode 5506/10000, loss: 0.0039689084514975555\n",
      "Episode Reward: 21.0\n",
      "Step 827 (4064589) @ Episode 5507/10000, loss: 0.0096416752785444268\n",
      "Episode Reward: 13.0\n",
      "Step 682 (4065271) @ Episode 5508/10000, loss: 0.0084910197183489895\n",
      "Episode Reward: 11.0\n",
      "Step 988 (4066259) @ Episode 5509/10000, loss: 0.0042981775477528575\n",
      "Episode Reward: 22.0\n",
      "Step 954 (4067213) @ Episode 5510/10000, loss: 0.0086957998573780065\n",
      "Episode Reward: 19.0\n",
      "Step 1003 (4068216) @ Episode 5511/10000, loss: 0.0027183871716260915\n",
      "Episode Reward: 17.0\n",
      "Step 1570 (4069786) @ Episode 5512/10000, loss: 0.0110618704929947854\n",
      "Episode Reward: 43.0\n",
      "Step 213 (4069999) @ Episode 5513/10000, loss: 0.0096075190231204037\n",
      " Copied model parameters to target network\n",
      "Step 1315 (4071101) @ Episode 5513/10000, loss: 0.0098713729530572894\n",
      "Episode Reward: 30.0\n",
      "Step 637 (4071738) @ Episode 5514/10000, loss: 0.0166363585740327842\n",
      "Episode Reward: 10.0\n",
      "Step 570 (4072308) @ Episode 5515/10000, loss: 0.0043001947924494744\n",
      "Episode Reward: 8.0\n",
      "Step 631 (4072939) @ Episode 5516/10000, loss: 0.0098340678960084925\n",
      "Episode Reward: 14.0\n",
      "Step 898 (4073837) @ Episode 5517/10000, loss: 0.0071671493351459563\n",
      "Episode Reward: 13.0\n",
      "Step 1170 (4075007) @ Episode 5518/10000, loss: 0.0038020375650376083\n",
      "Episode Reward: 27.0\n",
      "Step 1211 (4076218) @ Episode 5519/10000, loss: 0.0044152429327368746\n",
      "Episode Reward: 32.0\n",
      "Step 962 (4077180) @ Episode 5520/10000, loss: 0.0027543958276510243\n",
      "Episode Reward: 16.0\n",
      "Step 1325 (4078505) @ Episode 5521/10000, loss: 0.0149292945861816446\n",
      "Episode Reward: 34.0\n",
      "Step 1068 (4079573) @ Episode 5522/10000, loss: 0.0034736760426312685\n",
      "Episode Reward: 22.0\n",
      "Step 426 (4079999) @ Episode 5523/10000, loss: 0.0059446934610605247\n",
      " Copied model parameters to target network\n",
      "Step 530 (4080103) @ Episode 5523/10000, loss: 0.0063640298321843156\n",
      "Episode Reward: 8.0\n",
      "Step 820 (4080923) @ Episode 5524/10000, loss: 0.0117595922201871878\n",
      "Episode Reward: 22.0\n",
      "Step 548 (4081471) @ Episode 5525/10000, loss: 0.0065492838621139534\n",
      "Episode Reward: 8.0\n",
      "Step 740 (4082211) @ Episode 5526/10000, loss: 0.0072376127354800713\n",
      "Episode Reward: 10.0\n",
      "Step 849 (4083060) @ Episode 5527/10000, loss: 0.0071822125464677813\n",
      "Episode Reward: 16.0\n",
      "Step 736 (4083796) @ Episode 5528/10000, loss: 0.0038697500713169575\n",
      "Episode Reward: 12.0\n",
      "Step 962 (4084758) @ Episode 5529/10000, loss: 0.0051802964881062515\n",
      "Episode Reward: 15.0\n",
      "Step 1000 (4085758) @ Episode 5530/10000, loss: 0.021752415224909782\n",
      "Episode Reward: 24.0\n",
      "Step 564 (4086322) @ Episode 5531/10000, loss: 0.0062070181593298916\n",
      "Episode Reward: 8.0\n",
      "Step 619 (4086941) @ Episode 5532/10000, loss: 0.0056591490283608445\n",
      "Episode Reward: 10.0\n",
      "Step 982 (4087923) @ Episode 5533/10000, loss: 0.0052579687908291825\n",
      "Episode Reward: 14.0\n",
      "Step 562 (4088485) @ Episode 5534/10000, loss: 0.0041339187882840635\n",
      "Episode Reward: 9.0\n",
      "Step 852 (4089337) @ Episode 5535/10000, loss: 0.0094859749078750615\n",
      "Episode Reward: 14.0\n",
      "Step 662 (4089999) @ Episode 5536/10000, loss: 0.0038820235058665276\n",
      " Copied model parameters to target network\n",
      "Step 837 (4090174) @ Episode 5536/10000, loss: 0.0036880322732031345\n",
      "Episode Reward: 13.0\n",
      "Step 792 (4090966) @ Episode 5537/10000, loss: 0.0018144181231036782\n",
      "Episode Reward: 13.0\n",
      "Step 606 (4091572) @ Episode 5538/10000, loss: 0.0068279225379228595\n",
      "Episode Reward: 10.0\n",
      "Step 1061 (4092633) @ Episode 5539/10000, loss: 0.0020781969651579857\n",
      "Episode Reward: 22.0\n",
      "Step 1178 (4093811) @ Episode 5540/10000, loss: 0.0075163752771914005\n",
      "Episode Reward: 34.0\n",
      "Step 1121 (4094932) @ Episode 5541/10000, loss: 0.0063193379901349545\n",
      "Episode Reward: 23.0\n",
      "Step 1157 (4096089) @ Episode 5542/10000, loss: 0.0472293980419635876\n",
      "Episode Reward: 26.0\n",
      "Step 904 (4096993) @ Episode 5543/10000, loss: 0.0108506828546524055\n",
      "Episode Reward: 14.0\n",
      "Step 1431 (4098424) @ Episode 5544/10000, loss: 0.0057010082527995114\n",
      "Episode Reward: 34.0\n",
      "Step 850 (4099274) @ Episode 5545/10000, loss: 0.0087889200076460843\n",
      "Episode Reward: 16.0\n",
      "Step 725 (4099999) @ Episode 5546/10000, loss: 0.0043714344501495367\n",
      " Copied model parameters to target network\n",
      "Step 1174 (4100448) @ Episode 5546/10000, loss: 0.0035557346418499947\n",
      "Episode Reward: 24.0\n",
      "Step 1144 (4101592) @ Episode 5547/10000, loss: 0.0027407663874328136\n",
      "Episode Reward: 22.0\n",
      "Step 910 (4102502) @ Episode 5548/10000, loss: 0.0087666288018226625\n",
      "Episode Reward: 27.0\n",
      "Step 984 (4103486) @ Episode 5549/10000, loss: 0.0048535265959799295\n",
      "Episode Reward: 19.0\n",
      "Step 891 (4104377) @ Episode 5550/10000, loss: 0.0038861760403960943\n",
      "Episode Reward: 16.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 03:08:10,775] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video005550.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 701 (4105078) @ Episode 5551/10000, loss: 0.0047802333720028416\n",
      "Episode Reward: 10.0\n",
      "Step 1088 (4106166) @ Episode 5552/10000, loss: 0.0196563787758350374\n",
      "Episode Reward: 21.0\n",
      "Step 971 (4107137) @ Episode 5553/10000, loss: 0.0063399667851626875\n",
      "Episode Reward: 13.0\n",
      "Step 1477 (4108614) @ Episode 5554/10000, loss: 0.0054037082009017472\n",
      "Episode Reward: 40.0\n",
      "Step 803 (4109417) @ Episode 5555/10000, loss: 0.0034585283137857914\n",
      "Episode Reward: 21.0\n",
      "Step 582 (4109999) @ Episode 5556/10000, loss: 0.0069510312750935555\n",
      " Copied model parameters to target network\n",
      "Step 610 (4110027) @ Episode 5556/10000, loss: 0.0038312366232275963\n",
      "Episode Reward: 11.0\n",
      "Step 1347 (4111374) @ Episode 5557/10000, loss: 0.0038143261335790157\n",
      "Episode Reward: 32.0\n",
      "Step 827 (4112201) @ Episode 5558/10000, loss: 0.0023335828445851803\n",
      "Episode Reward: 13.0\n",
      "Step 881 (4113082) @ Episode 5559/10000, loss: 0.0020925442222505813\n",
      "Episode Reward: 14.0\n",
      "Step 852 (4113934) @ Episode 5560/10000, loss: 0.0056953160092234613\n",
      "Episode Reward: 18.0\n",
      "Step 835 (4114769) @ Episode 5561/10000, loss: 0.0066722533665597446\n",
      "Episode Reward: 18.0\n",
      "Step 863 (4115632) @ Episode 5562/10000, loss: 0.0733323097229003922\n",
      "Episode Reward: 14.0\n",
      "Step 805 (4116437) @ Episode 5563/10000, loss: 0.0031990793067961935\n",
      "Episode Reward: 12.0\n",
      "Step 800 (4117237) @ Episode 5564/10000, loss: 0.0056638433597981935\n",
      "Episode Reward: 16.0\n",
      "Step 774 (4118011) @ Episode 5565/10000, loss: 0.0042754141613841064\n",
      "Episode Reward: 19.0\n",
      "Step 861 (4118872) @ Episode 5566/10000, loss: 0.0047824895009398464\n",
      "Episode Reward: 14.0\n",
      "Step 872 (4119744) @ Episode 5567/10000, loss: 0.0020216247066855432\n",
      "Episode Reward: 15.0\n",
      "Step 255 (4119999) @ Episode 5568/10000, loss: 0.0051338681951165233\n",
      " Copied model parameters to target network\n",
      "Step 1187 (4120931) @ Episode 5568/10000, loss: 0.0052034053951501853\n",
      "Episode Reward: 18.0\n",
      "Step 1509 (4122440) @ Episode 5569/10000, loss: 0.0078144595026969915\n",
      "Episode Reward: 36.0\n",
      "Step 776 (4123216) @ Episode 5570/10000, loss: 0.0034715041983872656\n",
      "Episode Reward: 13.0\n",
      "Step 815 (4124031) @ Episode 5571/10000, loss: 0.0074775982648134233\n",
      "Episode Reward: 17.0\n",
      "Step 1177 (4125208) @ Episode 5572/10000, loss: 0.0083782263100147256\n",
      "Episode Reward: 17.0\n",
      "Step 574 (4125782) @ Episode 5573/10000, loss: 0.0025471365079283714\n",
      "Episode Reward: 9.0\n",
      "Step 1205 (4126987) @ Episode 5574/10000, loss: 0.0032091699540615083\n",
      "Episode Reward: 30.0\n",
      "Step 752 (4127739) @ Episode 5575/10000, loss: 0.0029154215008020465\n",
      "Episode Reward: 12.0\n",
      "Step 976 (4128715) @ Episode 5576/10000, loss: 0.0034672443289309746\n",
      "Episode Reward: 27.0\n",
      "Step 1043 (4129758) @ Episode 5577/10000, loss: 0.0078517012298107157\n",
      "Episode Reward: 18.0\n",
      "Step 241 (4129999) @ Episode 5578/10000, loss: 0.0051025282591581345\n",
      " Copied model parameters to target network\n",
      "Step 438 (4130196) @ Episode 5578/10000, loss: 0.0037693507038056857\n",
      "Episode Reward: 5.0\n",
      "Step 1303 (4131499) @ Episode 5579/10000, loss: 0.0019934969022870064\n",
      "Episode Reward: 34.0\n",
      "Step 645 (4132144) @ Episode 5580/10000, loss: 0.0054530631750822075\n",
      "Episode Reward: 8.0\n",
      "Step 985 (4133129) @ Episode 5581/10000, loss: 0.0051558325067162516\n",
      "Episode Reward: 17.0\n",
      "Step 896 (4134025) @ Episode 5582/10000, loss: 0.0024590312968939543\n",
      "Episode Reward: 15.0\n",
      "Step 1023 (4135048) @ Episode 5583/10000, loss: 0.0097890282049775127\n",
      "Episode Reward: 24.0\n",
      "Step 487 (4135535) @ Episode 5584/10000, loss: 0.0035047943238168955\n",
      "Episode Reward: 11.0\n",
      "Step 753 (4136288) @ Episode 5585/10000, loss: 0.0052170245908200743\n",
      "Episode Reward: 9.0\n",
      "Step 880 (4137168) @ Episode 5586/10000, loss: 0.0055850078351795676\n",
      "Episode Reward: 14.0\n",
      "Step 804 (4137972) @ Episode 5587/10000, loss: 0.0033445353619754314\n",
      "Episode Reward: 13.0\n",
      "Step 1229 (4139201) @ Episode 5588/10000, loss: 0.0084254723042249684\n",
      "Episode Reward: 27.0\n",
      "Step 798 (4139999) @ Episode 5589/10000, loss: 0.0046008620411157614\n",
      " Copied model parameters to target network\n",
      "Step 887 (4140088) @ Episode 5589/10000, loss: 0.0014912806218490005\n",
      "Episode Reward: 12.0\n",
      "Step 1212 (4141300) @ Episode 5590/10000, loss: 0.0100443912670016293\n",
      "Episode Reward: 28.0\n",
      "Step 1347 (4142647) @ Episode 5591/10000, loss: 0.0025921866763383154\n",
      "Episode Reward: 27.0\n",
      "Step 791 (4143438) @ Episode 5592/10000, loss: 0.0033433884382247925\n",
      "Episode Reward: 26.0\n",
      "Step 944 (4144382) @ Episode 5593/10000, loss: 0.0025935410521924496\n",
      "Episode Reward: 17.0\n",
      "Step 969 (4145351) @ Episode 5594/10000, loss: 0.0522576048970222546\n",
      "Episode Reward: 15.0\n",
      "Step 994 (4146345) @ Episode 5595/10000, loss: 0.0041723074391484266\n",
      "Episode Reward: 27.0\n",
      "Step 938 (4147283) @ Episode 5596/10000, loss: 0.0060523236170411115\n",
      "Episode Reward: 20.0\n",
      "Step 1067 (4148350) @ Episode 5597/10000, loss: 0.0020786593668162823\n",
      "Episode Reward: 21.0\n",
      "Step 887 (4149237) @ Episode 5598/10000, loss: 0.0048165828920900826\n",
      "Episode Reward: 19.0\n",
      "Step 762 (4149999) @ Episode 5599/10000, loss: 0.0038145217113196853\n",
      " Copied model parameters to target network\n",
      "Step 769 (4150006) @ Episode 5599/10000, loss: 0.0032927775755524635\n",
      "Episode Reward: 12.0\n",
      "Step 1035 (4151041) @ Episode 5600/10000, loss: 0.0047626974992454054\n",
      "Episode Reward: 20.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 03:15:20,223] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video005600.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1264 (4152305) @ Episode 5601/10000, loss: 0.0034763126168400058\n",
      "Episode Reward: 29.0\n",
      "Step 906 (4153211) @ Episode 5602/10000, loss: 0.0022200874518603086\n",
      "Episode Reward: 21.0\n",
      "Step 726 (4153937) @ Episode 5603/10000, loss: 0.0061139604076743134\n",
      "Episode Reward: 22.0\n",
      "Step 1163 (4155100) @ Episode 5604/10000, loss: 0.0026024293620139367\n",
      "Episode Reward: 27.0\n",
      "Step 985 (4156085) @ Episode 5605/10000, loss: 0.0124650932848453525\n",
      "Episode Reward: 20.0\n",
      "Step 636 (4156721) @ Episode 5606/10000, loss: 0.0146703645586967474\n",
      "Episode Reward: 9.0\n",
      "Step 1079 (4157800) @ Episode 5607/10000, loss: 0.0048609375953674325\n",
      "Episode Reward: 17.0\n",
      "Step 1224 (4159024) @ Episode 5608/10000, loss: 0.0048779547214508065\n",
      "Episode Reward: 32.0\n",
      "Step 737 (4159761) @ Episode 5609/10000, loss: 0.0040205791592597967\n",
      "Episode Reward: 14.0\n",
      "Step 238 (4159999) @ Episode 5610/10000, loss: 0.0069912713952362545\n",
      " Copied model parameters to target network\n",
      "Step 1028 (4160789) @ Episode 5610/10000, loss: 0.0016390988603234293\n",
      "Episode Reward: 23.0\n",
      "Step 1142 (4161931) @ Episode 5611/10000, loss: 0.0114266667515039447\n",
      "Episode Reward: 25.0\n",
      "Step 823 (4162754) @ Episode 5612/10000, loss: 0.0039540142752230173\n",
      "Episode Reward: 12.0\n",
      "Step 858 (4163612) @ Episode 5613/10000, loss: 0.0078455023467540746\n",
      "Episode Reward: 15.0\n",
      "Step 1040 (4164652) @ Episode 5614/10000, loss: 0.0054022874683141717\n",
      "Episode Reward: 13.0\n",
      "Step 1189 (4165841) @ Episode 5615/10000, loss: 0.0017277637962251902\n",
      "Episode Reward: 27.0\n",
      "Step 723 (4166564) @ Episode 5616/10000, loss: 0.0068015251308679584\n",
      "Episode Reward: 12.0\n",
      "Step 1415 (4167979) @ Episode 5617/10000, loss: 0.0066838464699685573\n",
      "Episode Reward: 31.0\n",
      "Step 506 (4168485) @ Episode 5618/10000, loss: 0.0032805008813738823\n",
      "Episode Reward: 8.0\n",
      "Step 649 (4169134) @ Episode 5619/10000, loss: 0.0081970784813165665\n",
      "Episode Reward: 9.0\n",
      "Step 865 (4169999) @ Episode 5620/10000, loss: 0.0032024192623794085\n",
      " Copied model parameters to target network\n",
      "Step 912 (4170046) @ Episode 5620/10000, loss: 0.0042133070528507233\n",
      "Episode Reward: 19.0\n",
      "Step 716 (4170762) @ Episode 5621/10000, loss: 0.0037170855794101954\n",
      "Episode Reward: 11.0\n",
      "Step 700 (4171462) @ Episode 5622/10000, loss: 0.0023697724100202325\n",
      "Episode Reward: 10.0\n",
      "Step 1035 (4172497) @ Episode 5623/10000, loss: 0.0056984089314937596\n",
      "Episode Reward: 18.0\n",
      "Step 943 (4173440) @ Episode 5624/10000, loss: 0.0059611545875668535\n",
      "Episode Reward: 19.0\n",
      "Step 982 (4174422) @ Episode 5625/10000, loss: 0.0045934682711958885\n",
      "Episode Reward: 20.0\n",
      "Step 665 (4175087) @ Episode 5626/10000, loss: 0.0057782344520092018\n",
      "Episode Reward: 11.0\n",
      "Step 827 (4175914) @ Episode 5627/10000, loss: 0.0048040244728326825\n",
      "Episode Reward: 12.0\n",
      "Step 788 (4176702) @ Episode 5628/10000, loss: 0.0027310266159474856\n",
      "Episode Reward: 13.0\n",
      "Step 616 (4177318) @ Episode 5629/10000, loss: 0.0116418413817882544\n",
      "Episode Reward: 9.0\n",
      "Step 1373 (4178691) @ Episode 5630/10000, loss: 0.0048896800726652145\n",
      "Episode Reward: 26.0\n",
      "Step 1256 (4179947) @ Episode 5631/10000, loss: 0.0060796132311224944\n",
      "Episode Reward: 39.0\n",
      "Step 52 (4179999) @ Episode 5632/10000, loss: 0.0042152646929025658\n",
      " Copied model parameters to target network\n",
      "Step 1108 (4181055) @ Episode 5632/10000, loss: 0.0041610249318182476\n",
      "Episode Reward: 29.0\n",
      "Step 1094 (4182149) @ Episode 5633/10000, loss: 0.0077114747837185867\n",
      "Episode Reward: 25.0\n",
      "Step 997 (4183146) @ Episode 5634/10000, loss: 0.0067894174717366695\n",
      "Episode Reward: 20.0\n",
      "Step 748 (4183894) @ Episode 5635/10000, loss: 0.0104587133973836917\n",
      "Episode Reward: 10.0\n",
      "Step 857 (4184751) @ Episode 5636/10000, loss: 0.0061559928581118585\n",
      "Episode Reward: 24.0\n",
      "Step 859 (4185610) @ Episode 5637/10000, loss: 0.0103988368064165125\n",
      "Episode Reward: 19.0\n",
      "Step 782 (4186392) @ Episode 5638/10000, loss: 0.0046892971731722355\n",
      "Episode Reward: 12.0\n",
      "Step 808 (4187200) @ Episode 5639/10000, loss: 0.0051174340769648554\n",
      "Episode Reward: 13.0\n",
      "Step 627 (4187827) @ Episode 5640/10000, loss: 0.0056155091151595116\n",
      "Episode Reward: 11.0\n",
      "Step 1101 (4188928) @ Episode 5641/10000, loss: 0.0230817757546901725\n",
      "Episode Reward: 22.0\n",
      "Step 727 (4189655) @ Episode 5642/10000, loss: 0.0105468239635229115\n",
      "Episode Reward: 15.0\n",
      "Step 344 (4189999) @ Episode 5643/10000, loss: 0.0023628417402505875\n",
      " Copied model parameters to target network\n",
      "Step 826 (4190481) @ Episode 5643/10000, loss: 0.0017757745226845145\n",
      "Episode Reward: 18.0\n",
      "Step 947 (4191428) @ Episode 5644/10000, loss: 0.0140509176999330526\n",
      "Episode Reward: 21.0\n",
      "Step 705 (4192133) @ Episode 5645/10000, loss: 0.0058393077924847626\n",
      "Episode Reward: 11.0\n",
      "Step 604 (4192737) @ Episode 5646/10000, loss: 0.0058927750214934356\n",
      "Episode Reward: 10.0\n",
      "Step 552 (4193289) @ Episode 5647/10000, loss: 0.0011450722813606262\n",
      "Episode Reward: 8.0\n",
      "Step 830 (4194119) @ Episode 5648/10000, loss: 0.0314204469323158267\n",
      "Episode Reward: 20.0\n",
      "Step 533 (4194652) @ Episode 5649/10000, loss: 0.0021023480221629143\n",
      "Episode Reward: 8.0\n",
      "Step 734 (4195386) @ Episode 5650/10000, loss: 0.0284462012350559235\n",
      "Episode Reward: 15.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 03:22:09,048] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video005650.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 503 (4195889) @ Episode 5651/10000, loss: 0.0028422756586223843\n",
      "Episode Reward: 7.0\n",
      "Step 904 (4196793) @ Episode 5652/10000, loss: 0.0035269483923912054\n",
      "Episode Reward: 15.0\n",
      "Step 739 (4197532) @ Episode 5653/10000, loss: 0.0039132819510996347\n",
      "Episode Reward: 15.0\n",
      "Step 541 (4198073) @ Episode 5654/10000, loss: 0.0061548482626676561\n",
      "Episode Reward: 8.0\n",
      "Step 736 (4198809) @ Episode 5655/10000, loss: 0.0105708371847867978\n",
      "Episode Reward: 11.0\n",
      "Step 899 (4199708) @ Episode 5656/10000, loss: 0.0063527021557092673\n",
      "Episode Reward: 25.0\n",
      "Step 291 (4199999) @ Episode 5657/10000, loss: 0.0154483662918210037\n",
      " Copied model parameters to target network\n",
      "Step 547 (4200255) @ Episode 5657/10000, loss: 0.0085570532828569415\n",
      "Episode Reward: 8.0\n",
      "Step 713 (4200968) @ Episode 5658/10000, loss: 0.0061973859556019317\n",
      "Episode Reward: 11.0\n",
      "Step 755 (4201723) @ Episode 5659/10000, loss: 0.0032051925081759695\n",
      "Episode Reward: 19.0\n",
      "Step 1007 (4202730) @ Episode 5660/10000, loss: 0.0110683459788560875\n",
      "Episode Reward: 16.0\n",
      "Step 1119 (4203849) @ Episode 5661/10000, loss: 0.0040338998660445215\n",
      "Episode Reward: 29.0\n",
      "Step 585 (4204434) @ Episode 5662/10000, loss: 0.0061395047232508663\n",
      "Episode Reward: 8.0\n",
      "Step 746 (4205180) @ Episode 5663/10000, loss: 0.0063549801707267765\n",
      "Episode Reward: 11.0\n",
      "Step 957 (4206137) @ Episode 5664/10000, loss: 0.0069842161610722543\n",
      "Episode Reward: 23.0\n",
      "Step 852 (4206989) @ Episode 5665/10000, loss: 0.0040680188685655593\n",
      "Episode Reward: 17.0\n",
      "Step 1008 (4207997) @ Episode 5666/10000, loss: 0.0129374824464321145\n",
      "Episode Reward: 25.0\n",
      "Step 796 (4208793) @ Episode 5667/10000, loss: 0.0061806989833712584\n",
      "Episode Reward: 16.0\n",
      "Step 677 (4209470) @ Episode 5668/10000, loss: 0.0086028780788183213\n",
      "Episode Reward: 9.0\n",
      "Step 529 (4209999) @ Episode 5669/10000, loss: 0.0054796086624264726\n",
      " Copied model parameters to target network\n",
      "Step 1136 (4210606) @ Episode 5669/10000, loss: 0.0041150329634547234\n",
      "Episode Reward: 29.0\n",
      "Step 964 (4211570) @ Episode 5670/10000, loss: 0.0024409345351159573\n",
      "Episode Reward: 26.0\n",
      "Step 678 (4212248) @ Episode 5671/10000, loss: 0.0038374564610421658\n",
      "Episode Reward: 9.0\n",
      "Step 714 (4212962) @ Episode 5672/10000, loss: 0.0064974958077073173\n",
      "Episode Reward: 15.0\n",
      "Step 1144 (4214106) @ Episode 5673/10000, loss: 0.0030374953057616955\n",
      "Episode Reward: 25.0\n",
      "Step 931 (4215037) @ Episode 5674/10000, loss: 0.0057108029723167425\n",
      "Episode Reward: 15.0\n",
      "Step 612 (4215649) @ Episode 5675/10000, loss: 0.0066342204809188848\n",
      "Episode Reward: 13.0\n",
      "Step 884 (4216533) @ Episode 5676/10000, loss: 0.0064807673916220665\n",
      "Episode Reward: 15.0\n",
      "Step 1049 (4217582) @ Episode 5677/10000, loss: 0.0029433418530970816\n",
      "Episode Reward: 22.0\n",
      "Step 713 (4218295) @ Episode 5678/10000, loss: 0.0080644395202398355\n",
      "Episode Reward: 9.0\n",
      "Step 748 (4219043) @ Episode 5679/10000, loss: 0.0022718282416462996\n",
      "Episode Reward: 12.0\n",
      "Step 956 (4219999) @ Episode 5680/10000, loss: 0.0204268395900726325\n",
      " Copied model parameters to target network\n",
      "Step 1058 (4220101) @ Episode 5680/10000, loss: 0.0044849202968180186\n",
      "Episode Reward: 22.0\n",
      "Step 1058 (4221159) @ Episode 5681/10000, loss: 0.0064833075739443345\n",
      "Episode Reward: 14.0\n",
      "Step 957 (4222116) @ Episode 5682/10000, loss: 0.0032852496951818466\n",
      "Episode Reward: 16.0\n",
      "Step 1149 (4223265) @ Episode 5683/10000, loss: 0.0028845854103565216\n",
      "Episode Reward: 23.0\n",
      "Step 1131 (4224396) @ Episode 5684/10000, loss: 0.0098557109013199895\n",
      "Episode Reward: 17.0\n",
      "Step 646 (4225042) @ Episode 5685/10000, loss: 0.0079258512705564594\n",
      "Episode Reward: 10.0\n",
      "Step 865 (4225907) @ Episode 5686/10000, loss: 0.0099970856681466145\n",
      "Episode Reward: 15.0\n",
      "Step 1139 (4227046) @ Episode 5687/10000, loss: 0.0038590985350310802\n",
      "Episode Reward: 20.0\n",
      "Step 938 (4227984) @ Episode 5688/10000, loss: 0.0054161590524017814\n",
      "Episode Reward: 16.0\n",
      "Step 794 (4228778) @ Episode 5689/10000, loss: 0.0033263491932302713\n",
      "Episode Reward: 18.0\n",
      "Step 791 (4229569) @ Episode 5690/10000, loss: 0.0024519427679479123\n",
      "Episode Reward: 16.0\n",
      "Step 430 (4229999) @ Episode 5691/10000, loss: 0.0074540423229336743\n",
      " Copied model parameters to target network\n",
      "Step 739 (4230308) @ Episode 5691/10000, loss: 0.0104666398838162426\n",
      "Episode Reward: 17.0\n",
      "Step 1368 (4231676) @ Episode 5692/10000, loss: 0.0033935380633920437\n",
      "Episode Reward: 33.0\n",
      "Step 962 (4232638) @ Episode 5693/10000, loss: 0.0083180880174040865\n",
      "Episode Reward: 25.0\n",
      "Step 531 (4233169) @ Episode 5694/10000, loss: 0.0063134110532701015\n",
      "Episode Reward: 8.0\n",
      "Step 931 (4234100) @ Episode 5695/10000, loss: 0.0413146838545799265\n",
      "Episode Reward: 15.0\n",
      "Step 1493 (4235593) @ Episode 5696/10000, loss: 0.0039983792230486875\n",
      "Episode Reward: 26.0\n",
      "Step 859 (4236452) @ Episode 5697/10000, loss: 0.0051309084519743925\n",
      "Episode Reward: 13.0\n",
      "Step 978 (4237430) @ Episode 5698/10000, loss: 0.0092296218499541287\n",
      "Episode Reward: 17.0\n",
      "Step 740 (4238170) @ Episode 5699/10000, loss: 0.0090781273320317275\n",
      "Episode Reward: 12.0\n",
      "Step 987 (4239157) @ Episode 5700/10000, loss: 0.0058361929841339595\n",
      "Episode Reward: 19.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 03:28:51,509] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video005700.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 794 (4239951) @ Episode 5701/10000, loss: 0.0051662405021488676\n",
      "Episode Reward: 13.0\n",
      "Step 48 (4239999) @ Episode 5702/10000, loss: 0.0016687448369339108\n",
      " Copied model parameters to target network\n",
      "Step 1150 (4241101) @ Episode 5702/10000, loss: 0.0027681840583682067\n",
      "Episode Reward: 22.0\n",
      "Step 1039 (4242140) @ Episode 5703/10000, loss: 0.0065710339695215225\n",
      "Episode Reward: 18.0\n",
      "Step 578 (4242718) @ Episode 5704/10000, loss: 0.0032450943253934383\n",
      "Episode Reward: 15.0\n",
      "Step 763 (4243481) @ Episode 5705/10000, loss: 0.0036213423591107137\n",
      "Episode Reward: 14.0\n",
      "Step 831 (4244312) @ Episode 5706/10000, loss: 0.0062287114560604095\n",
      "Episode Reward: 25.0\n",
      "Step 727 (4245039) @ Episode 5707/10000, loss: 0.0027101321611553438\n",
      "Episode Reward: 18.0\n",
      "Step 853 (4245892) @ Episode 5708/10000, loss: 0.0296152140945196154\n",
      "Episode Reward: 14.0\n",
      "Step 977 (4246869) @ Episode 5709/10000, loss: 0.0106819979846477545\n",
      "Episode Reward: 16.0\n",
      "Step 895 (4247764) @ Episode 5710/10000, loss: 0.0029625352472066885\n",
      "Episode Reward: 15.0\n",
      "Step 923 (4248687) @ Episode 5711/10000, loss: 0.0216176807880401654\n",
      "Episode Reward: 27.0\n",
      "Step 930 (4249617) @ Episode 5712/10000, loss: 0.0081312237307429313\n",
      "Episode Reward: 16.0\n",
      "Step 382 (4249999) @ Episode 5713/10000, loss: 0.0061211702413856987\n",
      " Copied model parameters to target network\n",
      "Step 1151 (4250768) @ Episode 5713/10000, loss: 0.0039690225385129457\n",
      "Episode Reward: 24.0\n",
      "Step 528 (4251296) @ Episode 5714/10000, loss: 0.0053339512087404735\n",
      "Episode Reward: 8.0\n",
      "Step 583 (4251879) @ Episode 5715/10000, loss: 0.0104796569794416436\n",
      "Episode Reward: 7.0\n",
      "Step 897 (4252776) @ Episode 5716/10000, loss: 0.0083523709326982525\n",
      "Episode Reward: 16.0\n",
      "Step 795 (4253571) @ Episode 5717/10000, loss: 0.0046899057924747476\n",
      "Episode Reward: 11.0\n",
      "Step 1068 (4254639) @ Episode 5718/10000, loss: 0.0077174371108412745\n",
      "Episode Reward: 20.0\n",
      "Step 1188 (4255827) @ Episode 5719/10000, loss: 0.0027618785388767727\n",
      "Episode Reward: 23.0\n",
      "Step 861 (4256688) @ Episode 5720/10000, loss: 0.0060847727581858635\n",
      "Episode Reward: 12.0\n",
      "Step 809 (4257497) @ Episode 5721/10000, loss: 0.0030480690766125917\n",
      "Episode Reward: 16.0\n",
      "Step 1139 (4258636) @ Episode 5722/10000, loss: 0.0036286420654505495\n",
      "Episode Reward: 22.0\n",
      "Step 717 (4259353) @ Episode 5723/10000, loss: 0.0038000813219696283\n",
      "Episode Reward: 8.0\n",
      "Step 646 (4259999) @ Episode 5724/10000, loss: 0.0088438941165804865\n",
      " Copied model parameters to target network\n",
      "Step 959 (4260312) @ Episode 5724/10000, loss: 0.0516161248087883154\n",
      "Episode Reward: 21.0\n",
      "Step 1084 (4261396) @ Episode 5725/10000, loss: 0.0069213300012052065\n",
      "Episode Reward: 28.0\n",
      "Step 833 (4262229) @ Episode 5726/10000, loss: 0.0067798402160406116\n",
      "Episode Reward: 14.0\n",
      "Step 948 (4263177) @ Episode 5727/10000, loss: 0.0121505055576562888\n",
      "Episode Reward: 22.0\n",
      "Step 1250 (4264427) @ Episode 5728/10000, loss: 0.0234346557408571245\n",
      "Episode Reward: 21.0\n",
      "Step 539 (4264966) @ Episode 5729/10000, loss: 0.0039864741265773778\n",
      "Episode Reward: 7.0\n",
      "Step 812 (4265778) @ Episode 5730/10000, loss: 0.0115013625472784047\n",
      "Episode Reward: 13.0\n",
      "Step 791 (4266569) @ Episode 5731/10000, loss: 0.0030133738182485104\n",
      "Episode Reward: 14.0\n",
      "Step 886 (4267455) @ Episode 5732/10000, loss: 0.0107936402782797811\n",
      "Episode Reward: 16.0\n",
      "Step 920 (4268375) @ Episode 5733/10000, loss: 0.0105535686016082765\n",
      "Episode Reward: 26.0\n",
      "Step 941 (4269316) @ Episode 5734/10000, loss: 0.0022864786442369223\n",
      "Episode Reward: 19.0\n",
      "Step 683 (4269999) @ Episode 5735/10000, loss: 0.0080331237986683853\n",
      " Copied model parameters to target network\n",
      "Step 751 (4270067) @ Episode 5735/10000, loss: 0.0079261120408773427\n",
      "Episode Reward: 13.0\n",
      "Step 851 (4270918) @ Episode 5736/10000, loss: 0.0019028701353818178\n",
      "Episode Reward: 15.0\n",
      "Step 1196 (4272114) @ Episode 5737/10000, loss: 0.0052731581963598733\n",
      "Episode Reward: 26.0\n",
      "Step 812 (4272926) @ Episode 5738/10000, loss: 0.0267917010933160786\n",
      "Episode Reward: 11.0\n",
      "Step 510 (4273436) @ Episode 5739/10000, loss: 0.0022581249941140413\n",
      "Episode Reward: 6.0\n",
      "Step 774 (4274210) @ Episode 5740/10000, loss: 0.0113355424255132685\n",
      "Episode Reward: 11.0\n",
      "Step 798 (4275008) @ Episode 5741/10000, loss: 0.0025349576026201255\n",
      "Episode Reward: 13.0\n",
      "Step 728 (4275736) @ Episode 5742/10000, loss: 0.0032980234827846293\n",
      "Episode Reward: 11.0\n",
      "Step 1133 (4276869) @ Episode 5743/10000, loss: 0.0035839413758367388\n",
      "Episode Reward: 27.0\n",
      "Step 1118 (4277987) @ Episode 5744/10000, loss: 0.0356107801198959357\n",
      "Episode Reward: 23.0\n",
      "Step 856 (4278843) @ Episode 5745/10000, loss: 0.0034366655163466938\n",
      "Episode Reward: 15.0\n",
      "Step 803 (4279646) @ Episode 5746/10000, loss: 0.0019060580525547266\n",
      "Episode Reward: 13.0\n",
      "Step 353 (4279999) @ Episode 5747/10000, loss: 0.0151730487123131754\n",
      " Copied model parameters to target network\n",
      "Step 842 (4280488) @ Episode 5747/10000, loss: 0.0040953243151307116\n",
      "Episode Reward: 14.0\n",
      "Step 852 (4281340) @ Episode 5748/10000, loss: 0.0053447638638317585\n",
      "Episode Reward: 13.0\n",
      "Step 524 (4281864) @ Episode 5749/10000, loss: 0.0025944598019123077\n",
      "Episode Reward: 6.0\n",
      "Step 780 (4282644) @ Episode 5750/10000, loss: 0.0016156255733221772\n",
      "Episode Reward: 16.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 03:35:36,075] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video005750.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1053 (4283697) @ Episode 5751/10000, loss: 0.0030819347593933344\n",
      "Episode Reward: 19.0\n",
      "Step 764 (4284461) @ Episode 5752/10000, loss: 0.0044634300284087665\n",
      "Episode Reward: 11.0\n",
      "Step 672 (4285133) @ Episode 5753/10000, loss: 0.0037746315356343985\n",
      "Episode Reward: 11.0\n",
      "Step 785 (4285918) @ Episode 5754/10000, loss: 0.0031932401470839977\n",
      "Episode Reward: 12.0\n",
      "Step 819 (4286737) @ Episode 5755/10000, loss: 0.0108043905347585685\n",
      "Episode Reward: 14.0\n",
      "Step 1319 (4288056) @ Episode 5756/10000, loss: 0.0054584811441600325\n",
      "Episode Reward: 30.0\n",
      "Step 854 (4288910) @ Episode 5757/10000, loss: 0.0041023064404726037\n",
      "Episode Reward: 14.0\n",
      "Step 1073 (4289983) @ Episode 5758/10000, loss: 0.0047768666408956055\n",
      "Episode Reward: 18.0\n",
      "Step 16 (4289999) @ Episode 5759/10000, loss: 0.0227162577211856845\n",
      " Copied model parameters to target network\n",
      "Step 990 (4290973) @ Episode 5759/10000, loss: 0.0137524325400590955\n",
      "Episode Reward: 20.0\n",
      "Step 678 (4291651) @ Episode 5760/10000, loss: 0.0094189923256635672\n",
      "Episode Reward: 12.0\n",
      "Step 989 (4292640) @ Episode 5761/10000, loss: 0.0025623934343457225\n",
      "Episode Reward: 21.0\n",
      "Step 533 (4293173) @ Episode 5762/10000, loss: 0.0045709470286965372\n",
      "Episode Reward: 9.0\n",
      "Step 940 (4294113) @ Episode 5763/10000, loss: 0.0031329942867159843\n",
      "Episode Reward: 17.0\n",
      "Step 1436 (4295549) @ Episode 5764/10000, loss: 0.0034028801601380112\n",
      "Episode Reward: 17.0\n",
      "Step 1029 (4296578) @ Episode 5765/10000, loss: 0.0089557571336627396\n",
      "Episode Reward: 27.0\n",
      "Step 519 (4297097) @ Episode 5766/10000, loss: 0.0016003377968445421\n",
      "Episode Reward: 6.0\n",
      "Step 654 (4297751) @ Episode 5767/10000, loss: 0.0064514856785535814\n",
      "Episode Reward: 9.0\n",
      "Step 1014 (4298765) @ Episode 5768/10000, loss: 0.0116035193204879765\n",
      "Episode Reward: 24.0\n",
      "Step 956 (4299721) @ Episode 5769/10000, loss: 0.0019906482193619013\n",
      "Episode Reward: 17.0\n",
      "Step 278 (4299999) @ Episode 5770/10000, loss: 0.0030417991802096367\n",
      " Copied model parameters to target network\n",
      "Step 1107 (4300828) @ Episode 5770/10000, loss: 0.0099846851080656054\n",
      "Episode Reward: 20.0\n",
      "Step 775 (4301603) @ Episode 5771/10000, loss: 0.0158527009189128885\n",
      "Episode Reward: 12.0\n",
      "Step 723 (4302326) @ Episode 5772/10000, loss: 0.0025230436585843563\n",
      "Episode Reward: 12.0\n",
      "Step 1191 (4303517) @ Episode 5773/10000, loss: 0.0043508438393473625\n",
      "Episode Reward: 31.0\n",
      "Step 681 (4304198) @ Episode 5774/10000, loss: 0.0081688705831766135\n",
      "Episode Reward: 10.0\n",
      "Step 1095 (4305293) @ Episode 5775/10000, loss: 0.0216397810727357862\n",
      "Episode Reward: 18.0\n",
      "Step 706 (4305999) @ Episode 5776/10000, loss: 0.0084624541923403744\n",
      "Episode Reward: 10.0\n",
      "Step 280 (4306279) @ Episode 5777/10000, loss: 0.0050043556839227683\n",
      "Episode Reward: 3.0\n",
      "Step 476 (4306755) @ Episode 5778/10000, loss: 0.0047716195695102215\n",
      "Episode Reward: 9.0\n",
      "Step 658 (4307413) @ Episode 5779/10000, loss: 0.0090432977303862575\n",
      "Episode Reward: 18.0\n",
      "Step 1096 (4308509) @ Episode 5780/10000, loss: 0.0048636174760758883\n",
      "Episode Reward: 23.0\n",
      "Step 777 (4309286) @ Episode 5781/10000, loss: 0.0094192437827587132\n",
      "Episode Reward: 14.0\n",
      "Step 713 (4309999) @ Episode 5782/10000, loss: 0.0036167870275676255\n",
      " Copied model parameters to target network\n",
      "Step 1098 (4310384) @ Episode 5782/10000, loss: 0.0085777081549167636\n",
      "Episode Reward: 22.0\n",
      "Step 951 (4311335) @ Episode 5783/10000, loss: 0.0049457992427051078\n",
      "Episode Reward: 17.0\n",
      "Step 662 (4311997) @ Episode 5784/10000, loss: 0.0076351491734385492\n",
      "Episode Reward: 9.0\n",
      "Step 856 (4312853) @ Episode 5785/10000, loss: 0.0116648813709616667\n",
      "Episode Reward: 15.0\n",
      "Step 932 (4313785) @ Episode 5786/10000, loss: 0.0034857487771660092\n",
      "Episode Reward: 15.0\n",
      "Step 825 (4314610) @ Episode 5787/10000, loss: 0.0053768842481076726\n",
      "Episode Reward: 12.0\n",
      "Step 949 (4315559) @ Episode 5788/10000, loss: 0.0076261609792709355\n",
      "Episode Reward: 17.0\n",
      "Step 758 (4316317) @ Episode 5789/10000, loss: 0.0055040833540260794\n",
      "Episode Reward: 13.0\n",
      "Step 1217 (4317534) @ Episode 5790/10000, loss: 0.0051030507311224948\n",
      "Episode Reward: 27.0\n",
      "Step 1363 (4318897) @ Episode 5791/10000, loss: 0.0938813164830207867\n",
      "Episode Reward: 28.0\n",
      "Step 807 (4319704) @ Episode 5792/10000, loss: 0.0074523082002997495\n",
      "Episode Reward: 10.0\n",
      "Step 295 (4319999) @ Episode 5793/10000, loss: 0.0071247685700654984\n",
      " Copied model parameters to target network\n",
      "Step 634 (4320338) @ Episode 5793/10000, loss: 0.0038188737817108635\n",
      "Episode Reward: 9.0\n",
      "Step 1001 (4321339) @ Episode 5794/10000, loss: 0.0114948172122240076\n",
      "Episode Reward: 17.0\n",
      "Step 680 (4322019) @ Episode 5795/10000, loss: 0.0029039443470537663\n",
      "Episode Reward: 15.0\n",
      "Step 843 (4322862) @ Episode 5796/10000, loss: 0.0073417974635958677\n",
      "Episode Reward: 13.0\n",
      "Step 923 (4323785) @ Episode 5797/10000, loss: 0.0118032973259687427\n",
      "Episode Reward: 14.0\n",
      "Step 1011 (4324796) @ Episode 5798/10000, loss: 0.0032091811299324036\n",
      "Episode Reward: 22.0\n",
      "Step 827 (4325623) @ Episode 5799/10000, loss: 0.0050121350213885315\n",
      "Episode Reward: 14.0\n",
      "Step 858 (4326481) @ Episode 5800/10000, loss: 0.0020867888815701013\n",
      "Episode Reward: 20.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 03:42:17,832] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video005800.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1141 (4327622) @ Episode 5801/10000, loss: 0.0042762970551848416\n",
      "Episode Reward: 23.0\n",
      "Step 737 (4328359) @ Episode 5802/10000, loss: 0.0084539018571376883\n",
      "Episode Reward: 19.0\n",
      "Step 873 (4329232) @ Episode 5803/10000, loss: 0.0024492659140378237\n",
      "Episode Reward: 19.0\n",
      "Step 494 (4329726) @ Episode 5804/10000, loss: 0.0029681001324206595\n",
      "Episode Reward: 8.0\n",
      "Step 273 (4329999) @ Episode 5805/10000, loss: 0.0101613383740186694\n",
      " Copied model parameters to target network\n",
      "Step 700 (4330426) @ Episode 5805/10000, loss: 0.0050623989664018153\n",
      "Episode Reward: 15.0\n",
      "Step 1244 (4331670) @ Episode 5806/10000, loss: 0.0032519116066396236\n",
      "Episode Reward: 22.0\n",
      "Step 969 (4332639) @ Episode 5807/10000, loss: 0.0045110429637134075\n",
      "Episode Reward: 17.0\n",
      "Step 943 (4333582) @ Episode 5808/10000, loss: 0.0095222406089305887\n",
      "Episode Reward: 16.0\n",
      "Step 754 (4334336) @ Episode 5809/10000, loss: 0.0051195588894188475\n",
      "Episode Reward: 23.0\n",
      "Step 1081 (4335417) @ Episode 5810/10000, loss: 0.0089020244777202626\n",
      "Episode Reward: 18.0\n",
      "Step 1301 (4336718) @ Episode 5811/10000, loss: 0.0084565579891204835\n",
      "Episode Reward: 26.0\n",
      "Step 1485 (4338203) @ Episode 5812/10000, loss: 0.0059194918721914295\n",
      "Episode Reward: 34.0\n",
      "Step 1048 (4339251) @ Episode 5813/10000, loss: 0.0048446613363921644\n",
      "Episode Reward: 22.0\n",
      "Step 748 (4339999) @ Episode 5814/10000, loss: 0.0037562348879873753\n",
      " Copied model parameters to target network\n",
      "Step 939 (4340190) @ Episode 5814/10000, loss: 0.0034827757626771927\n",
      "Episode Reward: 15.0\n",
      "Step 1144 (4341334) @ Episode 5815/10000, loss: 0.0143201649188995366\n",
      "Episode Reward: 24.0\n",
      "Step 871 (4342205) @ Episode 5816/10000, loss: 0.0260052308440208445\n",
      "Episode Reward: 19.0\n",
      "Step 632 (4342837) @ Episode 5817/10000, loss: 0.0014798428164795041\n",
      "Episode Reward: 8.0\n",
      "Step 1288 (4344125) @ Episode 5818/10000, loss: 0.0040619750507175926\n",
      "Episode Reward: 40.0\n",
      "Step 969 (4345094) @ Episode 5819/10000, loss: 0.0031526796519756317\n",
      "Episode Reward: 21.0\n",
      "Step 934 (4346028) @ Episode 5820/10000, loss: 0.0053605912253260615\n",
      "Episode Reward: 20.0\n",
      "Step 722 (4346750) @ Episode 5821/10000, loss: 0.0046945768408477317\n",
      "Episode Reward: 11.0\n",
      "Step 955 (4347705) @ Episode 5822/10000, loss: 0.0109907593578100284\n",
      "Episode Reward: 19.0\n",
      "Step 843 (4348548) @ Episode 5823/10000, loss: 0.0043722223490476617\n",
      "Episode Reward: 15.0\n",
      "Step 821 (4349369) @ Episode 5824/10000, loss: 0.0043511278927326285\n",
      "Episode Reward: 17.0\n",
      "Step 630 (4349999) @ Episode 5825/10000, loss: 0.0077897966839373114\n",
      " Copied model parameters to target network\n",
      "Step 1168 (4350537) @ Episode 5825/10000, loss: 0.0078206341713666922\n",
      "Episode Reward: 32.0\n",
      "Step 532 (4351069) @ Episode 5826/10000, loss: 0.0023653381504118443\n",
      "Episode Reward: 15.0\n",
      "Step 1156 (4352225) @ Episode 5827/10000, loss: 0.0069884178228676325\n",
      "Episode Reward: 23.0\n",
      "Step 819 (4353044) @ Episode 5828/10000, loss: 0.0120288394391536714\n",
      "Episode Reward: 14.0\n",
      "Step 737 (4353781) @ Episode 5829/10000, loss: 0.0255417358130216615\n",
      "Episode Reward: 12.0\n",
      "Step 768 (4354549) @ Episode 5830/10000, loss: 0.0033935499377548695\n",
      "Episode Reward: 16.0\n",
      "Step 976 (4355525) @ Episode 5831/10000, loss: 0.0095479823648929697\n",
      "Episode Reward: 16.0\n",
      "Step 680 (4356205) @ Episode 5832/10000, loss: 0.0048675881698727614\n",
      "Episode Reward: 12.0\n",
      "Step 676 (4356881) @ Episode 5833/10000, loss: 0.0090446518734097484\n",
      "Episode Reward: 9.0\n",
      "Step 548 (4357429) @ Episode 5834/10000, loss: 0.0019804064650088555\n",
      "Episode Reward: 7.0\n",
      "Step 882 (4358311) @ Episode 5835/10000, loss: 0.0185080599039793874\n",
      "Episode Reward: 14.0\n",
      "Step 714 (4359025) @ Episode 5836/10000, loss: 0.0054952995851635936\n",
      "Episode Reward: 11.0\n",
      "Step 302 (4359327) @ Episode 5837/10000, loss: 0.0030175279825925827\n",
      "Episode Reward: 3.0\n",
      "Step 672 (4359999) @ Episode 5838/10000, loss: 0.0055245347321033484\n",
      " Copied model parameters to target network\n",
      "Step 730 (4360057) @ Episode 5838/10000, loss: 0.0128106772899627693\n",
      "Episode Reward: 10.0\n",
      "Step 985 (4361042) @ Episode 5839/10000, loss: 0.0030255799647420645\n",
      "Episode Reward: 21.0\n",
      "Step 662 (4361704) @ Episode 5840/10000, loss: 0.0028347040060907602\n",
      "Episode Reward: 10.0\n",
      "Step 774 (4362478) @ Episode 5841/10000, loss: 0.0045979376882314683\n",
      "Episode Reward: 11.0\n",
      "Step 600 (4363078) @ Episode 5842/10000, loss: 0.0072063789702951915\n",
      "Episode Reward: 12.0\n",
      "Step 902 (4363980) @ Episode 5843/10000, loss: 0.0025918155442923307\n",
      "Episode Reward: 16.0\n",
      "Step 872 (4364852) @ Episode 5844/10000, loss: 0.0021969836670905358\n",
      "Episode Reward: 14.0\n",
      "Step 654 (4365506) @ Episode 5845/10000, loss: 0.0093241063877940185\n",
      "Episode Reward: 9.0\n",
      "Step 514 (4366020) @ Episode 5846/10000, loss: 0.0058178431354463107\n",
      "Episode Reward: 7.0\n",
      "Step 628 (4366648) @ Episode 5847/10000, loss: 0.0041515063494443893\n",
      "Episode Reward: 13.0\n",
      "Step 798 (4367446) @ Episode 5848/10000, loss: 0.0704675614833831842\n",
      "Episode Reward: 20.0\n",
      "Step 1495 (4368941) @ Episode 5849/10000, loss: 0.0026889662258327007\n",
      "Episode Reward: 34.0\n",
      "Step 633 (4369574) @ Episode 5850/10000, loss: 0.0029623289592564106\n",
      "Episode Reward: 10.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 03:48:56,121] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video005850.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 425 (4369999) @ Episode 5851/10000, loss: 0.0027004950679838657\n",
      " Copied model parameters to target network\n",
      "Step 809 (4370383) @ Episode 5851/10000, loss: 0.0027767745777964593\n",
      "Episode Reward: 14.0\n",
      "Step 672 (4371055) @ Episode 5852/10000, loss: 0.0046452535316348087\n",
      "Episode Reward: 10.0\n",
      "Step 793 (4371848) @ Episode 5853/10000, loss: 0.0044393590651452546\n",
      "Episode Reward: 11.0\n",
      "Step 748 (4372596) @ Episode 5854/10000, loss: 0.0041932915337383753\n",
      "Episode Reward: 15.0\n",
      "Step 441 (4373037) @ Episode 5855/10000, loss: 0.0017767850076779723\n",
      "Episode Reward: 6.0\n",
      "Step 888 (4373925) @ Episode 5856/10000, loss: 0.0026651420630514624\n",
      "Episode Reward: 21.0\n",
      "Step 1252 (4375177) @ Episode 5857/10000, loss: 0.0062931482680141935\n",
      "Episode Reward: 24.0\n",
      "Step 859 (4376036) @ Episode 5858/10000, loss: 0.0123382704332470957\n",
      "Episode Reward: 19.0\n",
      "Step 856 (4376892) @ Episode 5859/10000, loss: 0.0064119184389710435\n",
      "Episode Reward: 14.0\n",
      "Step 1039 (4377931) @ Episode 5860/10000, loss: 0.0081430049613118173\n",
      "Episode Reward: 17.0\n",
      "Step 747 (4378678) @ Episode 5861/10000, loss: 0.0052194702439010147\n",
      "Episode Reward: 12.0\n",
      "Step 720 (4379398) @ Episode 5862/10000, loss: 0.0031127315014600754\n",
      "Episode Reward: 9.0\n",
      "Step 601 (4379999) @ Episode 5863/10000, loss: 0.0055548758246004584\n",
      " Copied model parameters to target network\n",
      "Step 1026 (4380424) @ Episode 5863/10000, loss: 0.0055758613161742693\n",
      "Episode Reward: 17.0\n",
      "Step 767 (4381191) @ Episode 5864/10000, loss: 0.0059928894042968755\n",
      "Episode Reward: 15.0\n",
      "Step 925 (4382116) @ Episode 5865/10000, loss: 0.0067734401673078548\n",
      "Episode Reward: 20.0\n",
      "Step 798 (4382914) @ Episode 5866/10000, loss: 0.0328727997839450845\n",
      "Episode Reward: 11.0\n",
      "Step 1147 (4384061) @ Episode 5867/10000, loss: 0.0047155632637441166\n",
      "Episode Reward: 23.0\n",
      "Step 1094 (4385155) @ Episode 5868/10000, loss: 0.0018089320510625846\n",
      "Episode Reward: 20.0\n",
      "Step 1081 (4386236) @ Episode 5869/10000, loss: 0.0082176169380545623\n",
      "Episode Reward: 18.0\n",
      "Step 912 (4387148) @ Episode 5870/10000, loss: 0.0047715418040752415\n",
      "Episode Reward: 16.0\n",
      "Step 940 (4388088) @ Episode 5871/10000, loss: 0.0059500029310584077\n",
      "Episode Reward: 20.0\n",
      "Step 979 (4389067) @ Episode 5872/10000, loss: 0.0049561699852347375\n",
      "Episode Reward: 19.0\n",
      "Step 932 (4389999) @ Episode 5873/10000, loss: 0.0082326186820864682\n",
      " Copied model parameters to target network\n",
      "Step 1035 (4390102) @ Episode 5873/10000, loss: 0.0033253363799303775\n",
      "Episode Reward: 26.0\n",
      "Step 870 (4390972) @ Episode 5874/10000, loss: 0.0029259966686367994\n",
      "Episode Reward: 13.0\n",
      "Step 546 (4391518) @ Episode 5875/10000, loss: 0.0258376467972993855\n",
      "Episode Reward: 7.0\n",
      "Step 829 (4392347) @ Episode 5876/10000, loss: 0.0045678773894906044\n",
      "Episode Reward: 12.0\n",
      "Step 976 (4393323) @ Episode 5877/10000, loss: 0.0057257199659943588\n",
      "Episode Reward: 23.0\n",
      "Step 889 (4394212) @ Episode 5878/10000, loss: 0.0079313600435853676\n",
      "Episode Reward: 14.0\n",
      "Step 736 (4394948) @ Episode 5879/10000, loss: 0.0057601975277066235\n",
      "Episode Reward: 12.0\n",
      "Step 624 (4395572) @ Episode 5880/10000, loss: 0.0021964989136904486\n",
      "Episode Reward: 9.0\n",
      "Step 742 (4396314) @ Episode 5881/10000, loss: 0.0027822889387607574\n",
      "Episode Reward: 11.0\n",
      "Step 617 (4396931) @ Episode 5882/10000, loss: 0.0041883699595928194\n",
      "Episode Reward: 10.0\n",
      "Step 583 (4397514) @ Episode 5883/10000, loss: 0.0054155280813574793\n",
      "Episode Reward: 9.0\n",
      "Step 547 (4398061) @ Episode 5884/10000, loss: 0.0053763636387884627\n",
      "Episode Reward: 8.0\n",
      "Step 745 (4398806) @ Episode 5885/10000, loss: 0.0379570424556732216\n",
      "Episode Reward: 13.0\n",
      "Step 784 (4399590) @ Episode 5886/10000, loss: 0.0319672264158725745\n",
      "Episode Reward: 18.0\n",
      "Step 409 (4399999) @ Episode 5887/10000, loss: 0.0046086092479527736\n",
      " Copied model parameters to target network\n",
      "Step 642 (4400232) @ Episode 5887/10000, loss: 0.0021808966994285583\n",
      "Episode Reward: 10.0\n",
      "Step 1015 (4401247) @ Episode 5888/10000, loss: 0.0045189093798398975\n",
      "Episode Reward: 19.0\n",
      "Step 580 (4401827) @ Episode 5889/10000, loss: 0.0143630858510732655\n",
      "Episode Reward: 9.0\n",
      "Step 845 (4402672) @ Episode 5890/10000, loss: 0.0094524733722209935\n",
      "Episode Reward: 16.0\n",
      "Step 558 (4403230) @ Episode 5891/10000, loss: 0.0040259915404021743\n",
      "Episode Reward: 8.0\n",
      "Step 1159 (4404389) @ Episode 5892/10000, loss: 0.0059456927701830865\n",
      "Episode Reward: 19.0\n",
      "Step 813 (4405202) @ Episode 5893/10000, loss: 0.0042860624380409722\n",
      "Episode Reward: 14.0\n",
      "Step 416 (4405618) @ Episode 5894/10000, loss: 0.0049856295809149745\n",
      "Episode Reward: 6.0\n",
      "Step 1395 (4407013) @ Episode 5895/10000, loss: 0.0036368153523653746\n",
      "Episode Reward: 36.0\n",
      "Step 931 (4407944) @ Episode 5896/10000, loss: 0.0060964291915297515\n",
      "Episode Reward: 15.0\n",
      "Step 1028 (4408972) @ Episode 5897/10000, loss: 0.0052666794508695634\n",
      "Episode Reward: 18.0\n",
      "Step 455 (4409427) @ Episode 5898/10000, loss: 0.0047143925912678245\n",
      "Episode Reward: 6.0\n",
      "Step 572 (4409999) @ Episode 5899/10000, loss: 0.0038303660694509745\n",
      " Copied model parameters to target network\n",
      "Step 890 (4410317) @ Episode 5899/10000, loss: 0.0163312796503305447\n",
      "Episode Reward: 20.0\n",
      "Step 919 (4411236) @ Episode 5900/10000, loss: 0.0106206098571419724\n",
      "Episode Reward: 18.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 03:55:21,739] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video005900.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1372 (4412608) @ Episode 5901/10000, loss: 0.0021523036994040012\n",
      "Episode Reward: 26.0\n",
      "Step 661 (4413269) @ Episode 5902/10000, loss: 0.0327635332942009695\n",
      "Episode Reward: 11.0\n",
      "Step 681 (4413950) @ Episode 5903/10000, loss: 0.0082849422469735157\n",
      "Episode Reward: 10.0\n",
      "Step 771 (4414721) @ Episode 5904/10000, loss: 0.0048556001856923105\n",
      "Episode Reward: 13.0\n",
      "Step 769 (4415490) @ Episode 5905/10000, loss: 0.0065260585397481923\n",
      "Episode Reward: 7.0\n",
      "Step 1000 (4416490) @ Episode 5906/10000, loss: 0.006686042994260788\n",
      "Episode Reward: 27.0\n",
      "Step 714 (4417204) @ Episode 5907/10000, loss: 0.0077493996359407993\n",
      "Episode Reward: 12.0\n",
      "Step 611 (4417815) @ Episode 5908/10000, loss: 0.0088733285665512085\n",
      "Episode Reward: 9.0\n",
      "Step 642 (4418457) @ Episode 5909/10000, loss: 0.0028315954841673374\n",
      "Episode Reward: 9.0\n",
      "Step 1379 (4419836) @ Episode 5910/10000, loss: 0.0027068902272731066\n",
      "Episode Reward: 38.0\n",
      "Step 163 (4419999) @ Episode 5911/10000, loss: 0.0022413739934563637\n",
      " Copied model parameters to target network\n",
      "Step 958 (4420794) @ Episode 5911/10000, loss: 0.0083639714866876685\n",
      "Episode Reward: 18.0\n",
      "Step 739 (4421533) @ Episode 5912/10000, loss: 0.0073689455166459085\n",
      "Episode Reward: 13.0\n",
      "Step 676 (4422209) @ Episode 5913/10000, loss: 0.0053388462401926527\n",
      "Episode Reward: 12.0\n",
      "Step 740 (4422949) @ Episode 5914/10000, loss: 0.0034949118271470072\n",
      "Episode Reward: 13.0\n",
      "Step 497 (4423446) @ Episode 5915/10000, loss: 0.0020518773235380656\n",
      "Episode Reward: 6.0\n",
      "Step 754 (4424200) @ Episode 5916/10000, loss: 0.0053409500978887082\n",
      "Episode Reward: 19.0\n",
      "Step 668 (4424868) @ Episode 5917/10000, loss: 0.0040626376867294313\n",
      "Episode Reward: 10.0\n",
      "Step 714 (4425582) @ Episode 5918/10000, loss: 0.0020226249471306873\n",
      "Episode Reward: 11.0\n",
      "Step 720 (4426302) @ Episode 5919/10000, loss: 0.0050863223150372505\n",
      "Episode Reward: 11.0\n",
      "Step 858 (4427160) @ Episode 5920/10000, loss: 0.0043627708218991763\n",
      "Episode Reward: 20.0\n",
      "Step 861 (4428021) @ Episode 5921/10000, loss: 0.0071786222979426383\n",
      "Episode Reward: 20.0\n",
      "Step 902 (4428923) @ Episode 5922/10000, loss: 0.0028361734002828685\n",
      "Episode Reward: 14.0\n",
      "Step 682 (4429605) @ Episode 5923/10000, loss: 0.0029509023297578096\n",
      "Episode Reward: 14.0\n",
      "Step 394 (4429999) @ Episode 5924/10000, loss: 0.0157063752412796025\n",
      " Copied model parameters to target network\n",
      "Step 1261 (4430866) @ Episode 5924/10000, loss: 0.0042287195101380357\n",
      "Episode Reward: 25.0\n",
      "Step 1356 (4432222) @ Episode 5925/10000, loss: 0.0061269914731383325\n",
      "Episode Reward: 27.0\n",
      "Step 872 (4433094) @ Episode 5926/10000, loss: 0.0051380861550569535\n",
      "Episode Reward: 15.0\n",
      "Step 419 (4433513) @ Episode 5927/10000, loss: 0.0016341066220775247\n",
      "Episode Reward: 4.0\n",
      "Step 649 (4434162) @ Episode 5928/10000, loss: 0.0050645670853555245\n",
      "Episode Reward: 9.0\n",
      "Step 599 (4434761) @ Episode 5929/10000, loss: 0.0022868660744279623\n",
      "Episode Reward: 10.0\n",
      "Step 707 (4435468) @ Episode 5930/10000, loss: 0.0043803383596241473\n",
      "Episode Reward: 9.0\n",
      "Step 1036 (4436504) @ Episode 5931/10000, loss: 0.0014664933551102877\n",
      "Episode Reward: 21.0\n",
      "Step 1149 (4437653) @ Episode 5932/10000, loss: 0.0024617896415293217\n",
      "Episode Reward: 27.0\n",
      "Step 542 (4438195) @ Episode 5933/10000, loss: 0.0047681629657745366\n",
      "Episode Reward: 7.0\n",
      "Step 775 (4438970) @ Episode 5934/10000, loss: 0.0040435651317238815\n",
      "Episode Reward: 14.0\n",
      "Step 766 (4439736) @ Episode 5935/10000, loss: 0.0042341225780546665\n",
      "Episode Reward: 12.0\n",
      "Step 263 (4439999) @ Episode 5936/10000, loss: 0.0053726159967482097\n",
      " Copied model parameters to target network\n",
      "Step 632 (4440368) @ Episode 5936/10000, loss: 0.0088685620576143266\n",
      "Episode Reward: 9.0\n",
      "Step 643 (4441011) @ Episode 5937/10000, loss: 0.0022309815976768738\n",
      "Episode Reward: 9.0\n",
      "Step 498 (4441509) @ Episode 5938/10000, loss: 0.0059229610487818724\n",
      "Episode Reward: 7.0\n",
      "Step 707 (4442216) @ Episode 5939/10000, loss: 0.0038956408388912678\n",
      "Episode Reward: 14.0\n",
      "Step 926 (4443142) @ Episode 5940/10000, loss: 0.0037688231095671654\n",
      "Episode Reward: 20.0\n",
      "Step 516 (4443658) @ Episode 5941/10000, loss: 0.0170923825353384022\n",
      "Episode Reward: 7.0\n",
      "Step 806 (4444464) @ Episode 5942/10000, loss: 0.0039739361964166164\n",
      "Episode Reward: 12.0\n",
      "Step 653 (4445117) @ Episode 5943/10000, loss: 0.0044036889448761946\n",
      "Episode Reward: 10.0\n",
      "Step 803 (4445920) @ Episode 5944/10000, loss: 0.0094695035368204125\n",
      "Episode Reward: 14.0\n",
      "Step 969 (4446889) @ Episode 5945/10000, loss: 0.0067309057340025957\n",
      "Episode Reward: 22.0\n",
      "Step 763 (4447652) @ Episode 5946/10000, loss: 0.0019924009684473276\n",
      "Episode Reward: 18.0\n",
      "Step 991 (4448643) @ Episode 5947/10000, loss: 0.0018141550244763494\n",
      "Episode Reward: 15.0\n",
      "Step 506 (4449149) @ Episode 5948/10000, loss: 0.0052561713382601746\n",
      "Episode Reward: 9.0\n",
      "Step 850 (4449999) @ Episode 5949/10000, loss: 0.0095198228955268864\n",
      " Copied model parameters to target network\n",
      "Step 1112 (4450261) @ Episode 5949/10000, loss: 0.0036804261617362515\n",
      "Episode Reward: 21.0\n",
      "Step 827 (4451088) @ Episode 5950/10000, loss: 0.0062799723818898263\n",
      "Episode Reward: 17.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 04:01:35,493] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video005950.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1221 (4452309) @ Episode 5951/10000, loss: 0.0077172918245196344\n",
      "Episode Reward: 24.0\n",
      "Step 1011 (4453320) @ Episode 5952/10000, loss: 0.003451008815318346\n",
      "Episode Reward: 16.0\n",
      "Step 606 (4453926) @ Episode 5953/10000, loss: 0.0024454421363770964\n",
      "Episode Reward: 9.0\n",
      "Step 361 (4454287) @ Episode 5954/10000, loss: 0.0044007399119436745\n",
      "Episode Reward: 4.0\n",
      "Step 765 (4455052) @ Episode 5955/10000, loss: 0.0091975601390004167\n",
      "Episode Reward: 13.0\n",
      "Step 1069 (4456121) @ Episode 5956/10000, loss: 0.0059202248230576515\n",
      "Episode Reward: 23.0\n",
      "Step 760 (4456881) @ Episode 5957/10000, loss: 0.0314738936722278618\n",
      "Episode Reward: 11.0\n",
      "Step 595 (4457476) @ Episode 5958/10000, loss: 0.0027264661621302366\n",
      "Episode Reward: 9.0\n",
      "Step 341 (4457817) @ Episode 5959/10000, loss: 0.0061722858808934692\n",
      "Episode Reward: 4.0\n",
      "Step 547 (4458364) @ Episode 5960/10000, loss: 0.0247786827385425577\n",
      "Episode Reward: 7.0\n",
      "Step 983 (4459347) @ Episode 5961/10000, loss: 0.0097335828468203545\n",
      "Episode Reward: 21.0\n",
      "Step 652 (4459999) @ Episode 5962/10000, loss: 0.0039168624207377436\n",
      " Copied model parameters to target network\n",
      "Step 1004 (4460351) @ Episode 5962/10000, loss: 0.0050672506913542755\n",
      "Episode Reward: 18.0\n",
      "Step 568 (4460919) @ Episode 5963/10000, loss: 0.0055072424001991752\n",
      "Episode Reward: 9.0\n",
      "Step 637 (4461556) @ Episode 5964/10000, loss: 0.0025421660393476486\n",
      "Episode Reward: 9.0\n",
      "Step 890 (4462446) @ Episode 5965/10000, loss: 0.0035873977467417717\n",
      "Episode Reward: 12.0\n",
      "Step 682 (4463128) @ Episode 5966/10000, loss: 0.0123078078031539925\n",
      "Episode Reward: 14.0\n",
      "Step 914 (4464042) @ Episode 5967/10000, loss: 0.0040296334773302083\n",
      "Episode Reward: 20.0\n",
      "Step 1223 (4465265) @ Episode 5968/10000, loss: 0.0035698269493877888\n",
      "Episode Reward: 20.0\n",
      "Step 458 (4465723) @ Episode 5969/10000, loss: 0.0019545261748135095\n",
      "Episode Reward: 6.0\n",
      "Step 564 (4466287) @ Episode 5970/10000, loss: 0.0046765138395130635\n",
      "Episode Reward: 14.0\n",
      "Step 861 (4467148) @ Episode 5971/10000, loss: 0.0047765062190592296\n",
      "Episode Reward: 17.0\n",
      "Step 860 (4468008) @ Episode 5972/10000, loss: 0.0064060194417834287\n",
      "Episode Reward: 14.0\n",
      "Step 811 (4468819) @ Episode 5973/10000, loss: 0.0030679614283144474\n",
      "Episode Reward: 12.0\n",
      "Step 691 (4469510) @ Episode 5974/10000, loss: 0.0072430269792675974\n",
      "Episode Reward: 15.0\n",
      "Step 489 (4469999) @ Episode 5975/10000, loss: 0.0069943806156516075\n",
      " Copied model parameters to target network\n",
      "Step 535 (4470045) @ Episode 5975/10000, loss: 0.0027196994051337249\n",
      "Episode Reward: 9.0\n",
      "Step 621 (4470666) @ Episode 5976/10000, loss: 0.0076592722907662395\n",
      "Episode Reward: 9.0\n",
      "Step 890 (4471556) @ Episode 5977/10000, loss: 0.0084894578903913528\n",
      "Episode Reward: 17.0\n",
      "Step 640 (4472196) @ Episode 5978/10000, loss: 0.0027847483288496733\n",
      "Episode Reward: 10.0\n",
      "Step 454 (4472650) @ Episode 5979/10000, loss: 0.0021604008506983526\n",
      "Episode Reward: 6.0\n",
      "Step 567 (4473217) @ Episode 5980/10000, loss: 0.0015458238776773214\n",
      "Episode Reward: 8.0\n",
      "Step 1137 (4474354) @ Episode 5981/10000, loss: 0.0024722828529775143\n",
      "Episode Reward: 31.0\n",
      "Step 636 (4474990) @ Episode 5982/10000, loss: 0.0130802243947982796\n",
      "Episode Reward: 8.0\n",
      "Step 689 (4475679) @ Episode 5983/10000, loss: 0.0103695411235094075\n",
      "Episode Reward: 10.0\n",
      "Step 862 (4476541) @ Episode 5984/10000, loss: 0.0028888662345707417\n",
      "Episode Reward: 14.0\n",
      "Step 801 (4477342) @ Episode 5985/10000, loss: 0.0032590220216661696\n",
      "Episode Reward: 21.0\n",
      "Step 1019 (4478361) @ Episode 5986/10000, loss: 0.0036609936505556107\n",
      "Episode Reward: 17.0\n",
      "Step 676 (4479037) @ Episode 5987/10000, loss: 0.0078583322465419776\n",
      "Episode Reward: 14.0\n",
      "Step 962 (4479999) @ Episode 5988/10000, loss: 0.0025221640244126325\n",
      " Copied model parameters to target network\n",
      "Step 1020 (4480057) @ Episode 5988/10000, loss: 0.0050897835753858094\n",
      "Episode Reward: 22.0\n",
      "Step 754 (4480811) @ Episode 5989/10000, loss: 0.0038425144739449024\n",
      "Episode Reward: 17.0\n",
      "Step 679 (4481490) @ Episode 5990/10000, loss: 0.0048230877146124845\n",
      "Episode Reward: 13.0\n",
      "Step 739 (4482229) @ Episode 5991/10000, loss: 0.0163958407938480386\n",
      "Episode Reward: 15.0\n",
      "Step 673 (4482902) @ Episode 5992/10000, loss: 0.0014608707278966904\n",
      "Episode Reward: 11.0\n",
      "Step 893 (4483795) @ Episode 5993/10000, loss: 0.0037329816259443765\n",
      "Episode Reward: 16.0\n",
      "Step 721 (4484516) @ Episode 5994/10000, loss: 0.0057228505611419685\n",
      "Episode Reward: 12.0\n",
      "Step 999 (4485515) @ Episode 5995/10000, loss: 0.0078664645552635294\n",
      "Episode Reward: 18.0\n",
      "Step 783 (4486298) @ Episode 5996/10000, loss: 0.0090715745463967327\n",
      "Episode Reward: 16.0\n",
      "Step 684 (4486982) @ Episode 5997/10000, loss: 0.0032843779772520065\n",
      "Episode Reward: 12.0\n",
      "Step 929 (4487911) @ Episode 5998/10000, loss: 0.0050677480176091194\n",
      "Episode Reward: 19.0\n",
      "Step 490 (4488401) @ Episode 5999/10000, loss: 0.0057103056460618973\n",
      "Episode Reward: 7.0\n",
      "Step 974 (4489375) @ Episode 6000/10000, loss: 0.0062596406787633992\n",
      "Episode Reward: 17.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 04:07:34,046] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video006000.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 624 (4489999) @ Episode 6001/10000, loss: 0.0078948531299829485\n",
      " Copied model parameters to target network\n",
      "Step 786 (4490161) @ Episode 6001/10000, loss: 0.0076874764636158943\n",
      "Episode Reward: 13.0\n",
      "Step 722 (4490883) @ Episode 6002/10000, loss: 0.0142990574240684515\n",
      "Episode Reward: 11.0\n",
      "Step 653 (4491536) @ Episode 6003/10000, loss: 0.0052170236594974995\n",
      "Episode Reward: 10.0\n",
      "Step 723 (4492259) @ Episode 6004/10000, loss: 0.0031346010509878397\n",
      "Episode Reward: 18.0\n",
      "Step 978 (4493237) @ Episode 6005/10000, loss: 0.0138843972235918056\n",
      "Episode Reward: 16.0\n",
      "Step 1375 (4494612) @ Episode 6006/10000, loss: 0.0037544330116361387\n",
      "Episode Reward: 35.0\n",
      "Step 598 (4495210) @ Episode 6007/10000, loss: 0.0044150203466415405\n",
      "Episode Reward: 7.0\n",
      "Step 787 (4495997) @ Episode 6008/10000, loss: 0.0061939489096403125\n",
      "Episode Reward: 13.0\n",
      "Step 1069 (4497066) @ Episode 6009/10000, loss: 0.0058909957297146327\n",
      "Episode Reward: 28.0\n",
      "Step 833 (4497899) @ Episode 6010/10000, loss: 0.0018806355074048042\n",
      "Episode Reward: 16.0\n",
      "Step 856 (4498755) @ Episode 6011/10000, loss: 0.0047095995396375666\n",
      "Episode Reward: 17.0\n",
      "Step 483 (4499238) @ Episode 6012/10000, loss: 0.0068123624660074716\n",
      "Episode Reward: 7.0\n",
      "Step 633 (4499871) @ Episode 6013/10000, loss: 0.0021148824598640203\n",
      "Episode Reward: 11.0\n",
      "Step 128 (4499999) @ Episode 6014/10000, loss: 0.0030927148181945086\n",
      " Copied model parameters to target network\n",
      "Step 871 (4500742) @ Episode 6014/10000, loss: 0.0071085160598158843\n",
      "Episode Reward: 16.0\n",
      "Step 639 (4501381) @ Episode 6015/10000, loss: 0.0098470626398921015\n",
      "Episode Reward: 12.0\n",
      "Step 722 (4502103) @ Episode 6016/10000, loss: 0.0060610272921621846\n",
      "Episode Reward: 11.0\n",
      "Step 796 (4502899) @ Episode 6017/10000, loss: 0.0029203640297055244\n",
      "Episode Reward: 13.0\n",
      "Step 773 (4503672) @ Episode 6018/10000, loss: 0.0027290810830891132\n",
      "Episode Reward: 13.0\n",
      "Step 819 (4504491) @ Episode 6019/10000, loss: 0.0040810797363519673\n",
      "Episode Reward: 12.0\n",
      "Step 626 (4505117) @ Episode 6020/10000, loss: 0.0073797693476080894\n",
      "Episode Reward: 11.0\n",
      "Step 583 (4505700) @ Episode 6021/10000, loss: 0.0057408036664128395\n",
      "Episode Reward: 8.0\n",
      "Step 809 (4506509) @ Episode 6022/10000, loss: 0.0053330669179558756\n",
      "Episode Reward: 14.0\n",
      "Step 1072 (4507581) @ Episode 6023/10000, loss: 0.0018253233283758163\n",
      "Episode Reward: 22.0\n",
      "Step 600 (4508181) @ Episode 6024/10000, loss: 0.0043720062822103505\n",
      "Episode Reward: 9.0\n",
      "Step 1081 (4509262) @ Episode 6025/10000, loss: 0.0041900500655174255\n",
      "Episode Reward: 17.0\n",
      "Step 668 (4509930) @ Episode 6026/10000, loss: 0.1221424713730812192\n",
      "Episode Reward: 10.0\n",
      "Step 69 (4509999) @ Episode 6027/10000, loss: 0.0034814609680324793\n",
      " Copied model parameters to target network\n",
      "Step 660 (4510590) @ Episode 6027/10000, loss: 0.0026385204400867224\n",
      "Episode Reward: 14.0\n",
      "Step 789 (4511379) @ Episode 6028/10000, loss: 0.0033954558894038216\n",
      "Episode Reward: 14.0\n",
      "Step 589 (4511968) @ Episode 6029/10000, loss: 0.0049438080750405794\n",
      "Episode Reward: 8.0\n",
      "Step 1197 (4513165) @ Episode 6030/10000, loss: 0.0164196211844682785\n",
      "Episode Reward: 30.0\n",
      "Step 516 (4513681) @ Episode 6031/10000, loss: 0.0109922736883163456\n",
      "Episode Reward: 6.0\n",
      "Step 516 (4514197) @ Episode 6032/10000, loss: 0.1045061647891998354\n",
      "Episode Reward: 9.0\n",
      "Step 628 (4514825) @ Episode 6033/10000, loss: 0.0552494116127491445\n",
      "Episode Reward: 10.0\n",
      "Step 1020 (4515845) @ Episode 6034/10000, loss: 0.0040862532332539564\n",
      "Episode Reward: 20.0\n",
      "Step 1230 (4517075) @ Episode 6035/10000, loss: 0.0044696764089167124\n",
      "Episode Reward: 25.0\n",
      "Step 720 (4517795) @ Episode 6036/10000, loss: 0.0049911215901374824\n",
      "Episode Reward: 12.0\n",
      "Step 707 (4518502) @ Episode 6037/10000, loss: 0.0051594190299510966\n",
      "Episode Reward: 11.0\n",
      "Step 1140 (4519642) @ Episode 6038/10000, loss: 0.0064911656081676483\n",
      "Episode Reward: 22.0\n",
      "Step 357 (4519999) @ Episode 6039/10000, loss: 0.0051595205441117295\n",
      " Copied model parameters to target network\n",
      "Step 834 (4520476) @ Episode 6039/10000, loss: 0.0040151360444724566\n",
      "Episode Reward: 14.0\n",
      "Step 918 (4521394) @ Episode 6040/10000, loss: 0.0054463129490613948\n",
      "Episode Reward: 14.0\n",
      "Step 788 (4522182) @ Episode 6041/10000, loss: 0.0016151417512446642\n",
      "Episode Reward: 14.0\n",
      "Step 654 (4522836) @ Episode 6042/10000, loss: 0.0047119953669607646\n",
      "Episode Reward: 10.0\n",
      "Step 582 (4523418) @ Episode 6043/10000, loss: 0.0049335602670907977\n",
      "Episode Reward: 9.0\n",
      "Step 1003 (4524421) @ Episode 6044/10000, loss: 0.005455533973872662\n",
      "Episode Reward: 18.0\n",
      "Step 627 (4525048) @ Episode 6045/10000, loss: 0.0068841702304780485\n",
      "Episode Reward: 9.0\n",
      "Step 865 (4525913) @ Episode 6046/10000, loss: 0.0030863694846630096\n",
      "Episode Reward: 16.0\n",
      "Step 753 (4526666) @ Episode 6047/10000, loss: 0.0074915452860295773\n",
      "Episode Reward: 8.0\n",
      "Step 679 (4527345) @ Episode 6048/10000, loss: 0.0043053473345935345\n",
      "Episode Reward: 10.0\n",
      "Step 848 (4528193) @ Episode 6049/10000, loss: 0.0024371449835598475\n",
      "Episode Reward: 15.0\n",
      "Step 1041 (4529234) @ Episode 6050/10000, loss: 0.0035447601694613695\n",
      "Episode Reward: 18.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 04:13:46,978] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video006050.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 747 (4529981) @ Episode 6051/10000, loss: 0.0038968874141573906\n",
      "Episode Reward: 12.0\n",
      "Step 18 (4529999) @ Episode 6052/10000, loss: 0.0036361217498779297\n",
      " Copied model parameters to target network\n",
      "Step 725 (4530706) @ Episode 6052/10000, loss: 0.0069418456405401233\n",
      "Episode Reward: 13.0\n",
      "Step 1007 (4531713) @ Episode 6053/10000, loss: 0.0059380382299423226\n",
      "Episode Reward: 22.0\n",
      "Step 1187 (4532900) @ Episode 6054/10000, loss: 0.0014809858985245228\n",
      "Episode Reward: 21.0\n",
      "Step 1080 (4533980) @ Episode 6055/10000, loss: 0.0497961491346359256\n",
      "Episode Reward: 27.0\n",
      "Step 782 (4534762) @ Episode 6056/10000, loss: 0.0016024187207221985\n",
      "Episode Reward: 10.0\n",
      "Step 1152 (4535914) @ Episode 6057/10000, loss: 0.0025288872420787816\n",
      "Episode Reward: 25.0\n",
      "Step 576 (4536490) @ Episode 6058/10000, loss: 0.0107068652287125594\n",
      "Episode Reward: 8.0\n",
      "Step 642 (4537132) @ Episode 6059/10000, loss: 0.0719313323497772225\n",
      "Episode Reward: 8.0\n",
      "Step 870 (4538002) @ Episode 6060/10000, loss: 0.0047819144092500216\n",
      "Episode Reward: 16.0\n",
      "Step 866 (4538868) @ Episode 6061/10000, loss: 0.0084867589175701147\n",
      "Episode Reward: 13.0\n",
      "Step 889 (4539757) @ Episode 6062/10000, loss: 0.0205851364880800255\n",
      "Episode Reward: 14.0\n",
      "Step 242 (4539999) @ Episode 6063/10000, loss: 0.0104455137625336654\n",
      " Copied model parameters to target network\n",
      "Step 445 (4540202) @ Episode 6063/10000, loss: 0.0025126496329903603\n",
      "Episode Reward: 9.0\n",
      "Step 649 (4540851) @ Episode 6064/10000, loss: 0.0042270338162779813\n",
      "Episode Reward: 7.0\n",
      "Step 743 (4541594) @ Episode 6065/10000, loss: 0.0024558519944548607\n",
      "Episode Reward: 11.0\n",
      "Step 975 (4542569) @ Episode 6066/10000, loss: 0.0064053554087877275\n",
      "Episode Reward: 20.0\n",
      "Step 1268 (4543837) @ Episode 6067/10000, loss: 0.0067718313075602055\n",
      "Episode Reward: 23.0\n",
      "Step 692 (4544529) @ Episode 6068/10000, loss: 0.0052616256289184097\n",
      "Episode Reward: 10.0\n",
      "Step 807 (4545336) @ Episode 6069/10000, loss: 0.0057539120316505438\n",
      "Episode Reward: 19.0\n",
      "Step 780 (4546116) @ Episode 6070/10000, loss: 0.0019819838926196187\n",
      "Episode Reward: 13.0\n",
      "Step 806 (4546922) @ Episode 6071/10000, loss: 0.0012617309112101793\n",
      "Episode Reward: 13.0\n",
      "Step 972 (4547894) @ Episode 6072/10000, loss: 0.0060107875615358353\n",
      "Episode Reward: 16.0\n",
      "Step 831 (4548725) @ Episode 6073/10000, loss: 0.0153962420299649246\n",
      "Episode Reward: 12.0\n",
      "Step 454 (4549179) @ Episode 6074/10000, loss: 0.0043965736404061327\n",
      "Episode Reward: 6.0\n",
      "Step 705 (4549884) @ Episode 6075/10000, loss: 0.0059514464810490613\n",
      "Episode Reward: 11.0\n",
      "Step 115 (4549999) @ Episode 6076/10000, loss: 0.0115292426198720932\n",
      " Copied model parameters to target network\n",
      "Step 850 (4550734) @ Episode 6076/10000, loss: 0.0019402961479499936\n",
      "Episode Reward: 17.0\n",
      "Step 1129 (4551863) @ Episode 6077/10000, loss: 0.0018413534853607416\n",
      "Episode Reward: 34.0\n",
      "Step 853 (4552716) @ Episode 6078/10000, loss: 0.0046627838164567957\n",
      "Episode Reward: 15.0\n",
      "Step 936 (4553652) @ Episode 6079/10000, loss: 0.0040552327409386635\n",
      "Episode Reward: 15.0\n",
      "Step 753 (4554405) @ Episode 6080/10000, loss: 0.0047306497581303124\n",
      "Episode Reward: 22.0\n",
      "Step 706 (4555111) @ Episode 6081/10000, loss: 0.0065096244215965277\n",
      "Episode Reward: 12.0\n",
      "Step 788 (4555899) @ Episode 6082/10000, loss: 0.0043355342932045464\n",
      "Episode Reward: 12.0\n",
      "Step 1436 (4557335) @ Episode 6083/10000, loss: 0.0039199627935886387\n",
      "Episode Reward: 27.0\n",
      "Step 773 (4558108) @ Episode 6084/10000, loss: 0.0020114225335419187\n",
      "Episode Reward: 11.0\n",
      "Step 599 (4558707) @ Episode 6085/10000, loss: 0.0051875789649784565\n",
      "Episode Reward: 9.0\n",
      "Step 673 (4559380) @ Episode 6086/10000, loss: 0.0080403322353959083\n",
      "Episode Reward: 10.0\n",
      "Step 619 (4559999) @ Episode 6087/10000, loss: 0.0044027352705597883\n",
      " Copied model parameters to target network\n",
      "Step 916 (4560296) @ Episode 6087/10000, loss: 0.0027403356507420545\n",
      "Episode Reward: 17.0\n",
      "Step 797 (4561093) @ Episode 6088/10000, loss: 0.0050122332759201535\n",
      "Episode Reward: 12.0\n",
      "Step 1356 (4562449) @ Episode 6089/10000, loss: 0.0052195172756910324\n",
      "Episode Reward: 35.0\n",
      "Step 879 (4563328) @ Episode 6090/10000, loss: 0.0059245293959975244\n",
      "Episode Reward: 14.0\n",
      "Step 959 (4564287) @ Episode 6091/10000, loss: 0.0036898646503686905\n",
      "Episode Reward: 20.0\n",
      "Step 613 (4564900) @ Episode 6092/10000, loss: 0.0069889822043478495\n",
      "Episode Reward: 12.0\n",
      "Step 739 (4565639) @ Episode 6093/10000, loss: 0.0033429879695177084\n",
      "Episode Reward: 13.0\n",
      "Step 796 (4566435) @ Episode 6094/10000, loss: 0.0050779357552528384\n",
      "Episode Reward: 13.0\n",
      "Step 712 (4567147) @ Episode 6095/10000, loss: 0.0047429245896637445\n",
      "Episode Reward: 11.0\n",
      "Step 1158 (4568305) @ Episode 6096/10000, loss: 0.0045315311290323738\n",
      "Episode Reward: 24.0\n",
      "Step 1046 (4569351) @ Episode 6097/10000, loss: 0.0042433328926563268\n",
      "Episode Reward: 18.0\n",
      "Step 648 (4569999) @ Episode 6098/10000, loss: 0.0043490366078913212\n",
      " Copied model parameters to target network\n",
      "Step 854 (4570205) @ Episode 6098/10000, loss: 0.0051578860729932785\n",
      "Episode Reward: 13.0\n",
      "Step 826 (4571031) @ Episode 6099/10000, loss: 0.0057126088067889217\n",
      "Episode Reward: 13.0\n",
      "Step 491 (4571522) @ Episode 6100/10000, loss: 0.0040368717163801192\n",
      "Episode Reward: 7.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 04:20:18,889] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video006100.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1268 (4572790) @ Episode 6101/10000, loss: 0.0041715460829436784\n",
      "Episode Reward: 25.0\n",
      "Step 1158 (4573948) @ Episode 6102/10000, loss: 0.0049985423684120186\n",
      "Episode Reward: 25.0\n",
      "Step 742 (4574690) @ Episode 6103/10000, loss: 0.0043556308373808867\n",
      "Episode Reward: 14.0\n",
      "Step 1063 (4575753) @ Episode 6104/10000, loss: 0.0038592820055782795\n",
      "Episode Reward: 25.0\n",
      "Step 834 (4576587) @ Episode 6105/10000, loss: 0.0031248102895915512\n",
      "Episode Reward: 17.0\n",
      "Step 999 (4577586) @ Episode 6106/10000, loss: 0.0137825729325413737\n",
      "Episode Reward: 24.0\n",
      "Step 839 (4578425) @ Episode 6107/10000, loss: 0.0016821622848510742\n",
      "Episode Reward: 20.0\n",
      "Step 738 (4579163) @ Episode 6108/10000, loss: 0.0180502962321043125\n",
      "Episode Reward: 15.0\n",
      "Step 836 (4579999) @ Episode 6109/10000, loss: 0.0019426983781158924\n",
      " Copied model parameters to target network\n",
      "Step 990 (4580153) @ Episode 6109/10000, loss: 0.0039978032000362874\n",
      "Episode Reward: 16.0\n",
      "Step 683 (4580836) @ Episode 6110/10000, loss: 0.0030635264702141285\n",
      "Episode Reward: 12.0\n",
      "Step 1086 (4581922) @ Episode 6111/10000, loss: 0.0029187016189098363\n",
      "Episode Reward: 21.0\n",
      "Step 1108 (4583030) @ Episode 6112/10000, loss: 0.0047177411615848545\n",
      "Episode Reward: 25.0\n",
      "Step 482 (4583512) @ Episode 6113/10000, loss: 0.0023437510244548323\n",
      "Episode Reward: 6.0\n",
      "Step 626 (4584138) @ Episode 6114/10000, loss: 0.0022900938056409367\n",
      "Episode Reward: 11.0\n",
      "Step 682 (4584820) @ Episode 6115/10000, loss: 0.0026999393012374645\n",
      "Episode Reward: 9.0\n",
      "Step 1008 (4585828) @ Episode 6116/10000, loss: 0.0074795726686716087\n",
      "Episode Reward: 21.0\n",
      "Step 468 (4586296) @ Episode 6117/10000, loss: 0.0035131277982145553\n",
      "Episode Reward: 6.0\n",
      "Step 864 (4587160) @ Episode 6118/10000, loss: 0.0034930608235299587\n",
      "Episode Reward: 18.0\n",
      "Step 981 (4588141) @ Episode 6119/10000, loss: 0.0023149978369474413\n",
      "Episode Reward: 15.0\n",
      "Step 856 (4588997) @ Episode 6120/10000, loss: 0.0058023873716592793\n",
      "Episode Reward: 14.0\n",
      "Step 971 (4589968) @ Episode 6121/10000, loss: 0.0044958847574889665\n",
      "Episode Reward: 23.0\n",
      "Step 31 (4589999) @ Episode 6122/10000, loss: 0.0032558883540332317\n",
      " Copied model parameters to target network\n",
      "Step 1042 (4591010) @ Episode 6122/10000, loss: 0.0252129733562469487\n",
      "Episode Reward: 19.0\n",
      "Step 1093 (4592103) @ Episode 6123/10000, loss: 0.0021633720025420192\n",
      "Episode Reward: 20.0\n",
      "Step 689 (4592792) @ Episode 6124/10000, loss: 0.0038443810772150755\n",
      "Episode Reward: 10.0\n",
      "Step 515 (4593307) @ Episode 6125/10000, loss: 0.0030095241963863373\n",
      "Episode Reward: 6.0\n",
      "Step 571 (4593878) @ Episode 6126/10000, loss: 0.0016453471034765244\n",
      "Episode Reward: 8.0\n",
      "Step 372 (4594250) @ Episode 6127/10000, loss: 0.0038748597726225853\n",
      "Episode Reward: 4.0\n",
      "Step 537 (4594787) @ Episode 6128/10000, loss: 0.0049808295443654066\n",
      "Episode Reward: 10.0\n",
      "Step 535 (4595322) @ Episode 6129/10000, loss: 0.0071251103654503826\n",
      "Episode Reward: 8.0\n",
      "Step 907 (4596229) @ Episode 6130/10000, loss: 0.0015875529497861862\n",
      "Episode Reward: 16.0\n",
      "Step 826 (4597055) @ Episode 6131/10000, loss: 0.0074901413172483443\n",
      "Episode Reward: 14.0\n",
      "Step 1100 (4598155) @ Episode 6132/10000, loss: 0.0043601146899163724\n",
      "Episode Reward: 22.0\n",
      "Step 542 (4598697) @ Episode 6133/10000, loss: 0.0028028294909745455\n",
      "Episode Reward: 7.0\n",
      "Step 756 (4599453) @ Episode 6134/10000, loss: 0.0037101740017533302\n",
      "Episode Reward: 13.0\n",
      "Step 546 (4599999) @ Episode 6135/10000, loss: 0.0043405997566878796\n",
      " Copied model parameters to target network\n",
      "Step 1004 (4600457) @ Episode 6135/10000, loss: 0.0037329699844121933\n",
      "Episode Reward: 19.0\n",
      "Step 732 (4601189) @ Episode 6136/10000, loss: 0.0097668450325727467\n",
      "Episode Reward: 13.0\n",
      "Step 885 (4602074) @ Episode 6137/10000, loss: 0.0050221332348883153\n",
      "Episode Reward: 21.0\n",
      "Step 757 (4602831) @ Episode 6138/10000, loss: 0.0166389085352420852\n",
      "Episode Reward: 15.0\n",
      "Step 831 (4603662) @ Episode 6139/10000, loss: 0.0021656723693013198\n",
      "Episode Reward: 16.0\n",
      "Step 624 (4604286) @ Episode 6140/10000, loss: 0.0021916229743510485\n",
      "Episode Reward: 6.0\n",
      "Step 720 (4605006) @ Episode 6141/10000, loss: 0.0032605722080916166\n",
      "Episode Reward: 14.0\n",
      "Step 667 (4605673) @ Episode 6142/10000, loss: 0.0026104247663170187\n",
      "Episode Reward: 10.0\n",
      "Step 727 (4606400) @ Episode 6143/10000, loss: 0.0036690561100840576\n",
      "Episode Reward: 20.0\n",
      "Step 933 (4607333) @ Episode 6144/10000, loss: 0.0012067393399775028\n",
      "Episode Reward: 19.0\n",
      "Step 532 (4607865) @ Episode 6145/10000, loss: 0.0034567234106361866\n",
      "Episode Reward: 7.0\n",
      "Step 1229 (4609094) @ Episode 6146/10000, loss: 0.0026012128219008446\n",
      "Episode Reward: 28.0\n",
      "Step 905 (4609999) @ Episode 6147/10000, loss: 0.0012965450296178466\n",
      " Copied model parameters to target network\n",
      "Step 1178 (4610272) @ Episode 6147/10000, loss: 0.0038110273890197277\n",
      "Episode Reward: 24.0\n",
      "Step 724 (4610996) @ Episode 6148/10000, loss: 0.0032346476800739765\n",
      "Episode Reward: 13.0\n",
      "Step 856 (4611852) @ Episode 6149/10000, loss: 0.0039343219250440637\n",
      "Episode Reward: 13.0\n",
      "Step 1225 (4613077) @ Episode 6150/10000, loss: 0.0073341135866940026\n",
      "Episode Reward: 33.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 04:26:42,732] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video006150.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 530 (4613607) @ Episode 6151/10000, loss: 0.0220679379999637687\n",
      "Episode Reward: 7.0\n",
      "Step 602 (4614209) @ Episode 6152/10000, loss: 0.0040291142649948626\n",
      "Episode Reward: 10.0\n",
      "Step 652 (4614861) @ Episode 6153/10000, loss: 0.0067495983093976974\n",
      "Episode Reward: 9.0\n",
      "Step 990 (4615851) @ Episode 6154/10000, loss: 0.0037001278251409533\n",
      "Episode Reward: 16.0\n",
      "Step 596 (4616447) @ Episode 6155/10000, loss: 0.0047777472063899045\n",
      "Episode Reward: 9.0\n",
      "Step 1339 (4617786) @ Episode 6156/10000, loss: 0.0083820438012480746\n",
      "Episode Reward: 25.0\n",
      "Step 842 (4618628) @ Episode 6157/10000, loss: 0.0045895967632532127\n",
      "Episode Reward: 14.0\n",
      "Step 1048 (4619676) @ Episode 6158/10000, loss: 0.0036920690909028053\n",
      "Episode Reward: 18.0\n",
      "Step 323 (4619999) @ Episode 6159/10000, loss: 0.0031639658845961094\n",
      " Copied model parameters to target network\n",
      "Step 613 (4620289) @ Episode 6159/10000, loss: 0.0074501396156847487\n",
      "Episode Reward: 11.0\n",
      "Step 753 (4621042) @ Episode 6160/10000, loss: 0.0012311269529163837\n",
      "Episode Reward: 11.0\n",
      "Step 606 (4621648) @ Episode 6161/10000, loss: 0.0049354061484336857\n",
      "Episode Reward: 7.0\n",
      "Step 940 (4622588) @ Episode 6162/10000, loss: 0.0541376769542694155\n",
      "Episode Reward: 16.0\n",
      "Step 847 (4623435) @ Episode 6163/10000, loss: 0.0052759102545678616\n",
      "Episode Reward: 18.0\n",
      "Step 1006 (4624441) @ Episode 6164/10000, loss: 0.0072507485747337346\n",
      "Episode Reward: 22.0\n",
      "Step 564 (4625005) @ Episode 6165/10000, loss: 0.0027738623321056366\n",
      "Episode Reward: 9.0\n",
      "Step 515 (4625520) @ Episode 6166/10000, loss: 0.0028035040013492107\n",
      "Episode Reward: 6.0\n",
      "Step 494 (4626014) @ Episode 6167/10000, loss: 0.0018062540329992771\n",
      "Episode Reward: 7.0\n",
      "Step 646 (4626660) @ Episode 6168/10000, loss: 0.0030659371986985207\n",
      "Episode Reward: 11.0\n",
      "Step 962 (4627622) @ Episode 6169/10000, loss: 0.0038304268382489683\n",
      "Episode Reward: 17.0\n",
      "Step 902 (4628524) @ Episode 6170/10000, loss: 0.0025790538638830185\n",
      "Episode Reward: 16.0\n",
      "Step 454 (4628978) @ Episode 6171/10000, loss: 0.0065001649782061583\n",
      "Episode Reward: 7.0\n",
      "Step 844 (4629822) @ Episode 6172/10000, loss: 0.0094782272353768356\n",
      "Episode Reward: 23.0\n",
      "Step 177 (4629999) @ Episode 6173/10000, loss: 0.0056551387533545494\n",
      " Copied model parameters to target network\n",
      "Step 882 (4630704) @ Episode 6173/10000, loss: 0.0031713307835161686\n",
      "Episode Reward: 13.0\n",
      "Step 866 (4631570) @ Episode 6174/10000, loss: 0.0039479359984397895\n",
      "Episode Reward: 14.0\n",
      "Step 1169 (4632739) @ Episode 6175/10000, loss: 0.0040062433108687424\n",
      "Episode Reward: 19.0\n",
      "Step 913 (4633652) @ Episode 6176/10000, loss: 0.0038884456735104322\n",
      "Episode Reward: 17.0\n",
      "Step 372 (4634024) @ Episode 6177/10000, loss: 0.0058091445825994015\n",
      "Episode Reward: 4.0\n",
      "Step 522 (4634546) @ Episode 6178/10000, loss: 0.0045084287412464624\n",
      "Episode Reward: 6.0\n",
      "Step 875 (4635421) @ Episode 6179/10000, loss: 0.0178895108401775362\n",
      "Episode Reward: 13.0\n",
      "Step 725 (4636146) @ Episode 6180/10000, loss: 0.0025366730988025665\n",
      "Episode Reward: 9.0\n",
      "Step 889 (4637035) @ Episode 6181/10000, loss: 0.0046126754023134715\n",
      "Episode Reward: 18.0\n",
      "Step 593 (4637628) @ Episode 6182/10000, loss: 0.0017970306798815727\n",
      "Episode Reward: 8.0\n",
      "Step 742 (4638370) @ Episode 6183/10000, loss: 0.0038998275995254517\n",
      "Episode Reward: 12.0\n",
      "Step 653 (4639023) @ Episode 6184/10000, loss: 0.0320625714957714115\n",
      "Episode Reward: 9.0\n",
      "Step 630 (4639653) @ Episode 6185/10000, loss: 0.0036466340534389027\n",
      "Episode Reward: 8.0\n",
      "Step 346 (4639999) @ Episode 6186/10000, loss: 0.0055626798421144485\n",
      " Copied model parameters to target network\n",
      "Step 651 (4640304) @ Episode 6186/10000, loss: 0.0056493161246180534\n",
      "Episode Reward: 10.0\n",
      "Step 892 (4641196) @ Episode 6187/10000, loss: 0.0049132602289319044\n",
      "Episode Reward: 13.0\n",
      "Step 615 (4641811) @ Episode 6188/10000, loss: 0.0083003435283899353\n",
      "Episode Reward: 14.0\n",
      "Step 910 (4642721) @ Episode 6189/10000, loss: 0.0039857616648077965\n",
      "Episode Reward: 16.0\n",
      "Step 862 (4643583) @ Episode 6190/10000, loss: 0.0030892924405634403\n",
      "Episode Reward: 15.0\n",
      "Step 756 (4644339) @ Episode 6191/10000, loss: 0.0032397652976214886\n",
      "Episode Reward: 13.0\n",
      "Step 521 (4644860) @ Episode 6192/10000, loss: 0.0176851712167263036\n",
      "Episode Reward: 9.0\n",
      "Step 502 (4645362) @ Episode 6193/10000, loss: 0.0061434917151927955\n",
      "Episode Reward: 7.0\n",
      "Step 734 (4646096) @ Episode 6194/10000, loss: 0.0026157698594033723\n",
      "Episode Reward: 14.0\n",
      "Step 582 (4646678) @ Episode 6195/10000, loss: 0.0067963153123855596\n",
      "Episode Reward: 10.0\n",
      "Step 1221 (4647899) @ Episode 6196/10000, loss: 0.0076442416757345205\n",
      "Episode Reward: 23.0\n",
      "Step 514 (4648413) @ Episode 6197/10000, loss: 0.0061002648435533054\n",
      "Episode Reward: 7.0\n",
      "Step 393 (4648806) @ Episode 6198/10000, loss: 0.0055668754503130914\n",
      "Episode Reward: 4.0\n",
      "Step 446 (4649252) @ Episode 6199/10000, loss: 0.0070318300276994705\n",
      "Episode Reward: 6.0\n",
      "Step 701 (4649953) @ Episode 6200/10000, loss: 0.0035450956784188747\n",
      "Episode Reward: 9.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 04:32:28,523] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video006200.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 46 (4649999) @ Episode 6201/10000, loss: 0.0038530249148607254\n",
      " Copied model parameters to target network\n",
      "Step 727 (4650680) @ Episode 6201/10000, loss: 0.0032851099967956543\n",
      "Episode Reward: 12.0\n",
      "Step 596 (4651276) @ Episode 6202/10000, loss: 0.0060063060373067864\n",
      "Episode Reward: 10.0\n",
      "Step 797 (4652073) @ Episode 6203/10000, loss: 0.0316084958612918858\n",
      "Episode Reward: 14.0\n",
      "Step 761 (4652834) @ Episode 6204/10000, loss: 0.0063690315000712876\n",
      "Episode Reward: 12.0\n",
      "Step 833 (4653667) @ Episode 6205/10000, loss: 0.0045795654878020295\n",
      "Episode Reward: 13.0\n",
      "Step 728 (4654395) @ Episode 6206/10000, loss: 0.0729524120688438494\n",
      "Episode Reward: 11.0\n",
      "Step 787 (4655182) @ Episode 6207/10000, loss: 0.0043224189430475235\n",
      "Episode Reward: 14.0\n",
      "Step 834 (4656016) @ Episode 6208/10000, loss: 0.0054448144510388373\n",
      "Episode Reward: 14.0\n",
      "Step 985 (4657001) @ Episode 6209/10000, loss: 0.0021177716553211218\n",
      "Episode Reward: 23.0\n",
      "Step 817 (4657818) @ Episode 6210/10000, loss: 0.0031198286451399326\n",
      "Episode Reward: 16.0\n",
      "Step 925 (4658743) @ Episode 6211/10000, loss: 0.0044294754043221475\n",
      "Episode Reward: 20.0\n",
      "Step 588 (4659331) @ Episode 6212/10000, loss: 0.0155500341206789023\n",
      "Episode Reward: 9.0\n",
      "Step 668 (4659999) @ Episode 6213/10000, loss: 0.0045662047341465957\n",
      " Copied model parameters to target network\n",
      "Step 1221 (4660552) @ Episode 6213/10000, loss: 0.0022723281290382147\n",
      "Episode Reward: 23.0\n",
      "Step 1092 (4661644) @ Episode 6214/10000, loss: 0.0026503787375986576\n",
      "Episode Reward: 23.0\n",
      "Step 712 (4662356) @ Episode 6215/10000, loss: 0.0031798332929611206\n",
      "Episode Reward: 11.0\n",
      "Step 745 (4663101) @ Episode 6216/10000, loss: 0.0123714534565806398\n",
      "Episode Reward: 12.0\n",
      "Step 795 (4663896) @ Episode 6217/10000, loss: 0.0043758787214756017\n",
      "Episode Reward: 13.0\n",
      "Step 878 (4664774) @ Episode 6218/10000, loss: 0.0045156739652156836\n",
      "Episode Reward: 15.0\n",
      "Step 823 (4665597) @ Episode 6219/10000, loss: 0.0019526098622009158\n",
      "Episode Reward: 13.0\n",
      "Step 918 (4666515) @ Episode 6220/10000, loss: 0.0045619830489158635\n",
      "Episode Reward: 22.0\n",
      "Step 1030 (4667545) @ Episode 6221/10000, loss: 0.0027857348322868347\n",
      "Episode Reward: 17.0\n",
      "Step 764 (4668309) @ Episode 6222/10000, loss: 0.0026520472019910812\n",
      "Episode Reward: 16.0\n",
      "Step 785 (4669094) @ Episode 6223/10000, loss: 0.0036618914455175455\n",
      "Episode Reward: 15.0\n",
      "Step 750 (4669844) @ Episode 6224/10000, loss: 0.0078964121639728557\n",
      "Episode Reward: 15.0\n",
      "Step 155 (4669999) @ Episode 6225/10000, loss: 0.0031911190599203115\n",
      " Copied model parameters to target network\n",
      "Step 844 (4670688) @ Episode 6225/10000, loss: 0.0051873382180929183\n",
      "Episode Reward: 14.0\n",
      "Step 808 (4671496) @ Episode 6226/10000, loss: 0.0030122301541268826\n",
      "Episode Reward: 18.0\n",
      "Step 866 (4672362) @ Episode 6227/10000, loss: 0.0025192366447299725\n",
      "Episode Reward: 16.0\n",
      "Step 1313 (4673675) @ Episode 6228/10000, loss: 0.0026780189946293836\n",
      "Episode Reward: 29.0\n",
      "Step 798 (4674473) @ Episode 6229/10000, loss: 0.0101965628564357764\n",
      "Episode Reward: 15.0\n",
      "Step 415 (4674888) @ Episode 6230/10000, loss: 0.0045150937512516975\n",
      "Episode Reward: 6.0\n",
      "Step 679 (4675567) @ Episode 6231/10000, loss: 0.0070105614140629776\n",
      "Episode Reward: 11.0\n",
      "Step 834 (4676401) @ Episode 6232/10000, loss: 0.0177830103784799584\n",
      "Episode Reward: 12.0\n",
      "Step 945 (4677346) @ Episode 6233/10000, loss: 0.0083668669685721497\n",
      "Episode Reward: 18.0\n",
      "Step 488 (4677834) @ Episode 6234/10000, loss: 0.0129801798611879353\n",
      "Episode Reward: 7.0\n",
      "Step 661 (4678495) @ Episode 6235/10000, loss: 0.0035016566980630164\n",
      "Episode Reward: 12.0\n",
      "Step 1183 (4679678) @ Episode 6236/10000, loss: 0.0018832066562026745\n",
      "Episode Reward: 30.0\n",
      "Step 321 (4679999) @ Episode 6237/10000, loss: 0.0042604915797710423\n",
      " Copied model parameters to target network\n",
      "Step 744 (4680422) @ Episode 6237/10000, loss: 0.0097626075148582466\n",
      "Episode Reward: 13.0\n",
      "Step 931 (4681353) @ Episode 6238/10000, loss: 0.0471481755375862183\n",
      "Episode Reward: 17.0\n",
      "Step 772 (4682125) @ Episode 6239/10000, loss: 0.0032379613257944584\n",
      "Episode Reward: 10.0\n",
      "Step 689 (4682814) @ Episode 6240/10000, loss: 0.0041158427484333515\n",
      "Episode Reward: 12.0\n",
      "Step 1031 (4683845) @ Episode 6241/10000, loss: 0.0032994202338159084\n",
      "Episode Reward: 22.0\n",
      "Step 999 (4684844) @ Episode 6242/10000, loss: 0.0066911289468407632\n",
      "Episode Reward: 28.0\n",
      "Step 663 (4685507) @ Episode 6243/10000, loss: 0.0043743243440985683\n",
      "Episode Reward: 15.0\n",
      "Step 1045 (4686552) @ Episode 6244/10000, loss: 0.0035107552539557224\n",
      "Episode Reward: 22.0\n",
      "Step 1036 (4687588) @ Episode 6245/10000, loss: 0.0143869202584028244\n",
      "Episode Reward: 31.0\n",
      "Step 770 (4688358) @ Episode 6246/10000, loss: 0.0054961005225777635\n",
      "Episode Reward: 16.0\n",
      "Step 981 (4689339) @ Episode 6247/10000, loss: 0.0040904553607106216\n",
      "Episode Reward: 18.0\n",
      "Step 660 (4689999) @ Episode 6248/10000, loss: 0.0103100379928946582\n",
      " Copied model parameters to target network\n",
      "Step 794 (4690133) @ Episode 6248/10000, loss: 0.0056402455084025868\n",
      "Episode Reward: 12.0\n",
      "Step 1079 (4691212) @ Episode 6249/10000, loss: 0.0092099085450172422\n",
      "Episode Reward: 29.0\n",
      "Step 908 (4692120) @ Episode 6250/10000, loss: 0.0266678426414728165\n",
      "Episode Reward: 16.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 04:39:00,175] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video006250.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 531 (4692651) @ Episode 6251/10000, loss: 0.0029376782476902013\n",
      "Episode Reward: 8.0\n",
      "Step 834 (4693485) @ Episode 6252/10000, loss: 0.0031538389157503843\n",
      "Episode Reward: 12.0\n",
      "Step 731 (4694216) @ Episode 6253/10000, loss: 0.0039861043915152556\n",
      "Episode Reward: 13.0\n",
      "Step 767 (4694983) @ Episode 6254/10000, loss: 0.0102213080972433093\n",
      "Episode Reward: 16.0\n",
      "Step 1252 (4696235) @ Episode 6255/10000, loss: 0.0516946241259574946\n",
      "Episode Reward: 36.0\n",
      "Step 1061 (4697296) @ Episode 6256/10000, loss: 0.0035679247230291367\n",
      "Episode Reward: 21.0\n",
      "Step 537 (4697833) @ Episode 6257/10000, loss: 0.0036625692155212164\n",
      "Episode Reward: 12.0\n",
      "Step 862 (4698695) @ Episode 6258/10000, loss: 0.0074261627160012723\n",
      "Episode Reward: 20.0\n",
      "Step 809 (4699504) @ Episode 6259/10000, loss: 0.0028418062720447782\n",
      "Episode Reward: 16.0\n",
      "Step 495 (4699999) @ Episode 6260/10000, loss: 0.0022277052048593768\n",
      " Copied model parameters to target network\n",
      "Step 773 (4700277) @ Episode 6260/10000, loss: 0.00149122672155499465\n",
      "Episode Reward: 13.0\n",
      "Step 1046 (4701323) @ Episode 6261/10000, loss: 0.0059262369759380826\n",
      "Episode Reward: 17.0\n",
      "Step 772 (4702095) @ Episode 6262/10000, loss: 0.0026978212408721447\n",
      "Episode Reward: 14.0\n",
      "Step 716 (4702811) @ Episode 6263/10000, loss: 0.0117966728284955026\n",
      "Episode Reward: 10.0\n",
      "Step 1564 (4704375) @ Episode 6264/10000, loss: 0.0018405432347208261\n",
      "Episode Reward: 32.0\n",
      "Step 1223 (4705598) @ Episode 6265/10000, loss: 0.0051408298313617713\n",
      "Episode Reward: 28.0\n",
      "Step 1048 (4706646) @ Episode 6266/10000, loss: 0.0024874927476048472\n",
      "Episode Reward: 15.0\n",
      "Step 902 (4707548) @ Episode 6267/10000, loss: 0.0049689291045069695\n",
      "Episode Reward: 21.0\n",
      "Step 749 (4708297) @ Episode 6268/10000, loss: 0.0057349475100636484\n",
      "Episode Reward: 15.0\n",
      "Step 926 (4709223) @ Episode 6269/10000, loss: 0.0112169589847326286\n",
      "Episode Reward: 20.0\n",
      "Step 776 (4709999) @ Episode 6270/10000, loss: 0.0018694335594773293\n",
      " Copied model parameters to target network\n",
      "Step 800 (4710023) @ Episode 6270/10000, loss: 0.0029521246906369925\n",
      "Episode Reward: 15.0\n",
      "Step 1076 (4711099) @ Episode 6271/10000, loss: 0.0022957187611609697\n",
      "Episode Reward: 22.0\n",
      "Step 627 (4711726) @ Episode 6272/10000, loss: 0.0119360275566577917\n",
      "Episode Reward: 15.0\n",
      "Step 1119 (4712845) @ Episode 6273/10000, loss: 0.0018543612677603966\n",
      "Episode Reward: 18.0\n",
      "Step 1379 (4714224) @ Episode 6274/10000, loss: 0.0052237645722925664\n",
      "Episode Reward: 29.0\n",
      "Step 977 (4715201) @ Episode 6275/10000, loss: 0.0185585208237171173\n",
      "Episode Reward: 18.0\n",
      "Step 747 (4715948) @ Episode 6276/10000, loss: 0.0062148557044565683\n",
      "Episode Reward: 16.0\n",
      "Step 913 (4716861) @ Episode 6277/10000, loss: 0.0047491183504462245\n",
      "Episode Reward: 17.0\n",
      "Step 734 (4717595) @ Episode 6278/10000, loss: 0.0043709538877010345\n",
      "Episode Reward: 12.0\n",
      "Step 985 (4718580) @ Episode 6279/10000, loss: 0.0017687792424112558\n",
      "Episode Reward: 14.0\n",
      "Step 1127 (4719707) @ Episode 6280/10000, loss: 0.0187579318881034856\n",
      "Episode Reward: 22.0\n",
      "Step 292 (4719999) @ Episode 6281/10000, loss: 0.0023804402444511653\n",
      " Copied model parameters to target network\n",
      "Step 801 (4720508) @ Episode 6281/10000, loss: 0.0045984685420989996\n",
      "Episode Reward: 17.0\n",
      "Step 767 (4721275) @ Episode 6282/10000, loss: 0.0073689022101461897\n",
      "Episode Reward: 13.0\n",
      "Step 678 (4721953) @ Episode 6283/10000, loss: 0.0033586747013032436\n",
      "Episode Reward: 12.0\n",
      "Step 495 (4722448) @ Episode 6284/10000, loss: 0.0028570881113409996\n",
      "Episode Reward: 8.0\n",
      "Step 837 (4723285) @ Episode 6285/10000, loss: 0.0032225283794105053\n",
      "Episode Reward: 15.0\n",
      "Step 1386 (4724671) @ Episode 6286/10000, loss: 0.0117236990481615077\n",
      "Episode Reward: 24.0\n",
      "Step 984 (4725655) @ Episode 6287/10000, loss: 0.0025424680206924677\n",
      "Episode Reward: 15.0\n",
      "Step 763 (4726418) @ Episode 6288/10000, loss: 0.0031646725255995995\n",
      "Episode Reward: 19.0\n",
      "Step 804 (4727222) @ Episode 6289/10000, loss: 0.0045861601829528816\n",
      "Episode Reward: 19.0\n",
      "Step 775 (4727997) @ Episode 6290/10000, loss: 0.0028614024631679064\n",
      "Episode Reward: 14.0\n",
      "Step 1008 (4729005) @ Episode 6291/10000, loss: 0.0044893887825310236\n",
      "Episode Reward: 22.0\n",
      "Step 994 (4729999) @ Episode 6292/10000, loss: 0.1124494075775146517\n",
      " Copied model parameters to target network\n",
      "Step 1242 (4730247) @ Episode 6292/10000, loss: 0.0078873364254832275\n",
      "Episode Reward: 29.0\n",
      "Step 940 (4731187) @ Episode 6293/10000, loss: 0.0057189757935702857\n",
      "Episode Reward: 19.0\n",
      "Step 1043 (4732230) @ Episode 6294/10000, loss: 0.0050282683223485955\n",
      "Episode Reward: 26.0\n",
      "Step 942 (4733172) @ Episode 6295/10000, loss: 0.0031514330767095095\n",
      "Episode Reward: 26.0\n",
      "Step 886 (4734058) @ Episode 6296/10000, loss: 0.0099670737981796267\n",
      "Episode Reward: 15.0\n",
      "Step 900 (4734958) @ Episode 6297/10000, loss: 0.0194849818944931035\n",
      "Episode Reward: 15.0\n",
      "Step 1129 (4736087) @ Episode 6298/10000, loss: 0.0032131550833582883\n",
      "Episode Reward: 29.0\n",
      "Step 987 (4737074) @ Episode 6299/10000, loss: 0.0047912276349961764\n",
      "Episode Reward: 14.0\n",
      "Step 1165 (4738239) @ Episode 6300/10000, loss: 0.0029254159890115264\n",
      "Episode Reward: 25.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 04:46:07,480] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video006300.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 952 (4739191) @ Episode 6301/10000, loss: 0.0084370970726013186\n",
      "Episode Reward: 24.0\n",
      "Step 808 (4739999) @ Episode 6302/10000, loss: 0.0104281762614846235\n",
      " Copied model parameters to target network\n",
      "Step 852 (4740043) @ Episode 6302/10000, loss: 0.0353936403989791933\n",
      "Episode Reward: 15.0\n",
      "Step 1171 (4741214) @ Episode 6303/10000, loss: 0.0050273644737899342\n",
      "Episode Reward: 23.0\n",
      "Step 896 (4742110) @ Episode 6304/10000, loss: 0.0046166502870619366\n",
      "Episode Reward: 15.0\n",
      "Step 506 (4742616) @ Episode 6305/10000, loss: 0.0050928471609950066\n",
      "Episode Reward: 8.0\n",
      "Step 701 (4743317) @ Episode 6306/10000, loss: 0.0031382914166897535\n",
      "Episode Reward: 10.0\n",
      "Step 977 (4744294) @ Episode 6307/10000, loss: 0.0041863396763801575\n",
      "Episode Reward: 17.0\n",
      "Step 1543 (4745837) @ Episode 6308/10000, loss: 0.0094598177820444123\n",
      "Episode Reward: 44.0\n",
      "Step 1213 (4747050) @ Episode 6309/10000, loss: 0.0043594036251306537\n",
      "Episode Reward: 23.0\n",
      "Step 629 (4747679) @ Episode 6310/10000, loss: 0.0103684579953551383\n",
      "Episode Reward: 12.0\n",
      "Step 1278 (4748957) @ Episode 6311/10000, loss: 0.0049046953208744533\n",
      "Episode Reward: 33.0\n",
      "Step 1042 (4749999) @ Episode 6312/10000, loss: 0.0036282471846789123\n",
      " Copied model parameters to target network\n",
      "Step 1390 (4750347) @ Episode 6312/10000, loss: 0.0018958076834678655\n",
      "Episode Reward: 28.0\n",
      "Step 551 (4750898) @ Episode 6313/10000, loss: 0.0054105734452605254\n",
      "Episode Reward: 10.0\n",
      "Step 682 (4751580) @ Episode 6314/10000, loss: 0.0074970638379454613\n",
      "Episode Reward: 11.0\n",
      "Step 850 (4752430) @ Episode 6315/10000, loss: 0.0025147756095975637\n",
      "Episode Reward: 16.0\n",
      "Step 1049 (4753479) @ Episode 6316/10000, loss: 0.0038739023730158806\n",
      "Episode Reward: 20.0\n",
      "Step 828 (4754307) @ Episode 6317/10000, loss: 0.0034342326689511538\n",
      "Episode Reward: 11.0\n",
      "Step 815 (4755122) @ Episode 6318/10000, loss: 0.0043166340328752995\n",
      "Episode Reward: 16.0\n",
      "Step 1147 (4756269) @ Episode 6319/10000, loss: 0.0700477510690689113\n",
      "Episode Reward: 19.0\n",
      "Step 743 (4757012) @ Episode 6320/10000, loss: 0.0026880272198468447\n",
      "Episode Reward: 12.0\n",
      "Step 703 (4757715) @ Episode 6321/10000, loss: 0.0064577702432870865\n",
      "Episode Reward: 14.0\n",
      "Step 1495 (4759210) @ Episode 6322/10000, loss: 0.0028269891627132893\n",
      "Episode Reward: 28.0\n",
      "Step 789 (4759999) @ Episode 6323/10000, loss: 0.0124393990263342865\n",
      " Copied model parameters to target network\n",
      "Step 835 (4760045) @ Episode 6323/10000, loss: 0.0027177685406059027\n",
      "Episode Reward: 15.0\n",
      "Step 1015 (4761060) @ Episode 6324/10000, loss: 0.0037337061949074277\n",
      "Episode Reward: 18.0\n",
      "Step 921 (4761981) @ Episode 6325/10000, loss: 0.0044052819721400748\n",
      "Episode Reward: 19.0\n",
      "Step 812 (4762793) @ Episode 6326/10000, loss: 0.0083883656188845636\n",
      "Episode Reward: 28.0\n",
      "Step 1018 (4763811) @ Episode 6327/10000, loss: 0.0050727976486086845\n",
      "Episode Reward: 25.0\n",
      "Step 1074 (4764885) @ Episode 6328/10000, loss: 0.0049332450143992915\n",
      "Episode Reward: 19.0\n",
      "Step 642 (4765527) @ Episode 6329/10000, loss: 0.0036625340580940247\n",
      "Episode Reward: 10.0\n",
      "Step 879 (4766406) @ Episode 6330/10000, loss: 0.0034472513943910664\n",
      "Episode Reward: 14.0\n",
      "Step 977 (4767383) @ Episode 6331/10000, loss: 0.0052074561826884754\n",
      "Episode Reward: 18.0\n",
      "Step 907 (4768290) @ Episode 6332/10000, loss: 0.0038584009744226933\n",
      "Episode Reward: 15.0\n",
      "Step 995 (4769285) @ Episode 6333/10000, loss: 0.0049732280895113945\n",
      "Episode Reward: 18.0\n",
      "Step 714 (4769999) @ Episode 6334/10000, loss: 0.0063159377314150334\n",
      " Copied model parameters to target network\n",
      "Step 833 (4770118) @ Episode 6334/10000, loss: 0.0042739366181194786\n",
      "Episode Reward: 14.0\n",
      "Step 1059 (4771177) @ Episode 6335/10000, loss: 0.0022062642965465784\n",
      "Episode Reward: 12.0\n",
      "Step 681 (4771858) @ Episode 6336/10000, loss: 0.0031197059433907277\n",
      "Episode Reward: 11.0\n",
      "Step 581 (4772439) @ Episode 6337/10000, loss: 0.0061989193782210356\n",
      "Episode Reward: 11.0\n",
      "Step 925 (4773364) @ Episode 6338/10000, loss: 0.0064736753702163793\n",
      "Episode Reward: 20.0\n",
      "Step 1510 (4774874) @ Episode 6339/10000, loss: 0.0050920373760163785\n",
      "Episode Reward: 26.0\n",
      "Step 1040 (4775914) @ Episode 6340/10000, loss: 0.0041839638724923137\n",
      "Episode Reward: 25.0\n",
      "Step 514 (4776428) @ Episode 6341/10000, loss: 0.0064194239675998695\n",
      "Episode Reward: 6.0\n",
      "Step 563 (4776991) @ Episode 6342/10000, loss: 0.0039496873505413537\n",
      "Episode Reward: 9.0\n",
      "Step 641 (4777632) @ Episode 6343/10000, loss: 0.0024862410500645638\n",
      "Episode Reward: 9.0\n",
      "Step 608 (4778240) @ Episode 6344/10000, loss: 0.0094143543392419822\n",
      "Episode Reward: 9.0\n",
      "Step 452 (4778692) @ Episode 6345/10000, loss: 0.0038404949009418488\n",
      "Episode Reward: 5.0\n",
      "Step 539 (4779231) @ Episode 6346/10000, loss: 0.0023013555910438347\n",
      "Episode Reward: 8.0\n",
      "Step 753 (4779984) @ Episode 6347/10000, loss: 0.0082398485392332084\n",
      "Episode Reward: 12.0\n",
      "Step 15 (4779999) @ Episode 6348/10000, loss: 0.0061870901845395565\n",
      " Copied model parameters to target network\n",
      "Step 1009 (4780993) @ Episode 6348/10000, loss: 0.0053475946187973024\n",
      "Episode Reward: 19.0\n",
      "Step 1137 (4782130) @ Episode 6349/10000, loss: 0.0108837913721799856\n",
      "Episode Reward: 25.0\n",
      "Step 755 (4782885) @ Episode 6350/10000, loss: 0.0045317998155951544\n",
      "Episode Reward: 13.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 04:53:01,289] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video006350.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 989 (4783874) @ Episode 6351/10000, loss: 0.0026713246479630476\n",
      "Episode Reward: 16.0\n",
      "Step 575 (4784449) @ Episode 6352/10000, loss: 0.0025533312000334263\n",
      "Episode Reward: 8.0\n",
      "Step 625 (4785074) @ Episode 6353/10000, loss: 0.0059831128455698492\n",
      "Episode Reward: 12.0\n",
      "Step 986 (4786060) @ Episode 6354/10000, loss: 0.0037235170602798467\n",
      "Episode Reward: 21.0\n",
      "Step 740 (4786800) @ Episode 6355/10000, loss: 0.0026642056182026863\n",
      "Episode Reward: 12.0\n",
      "Step 733 (4787533) @ Episode 6356/10000, loss: 0.0024207131937146187\n",
      "Episode Reward: 15.0\n",
      "Step 698 (4788231) @ Episode 6357/10000, loss: 0.0041735135018825537\n",
      "Episode Reward: 10.0\n",
      "Step 941 (4789172) @ Episode 6358/10000, loss: 0.0025611480232328176\n",
      "Episode Reward: 15.0\n",
      "Step 743 (4789915) @ Episode 6359/10000, loss: 0.0077260374091565617\n",
      "Episode Reward: 13.0\n",
      "Step 84 (4789999) @ Episode 6360/10000, loss: 0.0028354139067232615\n",
      " Copied model parameters to target network\n",
      "Step 833 (4790748) @ Episode 6360/10000, loss: 0.0042287260293960575\n",
      "Episode Reward: 12.0\n",
      "Step 1277 (4792025) @ Episode 6361/10000, loss: 0.0035656804684549576\n",
      "Episode Reward: 26.0\n",
      "Step 706 (4792731) @ Episode 6362/10000, loss: 0.0063066259026527405\n",
      "Episode Reward: 14.0\n",
      "Step 944 (4793675) @ Episode 6363/10000, loss: 0.0102818896993994717\n",
      "Episode Reward: 16.0\n",
      "Step 912 (4794587) @ Episode 6364/10000, loss: 0.0057009165175259115\n",
      "Episode Reward: 17.0\n",
      "Step 777 (4795364) @ Episode 6365/10000, loss: 0.0040153665468096733\n",
      "Episode Reward: 9.0\n",
      "Step 530 (4795894) @ Episode 6366/10000, loss: 0.0087098907679319384\n",
      "Episode Reward: 11.0\n",
      "Step 708 (4796602) @ Episode 6367/10000, loss: 0.0037797372788190844\n",
      "Episode Reward: 11.0\n",
      "Step 614 (4797216) @ Episode 6368/10000, loss: 0.0033616623841226146\n",
      "Episode Reward: 11.0\n",
      "Step 1721 (4798937) @ Episode 6369/10000, loss: 0.0045255720615386964\n",
      "Episode Reward: 44.0\n",
      "Step 823 (4799760) @ Episode 6370/10000, loss: 0.0027492374647408724\n",
      "Episode Reward: 14.0\n",
      "Step 239 (4799999) @ Episode 6371/10000, loss: 0.0033174357376992702\n",
      " Copied model parameters to target network\n",
      "Step 920 (4800680) @ Episode 6371/10000, loss: 0.0026425393298268325\n",
      "Episode Reward: 13.0\n",
      "Step 864 (4801544) @ Episode 6372/10000, loss: 0.0036013540811836726\n",
      "Episode Reward: 17.0\n",
      "Step 806 (4802350) @ Episode 6373/10000, loss: 0.0091691380366683875\n",
      "Episode Reward: 13.0\n",
      "Step 965 (4803315) @ Episode 6374/10000, loss: 0.0030751798767596483\n",
      "Episode Reward: 26.0\n",
      "Step 1558 (4804873) @ Episode 6375/10000, loss: 0.0057039135135710242\n",
      "Episode Reward: 27.0\n",
      "Step 972 (4805845) @ Episode 6376/10000, loss: 0.0053084576502442367\n",
      "Episode Reward: 19.0\n",
      "Step 680 (4806525) @ Episode 6377/10000, loss: 0.0056984983384609228\n",
      "Episode Reward: 10.0\n",
      "Step 908 (4807433) @ Episode 6378/10000, loss: 0.0026661383453756575\n",
      "Episode Reward: 15.0\n",
      "Step 817 (4808250) @ Episode 6379/10000, loss: 0.0074362354353070264\n",
      "Episode Reward: 17.0\n",
      "Step 881 (4809131) @ Episode 6380/10000, loss: 0.0031936438754200935\n",
      "Episode Reward: 12.0\n",
      "Step 608 (4809739) @ Episode 6381/10000, loss: 0.0085173351690173155\n",
      "Episode Reward: 9.0\n",
      "Step 260 (4809999) @ Episode 6382/10000, loss: 0.0058423113077878953\n",
      " Copied model parameters to target network\n",
      "Step 698 (4810437) @ Episode 6382/10000, loss: 0.0012704812688753009\n",
      "Episode Reward: 12.0\n",
      "Step 879 (4811316) @ Episode 6383/10000, loss: 0.0019455819856375456\n",
      "Episode Reward: 10.0\n",
      "Step 1217 (4812533) @ Episode 6384/10000, loss: 0.0040794420056045055\n",
      "Episode Reward: 28.0\n",
      "Step 1123 (4813656) @ Episode 6385/10000, loss: 0.0029974281787872314\n",
      "Episode Reward: 20.0\n",
      "Step 826 (4814482) @ Episode 6386/10000, loss: 0.0064006778411567215\n",
      "Episode Reward: 18.0\n",
      "Step 909 (4815391) @ Episode 6387/10000, loss: 0.0033230015542358166\n",
      "Episode Reward: 13.0\n",
      "Step 940 (4816331) @ Episode 6388/10000, loss: 0.0038943719118833546\n",
      "Episode Reward: 14.0\n",
      "Step 757 (4817088) @ Episode 6389/10000, loss: 0.0044121150858700275\n",
      "Episode Reward: 15.0\n",
      "Step 1192 (4818280) @ Episode 6390/10000, loss: 0.0038515084888786077\n",
      "Episode Reward: 30.0\n",
      "Step 1061 (4819341) @ Episode 6391/10000, loss: 0.0057068285532295724\n",
      "Episode Reward: 29.0\n",
      "Step 658 (4819999) @ Episode 6392/10000, loss: 0.0030238095205277205\n",
      " Copied model parameters to target network\n",
      "Step 1195 (4820536) @ Episode 6392/10000, loss: 0.0021569153759628534\n",
      "Episode Reward: 27.0\n",
      "Step 845 (4821381) @ Episode 6393/10000, loss: 0.0048066982999444015\n",
      "Episode Reward: 17.0\n",
      "Step 592 (4821973) @ Episode 6394/10000, loss: 0.0133792124688625346\n",
      "Episode Reward: 8.0\n",
      "Step 849 (4822822) @ Episode 6395/10000, loss: 0.0037369222845882177\n",
      "Episode Reward: 19.0\n",
      "Step 798 (4823620) @ Episode 6396/10000, loss: 0.0023877117782831195\n",
      "Episode Reward: 13.0\n",
      "Step 1145 (4824765) @ Episode 6397/10000, loss: 0.0035194710362702614\n",
      "Episode Reward: 26.0\n",
      "Step 778 (4825543) @ Episode 6398/10000, loss: 0.0141231920570135126\n",
      "Episode Reward: 12.0\n",
      "Step 877 (4826420) @ Episode 6399/10000, loss: 0.0184048190712928776\n",
      "Episode Reward: 14.0\n",
      "Step 687 (4827107) @ Episode 6400/10000, loss: 0.0176637861877679823\n",
      "Episode Reward: 8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 04:59:54,780] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video006400.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 627 (4827734) @ Episode 6401/10000, loss: 0.0028536200989037756\n",
      "Episode Reward: 10.0\n",
      "Step 657 (4828391) @ Episode 6402/10000, loss: 0.0084884529933333445\n",
      "Episode Reward: 12.0\n",
      "Step 511 (4828902) @ Episode 6403/10000, loss: 0.0045642647892236714\n",
      "Episode Reward: 9.0\n",
      "Step 1097 (4829999) @ Episode 6404/10000, loss: 0.0034320494160056114\n",
      " Copied model parameters to target network\n",
      "Step 1165 (4830067) @ Episode 6404/10000, loss: 0.0023854579776525497\n",
      "Episode Reward: 20.0\n",
      "Step 835 (4830902) @ Episode 6405/10000, loss: 0.0078465994447469713\n",
      "Episode Reward: 18.0\n",
      "Step 539 (4831441) @ Episode 6406/10000, loss: 0.0034645940177142625\n",
      "Episode Reward: 9.0\n",
      "Step 820 (4832261) @ Episode 6407/10000, loss: 0.0041771209798753268\n",
      "Episode Reward: 13.0\n",
      "Step 1105 (4833366) @ Episode 6408/10000, loss: 0.0376568362116813668\n",
      "Episode Reward: 21.0\n",
      "Step 822 (4834188) @ Episode 6409/10000, loss: 0.0037077877204865217\n",
      "Episode Reward: 14.0\n",
      "Step 1272 (4835460) @ Episode 6410/10000, loss: 0.0057123382575809956\n",
      "Episode Reward: 29.0\n",
      "Step 1146 (4836606) @ Episode 6411/10000, loss: 0.0038567828014492996\n",
      "Episode Reward: 27.0\n",
      "Step 1365 (4837971) @ Episode 6412/10000, loss: 0.0030333546455949545\n",
      "Episode Reward: 32.0\n",
      "Step 1161 (4839132) @ Episode 6413/10000, loss: 0.0042262999340891847\n",
      "Episode Reward: 23.0\n",
      "Step 867 (4839999) @ Episode 6414/10000, loss: 0.0068841716274619134\n",
      " Copied model parameters to target network\n",
      "Step 1010 (4840142) @ Episode 6414/10000, loss: 0.0041619460098445415\n",
      "Episode Reward: 20.0\n",
      "Step 860 (4841002) @ Episode 6415/10000, loss: 0.0116464216262102136\n",
      "Episode Reward: 20.0\n",
      "Step 391 (4841393) @ Episode 6416/10000, loss: 0.0041131475009024145\n",
      "Episode Reward: 8.0\n",
      "Step 1023 (4842416) @ Episode 6417/10000, loss: 0.0041822232306003573\n",
      "Episode Reward: 17.0\n",
      "Step 534 (4842950) @ Episode 6418/10000, loss: 0.0043568266555666925\n",
      "Episode Reward: 12.0\n",
      "Step 595 (4843545) @ Episode 6419/10000, loss: 0.0033901184797286987\n",
      "Episode Reward: 10.0\n",
      "Step 684 (4844229) @ Episode 6420/10000, loss: 0.0045662750490009785\n",
      "Episode Reward: 9.0\n",
      "Step 806 (4845035) @ Episode 6421/10000, loss: 0.0085564209148287777\n",
      "Episode Reward: 12.0\n",
      "Step 719 (4845754) @ Episode 6422/10000, loss: 0.0051517747342586527\n",
      "Episode Reward: 14.0\n",
      "Step 833 (4846587) @ Episode 6423/10000, loss: 0.0044566732831299305\n",
      "Episode Reward: 16.0\n",
      "Step 736 (4847323) @ Episode 6424/10000, loss: 0.0025448985397815704\n",
      "Episode Reward: 11.0\n",
      "Step 983 (4848306) @ Episode 6425/10000, loss: 0.0039194123819470406\n",
      "Episode Reward: 23.0\n",
      "Step 955 (4849261) @ Episode 6426/10000, loss: 0.0036996244452893734\n",
      "Episode Reward: 14.0\n",
      "Step 738 (4849999) @ Episode 6427/10000, loss: 0.0014688969822600484\n",
      " Copied model parameters to target network\n",
      "Step 894 (4850155) @ Episode 6427/10000, loss: 0.0047180475667119033\n",
      "Episode Reward: 16.0\n",
      "Step 710 (4850865) @ Episode 6428/10000, loss: 0.0058785644359886656\n",
      "Episode Reward: 15.0\n",
      "Step 564 (4851429) @ Episode 6429/10000, loss: 0.0047302078455686574\n",
      "Episode Reward: 8.0\n",
      "Step 707 (4852136) @ Episode 6430/10000, loss: 0.0056068357080221183\n",
      "Episode Reward: 12.0\n",
      "Step 1373 (4853509) @ Episode 6431/10000, loss: 0.0067676473408937456\n",
      "Episode Reward: 35.0\n",
      "Step 762 (4854271) @ Episode 6432/10000, loss: 0.0023759005125612025\n",
      "Episode Reward: 13.0\n",
      "Step 969 (4855240) @ Episode 6433/10000, loss: 0.0103510692715644847\n",
      "Episode Reward: 21.0\n",
      "Step 1297 (4856537) @ Episode 6434/10000, loss: 0.0197058990597724995\n",
      "Episode Reward: 22.0\n",
      "Step 471 (4857008) @ Episode 6435/10000, loss: 0.0075179263949394233\n",
      "Episode Reward: 7.0\n",
      "Step 714 (4857722) @ Episode 6436/10000, loss: 0.0069113383069634443\n",
      "Episode Reward: 11.0\n",
      "Step 880 (4858602) @ Episode 6437/10000, loss: 0.0052697518840432173\n",
      "Episode Reward: 19.0\n",
      "Step 1383 (4859985) @ Episode 6438/10000, loss: 0.0040741735137999063\n",
      "Episode Reward: 34.0\n",
      "Step 14 (4859999) @ Episode 6439/10000, loss: 0.0088149774819612595\n",
      " Copied model parameters to target network\n",
      "Step 671 (4860656) @ Episode 6439/10000, loss: 0.0114324958994984637\n",
      "Episode Reward: 10.0\n",
      "Step 751 (4861407) @ Episode 6440/10000, loss: 0.0047353040426969534\n",
      "Episode Reward: 11.0\n",
      "Step 1015 (4862422) @ Episode 6441/10000, loss: 0.0035810740664601326\n",
      "Episode Reward: 19.0\n",
      "Step 990 (4863412) @ Episode 6442/10000, loss: 0.0055185020901262764\n",
      "Episode Reward: 24.0\n",
      "Step 1140 (4864552) @ Episode 6443/10000, loss: 0.0019509587436914444\n",
      "Episode Reward: 25.0\n",
      "Step 1000 (4865552) @ Episode 6444/10000, loss: 0.005192209035158157\n",
      "Episode Reward: 19.0\n",
      "Step 686 (4866238) @ Episode 6445/10000, loss: 0.0035022534430027016\n",
      "Episode Reward: 11.0\n",
      "Step 628 (4866866) @ Episode 6446/10000, loss: 0.0054105222225189216\n",
      "Episode Reward: 10.0\n",
      "Step 949 (4867815) @ Episode 6447/10000, loss: 0.0151248052716255195\n",
      "Episode Reward: 16.0\n",
      "Step 585 (4868400) @ Episode 6448/10000, loss: 0.0050414605066180235\n",
      "Episode Reward: 8.0\n",
      "Step 995 (4869395) @ Episode 6449/10000, loss: 0.0050212340429425245\n",
      "Episode Reward: 17.0\n",
      "Step 561 (4869956) @ Episode 6450/10000, loss: 0.0073881316930055625\n",
      "Episode Reward: 6.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 05:06:36,059] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video006450.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 43 (4869999) @ Episode 6451/10000, loss: 0.0068185776472091675\n",
      " Copied model parameters to target network\n",
      "Step 1019 (4870975) @ Episode 6451/10000, loss: 0.0078439153730869383\n",
      "Episode Reward: 15.0\n",
      "Step 799 (4871774) @ Episode 6452/10000, loss: 0.0019894866272807123\n",
      "Episode Reward: 13.0\n",
      "Step 1032 (4872806) @ Episode 6453/10000, loss: 0.0062997862696647643\n",
      "Episode Reward: 22.0\n",
      "Step 846 (4873652) @ Episode 6454/10000, loss: 0.0059120338410139086\n",
      "Episode Reward: 15.0\n",
      "Step 903 (4874555) @ Episode 6455/10000, loss: 0.0102542396634817124\n",
      "Episode Reward: 18.0\n",
      "Step 1156 (4875711) @ Episode 6456/10000, loss: 0.0113740218803286556\n",
      "Episode Reward: 37.0\n",
      "Step 1373 (4877084) @ Episode 6457/10000, loss: 0.0047718901187181476\n",
      "Episode Reward: 27.0\n",
      "Step 1365 (4878449) @ Episode 6458/10000, loss: 0.0040550976991653446\n",
      "Episode Reward: 32.0\n",
      "Step 1013 (4879462) @ Episode 6459/10000, loss: 0.0097802830860018735\n",
      "Episode Reward: 21.0\n",
      "Step 537 (4879999) @ Episode 6460/10000, loss: 0.0044177654199302265\n",
      " Copied model parameters to target network\n",
      "Step 822 (4880284) @ Episode 6460/10000, loss: 0.0052398080006241852\n",
      "Episode Reward: 14.0\n",
      "Step 851 (4881135) @ Episode 6461/10000, loss: 0.0032932502217590815\n",
      "Episode Reward: 13.0\n",
      "Step 841 (4881976) @ Episode 6462/10000, loss: 0.0021475865505635746\n",
      "Episode Reward: 16.0\n",
      "Step 922 (4882898) @ Episode 6463/10000, loss: 0.0408258885145187425\n",
      "Episode Reward: 16.0\n",
      "Step 835 (4883733) @ Episode 6464/10000, loss: 0.0069804368540644655\n",
      "Episode Reward: 11.0\n",
      "Step 960 (4884693) @ Episode 6465/10000, loss: 0.0063493107445538045\n",
      "Episode Reward: 19.0\n",
      "Step 1452 (4886145) @ Episode 6466/10000, loss: 0.0049439622089266785\n",
      "Episode Reward: 39.0\n",
      "Step 732 (4886877) @ Episode 6467/10000, loss: 0.0033553922548890114\n",
      "Episode Reward: 14.0\n",
      "Step 1030 (4887907) @ Episode 6468/10000, loss: 0.0024118665605783463\n",
      "Episode Reward: 22.0\n",
      "Step 1174 (4889081) @ Episode 6469/10000, loss: 0.0025182545650750446\n",
      "Episode Reward: 21.0\n",
      "Step 918 (4889999) @ Episode 6470/10000, loss: 0.0048520835116505623\n",
      " Copied model parameters to target network\n",
      "Step 1125 (4890206) @ Episode 6470/10000, loss: 0.0020902506075799465\n",
      "Episode Reward: 21.0\n",
      "Step 1201 (4891407) @ Episode 6471/10000, loss: 0.0019641849212348464\n",
      "Episode Reward: 21.0\n",
      "Step 721 (4892128) @ Episode 6472/10000, loss: 0.0022077760659158236\n",
      "Episode Reward: 11.0\n",
      "Step 1013 (4893141) @ Episode 6473/10000, loss: 0.0044352654367685325\n",
      "Episode Reward: 16.0\n",
      "Step 620 (4893761) @ Episode 6474/10000, loss: 0.0135712698101997383\n",
      "Episode Reward: 16.0\n",
      "Step 912 (4894673) @ Episode 6475/10000, loss: 0.0036192075349390507\n",
      "Episode Reward: 16.0\n",
      "Step 980 (4895653) @ Episode 6476/10000, loss: 0.0112243602052330976\n",
      "Episode Reward: 14.0\n",
      "Step 934 (4896587) @ Episode 6477/10000, loss: 0.0055242711678147326\n",
      "Episode Reward: 16.0\n",
      "Step 1210 (4897797) @ Episode 6478/10000, loss: 0.0046728057786822323\n",
      "Episode Reward: 22.0\n",
      "Step 629 (4898426) @ Episode 6479/10000, loss: 0.0024630357511341576\n",
      "Episode Reward: 14.0\n",
      "Step 1135 (4899561) @ Episode 6480/10000, loss: 0.0076754288747906685\n",
      "Episode Reward: 23.0\n",
      "Step 438 (4899999) @ Episode 6481/10000, loss: 0.0014326395466923714\n",
      " Copied model parameters to target network\n",
      "Step 1034 (4900595) @ Episode 6481/10000, loss: 0.0052888342179358006\n",
      "Episode Reward: 17.0\n",
      "Step 1035 (4901630) @ Episode 6482/10000, loss: 0.0034551327116787434\n",
      "Episode Reward: 22.0\n",
      "Step 824 (4902454) @ Episode 6483/10000, loss: 0.0020417934283614163\n",
      "Episode Reward: 14.0\n",
      "Step 991 (4903445) @ Episode 6484/10000, loss: 0.0064173876307904723\n",
      "Episode Reward: 16.0\n",
      "Step 788 (4904233) @ Episode 6485/10000, loss: 0.0038395663723349573\n",
      "Episode Reward: 12.0\n",
      "Step 1104 (4905337) @ Episode 6486/10000, loss: 0.0046751126646995544\n",
      "Episode Reward: 18.0\n",
      "Step 768 (4906105) @ Episode 6487/10000, loss: 0.0024261046200990677\n",
      "Episode Reward: 14.0\n",
      "Step 857 (4906962) @ Episode 6488/10000, loss: 0.0046308012679219257\n",
      "Episode Reward: 15.0\n",
      "Step 543 (4907505) @ Episode 6489/10000, loss: 0.0035827718675136566\n",
      "Episode Reward: 10.0\n",
      "Step 618 (4908123) @ Episode 6490/10000, loss: 0.0100039988756179814\n",
      "Episode Reward: 20.0\n",
      "Step 1292 (4909415) @ Episode 6491/10000, loss: 0.0065709250047802925\n",
      "Episode Reward: 25.0\n",
      "Step 584 (4909999) @ Episode 6492/10000, loss: 0.0058291684836149227\n",
      " Copied model parameters to target network\n",
      "Step 878 (4910293) @ Episode 6492/10000, loss: 0.0032321214675903325\n",
      "Episode Reward: 18.0\n",
      "Step 762 (4911055) @ Episode 6493/10000, loss: 0.0025190305896103387\n",
      "Episode Reward: 12.0\n",
      "Step 566 (4911621) @ Episode 6494/10000, loss: 0.0018453694647178054\n",
      "Episode Reward: 7.0\n",
      "Step 836 (4912457) @ Episode 6495/10000, loss: 0.0097371563315391545\n",
      "Episode Reward: 16.0\n",
      "Step 1159 (4913616) @ Episode 6496/10000, loss: 0.0032142868731170893\n",
      "Episode Reward: 39.0\n",
      "Step 701 (4914317) @ Episode 6497/10000, loss: 0.0026195165701210515\n",
      "Episode Reward: 7.0\n",
      "Step 828 (4915145) @ Episode 6498/10000, loss: 0.0010905188973993063\n",
      "Episode Reward: 14.0\n",
      "Step 1210 (4916355) @ Episode 6499/10000, loss: 0.0032678712159395222\n",
      "Episode Reward: 25.0\n",
      "Step 634 (4916989) @ Episode 6500/10000, loss: 0.0036735869944095615\n",
      "Episode Reward: 8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 05:13:47,258] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video006500.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 846 (4917835) @ Episode 6501/10000, loss: 0.0051556257531046874\n",
      "Episode Reward: 14.0\n",
      "Step 1047 (4918882) @ Episode 6502/10000, loss: 0.0046037836000323296\n",
      "Episode Reward: 30.0\n",
      "Step 860 (4919742) @ Episode 6503/10000, loss: 0.0062346332706511024\n",
      "Episode Reward: 19.0\n",
      "Step 257 (4919999) @ Episode 6504/10000, loss: 0.0037398035638034344\n",
      " Copied model parameters to target network\n",
      "Step 930 (4920672) @ Episode 6504/10000, loss: 0.0040428307838737965\n",
      "Episode Reward: 18.0\n",
      "Step 555 (4921227) @ Episode 6505/10000, loss: 0.0050399773754179483\n",
      "Episode Reward: 10.0\n",
      "Step 671 (4921898) @ Episode 6506/10000, loss: 0.0027191764675080776\n",
      "Episode Reward: 11.0\n",
      "Step 826 (4922724) @ Episode 6507/10000, loss: 0.0012729689478874207\n",
      "Episode Reward: 14.0\n",
      "Step 689 (4923413) @ Episode 6508/10000, loss: 0.0059607606381177917\n",
      "Episode Reward: 14.0\n",
      "Step 776 (4924189) @ Episode 6509/10000, loss: 0.0538878813385963444\n",
      "Episode Reward: 16.0\n",
      "Step 634 (4924823) @ Episode 6510/10000, loss: 0.0124981235712766656\n",
      "Episode Reward: 10.0\n",
      "Step 1040 (4925863) @ Episode 6511/10000, loss: 0.0062124240212142475\n",
      "Episode Reward: 21.0\n",
      "Step 1163 (4927026) @ Episode 6512/10000, loss: 0.0017539410619065166\n",
      "Episode Reward: 26.0\n",
      "Step 886 (4927912) @ Episode 6513/10000, loss: 0.0052627641707658772\n",
      "Episode Reward: 14.0\n",
      "Step 737 (4928649) @ Episode 6514/10000, loss: 0.0066937883384525785\n",
      "Episode Reward: 14.0\n",
      "Step 1350 (4929999) @ Episode 6515/10000, loss: 0.0076300371438264855\n",
      " Copied model parameters to target network\n",
      "Step 1382 (4930031) @ Episode 6515/10000, loss: 0.0087598860263824467\n",
      "Episode Reward: 43.0\n",
      "Step 682 (4930713) @ Episode 6516/10000, loss: 0.0043709930032491683\n",
      "Episode Reward: 10.0\n",
      "Step 866 (4931579) @ Episode 6517/10000, loss: 0.0113905705511569982\n",
      "Episode Reward: 18.0\n",
      "Step 848 (4932427) @ Episode 6518/10000, loss: 0.0051499628461897373\n",
      "Episode Reward: 13.0\n",
      "Step 936 (4933363) @ Episode 6519/10000, loss: 0.0038257716223597527\n",
      "Episode Reward: 20.0\n",
      "Step 1461 (4934824) @ Episode 6520/10000, loss: 0.0034611723385751247\n",
      "Episode Reward: 31.0\n",
      "Step 868 (4935692) @ Episode 6521/10000, loss: 0.0037547959946095943\n",
      "Episode Reward: 15.0\n",
      "Step 727 (4936419) @ Episode 6522/10000, loss: 0.0028428782243281603\n",
      "Episode Reward: 16.0\n",
      "Step 712 (4937131) @ Episode 6523/10000, loss: 0.0039477143436670395\n",
      "Episode Reward: 13.0\n",
      "Step 1067 (4938198) @ Episode 6524/10000, loss: 0.0138491131365299226\n",
      "Episode Reward: 23.0\n",
      "Step 1143 (4939341) @ Episode 6525/10000, loss: 0.0040028765797615053\n",
      "Episode Reward: 32.0\n",
      "Step 658 (4939999) @ Episode 6526/10000, loss: 0.0059643182903528215\n",
      " Copied model parameters to target network\n",
      "Step 1287 (4940628) @ Episode 6526/10000, loss: 0.0029887296259403234\n",
      "Episode Reward: 21.0\n",
      "Step 1183 (4941811) @ Episode 6527/10000, loss: 0.0036188948433846235\n",
      "Episode Reward: 27.0\n",
      "Step 889 (4942700) @ Episode 6528/10000, loss: 0.0057020196691155436\n",
      "Episode Reward: 22.0\n",
      "Step 905 (4943605) @ Episode 6529/10000, loss: 0.0049125049263238919\n",
      "Episode Reward: 14.0\n",
      "Step 538 (4944143) @ Episode 6530/10000, loss: 0.0036594038829207427\n",
      "Episode Reward: 8.0\n",
      "Step 1033 (4945176) @ Episode 6531/10000, loss: 0.0070745786651968962\n",
      "Episode Reward: 18.0\n",
      "Step 900 (4946076) @ Episode 6532/10000, loss: 0.0033416431397199634\n",
      "Episode Reward: 16.0\n",
      "Step 423 (4946499) @ Episode 6533/10000, loss: 0.0044973110780119985\n",
      "Episode Reward: 6.0\n",
      "Step 816 (4947315) @ Episode 6534/10000, loss: 0.0055448501370847225\n",
      "Episode Reward: 13.0\n",
      "Step 1071 (4948386) @ Episode 6535/10000, loss: 0.0058424915187060834\n",
      "Episode Reward: 25.0\n",
      "Step 976 (4949362) @ Episode 6536/10000, loss: 0.0038670285139232874\n",
      "Episode Reward: 26.0\n",
      "Step 637 (4949999) @ Episode 6537/10000, loss: 0.0034833103418350225\n",
      " Copied model parameters to target network\n",
      "Step 821 (4950183) @ Episode 6537/10000, loss: 0.0068055232986807826\n",
      "Episode Reward: 17.0\n",
      "Step 979 (4951162) @ Episode 6538/10000, loss: 0.0024369410239160065\n",
      "Episode Reward: 33.0\n",
      "Step 1355 (4952517) @ Episode 6539/10000, loss: 0.0044352728873491294\n",
      "Episode Reward: 35.0\n",
      "Step 1210 (4953727) @ Episode 6540/10000, loss: 0.0061821546405553824\n",
      "Episode Reward: 25.0\n",
      "Step 1148 (4954875) @ Episode 6541/10000, loss: 0.0962340235710144385\n",
      "Episode Reward: 26.0\n",
      "Step 982 (4955857) @ Episode 6542/10000, loss: 0.0073964474722743034\n",
      "Episode Reward: 19.0\n",
      "Step 772 (4956629) @ Episode 6543/10000, loss: 0.0034439098089933395\n",
      "Episode Reward: 17.0\n",
      "Step 944 (4957573) @ Episode 6544/10000, loss: 0.0041866144165396696\n",
      "Episode Reward: 16.0\n",
      "Step 867 (4958440) @ Episode 6545/10000, loss: 0.0079987281933426865\n",
      "Episode Reward: 27.0\n",
      "Step 670 (4959110) @ Episode 6546/10000, loss: 0.0057973102666437634\n",
      "Episode Reward: 10.0\n",
      "Step 574 (4959684) @ Episode 6547/10000, loss: 0.0096701746806502348\n",
      "Episode Reward: 9.0\n",
      "Step 315 (4959999) @ Episode 6548/10000, loss: 0.0060974452644586565\n",
      " Copied model parameters to target network\n",
      "Step 1306 (4960990) @ Episode 6548/10000, loss: 0.0091501716524362567\n",
      "Episode Reward: 26.0\n",
      "Step 978 (4961968) @ Episode 6549/10000, loss: 0.0122284879907965666\n",
      "Episode Reward: 17.0\n",
      "Step 785 (4962753) @ Episode 6550/10000, loss: 0.0093632359057664876\n",
      "Episode Reward: 14.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 05:20:53,493] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video006550.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 704 (4963457) @ Episode 6551/10000, loss: 0.0025346660986542787\n",
      "Episode Reward: 9.0\n",
      "Step 791 (4964248) @ Episode 6552/10000, loss: 0.0044804154895246034\n",
      "Episode Reward: 17.0\n",
      "Step 1163 (4965411) @ Episode 6553/10000, loss: 0.0074043897911906245\n",
      "Episode Reward: 31.0\n",
      "Step 843 (4966254) @ Episode 6554/10000, loss: 0.0030854349024593834\n",
      "Episode Reward: 13.0\n",
      "Step 992 (4967246) @ Episode 6555/10000, loss: 0.0077103972434997564\n",
      "Episode Reward: 25.0\n",
      "Step 982 (4968228) @ Episode 6556/10000, loss: 0.0289040282368659975\n",
      "Episode Reward: 24.0\n",
      "Step 670 (4968898) @ Episode 6557/10000, loss: 0.0034120318014174775\n",
      "Episode Reward: 10.0\n",
      "Step 896 (4969794) @ Episode 6558/10000, loss: 0.0082492269575595865\n",
      "Episode Reward: 14.0\n",
      "Step 205 (4969999) @ Episode 6559/10000, loss: 0.0029199745040386915\n",
      " Copied model parameters to target network\n",
      "Step 952 (4970746) @ Episode 6559/10000, loss: 0.0040784021839499472\n",
      "Episode Reward: 16.0\n",
      "Step 795 (4971541) @ Episode 6560/10000, loss: 0.0037511312402784824\n",
      "Episode Reward: 15.0\n",
      "Step 1056 (4972597) @ Episode 6561/10000, loss: 0.0043668895959854135\n",
      "Episode Reward: 19.0\n",
      "Step 662 (4973259) @ Episode 6562/10000, loss: 0.0035134800709784036\n",
      "Episode Reward: 9.0\n",
      "Step 1202 (4974461) @ Episode 6563/10000, loss: 0.0042429766617715367\n",
      "Episode Reward: 26.0\n",
      "Step 858 (4975319) @ Episode 6564/10000, loss: 0.0019893608987331395\n",
      "Episode Reward: 13.0\n",
      "Step 1401 (4976720) @ Episode 6565/10000, loss: 0.0411858446896076266\n",
      "Episode Reward: 32.0\n",
      "Step 980 (4977700) @ Episode 6566/10000, loss: 0.0038836295716464525\n",
      "Episode Reward: 20.0\n",
      "Step 617 (4978317) @ Episode 6567/10000, loss: 0.0089497063308954245\n",
      "Episode Reward: 11.0\n",
      "Step 1046 (4979363) @ Episode 6568/10000, loss: 0.0022778813727200034\n",
      "Episode Reward: 23.0\n",
      "Step 636 (4979999) @ Episode 6569/10000, loss: 0.0047980630770325665\n",
      " Copied model parameters to target network\n",
      "Step 817 (4980180) @ Episode 6569/10000, loss: 0.0093826400116086747\n",
      "Episode Reward: 14.0\n",
      "Step 1284 (4981464) @ Episode 6570/10000, loss: 0.0041331951506435874\n",
      "Episode Reward: 30.0\n",
      "Step 700 (4982164) @ Episode 6571/10000, loss: 0.0029588155448436737\n",
      "Episode Reward: 14.0\n",
      "Step 692 (4982856) @ Episode 6572/10000, loss: 0.0035329409874975687\n",
      "Episode Reward: 11.0\n",
      "Step 730 (4983586) @ Episode 6573/10000, loss: 0.0041623264551162725\n",
      "Episode Reward: 16.0\n",
      "Step 850 (4984436) @ Episode 6574/10000, loss: 0.0030737482011318207\n",
      "Episode Reward: 18.0\n",
      "Step 1263 (4985699) @ Episode 6575/10000, loss: 0.0095801744610071185\n",
      "Episode Reward: 40.0\n",
      "Step 1099 (4986798) @ Episode 6576/10000, loss: 0.0060088792815804483\n",
      "Episode Reward: 19.0\n",
      "Step 788 (4987586) @ Episode 6577/10000, loss: 0.0029281908646225935\n",
      "Episode Reward: 14.0\n",
      "Step 725 (4988311) @ Episode 6578/10000, loss: 0.0113351661711931236\n",
      "Episode Reward: 11.0\n",
      "Step 924 (4989235) @ Episode 6579/10000, loss: 0.0043141646310687065\n",
      "Episode Reward: 21.0\n",
      "Step 452 (4989687) @ Episode 6580/10000, loss: 0.0178922116756439213\n",
      "Episode Reward: 6.0\n",
      "Step 312 (4989999) @ Episode 6581/10000, loss: 0.0060238675214350224\n",
      " Copied model parameters to target network\n",
      "Step 906 (4990593) @ Episode 6581/10000, loss: 0.0057238442823290825\n",
      "Episode Reward: 14.0\n",
      "Step 1402 (4991995) @ Episode 6582/10000, loss: 0.0042329179123044014\n",
      "Episode Reward: 32.0\n",
      "Step 836 (4992831) @ Episode 6583/10000, loss: 0.0026010994333773856\n",
      "Episode Reward: 15.0\n",
      "Step 989 (4993820) @ Episode 6584/10000, loss: 0.0025700186379253864\n",
      "Episode Reward: 18.0\n",
      "Step 928 (4994748) @ Episode 6585/10000, loss: 0.0026347071398049593\n",
      "Episode Reward: 16.0\n",
      "Step 1245 (4995993) @ Episode 6586/10000, loss: 0.0034909956157207494\n",
      "Episode Reward: 23.0\n",
      "Step 1054 (4997047) @ Episode 6587/10000, loss: 0.0038276070263236765\n",
      "Episode Reward: 20.0\n",
      "Step 1324 (4998371) @ Episode 6588/10000, loss: 0.0038865737151354556\n",
      "Episode Reward: 32.0\n",
      "Step 728 (4999099) @ Episode 6589/10000, loss: 0.0064898631535470496\n",
      "Episode Reward: 11.0\n",
      "Step 879 (4999978) @ Episode 6590/10000, loss: 0.0039390069432556635\n",
      "Episode Reward: 15.0\n",
      "Step 21 (4999999) @ Episode 6591/10000, loss: 0.0025580180808901787\n",
      " Copied model parameters to target network\n",
      "Step 1120 (5001098) @ Episode 6591/10000, loss: 0.0018003316363319755\n",
      "Episode Reward: 19.0\n",
      "Step 916 (5002014) @ Episode 6592/10000, loss: 0.0056740711443126215\n",
      "Episode Reward: 13.0\n",
      "Step 942 (5002956) @ Episode 6593/10000, loss: 0.0048829088918864738\n",
      "Episode Reward: 16.0\n",
      "Step 602 (5003558) @ Episode 6594/10000, loss: 0.0019997491035610437\n",
      "Episode Reward: 9.0\n",
      "Step 734 (5004292) @ Episode 6595/10000, loss: 0.0055744433775544176\n",
      "Episode Reward: 12.0\n",
      "Step 916 (5005208) @ Episode 6596/10000, loss: 0.0045430958271026615\n",
      "Episode Reward: 14.0\n",
      "Step 809 (5006017) @ Episode 6597/10000, loss: 0.0126612856984138496\n",
      "Episode Reward: 16.0\n",
      "Step 872 (5006889) @ Episode 6598/10000, loss: 0.0024279553908854723\n",
      "Episode Reward: 16.0\n",
      "Step 690 (5007579) @ Episode 6599/10000, loss: 0.0133603028953075416\n",
      "Episode Reward: 12.0\n",
      "Step 979 (5008558) @ Episode 6600/10000, loss: 0.0023647225461900234\n",
      "Episode Reward: 19.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 05:27:54,513] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video006600.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 774 (5009332) @ Episode 6601/10000, loss: 0.0042763380333781244\n",
      "Episode Reward: 12.0\n",
      "Step 667 (5009999) @ Episode 6602/10000, loss: 0.0066118640825152453\n",
      " Copied model parameters to target network\n",
      "Step 697 (5010029) @ Episode 6602/10000, loss: 0.0046388097107410438\n",
      "Episode Reward: 14.0\n",
      "Step 1357 (5011386) @ Episode 6603/10000, loss: 0.0050793243572115996\n",
      "Episode Reward: 27.0\n",
      "Step 734 (5012120) @ Episode 6604/10000, loss: 0.0045321956276893626\n",
      "Episode Reward: 11.0\n",
      "Step 688 (5012808) @ Episode 6605/10000, loss: 0.0049323523417115217\n",
      "Episode Reward: 12.0\n",
      "Step 733 (5013541) @ Episode 6606/10000, loss: 0.0050476230680942535\n",
      "Episode Reward: 12.0\n",
      "Step 772 (5014313) @ Episode 6607/10000, loss: 0.0158958565443754213\n",
      "Episode Reward: 14.0\n",
      "Step 827 (5015140) @ Episode 6608/10000, loss: 0.0040190150029957294\n",
      "Episode Reward: 17.0\n",
      "Step 904 (5016044) @ Episode 6609/10000, loss: 0.0039346190169453623\n",
      "Episode Reward: 20.0\n",
      "Step 1265 (5017309) @ Episode 6610/10000, loss: 0.0070399316027760513\n",
      "Episode Reward: 24.0\n",
      "Step 859 (5018168) @ Episode 6611/10000, loss: 0.0148589359596371654\n",
      "Episode Reward: 20.0\n",
      "Step 697 (5018865) @ Episode 6612/10000, loss: 0.0093982461839914323\n",
      "Episode Reward: 9.0\n",
      "Step 658 (5019523) @ Episode 6613/10000, loss: 0.0020714069250971086\n",
      "Episode Reward: 11.0\n",
      "Step 474 (5019997) @ Episode 6614/10000, loss: 0.0069464859552681455\n",
      "Episode Reward: 6.0\n",
      "Step 2 (5019999) @ Episode 6615/10000, loss: 0.0036413301713764668\n",
      " Copied model parameters to target network\n",
      "Step 954 (5020951) @ Episode 6615/10000, loss: 0.0038316729478538036\n",
      "Episode Reward: 17.0\n",
      "Step 717 (5021668) @ Episode 6616/10000, loss: 0.0064345523715019235\n",
      "Episode Reward: 16.0\n",
      "Step 1391 (5023059) @ Episode 6617/10000, loss: 0.0027162795886397362\n",
      "Episode Reward: 35.0\n",
      "Step 772 (5023831) @ Episode 6618/10000, loss: 0.0060613164678215986\n",
      "Episode Reward: 12.0\n",
      "Step 1019 (5024850) @ Episode 6619/10000, loss: 0.0051841232925653462\n",
      "Episode Reward: 21.0\n",
      "Step 900 (5025750) @ Episode 6620/10000, loss: 0.0059990510344505313\n",
      "Episode Reward: 18.0\n",
      "Step 583 (5026333) @ Episode 6621/10000, loss: 0.0026704440824687487\n",
      "Episode Reward: 9.0\n",
      "Step 926 (5027259) @ Episode 6622/10000, loss: 0.0059325103648006925\n",
      "Episode Reward: 17.0\n",
      "Step 856 (5028115) @ Episode 6623/10000, loss: 0.0075352434068918234\n",
      "Episode Reward: 13.0\n",
      "Step 1091 (5029206) @ Episode 6624/10000, loss: 0.0052193533629179397\n",
      "Episode Reward: 29.0\n",
      "Step 762 (5029968) @ Episode 6625/10000, loss: 0.0033489416819065814\n",
      "Episode Reward: 18.0\n",
      "Step 31 (5029999) @ Episode 6626/10000, loss: 0.0029363359790295362\n",
      " Copied model parameters to target network\n",
      "Step 1084 (5031052) @ Episode 6626/10000, loss: 0.0094987126067280778\n",
      "Episode Reward: 21.0\n",
      "Step 761 (5031813) @ Episode 6627/10000, loss: 0.0033844532445073128\n",
      "Episode Reward: 13.0\n",
      "Step 1053 (5032866) @ Episode 6628/10000, loss: 0.0064089824445545677\n",
      "Episode Reward: 22.0\n",
      "Step 698 (5033564) @ Episode 6629/10000, loss: 0.0060423156246542934\n",
      "Episode Reward: 13.0\n",
      "Step 891 (5034455) @ Episode 6630/10000, loss: 0.0031957668252289295\n",
      "Episode Reward: 16.0\n",
      "Step 967 (5035422) @ Episode 6631/10000, loss: 0.0050307987257838257\n",
      "Episode Reward: 22.0\n",
      "Step 906 (5036328) @ Episode 6632/10000, loss: 0.0373891964554786755\n",
      "Episode Reward: 17.0\n",
      "Step 418 (5036746) @ Episode 6633/10000, loss: 0.0081193186342716227\n",
      "Episode Reward: 6.0\n",
      "Step 1089 (5037835) @ Episode 6634/10000, loss: 0.0042902966961264619\n",
      "Episode Reward: 19.0\n",
      "Step 769 (5038604) @ Episode 6635/10000, loss: 0.0047260401770472538\n",
      "Episode Reward: 11.0\n",
      "Step 858 (5039462) @ Episode 6636/10000, loss: 0.0022139812353998423\n",
      "Episode Reward: 14.0\n",
      "Step 537 (5039999) @ Episode 6637/10000, loss: 0.0119470143690705386\n",
      " Copied model parameters to target network\n",
      "Step 844 (5040306) @ Episode 6637/10000, loss: 0.0071019181050360225\n",
      "Episode Reward: 9.0\n",
      "Step 871 (5041177) @ Episode 6638/10000, loss: 0.0052535897120833475\n",
      "Episode Reward: 18.0\n",
      "Step 662 (5041839) @ Episode 6639/10000, loss: 0.0053042815998196632\n",
      "Episode Reward: 10.0\n",
      "Step 1087 (5042926) @ Episode 6640/10000, loss: 0.0048408200964331634\n",
      "Episode Reward: 19.0\n",
      "Step 782 (5043708) @ Episode 6641/10000, loss: 0.0054391231387853627\n",
      "Episode Reward: 10.0\n",
      "Step 982 (5044690) @ Episode 6642/10000, loss: 0.0069372528232634073\n",
      "Episode Reward: 26.0\n",
      "Step 881 (5045571) @ Episode 6643/10000, loss: 0.0021956085693091154\n",
      "Episode Reward: 18.0\n",
      "Step 1401 (5046972) @ Episode 6644/10000, loss: 0.0031869551166892057\n",
      "Episode Reward: 35.0\n",
      "Step 1435 (5048407) @ Episode 6645/10000, loss: 0.0023651923984289173\n",
      "Episode Reward: 33.0\n",
      "Step 687 (5049094) @ Episode 6646/10000, loss: 0.0043975026346743116\n",
      "Episode Reward: 13.0\n",
      "Step 905 (5049999) @ Episode 6647/10000, loss: 0.0033302784431725748\n",
      " Copied model parameters to target network\n",
      "Step 1578 (5050672) @ Episode 6647/10000, loss: 0.0057186852209272247\n",
      "Episode Reward: 44.0\n",
      "Step 640 (5051312) @ Episode 6648/10000, loss: 0.0072081275284290316\n",
      "Episode Reward: 11.0\n",
      "Step 1231 (5052543) @ Episode 6649/10000, loss: 0.0035909756552428007\n",
      "Episode Reward: 34.0\n",
      "Step 644 (5053187) @ Episode 6650/10000, loss: 0.0059120757505297665\n",
      "Episode Reward: 11.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 05:34:48,835] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video006650.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 459 (5053646) @ Episode 6651/10000, loss: 0.0026075358036905527\n",
      "Episode Reward: 6.0\n",
      "Step 813 (5054459) @ Episode 6652/10000, loss: 0.0038557639345526695\n",
      "Episode Reward: 17.0\n",
      "Step 638 (5055097) @ Episode 6653/10000, loss: 0.0073566418141126634\n",
      "Episode Reward: 11.0\n",
      "Step 670 (5055767) @ Episode 6654/10000, loss: 0.0050345081835985186\n",
      "Episode Reward: 12.0\n",
      "Step 755 (5056522) @ Episode 6655/10000, loss: 0.0372287519276142114\n",
      "Episode Reward: 11.0\n",
      "Step 962 (5057484) @ Episode 6656/10000, loss: 0.0057064993306994444\n",
      "Episode Reward: 18.0\n",
      "Step 1207 (5058691) @ Episode 6657/10000, loss: 0.0041238274425268173\n",
      "Episode Reward: 23.0\n",
      "Step 855 (5059546) @ Episode 6658/10000, loss: 0.0103635331615805633\n",
      "Episode Reward: 12.0\n",
      "Step 453 (5059999) @ Episode 6659/10000, loss: 0.0040712417103350167\n",
      " Copied model parameters to target network\n",
      "Step 947 (5060493) @ Episode 6659/10000, loss: 0.0054202117025852246\n",
      "Episode Reward: 15.0\n",
      "Step 946 (5061439) @ Episode 6660/10000, loss: 0.0034436429850757124\n",
      "Episode Reward: 15.0\n",
      "Step 987 (5062426) @ Episode 6661/10000, loss: 0.0056275585666298872\n",
      "Episode Reward: 25.0\n",
      "Step 715 (5063141) @ Episode 6662/10000, loss: 0.0029411101713776595\n",
      "Episode Reward: 12.0\n",
      "Step 742 (5063883) @ Episode 6663/10000, loss: 0.0059436499141156678\n",
      "Episode Reward: 23.0\n",
      "Step 893 (5064776) @ Episode 6664/10000, loss: 0.0049382899887859827\n",
      "Episode Reward: 16.0\n",
      "Step 957 (5065733) @ Episode 6665/10000, loss: 0.0054226224310696125\n",
      "Episode Reward: 18.0\n",
      "Step 498 (5066231) @ Episode 6666/10000, loss: 0.0069825528189539913\n",
      "Episode Reward: 11.0\n",
      "Step 823 (5067054) @ Episode 6667/10000, loss: 0.0149008547887206086\n",
      "Episode Reward: 20.0\n",
      "Step 357 (5067411) @ Episode 6668/10000, loss: 0.0112586412578821185\n",
      "Episode Reward: 4.0\n",
      "Step 1026 (5068437) @ Episode 6669/10000, loss: 0.0028410302475094795\n",
      "Episode Reward: 21.0\n",
      "Step 522 (5068959) @ Episode 6670/10000, loss: 0.0118359103798866273\n",
      "Episode Reward: 7.0\n",
      "Step 1040 (5069999) @ Episode 6671/10000, loss: 0.0085441553965210913\n",
      " Copied model parameters to target network\n",
      "Step 1402 (5070361) @ Episode 6671/10000, loss: 0.0016395226120948792\n",
      "Episode Reward: 31.0\n",
      "Step 1078 (5071439) @ Episode 6672/10000, loss: 0.0048695066943764695\n",
      "Episode Reward: 30.0\n",
      "Step 845 (5072284) @ Episode 6673/10000, loss: 0.0069969897158443932\n",
      "Episode Reward: 12.0\n",
      "Step 607 (5072891) @ Episode 6674/10000, loss: 0.0064626145176589495\n",
      "Episode Reward: 9.0\n",
      "Step 942 (5073833) @ Episode 6675/10000, loss: 0.0031694550998508938\n",
      "Episode Reward: 19.0\n",
      "Step 1247 (5075080) @ Episode 6676/10000, loss: 0.0039226152002811434\n",
      "Episode Reward: 24.0\n",
      "Step 895 (5075975) @ Episode 6677/10000, loss: 0.0080152843147516256\n",
      "Episode Reward: 17.0\n",
      "Step 1060 (5077035) @ Episode 6678/10000, loss: 0.0075415852479636679\n",
      "Episode Reward: 20.0\n",
      "Step 1295 (5078330) @ Episode 6679/10000, loss: 0.0026368841063231235\n",
      "Episode Reward: 24.0\n",
      "Step 637 (5078967) @ Episode 6680/10000, loss: 0.0047864140942692765\n",
      "Episode Reward: 11.0\n",
      "Step 1032 (5079999) @ Episode 6681/10000, loss: 0.0032894003670662645\n",
      " Copied model parameters to target network\n",
      "Step 1085 (5080052) @ Episode 6681/10000, loss: 0.0057798018679022796\n",
      "Episode Reward: 18.0\n",
      "Step 798 (5080850) @ Episode 6682/10000, loss: 0.0428284853696823164\n",
      "Episode Reward: 14.0\n",
      "Step 734 (5081584) @ Episode 6683/10000, loss: 0.0051950239576399338\n",
      "Episode Reward: 16.0\n",
      "Step 621 (5082205) @ Episode 6684/10000, loss: 0.0050833839923143396\n",
      "Episode Reward: 10.0\n",
      "Step 1164 (5083369) @ Episode 6685/10000, loss: 0.0045699076727032663\n",
      "Episode Reward: 26.0\n",
      "Step 1277 (5084646) @ Episode 6686/10000, loss: 0.0065413657575845723\n",
      "Episode Reward: 25.0\n",
      "Step 881 (5085527) @ Episode 6687/10000, loss: 0.0034951607231050736\n",
      "Episode Reward: 14.0\n",
      "Step 1473 (5087000) @ Episode 6688/10000, loss: 0.0038372860290110117\n",
      "Episode Reward: 30.0\n",
      "Step 901 (5087901) @ Episode 6689/10000, loss: 0.0018702771048992872\n",
      "Episode Reward: 19.0\n",
      "Step 840 (5088741) @ Episode 6690/10000, loss: 0.0038146805018186576\n",
      "Episode Reward: 14.0\n",
      "Step 1038 (5089779) @ Episode 6691/10000, loss: 0.0066694156266748905\n",
      "Episode Reward: 21.0\n",
      "Step 220 (5089999) @ Episode 6692/10000, loss: 0.0027982748579233885\n",
      " Copied model parameters to target network\n",
      "Step 796 (5090575) @ Episode 6692/10000, loss: 0.0018890737555921078\n",
      "Episode Reward: 10.0\n",
      "Step 1240 (5091815) @ Episode 6693/10000, loss: 0.0022402668837457895\n",
      "Episode Reward: 28.0\n",
      "Step 879 (5092694) @ Episode 6694/10000, loss: 0.0038049262948334217\n",
      "Episode Reward: 13.0\n",
      "Step 1419 (5094113) @ Episode 6695/10000, loss: 0.0042802989482879646\n",
      "Episode Reward: 34.0\n",
      "Step 1095 (5095208) @ Episode 6696/10000, loss: 0.0211919602006673875\n",
      "Episode Reward: 21.0\n",
      "Step 768 (5095976) @ Episode 6697/10000, loss: 0.0035207411274313927\n",
      "Episode Reward: 13.0\n",
      "Step 770 (5096746) @ Episode 6698/10000, loss: 0.0032134805805981166\n",
      "Episode Reward: 13.0\n",
      "Step 1040 (5097786) @ Episode 6699/10000, loss: 0.0096842451021075257\n",
      "Episode Reward: 25.0\n",
      "Step 974 (5098760) @ Episode 6700/10000, loss: 0.0032231626100838184\n",
      "Episode Reward: 19.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 05:41:53,972] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video006700.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 886 (5099646) @ Episode 6701/10000, loss: 0.0057514491491019737\n",
      "Episode Reward: 20.0\n",
      "Step 353 (5099999) @ Episode 6702/10000, loss: 0.0026257815770804887\n",
      " Copied model parameters to target network\n",
      "Step 612 (5100258) @ Episode 6702/10000, loss: 0.0015516572166234255\n",
      "Episode Reward: 10.0\n",
      "Step 1045 (5101303) @ Episode 6703/10000, loss: 0.0253635756671428685\n",
      "Episode Reward: 22.0\n",
      "Step 764 (5102067) @ Episode 6704/10000, loss: 0.0088949399068951615\n",
      "Episode Reward: 15.0\n",
      "Step 500 (5102567) @ Episode 6705/10000, loss: 0.0053277476690709595\n",
      "Episode Reward: 6.0\n",
      "Step 803 (5103370) @ Episode 6706/10000, loss: 0.0030696182511746883\n",
      "Episode Reward: 12.0\n",
      "Step 786 (5104156) @ Episode 6707/10000, loss: 0.0079931560903787614\n",
      "Episode Reward: 12.0\n",
      "Step 993 (5105149) @ Episode 6708/10000, loss: 0.0062973564490675935\n",
      "Episode Reward: 17.0\n",
      "Step 1001 (5106150) @ Episode 6709/10000, loss: 0.0020837755873799324\n",
      "Episode Reward: 18.0\n",
      "Step 735 (5106885) @ Episode 6710/10000, loss: 0.0036275614984333515\n",
      "Episode Reward: 11.0\n",
      "Step 719 (5107604) @ Episode 6711/10000, loss: 0.0014729718677699566\n",
      "Episode Reward: 12.0\n",
      "Step 883 (5108487) @ Episode 6712/10000, loss: 0.0068001681938767433\n",
      "Episode Reward: 19.0\n",
      "Step 1380 (5109867) @ Episode 6713/10000, loss: 0.0036036681849509478\n",
      "Episode Reward: 38.0\n",
      "Step 132 (5109999) @ Episode 6714/10000, loss: 0.0067241364158689982\n",
      " Copied model parameters to target network\n",
      "Step 1067 (5110934) @ Episode 6714/10000, loss: 0.0061055859550833796\n",
      "Episode Reward: 22.0\n",
      "Step 1318 (5112252) @ Episode 6715/10000, loss: 0.0114898458123207154\n",
      "Episode Reward: 27.0\n",
      "Step 903 (5113155) @ Episode 6716/10000, loss: 0.0039841695688664915\n",
      "Episode Reward: 15.0\n",
      "Step 684 (5113839) @ Episode 6717/10000, loss: 0.0033646756783127785\n",
      "Episode Reward: 11.0\n",
      "Step 1266 (5115105) @ Episode 6718/10000, loss: 0.0240343045443296435\n",
      "Episode Reward: 36.0\n",
      "Step 1159 (5116264) @ Episode 6719/10000, loss: 0.0034578475169837475\n",
      "Episode Reward: 24.0\n",
      "Step 1319 (5117583) @ Episode 6720/10000, loss: 0.0031439512968063354\n",
      "Episode Reward: 31.0\n",
      "Step 1343 (5118926) @ Episode 6721/10000, loss: 0.0052762711420655254\n",
      "Episode Reward: 29.0\n",
      "Step 924 (5119850) @ Episode 6722/10000, loss: 0.0022017282899469137\n",
      "Episode Reward: 22.0\n",
      "Step 149 (5119999) @ Episode 6723/10000, loss: 0.0121538620442152024\n",
      " Copied model parameters to target network\n",
      "Step 1081 (5120931) @ Episode 6723/10000, loss: 0.0051404973492026335\n",
      "Episode Reward: 18.0\n",
      "Step 749 (5121680) @ Episode 6724/10000, loss: 0.0098117142915725712\n",
      "Episode Reward: 12.0\n",
      "Step 975 (5122655) @ Episode 6725/10000, loss: 0.0035438907798379663\n",
      "Episode Reward: 19.0\n",
      "Step 846 (5123501) @ Episode 6726/10000, loss: 0.0019804683979600676\n",
      "Episode Reward: 12.0\n",
      "Step 766 (5124267) @ Episode 6727/10000, loss: 0.0048443037085235125\n",
      "Episode Reward: 11.0\n",
      "Step 1363 (5125630) @ Episode 6728/10000, loss: 0.0079143038019537935\n",
      "Episode Reward: 43.0\n",
      "Step 1159 (5126789) @ Episode 6729/10000, loss: 0.0042342417873442175\n",
      "Episode Reward: 19.0\n",
      "Step 678 (5127467) @ Episode 6730/10000, loss: 0.0071748918853700166\n",
      "Episode Reward: 16.0\n",
      "Step 434 (5127901) @ Episode 6731/10000, loss: 0.0037181321531534195\n",
      "Episode Reward: 6.0\n",
      "Step 608 (5128509) @ Episode 6732/10000, loss: 0.0084600485861301425\n",
      "Episode Reward: 11.0\n",
      "Step 867 (5129376) @ Episode 6733/10000, loss: 0.0047153402119874956\n",
      "Episode Reward: 12.0\n",
      "Step 564 (5129940) @ Episode 6734/10000, loss: 0.0022247713059186935\n",
      "Episode Reward: 7.0\n",
      "Step 59 (5129999) @ Episode 6735/10000, loss: 0.0063829845748841767\n",
      " Copied model parameters to target network\n",
      "Step 1226 (5131166) @ Episode 6735/10000, loss: 0.0062387967482209206\n",
      "Episode Reward: 26.0\n",
      "Step 713 (5131879) @ Episode 6736/10000, loss: 0.0033632814884185795\n",
      "Episode Reward: 10.0\n",
      "Step 880 (5132759) @ Episode 6737/10000, loss: 0.0078166946768760686\n",
      "Episode Reward: 17.0\n",
      "Step 968 (5133727) @ Episode 6738/10000, loss: 0.0087369186803698543\n",
      "Episode Reward: 25.0\n",
      "Step 544 (5134271) @ Episode 6739/10000, loss: 0.0090610580518841745\n",
      "Episode Reward: 8.0\n",
      "Step 962 (5135233) @ Episode 6740/10000, loss: 0.0045145577751100065\n",
      "Episode Reward: 18.0\n",
      "Step 1047 (5136280) @ Episode 6741/10000, loss: 0.0024976264685392387\n",
      "Episode Reward: 17.0\n",
      "Step 744 (5137024) @ Episode 6742/10000, loss: 0.0159040652215480814\n",
      "Episode Reward: 16.0\n",
      "Step 554 (5137578) @ Episode 6743/10000, loss: 0.0067350883036851888\n",
      "Episode Reward: 7.0\n",
      "Step 785 (5138363) @ Episode 6744/10000, loss: 0.0029521593824028974\n",
      "Episode Reward: 18.0\n",
      "Step 950 (5139313) @ Episode 6745/10000, loss: 0.0064036585390567784\n",
      "Episode Reward: 20.0\n",
      "Step 686 (5139999) @ Episode 6746/10000, loss: 0.0050008236430585384\n",
      " Copied model parameters to target network\n",
      "Step 930 (5140243) @ Episode 6746/10000, loss: 0.0175665747374296268\n",
      "Episode Reward: 15.0\n",
      "Step 780 (5141023) @ Episode 6747/10000, loss: 0.0057554501108825214\n",
      "Episode Reward: 16.0\n",
      "Step 754 (5141777) @ Episode 6748/10000, loss: 0.0045995307154953483\n",
      "Episode Reward: 15.0\n",
      "Step 666 (5142443) @ Episode 6749/10000, loss: 0.0037528038956224923\n",
      "Episode Reward: 9.0\n",
      "Step 776 (5143219) @ Episode 6750/10000, loss: 0.0083177983760833748\n",
      "Episode Reward: 13.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 05:48:44,484] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video006750.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 778 (5143997) @ Episode 6751/10000, loss: 0.0037734895013272762\n",
      "Episode Reward: 11.0\n",
      "Step 856 (5144853) @ Episode 6752/10000, loss: 0.0020059996750205755\n",
      "Episode Reward: 15.0\n",
      "Step 918 (5145771) @ Episode 6753/10000, loss: 0.0015948519576340914\n",
      "Episode Reward: 16.0\n",
      "Step 1303 (5147074) @ Episode 6754/10000, loss: 0.0038237390108406544\n",
      "Episode Reward: 27.0\n",
      "Step 786 (5147860) @ Episode 6755/10000, loss: 0.0034068087115883827\n",
      "Episode Reward: 18.0\n",
      "Step 691 (5148551) @ Episode 6756/10000, loss: 0.0142030036076903344\n",
      "Episode Reward: 10.0\n",
      "Step 869 (5149420) @ Episode 6757/10000, loss: 0.0071246419101953515\n",
      "Episode Reward: 18.0\n",
      "Step 579 (5149999) @ Episode 6758/10000, loss: 0.0036669289693236355\n",
      " Copied model parameters to target network\n",
      "Step 1056 (5150476) @ Episode 6758/10000, loss: 0.0059570050798356538\n",
      "Episode Reward: 20.0\n",
      "Step 594 (5151070) @ Episode 6759/10000, loss: 0.0029358649626374245\n",
      "Episode Reward: 8.0\n",
      "Step 1131 (5152201) @ Episode 6760/10000, loss: 0.0065351435914635666\n",
      "Episode Reward: 19.0\n",
      "Step 715 (5152916) @ Episode 6761/10000, loss: 0.0052347960881888877\n",
      "Episode Reward: 12.0\n",
      "Step 938 (5153854) @ Episode 6762/10000, loss: 0.0047575966455042365\n",
      "Episode Reward: 24.0\n",
      "Step 657 (5154511) @ Episode 6763/10000, loss: 0.0196514874696731575\n",
      "Episode Reward: 12.0\n",
      "Step 537 (5155048) @ Episode 6764/10000, loss: 0.0026940307579934597\n",
      "Episode Reward: 10.0\n",
      "Step 922 (5155970) @ Episode 6765/10000, loss: 0.0059461826458573345\n",
      "Episode Reward: 19.0\n",
      "Step 992 (5156962) @ Episode 6766/10000, loss: 0.0189187303185462953\n",
      "Episode Reward: 19.0\n",
      "Step 687 (5157649) @ Episode 6767/10000, loss: 0.0130116660147905355\n",
      "Episode Reward: 11.0\n",
      "Step 426 (5158075) @ Episode 6768/10000, loss: 0.0073341755196452147\n",
      "Episode Reward: 6.0\n",
      "Step 796 (5158871) @ Episode 6769/10000, loss: 0.0037758229300379753\n",
      "Episode Reward: 15.0\n",
      "Step 619 (5159490) @ Episode 6770/10000, loss: 0.0080612367019057276\n",
      "Episode Reward: 10.0\n",
      "Step 509 (5159999) @ Episode 6771/10000, loss: 0.0076390965841710573\n",
      " Copied model parameters to target network\n",
      "Step 896 (5160386) @ Episode 6771/10000, loss: 0.0059149339795112617\n",
      "Episode Reward: 13.0\n",
      "Step 568 (5160954) @ Episode 6772/10000, loss: 0.0065509276464581494\n",
      "Episode Reward: 11.0\n",
      "Step 575 (5161529) @ Episode 6773/10000, loss: 0.0042055351659655572\n",
      "Episode Reward: 8.0\n",
      "Step 771 (5162300) @ Episode 6774/10000, loss: 0.0023541459813714027\n",
      "Episode Reward: 14.0\n",
      "Step 945 (5163245) @ Episode 6775/10000, loss: 0.0029270534869283438\n",
      "Episode Reward: 18.0\n",
      "Step 690 (5163935) @ Episode 6776/10000, loss: 0.0024662045761942863\n",
      "Episode Reward: 14.0\n",
      "Step 970 (5164905) @ Episode 6777/10000, loss: 0.0065974066965281965\n",
      "Episode Reward: 15.0\n",
      "Step 757 (5165662) @ Episode 6778/10000, loss: 0.0110853835940361025\n",
      "Episode Reward: 19.0\n",
      "Step 919 (5166581) @ Episode 6779/10000, loss: 0.0072352895513176925\n",
      "Episode Reward: 17.0\n",
      "Step 875 (5167456) @ Episode 6780/10000, loss: 0.0096476273611187933\n",
      "Episode Reward: 19.0\n",
      "Step 797 (5168253) @ Episode 6781/10000, loss: 0.0102040022611618042\n",
      "Episode Reward: 13.0\n",
      "Step 726 (5168979) @ Episode 6782/10000, loss: 0.0038726313505321747\n",
      "Episode Reward: 12.0\n",
      "Step 906 (5169885) @ Episode 6783/10000, loss: 0.0122693926095962527\n",
      "Episode Reward: 14.0\n",
      "Step 114 (5169999) @ Episode 6784/10000, loss: 0.0023289013188332325\n",
      " Copied model parameters to target network\n",
      "Step 782 (5170667) @ Episode 6784/10000, loss: 0.0308242589235305815\n",
      "Episode Reward: 15.0\n",
      "Step 448 (5171115) @ Episode 6785/10000, loss: 0.0108899772167205816\n",
      "Episode Reward: 5.0\n",
      "Step 1131 (5172246) @ Episode 6786/10000, loss: 0.0021982793696224697\n",
      "Episode Reward: 20.0\n",
      "Step 743 (5172989) @ Episode 6787/10000, loss: 0.0053167887963354595\n",
      "Episode Reward: 12.0\n",
      "Step 606 (5173595) @ Episode 6788/10000, loss: 0.0021874047815799713\n",
      "Episode Reward: 9.0\n",
      "Step 938 (5174533) @ Episode 6789/10000, loss: 0.0089703211560845385\n",
      "Episode Reward: 18.0\n",
      "Step 1500 (5176033) @ Episode 6790/10000, loss: 0.0119854910299181946\n",
      "Episode Reward: 31.0\n",
      "Step 863 (5176896) @ Episode 6791/10000, loss: 0.0053284522145986564\n",
      "Episode Reward: 13.0\n",
      "Step 999 (5177895) @ Episode 6792/10000, loss: 0.0025887428782880306\n",
      "Episode Reward: 21.0\n",
      "Step 665 (5178560) @ Episode 6793/10000, loss: 0.0028414344415068626\n",
      "Episode Reward: 9.0\n",
      "Step 831 (5179391) @ Episode 6794/10000, loss: 0.0104871056973934176\n",
      "Episode Reward: 14.0\n",
      "Step 608 (5179999) @ Episode 6795/10000, loss: 0.0093324612826108933\n",
      " Copied model parameters to target network\n",
      "Step 672 (5180063) @ Episode 6795/10000, loss: 0.0060928924940526485\n",
      "Episode Reward: 9.0\n",
      "Step 1190 (5181253) @ Episode 6796/10000, loss: 0.0093644950538873676\n",
      "Episode Reward: 22.0\n",
      "Step 905 (5182158) @ Episode 6797/10000, loss: 0.0107784084975719455\n",
      "Episode Reward: 15.0\n",
      "Step 1383 (5183541) @ Episode 6798/10000, loss: 0.0026857871562242514\n",
      "Episode Reward: 29.0\n",
      "Step 930 (5184471) @ Episode 6799/10000, loss: 0.0056723235175013544\n",
      "Episode Reward: 15.0\n",
      "Step 620 (5185091) @ Episode 6800/10000, loss: 0.0049044373445212845\n",
      "Episode Reward: 10.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 05:55:13,505] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video006800.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 540 (5185631) @ Episode 6801/10000, loss: 0.0033821933902800083\n",
      "Episode Reward: 8.0\n",
      "Step 1076 (5186707) @ Episode 6802/10000, loss: 0.0032194997183978558\n",
      "Episode Reward: 20.0\n",
      "Step 558 (5187265) @ Episode 6803/10000, loss: 0.0180459320545196537\n",
      "Episode Reward: 7.0\n",
      "Step 499 (5187764) @ Episode 6804/10000, loss: 0.0042143524624407294\n",
      "Episode Reward: 7.0\n",
      "Step 844 (5188608) @ Episode 6805/10000, loss: 0.0064387256279587755\n",
      "Episode Reward: 13.0\n",
      "Step 909 (5189517) @ Episode 6806/10000, loss: 0.0035070038866251707\n",
      "Episode Reward: 15.0\n",
      "Step 482 (5189999) @ Episode 6807/10000, loss: 0.0076874122023582463\n",
      " Copied model parameters to target network\n",
      "Step 1277 (5190794) @ Episode 6807/10000, loss: 0.0046650478616356855\n",
      "Episode Reward: 24.0\n",
      "Step 736 (5191530) @ Episode 6808/10000, loss: 0.0046825278550386433\n",
      "Episode Reward: 10.0\n",
      "Step 1041 (5192571) @ Episode 6809/10000, loss: 0.0034130332060158253\n",
      "Episode Reward: 25.0\n",
      "Step 1118 (5193689) @ Episode 6810/10000, loss: 0.0042375652119517335\n",
      "Episode Reward: 30.0\n",
      "Step 688 (5194377) @ Episode 6811/10000, loss: 0.0075889430008828642\n",
      "Episode Reward: 10.0\n",
      "Step 380 (5194757) @ Episode 6812/10000, loss: 0.0042263157665729521\n",
      "Episode Reward: 8.0\n",
      "Step 943 (5195700) @ Episode 6813/10000, loss: 0.0067668501287698754\n",
      "Episode Reward: 17.0\n",
      "Step 802 (5196502) @ Episode 6814/10000, loss: 0.0059746135957539084\n",
      "Episode Reward: 16.0\n",
      "Step 611 (5197113) @ Episode 6815/10000, loss: 0.0034868251532316213\n",
      "Episode Reward: 9.0\n",
      "Step 520 (5197633) @ Episode 6816/10000, loss: 0.0022597792558372025\n",
      "Episode Reward: 7.0\n",
      "Step 979 (5198612) @ Episode 6817/10000, loss: 0.0032463071402162313\n",
      "Episode Reward: 15.0\n",
      "Step 1048 (5199660) @ Episode 6818/10000, loss: 0.0136352982372045521\n",
      "Episode Reward: 19.0\n",
      "Step 339 (5199999) @ Episode 6819/10000, loss: 0.0034805578179657465\n",
      " Copied model parameters to target network\n",
      "Step 1064 (5200724) @ Episode 6819/10000, loss: 0.0132140778005123147\n",
      "Episode Reward: 20.0\n",
      "Step 1056 (5201780) @ Episode 6820/10000, loss: 0.0037292134948074818\n",
      "Episode Reward: 24.0\n",
      "Step 1089 (5202869) @ Episode 6821/10000, loss: 0.0026547794695943594\n",
      "Episode Reward: 26.0\n",
      "Step 560 (5203429) @ Episode 6822/10000, loss: 0.0162007417529821434\n",
      "Episode Reward: 7.0\n",
      "Step 768 (5204197) @ Episode 6823/10000, loss: 0.0024737142957746983\n",
      "Episode Reward: 12.0\n",
      "Step 925 (5205122) @ Episode 6824/10000, loss: 0.0055483910255134116\n",
      "Episode Reward: 15.0\n",
      "Step 588 (5205710) @ Episode 6825/10000, loss: 0.0021932211238890886\n",
      "Episode Reward: 9.0\n",
      "Step 654 (5206364) @ Episode 6826/10000, loss: 0.0017289703246206045\n",
      "Episode Reward: 11.0\n",
      "Step 838 (5207202) @ Episode 6827/10000, loss: 0.0047590420581400394\n",
      "Episode Reward: 13.0\n",
      "Step 555 (5207757) @ Episode 6828/10000, loss: 0.0052078077569603925\n",
      "Episode Reward: 8.0\n",
      "Step 851 (5208608) @ Episode 6829/10000, loss: 0.0024835793301463127\n",
      "Episode Reward: 13.0\n",
      "Step 875 (5209483) @ Episode 6830/10000, loss: 0.0104922130703926093\n",
      "Episode Reward: 13.0\n",
      "Step 516 (5209999) @ Episode 6831/10000, loss: 0.0058487029746174818\n",
      " Copied model parameters to target network\n",
      "Step 845 (5210328) @ Episode 6831/10000, loss: 0.0046572396531701098\n",
      "Episode Reward: 17.0\n",
      "Step 712 (5211040) @ Episode 6832/10000, loss: 0.0224704220890998845\n",
      "Episode Reward: 19.0\n",
      "Step 679 (5211719) @ Episode 6833/10000, loss: 0.0030144019983708866\n",
      "Episode Reward: 13.0\n",
      "Step 708 (5212427) @ Episode 6834/10000, loss: 0.0039195194840431215\n",
      "Episode Reward: 11.0\n",
      "Step 847 (5213274) @ Episode 6835/10000, loss: 0.0049682930111885076\n",
      "Episode Reward: 13.0\n",
      "Step 821 (5214095) @ Episode 6836/10000, loss: 0.0024367412552237515\n",
      "Episode Reward: 16.0\n",
      "Step 478 (5214573) @ Episode 6837/10000, loss: 0.0034975444432348013\n",
      "Episode Reward: 7.0\n",
      "Step 588 (5215161) @ Episode 6838/10000, loss: 0.0035176551900804043\n",
      "Episode Reward: 9.0\n",
      "Step 564 (5215725) @ Episode 6839/10000, loss: 0.0270892512053251276\n",
      "Episode Reward: 6.0\n",
      "Step 1138 (5216863) @ Episode 6840/10000, loss: 0.0048951413482427657\n",
      "Episode Reward: 22.0\n",
      "Step 1028 (5217891) @ Episode 6841/10000, loss: 0.0046106129884719854\n",
      "Episode Reward: 19.0\n",
      "Step 730 (5218621) @ Episode 6842/10000, loss: 0.0030055423267185695\n",
      "Episode Reward: 14.0\n",
      "Step 613 (5219234) @ Episode 6843/10000, loss: 0.0036135234404355288\n",
      "Episode Reward: 9.0\n",
      "Step 623 (5219857) @ Episode 6844/10000, loss: 0.0036093988455832005\n",
      "Episode Reward: 9.0\n",
      "Step 142 (5219999) @ Episode 6845/10000, loss: 0.0098515693098306664\n",
      " Copied model parameters to target network\n",
      "Step 785 (5220642) @ Episode 6845/10000, loss: 0.0037949837278574705\n",
      "Episode Reward: 14.0\n",
      "Step 550 (5221192) @ Episode 6846/10000, loss: 0.0111223123967647554\n",
      "Episode Reward: 8.0\n",
      "Step 1164 (5222356) @ Episode 6847/10000, loss: 0.0018933932296931744\n",
      "Episode Reward: 24.0\n",
      "Step 520 (5222876) @ Episode 6848/10000, loss: 0.0049292696639895445\n",
      "Episode Reward: 7.0\n",
      "Step 1179 (5224055) @ Episode 6849/10000, loss: 0.0055014574900269516\n",
      "Episode Reward: 23.0\n",
      "Step 898 (5224953) @ Episode 6850/10000, loss: 0.0047973929904401378\n",
      "Episode Reward: 18.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 06:01:26,795] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video006850.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 895 (5225848) @ Episode 6851/10000, loss: 0.0040213381871581087\n",
      "Episode Reward: 17.0\n",
      "Step 796 (5226644) @ Episode 6852/10000, loss: 0.0028550922870635986\n",
      "Episode Reward: 12.0\n",
      "Step 979 (5227623) @ Episode 6853/10000, loss: 0.0034352403599768877\n",
      "Episode Reward: 18.0\n",
      "Step 1236 (5228859) @ Episode 6854/10000, loss: 0.0043490491807460785\n",
      "Episode Reward: 29.0\n",
      "Step 975 (5229834) @ Episode 6855/10000, loss: 0.0052539017051458365\n",
      "Episode Reward: 15.0\n",
      "Step 165 (5229999) @ Episode 6856/10000, loss: 0.0029815272428095344\n",
      " Copied model parameters to target network\n",
      "Step 790 (5230624) @ Episode 6856/10000, loss: 0.0079952748492360126\n",
      "Episode Reward: 17.0\n",
      "Step 1065 (5231689) @ Episode 6857/10000, loss: 0.0054529444314539436\n",
      "Episode Reward: 30.0\n",
      "Step 714 (5232403) @ Episode 6858/10000, loss: 0.0033072535879909992\n",
      "Episode Reward: 11.0\n",
      "Step 1299 (5233702) @ Episode 6859/10000, loss: 0.0050214100629091265\n",
      "Episode Reward: 27.0\n",
      "Step 911 (5234613) @ Episode 6860/10000, loss: 0.0073795109055936346\n",
      "Episode Reward: 25.0\n",
      "Step 774 (5235387) @ Episode 6861/10000, loss: 0.0086115859448909765\n",
      "Episode Reward: 9.0\n",
      "Step 822 (5236209) @ Episode 6862/10000, loss: 0.0167927425354719166\n",
      "Episode Reward: 13.0\n",
      "Step 609 (5236818) @ Episode 6863/10000, loss: 0.0114300642162561425\n",
      "Episode Reward: 11.0\n",
      "Step 695 (5237513) @ Episode 6864/10000, loss: 0.0050129545852541922\n",
      "Episode Reward: 12.0\n",
      "Step 661 (5238174) @ Episode 6865/10000, loss: 0.0124987717717885974\n",
      "Episode Reward: 9.0\n",
      "Step 1043 (5239217) @ Episode 6866/10000, loss: 0.0027225324884057045\n",
      "Episode Reward: 22.0\n",
      "Step 782 (5239999) @ Episode 6867/10000, loss: 0.0064092124812304976\n",
      " Copied model parameters to target network\n",
      "Step 1340 (5240557) @ Episode 6867/10000, loss: 0.0049130115658044815\n",
      "Episode Reward: 23.0\n",
      "Step 890 (5241447) @ Episode 6868/10000, loss: 0.0039512151852250104\n",
      "Episode Reward: 16.0\n",
      "Step 706 (5242153) @ Episode 6869/10000, loss: 0.0037398654967546463\n",
      "Episode Reward: 13.0\n",
      "Step 389 (5242542) @ Episode 6870/10000, loss: 0.0053304219618439674\n",
      "Episode Reward: 5.0\n",
      "Step 763 (5243305) @ Episode 6871/10000, loss: 0.0036529120989143854\n",
      "Episode Reward: 16.0\n",
      "Step 528 (5243833) @ Episode 6872/10000, loss: 0.0046703447587788105\n",
      "Episode Reward: 6.0\n",
      "Step 672 (5244505) @ Episode 6873/10000, loss: 0.0097273411229252825\n",
      "Episode Reward: 6.0\n",
      "Step 528 (5245033) @ Episode 6874/10000, loss: 0.0024435545783489943\n",
      "Episode Reward: 8.0\n",
      "Step 619 (5245652) @ Episode 6875/10000, loss: 0.0143762473016977315\n",
      "Episode Reward: 14.0\n",
      "Step 784 (5246436) @ Episode 6876/10000, loss: 0.0027553252875804996\n",
      "Episode Reward: 14.0\n",
      "Step 806 (5247242) @ Episode 6877/10000, loss: 0.0033407132141292095\n",
      "Episode Reward: 17.0\n",
      "Step 1001 (5248243) @ Episode 6878/10000, loss: 0.001969582401216037\n",
      "Episode Reward: 17.0\n",
      "Step 485 (5248728) @ Episode 6879/10000, loss: 0.0038355798460543156\n",
      "Episode Reward: 6.0\n",
      "Step 921 (5249649) @ Episode 6880/10000, loss: 0.0089318212121725085\n",
      "Episode Reward: 15.0\n",
      "Step 350 (5249999) @ Episode 6881/10000, loss: 0.0039769127033650875\n",
      " Copied model parameters to target network\n",
      "Step 778 (5250427) @ Episode 6881/10000, loss: 0.0066993767395615582\n",
      "Episode Reward: 16.0\n",
      "Step 700 (5251127) @ Episode 6882/10000, loss: 0.0042495150119066246\n",
      "Episode Reward: 11.0\n",
      "Step 1011 (5252138) @ Episode 6883/10000, loss: 0.0030129908118396997\n",
      "Episode Reward: 17.0\n",
      "Step 822 (5252960) @ Episode 6884/10000, loss: 0.0063460236415266995\n",
      "Episode Reward: 15.0\n",
      "Step 679 (5253639) @ Episode 6885/10000, loss: 0.0026191337965428833\n",
      "Episode Reward: 10.0\n",
      "Step 1097 (5254736) @ Episode 6886/10000, loss: 0.0147247733548283586\n",
      "Episode Reward: 21.0\n",
      "Step 1232 (5255968) @ Episode 6887/10000, loss: 0.0042315963655710224\n",
      "Episode Reward: 22.0\n",
      "Step 770 (5256738) @ Episode 6888/10000, loss: 0.0070285196416083076\n",
      "Episode Reward: 12.0\n",
      "Step 810 (5257548) @ Episode 6889/10000, loss: 0.0059202294796705254\n",
      "Episode Reward: 14.0\n",
      "Step 992 (5258540) @ Episode 6890/10000, loss: 0.0053092567250132565\n",
      "Episode Reward: 20.0\n",
      "Step 531 (5259071) @ Episode 6891/10000, loss: 0.0140957636758685115\n",
      "Episode Reward: 7.0\n",
      "Step 844 (5259915) @ Episode 6892/10000, loss: 0.0027836307417601347\n",
      "Episode Reward: 16.0\n",
      "Step 84 (5259999) @ Episode 6893/10000, loss: 0.0037668840959668163\n",
      " Copied model parameters to target network\n",
      "Step 819 (5260734) @ Episode 6893/10000, loss: 0.0039221053011715418\n",
      "Episode Reward: 14.0\n",
      "Step 936 (5261670) @ Episode 6894/10000, loss: 0.0032393285073339943\n",
      "Episode Reward: 19.0\n",
      "Step 696 (5262366) @ Episode 6895/10000, loss: 0.0337763577699661256\n",
      "Episode Reward: 14.0\n",
      "Step 758 (5263124) @ Episode 6896/10000, loss: 0.0042558568529784686\n",
      "Episode Reward: 16.0\n",
      "Step 849 (5263973) @ Episode 6897/10000, loss: 0.0051464680582284935\n",
      "Episode Reward: 13.0\n",
      "Step 1148 (5265121) @ Episode 6898/10000, loss: 0.0032319584861397743\n",
      "Episode Reward: 20.0\n",
      "Step 1061 (5266182) @ Episode 6899/10000, loss: 0.0025102291256189346\n",
      "Episode Reward: 19.0\n",
      "Step 811 (5266993) @ Episode 6900/10000, loss: 0.0025301100686192513\n",
      "Episode Reward: 13.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 06:07:56,887] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video006900.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 620 (5267613) @ Episode 6901/10000, loss: 0.0047889091074466705\n",
      "Episode Reward: 10.0\n",
      "Step 1040 (5268653) @ Episode 6902/10000, loss: 0.0020902724936604536\n",
      "Episode Reward: 23.0\n",
      "Step 823 (5269476) @ Episode 6903/10000, loss: 0.0126417949795722962\n",
      "Episode Reward: 13.0\n",
      "Step 523 (5269999) @ Episode 6904/10000, loss: 0.0063942549750208855\n",
      " Copied model parameters to target network\n",
      "Step 1222 (5270698) @ Episode 6904/10000, loss: 0.0100363865494728098\n",
      "Episode Reward: 25.0\n",
      "Step 866 (5271564) @ Episode 6905/10000, loss: 0.0076184361241757875\n",
      "Episode Reward: 11.0\n",
      "Step 625 (5272189) @ Episode 6906/10000, loss: 0.0033220860641449694\n",
      "Episode Reward: 13.0\n",
      "Step 822 (5273011) @ Episode 6907/10000, loss: 0.0026135887019336224\n",
      "Episode Reward: 14.0\n",
      "Step 956 (5273967) @ Episode 6908/10000, loss: 0.0095803327858448037\n",
      "Episode Reward: 19.0\n",
      "Step 872 (5274839) @ Episode 6909/10000, loss: 0.0037152078002691276\n",
      "Episode Reward: 15.0\n",
      "Step 559 (5275398) @ Episode 6910/10000, loss: 0.0040345210582017946\n",
      "Episode Reward: 8.0\n",
      "Step 1340 (5276738) @ Episode 6911/10000, loss: 0.0024810293689370155\n",
      "Episode Reward: 35.0\n",
      "Step 612 (5277350) @ Episode 6912/10000, loss: 0.0027375633362680674\n",
      "Episode Reward: 9.0\n",
      "Step 812 (5278162) @ Episode 6913/10000, loss: 0.0056834835559129715\n",
      "Episode Reward: 17.0\n",
      "Step 774 (5278936) @ Episode 6914/10000, loss: 0.0786559879779815754\n",
      "Episode Reward: 13.0\n",
      "Step 1036 (5279972) @ Episode 6915/10000, loss: 0.0073047690093517325\n",
      "Episode Reward: 15.0\n",
      "Step 27 (5279999) @ Episode 6916/10000, loss: 0.0020006191916763783\n",
      " Copied model parameters to target network\n",
      "Step 1130 (5281102) @ Episode 6916/10000, loss: 0.0347280167043209192\n",
      "Episode Reward: 35.0\n",
      "Step 619 (5281721) @ Episode 6917/10000, loss: 0.0028084472287446267\n",
      "Episode Reward: 10.0\n",
      "Step 890 (5282611) @ Episode 6918/10000, loss: 0.0037953804712742567\n",
      "Episode Reward: 15.0\n",
      "Step 720 (5283331) @ Episode 6919/10000, loss: 0.0033008526079356675\n",
      "Episode Reward: 10.0\n",
      "Step 1046 (5284377) @ Episode 6920/10000, loss: 0.0279969479888677625\n",
      "Episode Reward: 19.0\n",
      "Step 752 (5285129) @ Episode 6921/10000, loss: 0.0045172600075602537\n",
      "Episode Reward: 11.0\n",
      "Step 691 (5285820) @ Episode 6922/10000, loss: 0.0087233018130064015\n",
      "Episode Reward: 11.0\n",
      "Step 724 (5286544) @ Episode 6923/10000, loss: 0.0053471536375582226\n",
      "Episode Reward: 11.0\n",
      "Step 601 (5287145) @ Episode 6924/10000, loss: 0.0051766205579042435\n",
      "Episode Reward: 9.0\n",
      "Step 835 (5287980) @ Episode 6925/10000, loss: 0.0039194743148982525\n",
      "Episode Reward: 12.0\n",
      "Step 731 (5288711) @ Episode 6926/10000, loss: 0.0030896798707544804\n",
      "Episode Reward: 11.0\n",
      "Step 552 (5289263) @ Episode 6927/10000, loss: 0.0034706981386989355\n",
      "Episode Reward: 8.0\n",
      "Step 736 (5289999) @ Episode 6928/10000, loss: 0.0053973169997334486\n",
      " Copied model parameters to target network\n",
      "Step 1037 (5290300) @ Episode 6928/10000, loss: 0.0041812793351709845\n",
      "Episode Reward: 20.0\n",
      "Step 952 (5291252) @ Episode 6929/10000, loss: 0.0061072623357176785\n",
      "Episode Reward: 19.0\n",
      "Step 713 (5291965) @ Episode 6930/10000, loss: 0.0124287251383066183\n",
      "Episode Reward: 11.0\n",
      "Step 615 (5292580) @ Episode 6931/10000, loss: 0.0030803536064922815\n",
      "Episode Reward: 8.0\n",
      "Step 845 (5293425) @ Episode 6932/10000, loss: 0.0077660675160586835\n",
      "Episode Reward: 15.0\n",
      "Step 579 (5294004) @ Episode 6933/10000, loss: 0.0039806552231311873\n",
      "Episode Reward: 13.0\n",
      "Step 960 (5294964) @ Episode 6934/10000, loss: 0.0035478202626109123\n",
      "Episode Reward: 21.0\n",
      "Step 884 (5295848) @ Episode 6935/10000, loss: 0.0060977181419730196\n",
      "Episode Reward: 21.0\n",
      "Step 887 (5296735) @ Episode 6936/10000, loss: 0.0043150382116436966\n",
      "Episode Reward: 17.0\n",
      "Step 772 (5297507) @ Episode 6937/10000, loss: 0.0051580704748630526\n",
      "Episode Reward: 14.0\n",
      "Step 693 (5298200) @ Episode 6938/10000, loss: 0.0020428383722901344\n",
      "Episode Reward: 15.0\n",
      "Step 801 (5299001) @ Episode 6939/10000, loss: 0.0091256750747561454\n",
      "Episode Reward: 15.0\n",
      "Step 996 (5299997) @ Episode 6940/10000, loss: 0.0201670713722705848\n",
      "Episode Reward: 19.0\n",
      "Step 2 (5299999) @ Episode 6941/10000, loss: 0.0092257531359791765\n",
      " Copied model parameters to target network\n",
      "Step 1532 (5301529) @ Episode 6941/10000, loss: 0.0064710029400885105\n",
      "Episode Reward: 35.0\n",
      "Step 740 (5302269) @ Episode 6942/10000, loss: 0.0029772724956274033\n",
      "Episode Reward: 11.0\n",
      "Step 826 (5303095) @ Episode 6943/10000, loss: 0.0035201681312173605\n",
      "Episode Reward: 15.0\n",
      "Step 828 (5303923) @ Episode 6944/10000, loss: 0.0043648723512887955\n",
      "Episode Reward: 21.0\n",
      "Step 997 (5304920) @ Episode 6945/10000, loss: 0.0790449157357215965\n",
      "Episode Reward: 23.0\n",
      "Step 1212 (5306132) @ Episode 6946/10000, loss: 0.0035084290429949764\n",
      "Episode Reward: 31.0\n",
      "Step 930 (5307062) @ Episode 6947/10000, loss: 0.0113802161067724235\n",
      "Episode Reward: 14.0\n",
      "Step 1108 (5308170) @ Episode 6948/10000, loss: 0.0028100665658712387\n",
      "Episode Reward: 21.0\n",
      "Step 916 (5309086) @ Episode 6949/10000, loss: 0.0117529183626174935\n",
      "Episode Reward: 14.0\n",
      "Step 913 (5309999) @ Episode 6950/10000, loss: 0.0268577449023723684\n",
      " Copied model parameters to target network\n",
      "Step 1145 (5310231) @ Episode 6950/10000, loss: 0.0042199194431304933\n",
      "Episode Reward: 23.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 06:14:40,637] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video006950.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 640 (5310871) @ Episode 6951/10000, loss: 0.0092276409268379217\n",
      "Episode Reward: 12.0\n",
      "Step 611 (5311482) @ Episode 6952/10000, loss: 0.0055978372693061838\n",
      "Episode Reward: 7.0\n",
      "Step 1172 (5312654) @ Episode 6953/10000, loss: 0.0046242764219641685\n",
      "Episode Reward: 22.0\n",
      "Step 953 (5313607) @ Episode 6954/10000, loss: 0.0085681369528174484\n",
      "Episode Reward: 18.0\n",
      "Step 825 (5314432) @ Episode 6955/10000, loss: 0.0075516593642532825\n",
      "Episode Reward: 14.0\n",
      "Step 907 (5315339) @ Episode 6956/10000, loss: 0.0037501719780266285\n",
      "Episode Reward: 14.0\n",
      "Step 1012 (5316351) @ Episode 6957/10000, loss: 0.0020886093843728304\n",
      "Episode Reward: 17.0\n",
      "Step 1455 (5317806) @ Episode 6958/10000, loss: 0.0079819224774837565\n",
      "Episode Reward: 42.0\n",
      "Step 937 (5318743) @ Episode 6959/10000, loss: 0.0023933229967951775\n",
      "Episode Reward: 17.0\n",
      "Step 588 (5319331) @ Episode 6960/10000, loss: 0.0047860224731266574\n",
      "Episode Reward: 9.0\n",
      "Step 668 (5319999) @ Episode 6961/10000, loss: 0.0025435574352741247\n",
      " Copied model parameters to target network\n",
      "Step 1071 (5320402) @ Episode 6961/10000, loss: 0.0060998350381851237\n",
      "Episode Reward: 22.0\n",
      "Step 801 (5321203) @ Episode 6962/10000, loss: 0.0041803480125963696\n",
      "Episode Reward: 12.0\n",
      "Step 911 (5322114) @ Episode 6963/10000, loss: 0.0056968247517943384\n",
      "Episode Reward: 23.0\n",
      "Step 596 (5322710) @ Episode 6964/10000, loss: 0.0055344421416521074\n",
      "Episode Reward: 9.0\n",
      "Step 893 (5323603) @ Episode 6965/10000, loss: 0.0052194721065461636\n",
      "Episode Reward: 18.0\n",
      "Step 758 (5324361) @ Episode 6966/10000, loss: 0.0018959064036607742\n",
      "Episode Reward: 13.0\n",
      "Step 1174 (5325535) @ Episode 6967/10000, loss: 0.0141252679750323396\n",
      "Episode Reward: 33.0\n",
      "Step 646 (5326181) @ Episode 6968/10000, loss: 0.0024830645415931945\n",
      "Episode Reward: 10.0\n",
      "Step 1079 (5327260) @ Episode 6969/10000, loss: 0.0052041425369679938\n",
      "Episode Reward: 27.0\n",
      "Step 1125 (5328385) @ Episode 6970/10000, loss: 0.0201039016246795652\n",
      "Episode Reward: 25.0\n",
      "Step 964 (5329349) @ Episode 6971/10000, loss: 0.0119664054363965997\n",
      "Episode Reward: 19.0\n",
      "Step 650 (5329999) @ Episode 6972/10000, loss: 0.0072651067748665815\n",
      " Copied model parameters to target network\n",
      "Step 832 (5330181) @ Episode 6972/10000, loss: 0.0030435055959969765\n",
      "Episode Reward: 19.0\n",
      "Step 642 (5330823) @ Episode 6973/10000, loss: 0.0072502088733017445\n",
      "Episode Reward: 9.0\n",
      "Step 895 (5331718) @ Episode 6974/10000, loss: 0.0031040268950164327\n",
      "Episode Reward: 21.0\n",
      "Step 699 (5332417) @ Episode 6975/10000, loss: 0.0036609694361686707\n",
      "Episode Reward: 14.0\n",
      "Step 710 (5333127) @ Episode 6976/10000, loss: 0.0059712599031627184\n",
      "Episode Reward: 11.0\n",
      "Step 1165 (5334292) @ Episode 6977/10000, loss: 0.0025047319941222668\n",
      "Episode Reward: 23.0\n",
      "Step 975 (5335267) @ Episode 6978/10000, loss: 0.0041049895808100715\n",
      "Episode Reward: 15.0\n",
      "Step 848 (5336115) @ Episode 6979/10000, loss: 0.0045269941911101348\n",
      "Episode Reward: 15.0\n",
      "Step 778 (5336893) @ Episode 6980/10000, loss: 0.0021433369256556034\n",
      "Episode Reward: 16.0\n",
      "Step 1053 (5337946) @ Episode 6981/10000, loss: 0.0134045686572790157\n",
      "Episode Reward: 20.0\n",
      "Step 561 (5338507) @ Episode 6982/10000, loss: 0.0052107521332800393\n",
      "Episode Reward: 9.0\n",
      "Step 990 (5339497) @ Episode 6983/10000, loss: 0.0051127076148986824\n",
      "Episode Reward: 17.0\n",
      "Step 502 (5339999) @ Episode 6984/10000, loss: 0.0035319859161973048\n",
      " Copied model parameters to target network\n",
      "Step 844 (5340341) @ Episode 6984/10000, loss: 0.0073533384129405025\n",
      "Episode Reward: 17.0\n",
      "Step 544 (5340885) @ Episode 6985/10000, loss: 0.0064828125759959224\n",
      "Episode Reward: 9.0\n",
      "Step 929 (5341814) @ Episode 6986/10000, loss: 0.0095264725387096472\n",
      "Episode Reward: 15.0\n",
      "Step 850 (5342664) @ Episode 6987/10000, loss: 0.0053257686085999014\n",
      "Episode Reward: 16.0\n",
      "Step 885 (5343549) @ Episode 6988/10000, loss: 0.0031407983042299747\n",
      "Episode Reward: 14.0\n",
      "Step 744 (5344293) @ Episode 6989/10000, loss: 0.0069939102977514272\n",
      "Episode Reward: 11.0\n",
      "Step 719 (5345012) @ Episode 6990/10000, loss: 0.0060439733788371094\n",
      "Episode Reward: 13.0\n",
      "Step 1115 (5346127) @ Episode 6991/10000, loss: 0.0043740193359553814\n",
      "Episode Reward: 23.0\n",
      "Step 1069 (5347196) @ Episode 6992/10000, loss: 0.0034458574373275043\n",
      "Episode Reward: 18.0\n",
      "Step 999 (5348195) @ Episode 6993/10000, loss: 0.0080897836014628413\n",
      "Episode Reward: 26.0\n",
      "Step 842 (5349037) @ Episode 6994/10000, loss: 0.0072645228356122978\n",
      "Episode Reward: 14.0\n",
      "Step 820 (5349857) @ Episode 6995/10000, loss: 0.0046644369140267377\n",
      "Episode Reward: 22.0\n",
      "Step 142 (5349999) @ Episode 6996/10000, loss: 0.0075792060233652592\n",
      " Copied model parameters to target network\n",
      "Step 576 (5350433) @ Episode 6996/10000, loss: 0.0032044232357293367\n",
      "Episode Reward: 9.0\n",
      "Step 848 (5351281) @ Episode 6997/10000, loss: 0.0649902820587158225\n",
      "Episode Reward: 23.0\n",
      "Step 781 (5352062) @ Episode 6998/10000, loss: 0.0079572433605790146\n",
      "Episode Reward: 15.0\n",
      "Step 483 (5352545) @ Episode 6999/10000, loss: 0.0036524746101349592\n",
      "Episode Reward: 7.0\n",
      "Step 601 (5353146) @ Episode 7000/10000, loss: 0.0156841650605201725\n",
      "Episode Reward: 8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 06:21:22,196] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video007000.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 781 (5353927) @ Episode 7001/10000, loss: 0.0033581175375729896\n",
      "Episode Reward: 13.0\n",
      "Step 1079 (5355006) @ Episode 7002/10000, loss: 0.0048177521675825127\n",
      "Episode Reward: 22.0\n",
      "Step 1181 (5356187) @ Episode 7003/10000, loss: 0.0038357130251824856\n",
      "Episode Reward: 28.0\n",
      "Step 811 (5356998) @ Episode 7004/10000, loss: 0.0055075711570680147\n",
      "Episode Reward: 13.0\n",
      "Step 1028 (5358026) @ Episode 7005/10000, loss: 0.0019800979644060135\n",
      "Episode Reward: 24.0\n",
      "Step 723 (5358749) @ Episode 7006/10000, loss: 0.0018718475475907326\n",
      "Episode Reward: 12.0\n",
      "Step 1044 (5359793) @ Episode 7007/10000, loss: 0.0186732560396194464\n",
      "Episode Reward: 17.0\n",
      "Step 206 (5359999) @ Episode 7008/10000, loss: 0.0047338414005935198\n",
      " Copied model parameters to target network\n",
      "Step 633 (5360426) @ Episode 7008/10000, loss: 0.0122022172436118136\n",
      "Episode Reward: 10.0\n",
      "Step 988 (5361414) @ Episode 7009/10000, loss: 0.0057009868323802952\n",
      "Episode Reward: 19.0\n",
      "Step 796 (5362210) @ Episode 7010/10000, loss: 0.0052544586360454565\n",
      "Episode Reward: 12.0\n",
      "Step 700 (5362910) @ Episode 7011/10000, loss: 0.0056501599028706555\n",
      "Episode Reward: 11.0\n",
      "Step 807 (5363717) @ Episode 7012/10000, loss: 0.0117824440822005275\n",
      "Episode Reward: 13.0\n",
      "Step 980 (5364697) @ Episode 7013/10000, loss: 0.0065806284546852117\n",
      "Episode Reward: 17.0\n",
      "Step 635 (5365332) @ Episode 7014/10000, loss: 0.0049318722449243077\n",
      "Episode Reward: 10.0\n",
      "Step 749 (5366081) @ Episode 7015/10000, loss: 0.0029992156196385623\n",
      "Episode Reward: 13.0\n",
      "Step 1030 (5367111) @ Episode 7016/10000, loss: 0.0063240397721529014\n",
      "Episode Reward: 21.0\n",
      "Step 857 (5367968) @ Episode 7017/10000, loss: 0.0054380889050662524\n",
      "Episode Reward: 22.0\n",
      "Step 579 (5368547) @ Episode 7018/10000, loss: 0.0014980491250753403\n",
      "Episode Reward: 9.0\n",
      "Step 644 (5369191) @ Episode 7019/10000, loss: 0.0061268201097846035\n",
      "Episode Reward: 10.0\n",
      "Step 597 (5369788) @ Episode 7020/10000, loss: 0.0126459123566746715\n",
      "Episode Reward: 9.0\n",
      "Step 211 (5369999) @ Episode 7021/10000, loss: 0.0057170991785824366\n",
      " Copied model parameters to target network\n",
      "Step 1289 (5371077) @ Episode 7021/10000, loss: 0.0042433161288499834\n",
      "Episode Reward: 29.0\n",
      "Step 2042 (5373119) @ Episode 7022/10000, loss: 0.0096255140379071246\n",
      "Episode Reward: 47.0\n",
      "Step 834 (5373953) @ Episode 7023/10000, loss: 0.0031257066875696182\n",
      "Episode Reward: 14.0\n",
      "Step 901 (5374854) @ Episode 7024/10000, loss: 0.0065568485297262677\n",
      "Episode Reward: 16.0\n",
      "Step 747 (5375601) @ Episode 7025/10000, loss: 0.0067039891146123415\n",
      "Episode Reward: 10.0\n",
      "Step 515 (5376116) @ Episode 7026/10000, loss: 0.0033615734428167343\n",
      "Episode Reward: 7.0\n",
      "Step 412 (5376528) @ Episode 7027/10000, loss: 0.0029482073150575164\n",
      "Episode Reward: 8.0\n",
      "Step 845 (5377373) @ Episode 7028/10000, loss: 0.0057449266314506537\n",
      "Episode Reward: 13.0\n",
      "Step 1406 (5378779) @ Episode 7029/10000, loss: 0.0196138750761747363\n",
      "Episode Reward: 28.0\n",
      "Step 729 (5379508) @ Episode 7030/10000, loss: 0.0048538940027356154\n",
      "Episode Reward: 10.0\n",
      "Step 491 (5379999) @ Episode 7031/10000, loss: 0.0061985626816749573\n",
      " Copied model parameters to target network\n",
      "Step 782 (5380290) @ Episode 7031/10000, loss: 0.0055834129452705387\n",
      "Episode Reward: 13.0\n",
      "Step 573 (5380863) @ Episode 7032/10000, loss: 0.0066408882848918445\n",
      "Episode Reward: 8.0\n",
      "Step 437 (5381300) @ Episode 7033/10000, loss: 0.0028774878010153774\n",
      "Episode Reward: 6.0\n",
      "Step 781 (5382081) @ Episode 7034/10000, loss: 0.0039012345951050529\n",
      "Episode Reward: 16.0\n",
      "Step 1114 (5383195) @ Episode 7035/10000, loss: 0.0081737367436289796\n",
      "Episode Reward: 33.0\n",
      "Step 902 (5384097) @ Episode 7036/10000, loss: 0.0041783014312386518\n",
      "Episode Reward: 15.0\n",
      "Step 649 (5384746) @ Episode 7037/10000, loss: 0.0021219062618911266\n",
      "Episode Reward: 9.0\n",
      "Step 891 (5385637) @ Episode 7038/10000, loss: 0.0042489641346037393\n",
      "Episode Reward: 13.0\n",
      "Step 875 (5386512) @ Episode 7039/10000, loss: 0.0027555087581276894\n",
      "Episode Reward: 17.0\n",
      "Step 699 (5387211) @ Episode 7040/10000, loss: 0.0174112673848867457\n",
      "Episode Reward: 14.0\n",
      "Step 1189 (5388400) @ Episode 7041/10000, loss: 0.0046275733038783073\n",
      "Episode Reward: 31.0\n",
      "Step 667 (5389067) @ Episode 7042/10000, loss: 0.0035804030485451223\n",
      "Episode Reward: 11.0\n",
      "Step 813 (5389880) @ Episode 7043/10000, loss: 0.0036804135888814926\n",
      "Episode Reward: 7.0\n",
      "Step 119 (5389999) @ Episode 7044/10000, loss: 0.0083915647119283686\n",
      " Copied model parameters to target network\n",
      "Step 1179 (5391059) @ Episode 7044/10000, loss: 0.0032035966869443655\n",
      "Episode Reward: 24.0\n",
      "Step 718 (5391777) @ Episode 7045/10000, loss: 0.0029319331515580416\n",
      "Episode Reward: 10.0\n",
      "Step 674 (5392451) @ Episode 7046/10000, loss: 0.0072238501161336967\n",
      "Episode Reward: 10.0\n",
      "Step 948 (5393399) @ Episode 7047/10000, loss: 0.0029735849238932133\n",
      "Episode Reward: 24.0\n",
      "Step 798 (5394197) @ Episode 7048/10000, loss: 0.0099573042243719166\n",
      "Episode Reward: 13.0\n",
      "Step 953 (5395150) @ Episode 7049/10000, loss: 0.0048870281316339975\n",
      "Episode Reward: 14.0\n",
      "Step 893 (5396043) @ Episode 7050/10000, loss: 0.0055527323856949814\n",
      "Episode Reward: 18.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 06:27:58,743] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video007050.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 894 (5396937) @ Episode 7051/10000, loss: 0.0051170266233384616\n",
      "Episode Reward: 15.0\n",
      "Step 988 (5397925) @ Episode 7052/10000, loss: 0.0110495220869779595\n",
      "Episode Reward: 20.0\n",
      "Step 1318 (5399243) @ Episode 7053/10000, loss: 0.0040999995544552885\n",
      "Episode Reward: 27.0\n",
      "Step 756 (5399999) @ Episode 7054/10000, loss: 0.0038269751239567995\n",
      " Copied model parameters to target network\n",
      "Step 820 (5400063) @ Episode 7054/10000, loss: 0.0030157133005559444\n",
      "Episode Reward: 12.0\n",
      "Step 574 (5400637) @ Episode 7055/10000, loss: 0.0039664749056100845\n",
      "Episode Reward: 12.0\n",
      "Step 988 (5401625) @ Episode 7056/10000, loss: 0.0024034893140196867\n",
      "Episode Reward: 18.0\n",
      "Step 1133 (5402758) @ Episode 7057/10000, loss: 0.0071276254020631317\n",
      "Episode Reward: 18.0\n",
      "Step 811 (5403569) @ Episode 7058/10000, loss: 0.0114691788330674174\n",
      "Episode Reward: 13.0\n",
      "Step 872 (5404441) @ Episode 7059/10000, loss: 0.0050522172823548325\n",
      "Episode Reward: 22.0\n",
      "Step 903 (5405344) @ Episode 7060/10000, loss: 0.0061415415257215593\n",
      "Episode Reward: 15.0\n",
      "Step 800 (5406144) @ Episode 7061/10000, loss: 0.0094143003225326545\n",
      "Episode Reward: 16.0\n",
      "Step 1015 (5407159) @ Episode 7062/10000, loss: 0.0014126342721283436\n",
      "Episode Reward: 16.0\n",
      "Step 729 (5407888) @ Episode 7063/10000, loss: 0.0022347574122250087\n",
      "Episode Reward: 18.0\n",
      "Step 691 (5408579) @ Episode 7064/10000, loss: 0.0163889639079570775\n",
      "Episode Reward: 11.0\n",
      "Step 907 (5409486) @ Episode 7065/10000, loss: 0.0071392008103430276\n",
      "Episode Reward: 13.0\n",
      "Step 513 (5409999) @ Episode 7066/10000, loss: 0.0138435978442430595\n",
      " Copied model parameters to target network\n",
      "Step 911 (5410397) @ Episode 7066/10000, loss: 0.0035872962325811386\n",
      "Episode Reward: 15.0\n",
      "Step 817 (5411214) @ Episode 7067/10000, loss: 0.0037176732439547777\n",
      "Episode Reward: 14.0\n",
      "Step 954 (5412168) @ Episode 7068/10000, loss: 0.0043869679793715489\n",
      "Episode Reward: 19.0\n",
      "Step 1246 (5413414) @ Episode 7069/10000, loss: 0.0080316960811614994\n",
      "Episode Reward: 30.0\n",
      "Step 573 (5413987) @ Episode 7070/10000, loss: 0.0083065144717693338\n",
      "Episode Reward: 8.0\n",
      "Step 676 (5414663) @ Episode 7071/10000, loss: 0.0055383001454174524\n",
      "Episode Reward: 8.0\n",
      "Step 613 (5415276) @ Episode 7072/10000, loss: 0.0024616564624011517\n",
      "Episode Reward: 8.0\n",
      "Step 864 (5416140) @ Episode 7073/10000, loss: 0.0034136106260120876\n",
      "Episode Reward: 15.0\n",
      "Step 840 (5416980) @ Episode 7074/10000, loss: 0.0053689694032073026\n",
      "Episode Reward: 18.0\n",
      "Step 913 (5417893) @ Episode 7075/10000, loss: 0.0038745058700442314\n",
      "Episode Reward: 14.0\n",
      "Step 730 (5418623) @ Episode 7076/10000, loss: 0.0049878824502229697\n",
      "Episode Reward: 13.0\n",
      "Step 1316 (5419939) @ Episode 7077/10000, loss: 0.0236985702067613608\n",
      "Episode Reward: 28.0\n",
      "Step 60 (5419999) @ Episode 7078/10000, loss: 0.0049763866700232033\n",
      " Copied model parameters to target network\n",
      "Step 1027 (5420966) @ Episode 7078/10000, loss: 0.0038628219626843937\n",
      "Episode Reward: 17.0\n",
      "Step 1125 (5422091) @ Episode 7079/10000, loss: 0.0035005139652639627\n",
      "Episode Reward: 24.0\n",
      "Step 903 (5422994) @ Episode 7080/10000, loss: 0.0102792829275131235\n",
      "Episode Reward: 12.0\n",
      "Step 646 (5423640) @ Episode 7081/10000, loss: 0.0058651063591241845\n",
      "Episode Reward: 9.0\n",
      "Step 633 (5424273) @ Episode 7082/10000, loss: 0.0026189540512859826\n",
      "Episode Reward: 8.0\n",
      "Step 983 (5425256) @ Episode 7083/10000, loss: 0.0036321929655969143\n",
      "Episode Reward: 16.0\n",
      "Step 504 (5425760) @ Episode 7084/10000, loss: 0.0041008153930306435\n",
      "Episode Reward: 8.0\n",
      "Step 587 (5426347) @ Episode 7085/10000, loss: 0.0031349798664450645\n",
      "Episode Reward: 9.0\n",
      "Step 618 (5426965) @ Episode 7086/10000, loss: 0.0041004195809364325\n",
      "Episode Reward: 9.0\n",
      "Step 897 (5427862) @ Episode 7087/10000, loss: 0.0023652208037674427\n",
      "Episode Reward: 15.0\n",
      "Step 1225 (5429087) @ Episode 7088/10000, loss: 0.0015531060053035617\n",
      "Episode Reward: 27.0\n",
      "Step 621 (5429708) @ Episode 7089/10000, loss: 0.0018253175076097255\n",
      "Episode Reward: 9.0\n",
      "Step 291 (5429999) @ Episode 7090/10000, loss: 0.0050261039286851885\n",
      " Copied model parameters to target network\n",
      "Step 1168 (5430876) @ Episode 7090/10000, loss: 0.0071628205478191385\n",
      "Episode Reward: 23.0\n",
      "Step 504 (5431380) @ Episode 7091/10000, loss: 0.0033540474250912666\n",
      "Episode Reward: 8.0\n",
      "Step 859 (5432239) @ Episode 7092/10000, loss: 0.0072382446378469473\n",
      "Episode Reward: 16.0\n",
      "Step 853 (5433092) @ Episode 7093/10000, loss: 0.0057221618480980455\n",
      "Episode Reward: 16.0\n",
      "Step 797 (5433889) @ Episode 7094/10000, loss: 0.0035575972869992256\n",
      "Episode Reward: 13.0\n",
      "Step 914 (5434803) @ Episode 7095/10000, loss: 0.0087107960134744645\n",
      "Episode Reward: 17.0\n",
      "Step 872 (5435675) @ Episode 7096/10000, loss: 0.0080140391364693643\n",
      "Episode Reward: 15.0\n",
      "Step 927 (5436602) @ Episode 7097/10000, loss: 0.0047331633977591993\n",
      "Episode Reward: 15.0\n",
      "Step 840 (5437442) @ Episode 7098/10000, loss: 0.0052478555589914326\n",
      "Episode Reward: 13.0\n",
      "Step 669 (5438111) @ Episode 7099/10000, loss: 0.0034436071291565895\n",
      "Episode Reward: 10.0\n",
      "Step 1057 (5439168) @ Episode 7100/10000, loss: 0.0032851588912308216\n",
      "Episode Reward: 22.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 06:34:42,098] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video007100.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 762 (5439930) @ Episode 7101/10000, loss: 0.0052792923524975787\n",
      "Episode Reward: 11.0\n",
      "Step 69 (5439999) @ Episode 7102/10000, loss: 0.0304508507251739595\n",
      " Copied model parameters to target network\n",
      "Step 735 (5440665) @ Episode 7102/10000, loss: 0.0020101978443562984\n",
      "Episode Reward: 10.0\n",
      "Step 680 (5441345) @ Episode 7103/10000, loss: 0.0151329357177019124\n",
      "Episode Reward: 10.0\n",
      "Step 1004 (5442349) @ Episode 7104/10000, loss: 0.0021239905618131167\n",
      "Episode Reward: 18.0\n",
      "Step 890 (5443239) @ Episode 7105/10000, loss: 0.0066666416823863985\n",
      "Episode Reward: 18.0\n",
      "Step 947 (5444186) @ Episode 7106/10000, loss: 0.0053057717159390455\n",
      "Episode Reward: 16.0\n",
      "Step 1001 (5445187) @ Episode 7107/10000, loss: 0.017050439491868028\n",
      "Episode Reward: 22.0\n",
      "Step 559 (5445746) @ Episode 7108/10000, loss: 0.0025291470810770996\n",
      "Episode Reward: 8.0\n",
      "Step 731 (5446477) @ Episode 7109/10000, loss: 0.0091553330421447757\n",
      "Episode Reward: 11.0\n",
      "Step 1072 (5447549) @ Episode 7110/10000, loss: 0.0048448583111166954\n",
      "Episode Reward: 26.0\n",
      "Step 876 (5448425) @ Episode 7111/10000, loss: 0.0043547758832573897\n",
      "Episode Reward: 14.0\n",
      "Step 1036 (5449461) @ Episode 7112/10000, loss: 0.0039763804525136955\n",
      "Episode Reward: 16.0\n",
      "Step 538 (5449999) @ Episode 7113/10000, loss: 0.0026620309799909593\n",
      " Copied model parameters to target network\n",
      "Step 680 (5450141) @ Episode 7113/10000, loss: 0.0049507999792695045\n",
      "Episode Reward: 12.0\n",
      "Step 736 (5450877) @ Episode 7114/10000, loss: 0.0023990429472178228\n",
      "Episode Reward: 10.0\n",
      "Step 1159 (5452036) @ Episode 7115/10000, loss: 0.0026070829480886464\n",
      "Episode Reward: 25.0\n",
      "Step 1318 (5453354) @ Episode 7116/10000, loss: 0.0051313061267137535\n",
      "Episode Reward: 29.0\n",
      "Step 954 (5454308) @ Episode 7117/10000, loss: 0.0023112772032618523\n",
      "Episode Reward: 24.0\n",
      "Step 769 (5455077) @ Episode 7118/10000, loss: 0.0027947875205427413\n",
      "Episode Reward: 12.0\n",
      "Step 1061 (5456138) @ Episode 7119/10000, loss: 0.0032304208725690847\n",
      "Episode Reward: 22.0\n",
      "Step 940 (5457078) @ Episode 7120/10000, loss: 0.0632903873920440784\n",
      "Episode Reward: 17.0\n",
      "Step 727 (5457805) @ Episode 7121/10000, loss: 0.0027339544612914324\n",
      "Episode Reward: 8.0\n",
      "Step 715 (5458520) @ Episode 7122/10000, loss: 0.0057098739780485637\n",
      "Episode Reward: 9.0\n",
      "Step 721 (5459241) @ Episode 7123/10000, loss: 0.0020745261572301388\n",
      "Episode Reward: 11.0\n",
      "Step 758 (5459999) @ Episode 7124/10000, loss: 0.0058657601475715643\n",
      " Copied model parameters to target network\n",
      "Step 1043 (5460284) @ Episode 7124/10000, loss: 0.0017482824623584747\n",
      "Episode Reward: 22.0\n",
      "Step 1204 (5461488) @ Episode 7125/10000, loss: 0.0070976838469505313\n",
      "Episode Reward: 29.0\n",
      "Step 1041 (5462529) @ Episode 7126/10000, loss: 0.0026419674977660184\n",
      "Episode Reward: 23.0\n",
      "Step 705 (5463234) @ Episode 7127/10000, loss: 0.0036911626812070616\n",
      "Episode Reward: 12.0\n",
      "Step 789 (5464023) @ Episode 7128/10000, loss: 0.0076350844465196132\n",
      "Episode Reward: 13.0\n",
      "Step 357 (5464380) @ Episode 7129/10000, loss: 0.0074747111648321153\n",
      "Episode Reward: 5.0\n",
      "Step 985 (5465365) @ Episode 7130/10000, loss: 0.0351060628890991215\n",
      "Episode Reward: 17.0\n",
      "Step 844 (5466209) @ Episode 7131/10000, loss: 0.0046447268687188625\n",
      "Episode Reward: 13.0\n",
      "Step 690 (5466899) @ Episode 7132/10000, loss: 0.0068739885464310658\n",
      "Episode Reward: 9.0\n",
      "Step 1196 (5468095) @ Episode 7133/10000, loss: 0.0100723905488848694\n",
      "Episode Reward: 34.0\n",
      "Step 1371 (5469466) @ Episode 7134/10000, loss: 0.0026099020615220073\n",
      "Episode Reward: 28.0\n",
      "Step 533 (5469999) @ Episode 7135/10000, loss: 0.0057420167140662678\n",
      " Copied model parameters to target network\n",
      "Step 670 (5470136) @ Episode 7135/10000, loss: 0.0022844136692583562\n",
      "Episode Reward: 11.0\n",
      "Step 731 (5470867) @ Episode 7136/10000, loss: 0.0029380698688328266\n",
      "Episode Reward: 13.0\n",
      "Step 681 (5471548) @ Episode 7137/10000, loss: 0.0033013820648193364\n",
      "Episode Reward: 10.0\n",
      "Step 977 (5472525) @ Episode 7138/10000, loss: 0.0058033885434269905\n",
      "Episode Reward: 21.0\n",
      "Step 822 (5473347) @ Episode 7139/10000, loss: 0.0051305070519447334\n",
      "Episode Reward: 12.0\n",
      "Step 493 (5473840) @ Episode 7140/10000, loss: 0.0088261961936950687\n",
      "Episode Reward: 6.0\n",
      "Step 708 (5474548) @ Episode 7141/10000, loss: 0.0094900783151388179\n",
      "Episode Reward: 12.0\n",
      "Step 528 (5475076) @ Episode 7142/10000, loss: 0.0019623367115855217\n",
      "Episode Reward: 13.0\n",
      "Step 815 (5475891) @ Episode 7143/10000, loss: 0.0047823814675211917\n",
      "Episode Reward: 11.0\n",
      "Step 1113 (5477004) @ Episode 7144/10000, loss: 0.0107641909271478655\n",
      "Episode Reward: 28.0\n",
      "Step 1049 (5478053) @ Episode 7145/10000, loss: 0.0012496501440182328\n",
      "Episode Reward: 22.0\n",
      "Step 577 (5478630) @ Episode 7146/10000, loss: 0.0040717590600252157\n",
      "Episode Reward: 8.0\n",
      "Step 553 (5479183) @ Episode 7147/10000, loss: 0.0062033087015151986\n",
      "Episode Reward: 8.0\n",
      "Step 709 (5479892) @ Episode 7148/10000, loss: 0.0060320151969790465\n",
      "Episode Reward: 12.0\n",
      "Step 107 (5479999) @ Episode 7149/10000, loss: 0.0023617120459675796\n",
      " Copied model parameters to target network\n",
      "Step 967 (5480859) @ Episode 7149/10000, loss: 0.0034728255122900013\n",
      "Episode Reward: 16.0\n",
      "Step 833 (5481692) @ Episode 7150/10000, loss: 0.00532457605004310656\n",
      "Episode Reward: 14.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 06:41:16,280] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video007150.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 680 (5482372) @ Episode 7151/10000, loss: 0.0072004036046564587\n",
      "Episode Reward: 11.0\n",
      "Step 532 (5482904) @ Episode 7152/10000, loss: 0.0078037371858954437\n",
      "Episode Reward: 7.0\n",
      "Step 906 (5483810) @ Episode 7153/10000, loss: 0.0031553697772324085\n",
      "Episode Reward: 16.0\n",
      "Step 934 (5484744) @ Episode 7154/10000, loss: 0.0025711925700306892\n",
      "Episode Reward: 16.0\n",
      "Step 671 (5485415) @ Episode 7155/10000, loss: 0.0069000259973108773\n",
      "Episode Reward: 14.0\n",
      "Step 784 (5486199) @ Episode 7156/10000, loss: 0.0090103223919868477\n",
      "Episode Reward: 14.0\n",
      "Step 1124 (5487323) @ Episode 7157/10000, loss: 0.0017242168541997671\n",
      "Episode Reward: 29.0\n",
      "Step 944 (5488267) @ Episode 7158/10000, loss: 0.0020720963366329673\n",
      "Episode Reward: 17.0\n",
      "Step 632 (5488899) @ Episode 7159/10000, loss: 0.0037349865306168795\n",
      "Episode Reward: 8.0\n",
      "Step 744 (5489643) @ Episode 7160/10000, loss: 0.0027668471448123455\n",
      "Episode Reward: 22.0\n",
      "Step 356 (5489999) @ Episode 7161/10000, loss: 0.0035992227494716644\n",
      " Copied model parameters to target network\n",
      "Step 549 (5490192) @ Episode 7161/10000, loss: 0.0035009281709790235\n",
      "Episode Reward: 15.0\n",
      "Step 623 (5490815) @ Episode 7162/10000, loss: 0.0048274751752614975\n",
      "Episode Reward: 8.0\n",
      "Step 894 (5491709) @ Episode 7163/10000, loss: 0.0091603333130478864\n",
      "Episode Reward: 15.0\n",
      "Step 831 (5492540) @ Episode 7164/10000, loss: 0.0033450417686253786\n",
      "Episode Reward: 13.0\n",
      "Step 914 (5493454) @ Episode 7165/10000, loss: 0.0045035043731331825\n",
      "Episode Reward: 17.0\n",
      "Step 683 (5494137) @ Episode 7166/10000, loss: 0.0044292598031461243\n",
      "Episode Reward: 8.0\n",
      "Step 884 (5495021) @ Episode 7167/10000, loss: 0.0045649963431060314\n",
      "Episode Reward: 20.0\n",
      "Step 625 (5495646) @ Episode 7168/10000, loss: 0.0023047360591590405\n",
      "Episode Reward: 10.0\n",
      "Step 793 (5496439) @ Episode 7169/10000, loss: 0.0023758872412145138\n",
      "Episode Reward: 13.0\n",
      "Step 777 (5497216) @ Episode 7170/10000, loss: 0.0114449439570307737\n",
      "Episode Reward: 12.0\n",
      "Step 812 (5498028) @ Episode 7171/10000, loss: 0.0096742250025272375\n",
      "Episode Reward: 14.0\n",
      "Step 920 (5498948) @ Episode 7172/10000, loss: 0.0038520372472703457\n",
      "Episode Reward: 16.0\n",
      "Step 897 (5499845) @ Episode 7173/10000, loss: 0.0031231604516506195\n",
      "Episode Reward: 19.0\n",
      "Step 154 (5499999) @ Episode 7174/10000, loss: 0.0115211680531501773\n",
      " Copied model parameters to target network\n",
      "Step 417 (5500262) @ Episode 7174/10000, loss: 0.0025572031736373944\n",
      "Episode Reward: 4.0\n",
      "Step 615 (5500877) @ Episode 7175/10000, loss: 0.0289051998406648645\n",
      "Episode Reward: 9.0\n",
      "Step 881 (5501758) @ Episode 7176/10000, loss: 0.0059551056474447257\n",
      "Episode Reward: 17.0\n",
      "Step 832 (5502590) @ Episode 7177/10000, loss: 0.0042159520089626317\n",
      "Episode Reward: 13.0\n",
      "Step 511 (5503101) @ Episode 7178/10000, loss: 0.0034794188104569915\n",
      "Episode Reward: 7.0\n",
      "Step 494 (5503595) @ Episode 7179/10000, loss: 0.0041340305469930174\n",
      "Episode Reward: 10.0\n",
      "Step 811 (5504406) @ Episode 7180/10000, loss: 0.0152449980378150945\n",
      "Episode Reward: 14.0\n",
      "Step 997 (5505403) @ Episode 7181/10000, loss: 0.0040204981341958055\n",
      "Episode Reward: 23.0\n",
      "Step 742 (5506145) @ Episode 7182/10000, loss: 0.0125043690204620367\n",
      "Episode Reward: 10.0\n",
      "Step 571 (5506716) @ Episode 7183/10000, loss: 0.0054779211059212685\n",
      "Episode Reward: 9.0\n",
      "Step 552 (5507268) @ Episode 7184/10000, loss: 0.0209312830120325138\n",
      "Episode Reward: 8.0\n",
      "Step 825 (5508093) @ Episode 7185/10000, loss: 0.0139317419379949577\n",
      "Episode Reward: 13.0\n",
      "Step 498 (5508591) @ Episode 7186/10000, loss: 0.0058646686375141144\n",
      "Episode Reward: 7.0\n",
      "Step 722 (5509313) @ Episode 7187/10000, loss: 0.0070594567805528645\n",
      "Episode Reward: 11.0\n",
      "Step 662 (5509975) @ Episode 7188/10000, loss: 0.0097026117146015174\n",
      "Episode Reward: 10.0\n",
      "Step 24 (5509999) @ Episode 7189/10000, loss: 0.0059055266901850776\n",
      " Copied model parameters to target network\n",
      "Step 987 (5510962) @ Episode 7189/10000, loss: 0.0030726096592843533\n",
      "Episode Reward: 18.0\n",
      "Step 840 (5511802) @ Episode 7190/10000, loss: 0.0032400563359260568\n",
      "Episode Reward: 11.0\n",
      "Step 660 (5512462) @ Episode 7191/10000, loss: 0.0077149695716798306\n",
      "Episode Reward: 10.0\n",
      "Step 863 (5513325) @ Episode 7192/10000, loss: 0.0022160254884511232\n",
      "Episode Reward: 22.0\n",
      "Step 654 (5513979) @ Episode 7193/10000, loss: 0.0036066563334316015\n",
      "Episode Reward: 17.0\n",
      "Step 971 (5514950) @ Episode 7194/10000, loss: 0.0510398745536804235\n",
      "Episode Reward: 22.0\n",
      "Step 985 (5515935) @ Episode 7195/10000, loss: 0.0108752436935901647\n",
      "Episode Reward: 17.0\n",
      "Step 1055 (5516990) @ Episode 7196/10000, loss: 0.0040145795792341232\n",
      "Episode Reward: 26.0\n",
      "Step 798 (5517788) @ Episode 7197/10000, loss: 0.0036772263702005156\n",
      "Episode Reward: 16.0\n",
      "Step 1007 (5518795) @ Episode 7198/10000, loss: 0.0027031169738620526\n",
      "Episode Reward: 14.0\n",
      "Step 814 (5519609) @ Episode 7199/10000, loss: 0.0027820360846817493\n",
      "Episode Reward: 13.0\n",
      "Step 390 (5519999) @ Episode 7200/10000, loss: 0.0113462172448635164\n",
      " Copied model parameters to target network\n",
      "Step 699 (5520308) @ Episode 7200/10000, loss: 0.0464718528091907528\n",
      "Episode Reward: 12.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 06:47:19,183] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video007200.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 837 (5521145) @ Episode 7201/10000, loss: 0.0038500828668475157\n",
      "Episode Reward: 15.0\n",
      "Step 737 (5521882) @ Episode 7202/10000, loss: 0.0049822642467916015\n",
      "Episode Reward: 13.0\n",
      "Step 1043 (5522925) @ Episode 7203/10000, loss: 0.0054310685954988514\n",
      "Episode Reward: 21.0\n",
      "Step 1047 (5523972) @ Episode 7204/10000, loss: 0.0022901748307049274\n",
      "Episode Reward: 18.0\n",
      "Step 596 (5524568) @ Episode 7205/10000, loss: 0.0051640304736793046\n",
      "Episode Reward: 9.0\n",
      "Step 645 (5525213) @ Episode 7206/10000, loss: 0.0062821288593113423\n",
      "Episode Reward: 10.0\n",
      "Step 538 (5525751) @ Episode 7207/10000, loss: 0.0026204069145023823\n",
      "Episode Reward: 11.0\n",
      "Step 674 (5526425) @ Episode 7208/10000, loss: 0.0040480815805494785\n",
      "Episode Reward: 8.0\n",
      "Step 1013 (5527438) @ Episode 7209/10000, loss: 0.0036789672449231148\n",
      "Episode Reward: 21.0\n",
      "Step 777 (5528215) @ Episode 7210/10000, loss: 0.0083849895745515826\n",
      "Episode Reward: 12.0\n",
      "Step 702 (5528917) @ Episode 7211/10000, loss: 0.0059696901589632034\n",
      "Episode Reward: 17.0\n",
      "Step 1082 (5529999) @ Episode 7212/10000, loss: 0.0028023077175021173\n",
      " Copied model parameters to target network\n",
      "Step 1150 (5530067) @ Episode 7212/10000, loss: 0.0030754599720239644\n",
      "Episode Reward: 28.0\n",
      "Step 993 (5531060) @ Episode 7213/10000, loss: 0.0086158402264118235\n",
      "Episode Reward: 23.0\n",
      "Step 1131 (5532191) @ Episode 7214/10000, loss: 0.0032481686212122444\n",
      "Episode Reward: 26.0\n",
      "Step 750 (5532941) @ Episode 7215/10000, loss: 0.0057892659679055216\n",
      "Episode Reward: 10.0\n",
      "Step 804 (5533745) @ Episode 7216/10000, loss: 0.0036427290178835399\n",
      "Episode Reward: 16.0\n",
      "Step 835 (5534580) @ Episode 7217/10000, loss: 0.0051649599336087742\n",
      "Episode Reward: 24.0\n",
      "Step 697 (5535277) @ Episode 7218/10000, loss: 0.0096882134675979617\n",
      "Episode Reward: 7.0\n",
      "Step 684 (5535961) @ Episode 7219/10000, loss: 0.0030155545100569725\n",
      "Episode Reward: 10.0\n",
      "Step 812 (5536773) @ Episode 7220/10000, loss: 0.0107966996729373934\n",
      "Episode Reward: 14.0\n",
      "Step 1207 (5537980) @ Episode 7221/10000, loss: 0.0048822592943906787\n",
      "Episode Reward: 24.0\n",
      "Step 1179 (5539159) @ Episode 7222/10000, loss: 0.0061458488926291476\n",
      "Episode Reward: 27.0\n",
      "Step 471 (5539630) @ Episode 7223/10000, loss: 0.0034004473127424717\n",
      "Episode Reward: 7.0\n",
      "Step 369 (5539999) @ Episode 7224/10000, loss: 0.0068850256502628334\n",
      " Copied model parameters to target network\n",
      "Step 1359 (5540989) @ Episode 7224/10000, loss: 0.0079191112890839587\n",
      "Episode Reward: 36.0\n",
      "Step 682 (5541671) @ Episode 7225/10000, loss: 0.0106110051274299625\n",
      "Episode Reward: 20.0\n",
      "Step 960 (5542631) @ Episode 7226/10000, loss: 0.0065719960257411877\n",
      "Episode Reward: 16.0\n",
      "Step 799 (5543430) @ Episode 7227/10000, loss: 0.0044122627004981042\n",
      "Episode Reward: 19.0\n",
      "Step 751 (5544181) @ Episode 7228/10000, loss: 0.0061701652593910693\n",
      "Episode Reward: 12.0\n",
      "Step 694 (5544875) @ Episode 7229/10000, loss: 0.0044836015440523624\n",
      "Episode Reward: 11.0\n",
      "Step 752 (5545627) @ Episode 7230/10000, loss: 0.0103938626125454997\n",
      "Episode Reward: 12.0\n",
      "Step 1093 (5546720) @ Episode 7231/10000, loss: 0.0033040279522538185\n",
      "Episode Reward: 24.0\n",
      "Step 1248 (5547968) @ Episode 7232/10000, loss: 0.0207177419215440755\n",
      "Episode Reward: 29.0\n",
      "Step 699 (5548667) @ Episode 7233/10000, loss: 0.0077027212828397756\n",
      "Episode Reward: 10.0\n",
      "Step 1022 (5549689) @ Episode 7234/10000, loss: 0.0170214567333459856\n",
      "Episode Reward: 19.0\n",
      "Step 310 (5549999) @ Episode 7235/10000, loss: 0.0032456864137202575\n",
      " Copied model parameters to target network\n",
      "Step 627 (5550316) @ Episode 7235/10000, loss: 0.0036728186532855034\n",
      "Episode Reward: 9.0\n",
      "Step 715 (5551031) @ Episode 7236/10000, loss: 0.0048132068477571018\n",
      "Episode Reward: 10.0\n",
      "Step 1095 (5552126) @ Episode 7237/10000, loss: 0.0045740427449345596\n",
      "Episode Reward: 26.0\n",
      "Step 590 (5552716) @ Episode 7238/10000, loss: 0.0067705297842621876\n",
      "Episode Reward: 12.0\n",
      "Step 686 (5553402) @ Episode 7239/10000, loss: 0.0054533528164029124\n",
      "Episode Reward: 12.0\n",
      "Step 727 (5554129) @ Episode 7240/10000, loss: 0.0036148317158222293\n",
      "Episode Reward: 15.0\n",
      "Step 632 (5554761) @ Episode 7241/10000, loss: 0.0052111647091805935\n",
      "Episode Reward: 8.0\n",
      "Step 556 (5555317) @ Episode 7242/10000, loss: 0.0025657999794930227\n",
      "Episode Reward: 7.0\n",
      "Step 913 (5556230) @ Episode 7243/10000, loss: 0.0076914420351386074\n",
      "Episode Reward: 13.0\n",
      "Step 1222 (5557452) @ Episode 7244/10000, loss: 0.0021040821447968483\n",
      "Episode Reward: 29.0\n",
      "Step 714 (5558166) @ Episode 7245/10000, loss: 0.0092051932588219648\n",
      "Episode Reward: 10.0\n",
      "Step 556 (5558722) @ Episode 7246/10000, loss: 0.0016697195824235678\n",
      "Episode Reward: 7.0\n",
      "Step 930 (5559652) @ Episode 7247/10000, loss: 0.0122450347989797665\n",
      "Episode Reward: 15.0\n",
      "Step 347 (5559999) @ Episode 7248/10000, loss: 0.0024321973323822025\n",
      " Copied model parameters to target network\n",
      "Step 967 (5560619) @ Episode 7248/10000, loss: 0.0033863228745758533\n",
      "Episode Reward: 16.0\n",
      "Step 788 (5561407) @ Episode 7249/10000, loss: 0.0058513404801487926\n",
      "Episode Reward: 11.0\n",
      "Step 808 (5562215) @ Episode 7250/10000, loss: 0.0077382661402225494\n",
      "Episode Reward: 13.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 06:53:50,053] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video007250.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 566 (5562781) @ Episode 7251/10000, loss: 0.0044771311804652215\n",
      "Episode Reward: 7.0\n",
      "Step 543 (5563324) @ Episode 7252/10000, loss: 0.0182219352573156365\n",
      "Episode Reward: 9.0\n",
      "Step 472 (5563796) @ Episode 7253/10000, loss: 0.0024522303137928247\n",
      "Episode Reward: 6.0\n",
      "Step 683 (5564479) @ Episode 7254/10000, loss: 0.0047799199819564825\n",
      "Episode Reward: 14.0\n",
      "Step 688 (5565167) @ Episode 7255/10000, loss: 0.0076950732618570334\n",
      "Episode Reward: 13.0\n",
      "Step 960 (5566127) @ Episode 7256/10000, loss: 0.0167338736355304727\n",
      "Episode Reward: 18.0\n",
      "Step 524 (5566651) @ Episode 7257/10000, loss: 0.0088339466601610184\n",
      "Episode Reward: 8.0\n",
      "Step 815 (5567466) @ Episode 7258/10000, loss: 0.0040452331304550174\n",
      "Episode Reward: 18.0\n",
      "Step 1008 (5568474) @ Episode 7259/10000, loss: 0.0035015796311199665\n",
      "Episode Reward: 21.0\n",
      "Step 695 (5569169) @ Episode 7260/10000, loss: 0.0040400680154562964\n",
      "Episode Reward: 11.0\n",
      "Step 830 (5569999) @ Episode 7261/10000, loss: 0.0027945877518504865\n",
      " Copied model parameters to target network\n",
      "Step 915 (5570084) @ Episode 7261/10000, loss: 0.0305723436176776964\n",
      "Episode Reward: 14.0\n",
      "Step 792 (5570876) @ Episode 7262/10000, loss: 0.0053390827961266046\n",
      "Episode Reward: 13.0\n",
      "Step 755 (5571631) @ Episode 7263/10000, loss: 0.0029142741113901144\n",
      "Episode Reward: 18.0\n",
      "Step 1036 (5572667) @ Episode 7264/10000, loss: 0.0024357158690690994\n",
      "Episode Reward: 21.0\n",
      "Step 728 (5573395) @ Episode 7265/10000, loss: 0.0028952152933925394\n",
      "Episode Reward: 11.0\n",
      "Step 990 (5574385) @ Episode 7266/10000, loss: 0.0123019712045788763\n",
      "Episode Reward: 20.0\n",
      "Step 1071 (5575456) @ Episode 7267/10000, loss: 0.0192387420684099217\n",
      "Episode Reward: 15.0\n",
      "Step 747 (5576203) @ Episode 7268/10000, loss: 0.0081868879497051247\n",
      "Episode Reward: 12.0\n",
      "Step 930 (5577133) @ Episode 7269/10000, loss: 0.0031650182791054254\n",
      "Episode Reward: 20.0\n",
      "Step 739 (5577872) @ Episode 7270/10000, loss: 0.0032676672562956817\n",
      "Episode Reward: 14.0\n",
      "Step 825 (5578697) @ Episode 7271/10000, loss: 0.0031221066601574426\n",
      "Episode Reward: 17.0\n",
      "Step 473 (5579170) @ Episode 7272/10000, loss: 0.0047677266411483292\n",
      "Episode Reward: 7.0\n",
      "Step 829 (5579999) @ Episode 7273/10000, loss: 0.0114981606602668766\n",
      " Copied model parameters to target network\n",
      "Step 1309 (5580479) @ Episode 7273/10000, loss: 0.0052113104611635215\n",
      "Episode Reward: 35.0\n",
      "Step 800 (5581279) @ Episode 7274/10000, loss: 0.0074403691105544575\n",
      "Episode Reward: 13.0\n",
      "Step 749 (5582028) @ Episode 7275/10000, loss: 0.0045226337388157845\n",
      "Episode Reward: 12.0\n",
      "Step 550 (5582578) @ Episode 7276/10000, loss: 0.0028712225612252958\n",
      "Episode Reward: 7.0\n",
      "Step 1261 (5583839) @ Episode 7277/10000, loss: 0.0032042849343270063\n",
      "Episode Reward: 25.0\n",
      "Step 800 (5584639) @ Episode 7278/10000, loss: 0.0031944620423018932\n",
      "Episode Reward: 18.0\n",
      "Step 599 (5585238) @ Episode 7279/10000, loss: 0.0032170501071959734\n",
      "Episode Reward: 10.0\n",
      "Step 914 (5586152) @ Episode 7280/10000, loss: 0.0065193437039852144\n",
      "Episode Reward: 14.0\n",
      "Step 674 (5586826) @ Episode 7281/10000, loss: 0.0060568307526409632\n",
      "Episode Reward: 11.0\n",
      "Step 864 (5587690) @ Episode 7282/10000, loss: 0.0025596208870410927\n",
      "Episode Reward: 14.0\n",
      "Step 798 (5588488) @ Episode 7283/10000, loss: 0.0157962292432785033\n",
      "Episode Reward: 17.0\n",
      "Step 753 (5589241) @ Episode 7284/10000, loss: 0.0067829815670847897\n",
      "Episode Reward: 12.0\n",
      "Step 758 (5589999) @ Episode 7285/10000, loss: 0.0058614723384380348\n",
      " Copied model parameters to target network\n",
      "Step 940 (5590181) @ Episode 7285/10000, loss: 0.0041684503667056564\n",
      "Episode Reward: 14.0\n",
      "Step 895 (5591076) @ Episode 7286/10000, loss: 0.0030794716440141254\n",
      "Episode Reward: 14.0\n",
      "Step 658 (5591734) @ Episode 7287/10000, loss: 0.0078576235100626959\n",
      "Episode Reward: 11.0\n",
      "Step 781 (5592515) @ Episode 7288/10000, loss: 0.0033096300903707743\n",
      "Episode Reward: 16.0\n",
      "Step 949 (5593464) @ Episode 7289/10000, loss: 0.0057995375245809555\n",
      "Episode Reward: 20.0\n",
      "Step 512 (5593976) @ Episode 7290/10000, loss: 0.0078806076198816386\n",
      "Episode Reward: 8.0\n",
      "Step 1208 (5595184) @ Episode 7291/10000, loss: 0.0077060768380761155\n",
      "Episode Reward: 26.0\n",
      "Step 483 (5595667) @ Episode 7292/10000, loss: 0.0060692452825605875\n",
      "Episode Reward: 10.0\n",
      "Step 950 (5596617) @ Episode 7293/10000, loss: 0.0021765904966741837\n",
      "Episode Reward: 23.0\n",
      "Step 759 (5597376) @ Episode 7294/10000, loss: 0.0086879394948482515\n",
      "Episode Reward: 11.0\n",
      "Step 952 (5598328) @ Episode 7295/10000, loss: 0.0046278773806989193\n",
      "Episode Reward: 14.0\n",
      "Step 1372 (5599700) @ Episode 7296/10000, loss: 0.0036765416152775288\n",
      "Episode Reward: 25.0\n",
      "Step 299 (5599999) @ Episode 7297/10000, loss: 0.0053872494027018554\n",
      " Copied model parameters to target network\n",
      "Step 1201 (5600901) @ Episode 7297/10000, loss: 0.0025462068151682615\n",
      "Episode Reward: 18.0\n",
      "Step 979 (5601880) @ Episode 7298/10000, loss: 0.0114610595628619206\n",
      "Episode Reward: 16.0\n",
      "Step 806 (5602686) @ Episode 7299/10000, loss: 0.0030199105385690928\n",
      "Episode Reward: 14.0\n",
      "Step 1053 (5603739) @ Episode 7300/10000, loss: 0.0022107276599854233\n",
      "Episode Reward: 20.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 07:00:17,327] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video007300.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 834 (5604573) @ Episode 7301/10000, loss: 0.0087030930444598245\n",
      "Episode Reward: 13.0\n",
      "Step 843 (5605416) @ Episode 7302/10000, loss: 0.0093988012522459033\n",
      "Episode Reward: 13.0\n",
      "Step 1006 (5606422) @ Episode 7303/10000, loss: 0.0035792742855846887\n",
      "Episode Reward: 17.0\n",
      "Step 869 (5607291) @ Episode 7304/10000, loss: 0.0050961249507963665\n",
      "Episode Reward: 16.0\n",
      "Step 1169 (5608460) @ Episode 7305/10000, loss: 0.0064322473481297496\n",
      "Episode Reward: 24.0\n",
      "Step 678 (5609138) @ Episode 7306/10000, loss: 0.0377358645200729474\n",
      "Episode Reward: 12.0\n",
      "Step 779 (5609917) @ Episode 7307/10000, loss: 0.0300350319594144827\n",
      "Episode Reward: 17.0\n",
      "Step 82 (5609999) @ Episode 7308/10000, loss: 0.0049439403228461745\n",
      " Copied model parameters to target network\n",
      "Step 489 (5610406) @ Episode 7308/10000, loss: 0.0058795558288693438\n",
      "Episode Reward: 7.0\n",
      "Step 883 (5611289) @ Episode 7309/10000, loss: 0.0028347519692033536\n",
      "Episode Reward: 12.0\n",
      "Step 416 (5611705) @ Episode 7310/10000, loss: 0.0034800022840499885\n",
      "Episode Reward: 13.0\n",
      "Step 677 (5612382) @ Episode 7311/10000, loss: 0.0032217178959399465\n",
      "Episode Reward: 11.0\n",
      "Step 760 (5613142) @ Episode 7312/10000, loss: 0.0025192836765199977\n",
      "Episode Reward: 15.0\n",
      "Step 777 (5613919) @ Episode 7313/10000, loss: 0.0180482547730207444\n",
      "Episode Reward: 12.0\n",
      "Step 1105 (5615024) @ Episode 7314/10000, loss: 0.0050104432739317425\n",
      "Episode Reward: 20.0\n",
      "Step 927 (5615951) @ Episode 7315/10000, loss: 0.0041120070964097987\n",
      "Episode Reward: 22.0\n",
      "Step 903 (5616854) @ Episode 7316/10000, loss: 0.0220574662089347843\n",
      "Episode Reward: 17.0\n",
      "Step 1105 (5617959) @ Episode 7317/10000, loss: 0.0030647825915366415\n",
      "Episode Reward: 27.0\n",
      "Step 546 (5618505) @ Episode 7318/10000, loss: 0.0021126787178218365\n",
      "Episode Reward: 8.0\n",
      "Step 959 (5619464) @ Episode 7319/10000, loss: 0.0018492934759706259\n",
      "Episode Reward: 20.0\n",
      "Step 535 (5619999) @ Episode 7320/10000, loss: 0.0062922257930040366\n",
      " Copied model parameters to target network\n",
      "Step 606 (5620070) @ Episode 7320/10000, loss: 0.0064849304035305987\n",
      "Episode Reward: 9.0\n",
      "Step 454 (5620524) @ Episode 7321/10000, loss: 0.0098984073847532275\n",
      "Episode Reward: 6.0\n",
      "Step 594 (5621118) @ Episode 7322/10000, loss: 0.0539219491183757894\n",
      "Episode Reward: 12.0\n",
      "Step 904 (5622022) @ Episode 7323/10000, loss: 0.0040932297706604295\n",
      "Episode Reward: 14.0\n",
      "Step 1068 (5623090) @ Episode 7324/10000, loss: 0.0055173449218273165\n",
      "Episode Reward: 19.0\n",
      "Step 932 (5624022) @ Episode 7325/10000, loss: 0.0026023588143289097\n",
      "Episode Reward: 16.0\n",
      "Step 743 (5624765) @ Episode 7326/10000, loss: 0.0036900267004966736\n",
      "Episode Reward: 16.0\n",
      "Step 612 (5625377) @ Episode 7327/10000, loss: 0.0045582642778754232\n",
      "Episode Reward: 9.0\n",
      "Step 734 (5626111) @ Episode 7328/10000, loss: 0.0053170518949627884\n",
      "Episode Reward: 13.0\n",
      "Step 728 (5626839) @ Episode 7329/10000, loss: 0.0022064824588596825\n",
      "Episode Reward: 12.0\n",
      "Step 782 (5627621) @ Episode 7330/10000, loss: 0.0038225003518164168\n",
      "Episode Reward: 11.0\n",
      "Step 779 (5628400) @ Episode 7331/10000, loss: 0.0033726887777447788\n",
      "Episode Reward: 13.0\n",
      "Step 743 (5629143) @ Episode 7332/10000, loss: 0.0030668342951685192\n",
      "Episode Reward: 11.0\n",
      "Step 856 (5629999) @ Episode 7333/10000, loss: 0.0041893562301993372\n",
      " Copied model parameters to target network\n",
      "Step 1239 (5630382) @ Episode 7333/10000, loss: 0.0048039276152849201\n",
      "Episode Reward: 30.0\n",
      "Step 564 (5630946) @ Episode 7334/10000, loss: 0.0037579592317342768\n",
      "Episode Reward: 8.0\n",
      "Step 837 (5631783) @ Episode 7335/10000, loss: 0.0059959292411804276\n",
      "Episode Reward: 13.0\n",
      "Step 706 (5632489) @ Episode 7336/10000, loss: 0.0074062542989850046\n",
      "Episode Reward: 11.0\n",
      "Step 686 (5633175) @ Episode 7337/10000, loss: 0.0040403315797448166\n",
      "Episode Reward: 10.0\n",
      "Step 956 (5634131) @ Episode 7338/10000, loss: 0.0036508219782263046\n",
      "Episode Reward: 17.0\n",
      "Step 734 (5634865) @ Episode 7339/10000, loss: 0.0070613604038953785\n",
      "Episode Reward: 10.0\n",
      "Step 1007 (5635872) @ Episode 7340/10000, loss: 0.0048467619344592094\n",
      "Episode Reward: 16.0\n",
      "Step 855 (5636727) @ Episode 7341/10000, loss: 0.0067652580328285695\n",
      "Episode Reward: 14.0\n",
      "Step 901 (5637628) @ Episode 7342/10000, loss: 0.0055401665158569817\n",
      "Episode Reward: 19.0\n",
      "Step 786 (5638414) @ Episode 7343/10000, loss: 0.0042792130261659624\n",
      "Episode Reward: 13.0\n",
      "Step 1055 (5639469) @ Episode 7344/10000, loss: 0.0060731051489710815\n",
      "Episode Reward: 25.0\n",
      "Step 530 (5639999) @ Episode 7345/10000, loss: 0.0024928078055381775\n",
      " Copied model parameters to target network\n",
      "Step 610 (5640079) @ Episode 7345/10000, loss: 0.0151908397674560558\n",
      "Episode Reward: 8.0\n",
      "Step 755 (5640834) @ Episode 7346/10000, loss: 0.0023722839541733265\n",
      "Episode Reward: 10.0\n",
      "Step 859 (5641693) @ Episode 7347/10000, loss: 0.0093966815620660787\n",
      "Episode Reward: 17.0\n",
      "Step 1157 (5642850) @ Episode 7348/10000, loss: 0.0068189781159162525\n",
      "Episode Reward: 24.0\n",
      "Step 1110 (5643960) @ Episode 7349/10000, loss: 0.0140250222757458695\n",
      "Episode Reward: 20.0\n",
      "Step 728 (5644688) @ Episode 7350/10000, loss: 0.0145139321684837346\n",
      "Episode Reward: 10.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 07:06:41,659] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video007350.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 982 (5645670) @ Episode 7351/10000, loss: 0.0053735482506453994\n",
      "Episode Reward: 18.0\n",
      "Step 923 (5646593) @ Episode 7352/10000, loss: 0.0035940362140536315\n",
      "Episode Reward: 17.0\n",
      "Step 912 (5647505) @ Episode 7353/10000, loss: 0.0111738853156566627\n",
      "Episode Reward: 17.0\n",
      "Step 864 (5648369) @ Episode 7354/10000, loss: 0.0031601497903466225\n",
      "Episode Reward: 21.0\n",
      "Step 924 (5649293) @ Episode 7355/10000, loss: 0.0043861246667802338\n",
      "Episode Reward: 20.0\n",
      "Step 687 (5649980) @ Episode 7356/10000, loss: 0.0088764606043696432\n",
      "Episode Reward: 11.0\n",
      "Step 19 (5649999) @ Episode 7357/10000, loss: 0.0022424831986427307\n",
      " Copied model parameters to target network\n",
      "Step 1224 (5651204) @ Episode 7357/10000, loss: 0.0032438430935144424\n",
      "Episode Reward: 20.0\n",
      "Step 808 (5652012) @ Episode 7358/10000, loss: 0.0024366839788854125\n",
      "Episode Reward: 16.0\n",
      "Step 826 (5652838) @ Episode 7359/10000, loss: 0.0100372759625315677\n",
      "Episode Reward: 17.0\n",
      "Step 632 (5653470) @ Episode 7360/10000, loss: 0.0045714140869677075\n",
      "Episode Reward: 8.0\n",
      "Step 710 (5654180) @ Episode 7361/10000, loss: 0.0018148241797462106\n",
      "Episode Reward: 17.0\n",
      "Step 508 (5654688) @ Episode 7362/10000, loss: 0.0095406593754887583\n",
      "Episode Reward: 7.0\n",
      "Step 1043 (5655731) @ Episode 7363/10000, loss: 0.0026905057020485494\n",
      "Episode Reward: 16.0\n",
      "Step 664 (5656395) @ Episode 7364/10000, loss: 0.0152039406821131756\n",
      "Episode Reward: 10.0\n",
      "Step 907 (5657302) @ Episode 7365/10000, loss: 0.0081211663782596596\n",
      "Episode Reward: 21.0\n",
      "Step 1068 (5658370) @ Episode 7366/10000, loss: 0.0101315379142761235\n",
      "Episode Reward: 24.0\n",
      "Step 1284 (5659654) @ Episode 7367/10000, loss: 0.0027116951532661915\n",
      "Episode Reward: 28.0\n",
      "Step 345 (5659999) @ Episode 7368/10000, loss: 0.0036733255255967383\n",
      " Copied model parameters to target network\n",
      "Step 674 (5660328) @ Episode 7368/10000, loss: 0.0050117829814553265\n",
      "Episode Reward: 12.0\n",
      "Step 720 (5661048) @ Episode 7369/10000, loss: 0.0027909642085433006\n",
      "Episode Reward: 12.0\n",
      "Step 707 (5661755) @ Episode 7370/10000, loss: 0.0063499328680336475\n",
      "Episode Reward: 17.0\n",
      "Step 697 (5662452) @ Episode 7371/10000, loss: 0.0021470135543495417\n",
      "Episode Reward: 10.0\n",
      "Step 813 (5663265) @ Episode 7372/10000, loss: 0.0032255577389150868\n",
      "Episode Reward: 20.0\n",
      "Step 720 (5663985) @ Episode 7373/10000, loss: 0.0021501723676919937\n",
      "Episode Reward: 10.0\n",
      "Step 1086 (5665071) @ Episode 7374/10000, loss: 0.0046186223626136786\n",
      "Episode Reward: 17.0\n",
      "Step 523 (5665594) @ Episode 7375/10000, loss: 0.0035284985788166523\n",
      "Episode Reward: 6.0\n",
      "Step 832 (5666426) @ Episode 7376/10000, loss: 0.0145969651639461527\n",
      "Episode Reward: 17.0\n",
      "Step 1193 (5667619) @ Episode 7377/10000, loss: 0.0019130995497107506\n",
      "Episode Reward: 22.0\n",
      "Step 669 (5668288) @ Episode 7378/10000, loss: 0.0055630942806601524\n",
      "Episode Reward: 11.0\n",
      "Step 765 (5669053) @ Episode 7379/10000, loss: 0.0040154037997126586\n",
      "Episode Reward: 12.0\n",
      "Step 802 (5669855) @ Episode 7380/10000, loss: 0.0087785311043262485\n",
      "Episode Reward: 13.0\n",
      "Step 144 (5669999) @ Episode 7381/10000, loss: 0.0038116348441690207\n",
      " Copied model parameters to target network\n",
      "Step 946 (5670801) @ Episode 7381/10000, loss: 0.0121469777077436457\n",
      "Episode Reward: 19.0\n",
      "Step 698 (5671499) @ Episode 7382/10000, loss: 0.0105400234460830694\n",
      "Episode Reward: 11.0\n",
      "Step 748 (5672247) @ Episode 7383/10000, loss: 0.0661410093307495154\n",
      "Episode Reward: 13.0\n",
      "Step 705 (5672952) @ Episode 7384/10000, loss: 0.0056181345134973536\n",
      "Episode Reward: 15.0\n",
      "Step 931 (5673883) @ Episode 7385/10000, loss: 0.0036226378288120037\n",
      "Episode Reward: 15.0\n",
      "Step 803 (5674686) @ Episode 7386/10000, loss: 0.0119267124682664877\n",
      "Episode Reward: 17.0\n",
      "Step 666 (5675352) @ Episode 7387/10000, loss: 0.0032789870165288452\n",
      "Episode Reward: 9.0\n",
      "Step 898 (5676250) @ Episode 7388/10000, loss: 0.0013692266074940562\n",
      "Episode Reward: 15.0\n",
      "Step 1052 (5677302) @ Episode 7389/10000, loss: 0.0051057054661214357\n",
      "Episode Reward: 22.0\n",
      "Step 538 (5677840) @ Episode 7390/10000, loss: 0.0063900756649672985\n",
      "Episode Reward: 7.0\n",
      "Step 741 (5678581) @ Episode 7391/10000, loss: 0.0067891553044319156\n",
      "Episode Reward: 13.0\n",
      "Step 1114 (5679695) @ Episode 7392/10000, loss: 0.0050667938776314267\n",
      "Episode Reward: 20.0\n",
      "Step 304 (5679999) @ Episode 7393/10000, loss: 0.0053630857728421697\n",
      " Copied model parameters to target network\n",
      "Step 801 (5680496) @ Episode 7393/10000, loss: 0.0031248687300831085\n",
      "Episode Reward: 12.0\n",
      "Step 896 (5681392) @ Episode 7394/10000, loss: 0.0033055078238248825\n",
      "Episode Reward: 16.0\n",
      "Step 891 (5682283) @ Episode 7395/10000, loss: 0.0032242131419479847\n",
      "Episode Reward: 17.0\n",
      "Step 947 (5683230) @ Episode 7396/10000, loss: 0.0090843178331851967\n",
      "Episode Reward: 20.0\n",
      "Step 804 (5684034) @ Episode 7397/10000, loss: 0.0149807194247841846\n",
      "Episode Reward: 13.0\n",
      "Step 618 (5684652) @ Episode 7398/10000, loss: 0.0066656009294092655\n",
      "Episode Reward: 10.0\n",
      "Step 642 (5685294) @ Episode 7399/10000, loss: 0.0850913226604461724\n",
      "Episode Reward: 11.0\n",
      "Step 1088 (5686382) @ Episode 7400/10000, loss: 0.0018651138525456195\n",
      "Episode Reward: 27.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 07:13:09,396] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video007400.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 932 (5687314) @ Episode 7401/10000, loss: 0.0022261831909418106\n",
      "Episode Reward: 20.0\n",
      "Step 897 (5688211) @ Episode 7402/10000, loss: 0.0083639519289135932\n",
      "Episode Reward: 16.0\n",
      "Step 838 (5689049) @ Episode 7403/10000, loss: 0.0019728355109691626\n",
      "Episode Reward: 11.0\n",
      "Step 950 (5689999) @ Episode 7404/10000, loss: 0.0066472408361732967\n",
      " Copied model parameters to target network\n",
      "Step 996 (5690045) @ Episode 7404/10000, loss: 0.0048113451339304455\n",
      "Episode Reward: 18.0\n",
      "Step 1243 (5691288) @ Episode 7405/10000, loss: 0.0084589282050728815\n",
      "Episode Reward: 29.0\n",
      "Step 1076 (5692364) @ Episode 7406/10000, loss: 0.0043458458967506886\n",
      "Episode Reward: 25.0\n",
      "Step 807 (5693171) @ Episode 7407/10000, loss: 0.0046449061483144767\n",
      "Episode Reward: 14.0\n",
      "Step 500 (5693671) @ Episode 7408/10000, loss: 0.0058927368372678763\n",
      "Episode Reward: 8.0\n",
      "Step 662 (5694333) @ Episode 7409/10000, loss: 0.0025543239898979664\n",
      "Episode Reward: 10.0\n",
      "Step 515 (5694848) @ Episode 7410/10000, loss: 0.0038253362290561215\n",
      "Episode Reward: 7.0\n",
      "Step 600 (5695448) @ Episode 7411/10000, loss: 0.0064794057980179796\n",
      "Episode Reward: 9.0\n",
      "Step 1006 (5696454) @ Episode 7412/10000, loss: 0.007366777863353491\n",
      "Episode Reward: 20.0\n",
      "Step 1065 (5697519) @ Episode 7413/10000, loss: 0.0111266011372208666\n",
      "Episode Reward: 16.0\n",
      "Step 571 (5698090) @ Episode 7414/10000, loss: 0.0013939285418018699\n",
      "Episode Reward: 9.0\n",
      "Step 901 (5698991) @ Episode 7415/10000, loss: 0.0087726293131709117\n",
      "Episode Reward: 16.0\n",
      "Step 1008 (5699999) @ Episode 7416/10000, loss: 0.0023702192120254045\n",
      " Copied model parameters to target network\n",
      "Step 1308 (5700299) @ Episode 7416/10000, loss: 0.0020171951036900283\n",
      "Episode Reward: 30.0\n",
      "Step 503 (5700802) @ Episode 7417/10000, loss: 0.0027254044543951753\n",
      "Episode Reward: 6.0\n",
      "Step 879 (5701681) @ Episode 7418/10000, loss: 0.0027649332769215107\n",
      "Episode Reward: 16.0\n",
      "Step 880 (5702561) @ Episode 7419/10000, loss: 0.0066063776612281895\n",
      "Episode Reward: 18.0\n",
      "Step 278 (5702839) @ Episode 7420/10000, loss: 0.0060863220132887364\n",
      "Episode Reward: 3.0\n",
      "Step 823 (5703662) @ Episode 7421/10000, loss: 0.0038134194910526276\n",
      "Episode Reward: 13.0\n",
      "Step 973 (5704635) @ Episode 7422/10000, loss: 0.0013395826099440455\n",
      "Episode Reward: 16.0\n",
      "Step 1065 (5705700) @ Episode 7423/10000, loss: 0.0060037188231945045\n",
      "Episode Reward: 18.0\n",
      "Step 1074 (5706774) @ Episode 7424/10000, loss: 0.0070908451452851295\n",
      "Episode Reward: 20.0\n",
      "Step 899 (5707673) @ Episode 7425/10000, loss: 0.0154360001906752597\n",
      "Episode Reward: 14.0\n",
      "Step 688 (5708361) @ Episode 7426/10000, loss: 0.0099784974008798667\n",
      "Episode Reward: 11.0\n",
      "Step 965 (5709326) @ Episode 7427/10000, loss: 0.0018690477591007948\n",
      "Episode Reward: 22.0\n",
      "Step 673 (5709999) @ Episode 7428/10000, loss: 0.0065906178206205375\n",
      " Copied model parameters to target network\n",
      "Step 747 (5710073) @ Episode 7428/10000, loss: 0.0041203266009688385\n",
      "Episode Reward: 13.0\n",
      "Step 791 (5710864) @ Episode 7429/10000, loss: 0.0098369922488927843\n",
      "Episode Reward: 12.0\n",
      "Step 764 (5711628) @ Episode 7430/10000, loss: 0.0023031211458146577\n",
      "Episode Reward: 12.0\n",
      "Step 1027 (5712655) @ Episode 7431/10000, loss: 0.0099736917763948446\n",
      "Episode Reward: 15.0\n",
      "Step 776 (5713431) @ Episode 7432/10000, loss: 0.0270783156156539986\n",
      "Episode Reward: 12.0\n",
      "Step 1053 (5714484) @ Episode 7433/10000, loss: 0.0211682375520467764\n",
      "Episode Reward: 23.0\n",
      "Step 931 (5715415) @ Episode 7434/10000, loss: 0.0045367050915956595\n",
      "Episode Reward: 15.0\n",
      "Step 833 (5716248) @ Episode 7435/10000, loss: 0.0039093103259801865\n",
      "Episode Reward: 12.0\n",
      "Step 955 (5717203) @ Episode 7436/10000, loss: 0.0341848842799663544\n",
      "Episode Reward: 17.0\n",
      "Step 534 (5717737) @ Episode 7437/10000, loss: 0.0096146203577518465\n",
      "Episode Reward: 11.0\n",
      "Step 1013 (5718750) @ Episode 7438/10000, loss: 0.0040732328779995446\n",
      "Episode Reward: 24.0\n",
      "Step 475 (5719225) @ Episode 7439/10000, loss: 0.0031782658770680428\n",
      "Episode Reward: 8.0\n",
      "Step 601 (5719826) @ Episode 7440/10000, loss: 0.0055440058931708344\n",
      "Episode Reward: 9.0\n",
      "Step 173 (5719999) @ Episode 7441/10000, loss: 0.0082402424886822787\n",
      " Copied model parameters to target network\n",
      "Step 726 (5720552) @ Episode 7441/10000, loss: 0.0069430745206773288\n",
      "Episode Reward: 12.0\n",
      "Step 723 (5721275) @ Episode 7442/10000, loss: 0.0037958156317472467\n",
      "Episode Reward: 11.0\n",
      "Step 813 (5722088) @ Episode 7443/10000, loss: 0.0037412969395518303\n",
      "Episode Reward: 14.0\n",
      "Step 1050 (5723138) @ Episode 7444/10000, loss: 0.0024598678573966026\n",
      "Episode Reward: 23.0\n",
      "Step 698 (5723836) @ Episode 7445/10000, loss: 0.0078569902107119565\n",
      "Episode Reward: 11.0\n",
      "Step 944 (5724780) @ Episode 7446/10000, loss: 0.0042445370927453044\n",
      "Episode Reward: 21.0\n",
      "Step 660 (5725440) @ Episode 7447/10000, loss: 0.0026782983914017677\n",
      "Episode Reward: 12.0\n",
      "Step 811 (5726251) @ Episode 7448/10000, loss: 0.0756144300103187615\n",
      "Episode Reward: 17.0\n",
      "Step 971 (5727222) @ Episode 7449/10000, loss: 0.0028594639152288437\n",
      "Episode Reward: 18.0\n",
      "Step 610 (5727832) @ Episode 7450/10000, loss: 0.0041374550200998783\n",
      "Episode Reward: 11.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 07:19:39,699] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video007450.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1313 (5729145) @ Episode 7451/10000, loss: 0.0051146904006600385\n",
      "Episode Reward: 30.0\n",
      "Step 774 (5729919) @ Episode 7452/10000, loss: 0.0059483041986823085\n",
      "Episode Reward: 12.0\n",
      "Step 80 (5729999) @ Episode 7453/10000, loss: 0.0072272815741598616\n",
      " Copied model parameters to target network\n",
      "Step 1126 (5731045) @ Episode 7453/10000, loss: 0.0039284047670662468\n",
      "Episode Reward: 23.0\n",
      "Step 555 (5731600) @ Episode 7454/10000, loss: 0.0063470299355685714\n",
      "Episode Reward: 6.0\n",
      "Step 1010 (5732610) @ Episode 7455/10000, loss: 0.0040839645080268386\n",
      "Episode Reward: 27.0\n",
      "Step 1219 (5733829) @ Episode 7456/10000, loss: 0.0023523268755525357\n",
      "Episode Reward: 23.0\n",
      "Step 686 (5734515) @ Episode 7457/10000, loss: 0.0054696802981197836\n",
      "Episode Reward: 11.0\n",
      "Step 594 (5735109) @ Episode 7458/10000, loss: 0.0061226692050695427\n",
      "Episode Reward: 11.0\n",
      "Step 898 (5736007) @ Episode 7459/10000, loss: 0.0331779345870018338\n",
      "Episode Reward: 25.0\n",
      "Step 869 (5736876) @ Episode 7460/10000, loss: 0.0072283865883946422\n",
      "Episode Reward: 15.0\n",
      "Step 726 (5737602) @ Episode 7461/10000, loss: 0.0046197474002838135\n",
      "Episode Reward: 10.0\n",
      "Step 988 (5738590) @ Episode 7462/10000, loss: 0.0023953998461365763\n",
      "Episode Reward: 16.0\n",
      "Step 828 (5739418) @ Episode 7463/10000, loss: 0.0016711064381524925\n",
      "Episode Reward: 18.0\n",
      "Step 581 (5739999) @ Episode 7464/10000, loss: 0.0176958609372377494\n",
      " Copied model parameters to target network\n",
      "Step 590 (5740008) @ Episode 7464/10000, loss: 0.0040466329082846647\n",
      "Episode Reward: 14.0\n",
      "Step 682 (5740690) @ Episode 7465/10000, loss: 0.0057497592642903337\n",
      "Episode Reward: 9.0\n",
      "Step 1030 (5741720) @ Episode 7466/10000, loss: 0.0015116707654669884\n",
      "Episode Reward: 18.0\n",
      "Step 696 (5742416) @ Episode 7467/10000, loss: 0.0070363404229283335\n",
      "Episode Reward: 14.0\n",
      "Step 828 (5743244) @ Episode 7468/10000, loss: 0.0073438561521470556\n",
      "Episode Reward: 12.0\n",
      "Step 724 (5743968) @ Episode 7469/10000, loss: 0.0059978500939905642\n",
      "Episode Reward: 8.0\n",
      "Step 979 (5744947) @ Episode 7470/10000, loss: 0.0034603413660079243\n",
      "Episode Reward: 17.0\n",
      "Step 890 (5745837) @ Episode 7471/10000, loss: 0.0079039977863430987\n",
      "Episode Reward: 21.0\n",
      "Step 1024 (5746861) @ Episode 7472/10000, loss: 0.0074784639291465284\n",
      "Episode Reward: 18.0\n",
      "Step 910 (5747771) @ Episode 7473/10000, loss: 0.0031687656883150344\n",
      "Episode Reward: 20.0\n",
      "Step 1007 (5748778) @ Episode 7474/10000, loss: 0.0034543548244982965\n",
      "Episode Reward: 24.0\n",
      "Step 1058 (5749836) @ Episode 7475/10000, loss: 0.0146414265036582957\n",
      "Episode Reward: 20.0\n",
      "Step 163 (5749999) @ Episode 7476/10000, loss: 0.0145083982497453695\n",
      " Copied model parameters to target network\n",
      "Step 1433 (5751269) @ Episode 7476/10000, loss: 0.0017021099338307977\n",
      "Episode Reward: 35.0\n",
      "Step 991 (5752260) @ Episode 7477/10000, loss: 0.0050901426002383234\n",
      "Episode Reward: 16.0\n",
      "Step 475 (5752735) @ Episode 7478/10000, loss: 0.0053109265863895423\n",
      "Episode Reward: 7.0\n",
      "Step 835 (5753570) @ Episode 7479/10000, loss: 0.0051913061179220685\n",
      "Episode Reward: 14.0\n",
      "Step 651 (5754221) @ Episode 7480/10000, loss: 0.0048956191167235374\n",
      "Episode Reward: 8.0\n",
      "Step 639 (5754860) @ Episode 7481/10000, loss: 0.0199559256434440645\n",
      "Episode Reward: 12.0\n",
      "Step 564 (5755424) @ Episode 7482/10000, loss: 0.0034249888267368085\n",
      "Episode Reward: 8.0\n",
      "Step 797 (5756221) @ Episode 7483/10000, loss: 0.0022817221470177174\n",
      "Episode Reward: 12.0\n",
      "Step 893 (5757114) @ Episode 7484/10000, loss: 0.0161637309938669235\n",
      "Episode Reward: 12.0\n",
      "Step 792 (5757906) @ Episode 7485/10000, loss: 0.0127737792208790786\n",
      "Episode Reward: 16.0\n",
      "Step 539 (5758445) @ Episode 7486/10000, loss: 0.0073778671212494375\n",
      "Episode Reward: 8.0\n",
      "Step 533 (5758978) @ Episode 7487/10000, loss: 0.0024948124773800373\n",
      "Episode Reward: 8.0\n",
      "Step 736 (5759714) @ Episode 7488/10000, loss: 0.0210147053003311165\n",
      "Episode Reward: 11.0\n",
      "Step 285 (5759999) @ Episode 7489/10000, loss: 0.0029116361401975155\n",
      " Copied model parameters to target network\n",
      "Step 641 (5760355) @ Episode 7489/10000, loss: 0.0059917513281106956\n",
      "Episode Reward: 10.0\n",
      "Step 992 (5761347) @ Episode 7490/10000, loss: 0.0066949296742677693\n",
      "Episode Reward: 16.0\n",
      "Step 691 (5762038) @ Episode 7491/10000, loss: 0.0038427910767495632\n",
      "Episode Reward: 9.0\n",
      "Step 498 (5762536) @ Episode 7492/10000, loss: 0.0092987334355711941\n",
      "Episode Reward: 7.0\n",
      "Step 1068 (5763604) @ Episode 7493/10000, loss: 0.1171397939324379165\n",
      "Episode Reward: 24.0\n",
      "Step 832 (5764436) @ Episode 7494/10000, loss: 0.0038613730575889353\n",
      "Episode Reward: 15.0\n",
      "Step 754 (5765190) @ Episode 7495/10000, loss: 0.0042670257389545447\n",
      "Episode Reward: 14.0\n",
      "Step 620 (5765810) @ Episode 7496/10000, loss: 0.0037983315996825695\n",
      "Episode Reward: 9.0\n",
      "Step 728 (5766538) @ Episode 7497/10000, loss: 0.0080642960965633485\n",
      "Episode Reward: 18.0\n",
      "Step 799 (5767337) @ Episode 7498/10000, loss: 0.0083973314613103875\n",
      "Episode Reward: 18.0\n",
      "Step 554 (5767891) @ Episode 7499/10000, loss: 0.0030955779366195225\n",
      "Episode Reward: 8.0\n",
      "Step 697 (5768588) @ Episode 7500/10000, loss: 0.0190391205251216936\n",
      "Episode Reward: 12.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 07:26:01,962] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video007500.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1019 (5769607) @ Episode 7501/10000, loss: 0.0046892808750271823\n",
      "Episode Reward: 20.0\n",
      "Step 392 (5769999) @ Episode 7502/10000, loss: 0.0034863557666540146\n",
      " Copied model parameters to target network\n",
      "Step 664 (5770271) @ Episode 7502/10000, loss: 0.0026967464946210384\n",
      "Episode Reward: 10.0\n",
      "Step 807 (5771078) @ Episode 7503/10000, loss: 0.0023947355803102255\n",
      "Episode Reward: 11.0\n",
      "Step 806 (5771884) @ Episode 7504/10000, loss: 0.0013587318826466799\n",
      "Episode Reward: 10.0\n",
      "Step 778 (5772662) @ Episode 7505/10000, loss: 0.0508582219481468235\n",
      "Episode Reward: 13.0\n",
      "Step 486 (5773148) @ Episode 7506/10000, loss: 0.0060704532079398631\n",
      "Episode Reward: 6.0\n",
      "Step 358 (5773506) @ Episode 7507/10000, loss: 0.0067616486921906477\n",
      "Episode Reward: 4.0\n",
      "Step 703 (5774209) @ Episode 7508/10000, loss: 0.0017005590489134192\n",
      "Episode Reward: 13.0\n",
      "Step 681 (5774890) @ Episode 7509/10000, loss: 0.0019127056002616882\n",
      "Episode Reward: 10.0\n",
      "Step 954 (5775844) @ Episode 7510/10000, loss: 0.0061638206243515015\n",
      "Episode Reward: 20.0\n",
      "Step 590 (5776434) @ Episode 7511/10000, loss: 0.0082385651767253887\n",
      "Episode Reward: 7.0\n",
      "Step 754 (5777188) @ Episode 7512/10000, loss: 0.0031731505878269672\n",
      "Episode Reward: 13.0\n",
      "Step 854 (5778042) @ Episode 7513/10000, loss: 0.0077855251729488375\n",
      "Episode Reward: 14.0\n",
      "Step 661 (5778703) @ Episode 7514/10000, loss: 0.0068850079551339155\n",
      "Episode Reward: 9.0\n",
      "Step 759 (5779462) @ Episode 7515/10000, loss: 0.0085962684825062756\n",
      "Episode Reward: 11.0\n",
      "Step 537 (5779999) @ Episode 7516/10000, loss: 0.0083996746689081224\n",
      " Copied model parameters to target network\n",
      "Step 1043 (5780505) @ Episode 7516/10000, loss: 0.0085726119577884676\n",
      "Episode Reward: 18.0\n",
      "Step 513 (5781018) @ Episode 7517/10000, loss: 0.0066476585343480117\n",
      "Episode Reward: 8.0\n",
      "Step 798 (5781816) @ Episode 7518/10000, loss: 0.0039858315140008934\n",
      "Episode Reward: 12.0\n",
      "Step 805 (5782621) @ Episode 7519/10000, loss: 0.0055173053406178953\n",
      "Episode Reward: 18.0\n",
      "Step 928 (5783549) @ Episode 7520/10000, loss: 0.0066827074624598034\n",
      "Episode Reward: 16.0\n",
      "Step 690 (5784239) @ Episode 7521/10000, loss: 0.0035727382637560368\n",
      "Episode Reward: 11.0\n",
      "Step 795 (5785034) @ Episode 7522/10000, loss: 0.0167321115732193237\n",
      "Episode Reward: 12.0\n",
      "Step 736 (5785770) @ Episode 7523/10000, loss: 0.0147310448810458185\n",
      "Episode Reward: 13.0\n",
      "Step 759 (5786529) @ Episode 7524/10000, loss: 0.0031975447200238705\n",
      "Episode Reward: 12.0\n",
      "Step 905 (5787434) @ Episode 7525/10000, loss: 0.0101787773892283446\n",
      "Episode Reward: 22.0\n",
      "Step 412 (5787846) @ Episode 7526/10000, loss: 0.0040260618552565575\n",
      "Episode Reward: 5.0\n",
      "Step 976 (5788822) @ Episode 7527/10000, loss: 0.0043666083365678796\n",
      "Episode Reward: 27.0\n",
      "Step 894 (5789716) @ Episode 7528/10000, loss: 0.0175140015780925754\n",
      "Episode Reward: 20.0\n",
      "Step 283 (5789999) @ Episode 7529/10000, loss: 0.0018031408544629812\n",
      " Copied model parameters to target network\n",
      "Step 728 (5790444) @ Episode 7529/10000, loss: 0.0042389128357172017\n",
      "Episode Reward: 14.0\n",
      "Step 879 (5791323) @ Episode 7530/10000, loss: 0.0105606419965624817\n",
      "Episode Reward: 14.0\n",
      "Step 959 (5792282) @ Episode 7531/10000, loss: 0.0030178716406226166\n",
      "Episode Reward: 19.0\n",
      "Step 737 (5793019) @ Episode 7532/10000, loss: 0.0088034123182296756\n",
      "Episode Reward: 14.0\n",
      "Step 839 (5793858) @ Episode 7533/10000, loss: 0.0026551433838903904\n",
      "Episode Reward: 13.0\n",
      "Step 564 (5794422) @ Episode 7534/10000, loss: 0.0247446317225694667\n",
      "Episode Reward: 8.0\n",
      "Step 901 (5795323) @ Episode 7535/10000, loss: 0.0085260905325412755\n",
      "Episode Reward: 19.0\n",
      "Step 723 (5796046) @ Episode 7536/10000, loss: 0.0055993534624576576\n",
      "Episode Reward: 15.0\n",
      "Step 739 (5796785) @ Episode 7537/10000, loss: 0.1255602240562439975\n",
      "Episode Reward: 12.0\n",
      "Step 1128 (5797913) @ Episode 7538/10000, loss: 0.0048195170238614083\n",
      "Episode Reward: 27.0\n",
      "Step 844 (5798757) @ Episode 7539/10000, loss: 0.0061241085641086167\n",
      "Episode Reward: 14.0\n",
      "Step 655 (5799412) @ Episode 7540/10000, loss: 0.0076104700565338135\n",
      "Episode Reward: 13.0\n",
      "Step 587 (5799999) @ Episode 7541/10000, loss: 0.0048113027587533787\n",
      " Copied model parameters to target network\n",
      "Step 805 (5800217) @ Episode 7541/10000, loss: 0.0034204670228064064\n",
      "Episode Reward: 14.0\n",
      "Step 845 (5801062) @ Episode 7542/10000, loss: 0.0025379285216331486\n",
      "Episode Reward: 13.0\n",
      "Step 921 (5801983) @ Episode 7543/10000, loss: 0.0040804431773722174\n",
      "Episode Reward: 15.0\n",
      "Step 571 (5802554) @ Episode 7544/10000, loss: 0.0029576630331575874\n",
      "Episode Reward: 7.0\n",
      "Step 778 (5803332) @ Episode 7545/10000, loss: 0.0037663388065993786\n",
      "Episode Reward: 13.0\n",
      "Step 771 (5804103) @ Episode 7546/10000, loss: 0.0045110471546649935\n",
      "Episode Reward: 13.0\n",
      "Step 695 (5804798) @ Episode 7547/10000, loss: 0.0028151182923465967\n",
      "Episode Reward: 12.0\n",
      "Step 876 (5805674) @ Episode 7548/10000, loss: 0.0030153968837112196\n",
      "Episode Reward: 17.0\n",
      "Step 960 (5806634) @ Episode 7549/10000, loss: 0.0041566686704754832\n",
      "Episode Reward: 15.0\n",
      "Step 448 (5807082) @ Episode 7550/10000, loss: 0.0033454394433647394\n",
      "Episode Reward: 6.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 07:32:08,792] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video007550.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 777 (5807859) @ Episode 7551/10000, loss: 0.0032040150836110115\n",
      "Episode Reward: 17.0\n",
      "Step 720 (5808579) @ Episode 7552/10000, loss: 0.0043004094623029235\n",
      "Episode Reward: 11.0\n",
      "Step 1077 (5809656) @ Episode 7553/10000, loss: 0.0037694275379180916\n",
      "Episode Reward: 26.0\n",
      "Step 343 (5809999) @ Episode 7554/10000, loss: 0.0059930505231022835\n",
      " Copied model parameters to target network\n",
      "Step 1211 (5810867) @ Episode 7554/10000, loss: 0.0092821745201945326\n",
      "Episode Reward: 23.0\n",
      "Step 828 (5811695) @ Episode 7555/10000, loss: 0.0063787726685404783\n",
      "Episode Reward: 13.0\n",
      "Step 643 (5812338) @ Episode 7556/10000, loss: 0.0023476213682442904\n",
      "Episode Reward: 10.0\n",
      "Step 693 (5813031) @ Episode 7557/10000, loss: 0.0029415199533104897\n",
      "Episode Reward: 11.0\n",
      "Step 836 (5813867) @ Episode 7558/10000, loss: 0.0035319929011166096\n",
      "Episode Reward: 14.0\n",
      "Step 1022 (5814889) @ Episode 7559/10000, loss: 0.0041244719177484515\n",
      "Episode Reward: 19.0\n",
      "Step 807 (5815696) @ Episode 7560/10000, loss: 0.0039928611367940924\n",
      "Episode Reward: 13.0\n",
      "Step 992 (5816688) @ Episode 7561/10000, loss: 0.0038033712189644575\n",
      "Episode Reward: 17.0\n",
      "Step 912 (5817600) @ Episode 7562/10000, loss: 0.0015886889304965734\n",
      "Episode Reward: 15.0\n",
      "Step 719 (5818319) @ Episode 7563/10000, loss: 0.0037128552794456485\n",
      "Episode Reward: 11.0\n",
      "Step 942 (5819261) @ Episode 7564/10000, loss: 0.0097000291571021084\n",
      "Episode Reward: 16.0\n",
      "Step 623 (5819884) @ Episode 7565/10000, loss: 0.0073023336008191115\n",
      "Episode Reward: 10.0\n",
      "Step 115 (5819999) @ Episode 7566/10000, loss: 0.0016344671603292227\n",
      " Copied model parameters to target network\n",
      "Step 514 (5820398) @ Episode 7566/10000, loss: 0.0029784077778458595\n",
      "Episode Reward: 8.0\n",
      "Step 1231 (5821629) @ Episode 7567/10000, loss: 0.0020119431428611285\n",
      "Episode Reward: 22.0\n",
      "Step 582 (5822211) @ Episode 7568/10000, loss: 0.0024145753122866154\n",
      "Episode Reward: 9.0\n",
      "Step 518 (5822729) @ Episode 7569/10000, loss: 0.0026209643110632896\n",
      "Episode Reward: 6.0\n",
      "Step 566 (5823295) @ Episode 7570/10000, loss: 0.0035203681327402595\n",
      "Episode Reward: 9.0\n",
      "Step 1010 (5824305) @ Episode 7571/10000, loss: 0.0021194308064877987\n",
      "Episode Reward: 15.0\n",
      "Step 421 (5824726) @ Episode 7572/10000, loss: 0.0037760655395686626\n",
      "Episode Reward: 6.0\n",
      "Step 593 (5825319) @ Episode 7573/10000, loss: 0.0369633398950099955\n",
      "Episode Reward: 8.0\n",
      "Step 920 (5826239) @ Episode 7574/10000, loss: 0.0052442061714828014\n",
      "Episode Reward: 12.0\n",
      "Step 732 (5826971) @ Episode 7575/10000, loss: 0.0055376021191477776\n",
      "Episode Reward: 12.0\n",
      "Step 608 (5827579) @ Episode 7576/10000, loss: 0.0238338038325309757\n",
      "Episode Reward: 8.0\n",
      "Step 850 (5828429) @ Episode 7577/10000, loss: 0.0027818460948765286\n",
      "Episode Reward: 13.0\n",
      "Step 815 (5829244) @ Episode 7578/10000, loss: 0.0101108448579907425\n",
      "Episode Reward: 13.0\n",
      "Step 755 (5829999) @ Episode 7579/10000, loss: 0.0028105410747230053\n",
      " Copied model parameters to target network\n",
      "Step 995 (5830239) @ Episode 7579/10000, loss: 0.0022083013318479066\n",
      "Episode Reward: 16.0\n",
      "Step 800 (5831039) @ Episode 7580/10000, loss: 0.0029721031896776085\n",
      "Episode Reward: 13.0\n",
      "Step 565 (5831604) @ Episode 7581/10000, loss: 0.0504942461848259334\n",
      "Episode Reward: 8.0\n",
      "Step 853 (5832457) @ Episode 7582/10000, loss: 0.0021978926379233638\n",
      "Episode Reward: 15.0\n",
      "Step 865 (5833322) @ Episode 7583/10000, loss: 0.0051531093195080768\n",
      "Episode Reward: 21.0\n",
      "Step 345 (5833667) @ Episode 7584/10000, loss: 0.0066780536435544495\n",
      "Episode Reward: 4.0\n",
      "Step 690 (5834357) @ Episode 7585/10000, loss: 0.0060676783323287963\n",
      "Episode Reward: 12.0\n",
      "Step 1092 (5835449) @ Episode 7586/10000, loss: 0.0081819808110594756\n",
      "Episode Reward: 25.0\n",
      "Step 854 (5836303) @ Episode 7587/10000, loss: 0.0185749735683202745\n",
      "Episode Reward: 13.0\n",
      "Step 752 (5837055) @ Episode 7588/10000, loss: 0.0064331148751080045\n",
      "Episode Reward: 12.0\n",
      "Step 891 (5837946) @ Episode 7589/10000, loss: 0.0032249558717012405\n",
      "Episode Reward: 18.0\n",
      "Step 996 (5838942) @ Episode 7590/10000, loss: 0.0047012986615300183\n",
      "Episode Reward: 17.0\n",
      "Step 617 (5839559) @ Episode 7591/10000, loss: 0.0025962940417230135\n",
      "Episode Reward: 13.0\n",
      "Step 440 (5839999) @ Episode 7592/10000, loss: 0.0051195500418543816\n",
      " Copied model parameters to target network\n",
      "Step 625 (5840184) @ Episode 7592/10000, loss: 0.0187338348478078847\n",
      "Episode Reward: 10.0\n",
      "Step 1211 (5841395) @ Episode 7593/10000, loss: 0.0025014532729983337\n",
      "Episode Reward: 22.0\n",
      "Step 785 (5842180) @ Episode 7594/10000, loss: 0.0057750474661588675\n",
      "Episode Reward: 13.0\n",
      "Step 847 (5843027) @ Episode 7595/10000, loss: 0.0168551541864871987\n",
      "Episode Reward: 13.0\n",
      "Step 538 (5843565) @ Episode 7596/10000, loss: 0.0110004656016826636\n",
      "Episode Reward: 6.0\n",
      "Step 578 (5844143) @ Episode 7597/10000, loss: 0.0027355283964425325\n",
      "Episode Reward: 8.0\n",
      "Step 688 (5844831) @ Episode 7598/10000, loss: 0.0025315280072391033\n",
      "Episode Reward: 10.0\n",
      "Step 975 (5845806) @ Episode 7599/10000, loss: 0.0052734175696969037\n",
      "Episode Reward: 15.0\n",
      "Step 599 (5846405) @ Episode 7600/10000, loss: 0.0050285616889595985\n",
      "Episode Reward: 8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 07:38:18,918] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video007600.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 864 (5847269) @ Episode 7601/10000, loss: 0.0052321352995932185\n",
      "Episode Reward: 21.0\n",
      "Step 727 (5847996) @ Episode 7602/10000, loss: 0.0021679294295608997\n",
      "Episode Reward: 16.0\n",
      "Step 1297 (5849293) @ Episode 7603/10000, loss: 0.0208398811519145975\n",
      "Episode Reward: 24.0\n",
      "Step 706 (5849999) @ Episode 7604/10000, loss: 0.0025543947704136373\n",
      " Copied model parameters to target network\n",
      "Step 763 (5850056) @ Episode 7604/10000, loss: 0.0026838919147849083\n",
      "Episode Reward: 16.0\n",
      "Step 521 (5850577) @ Episode 7605/10000, loss: 0.0057405214756727223\n",
      "Episode Reward: 7.0\n",
      "Step 969 (5851546) @ Episode 7606/10000, loss: 0.0045050787739455733\n",
      "Episode Reward: 19.0\n",
      "Step 501 (5852047) @ Episode 7607/10000, loss: 0.0204371921718120577\n",
      "Episode Reward: 10.0\n",
      "Step 697 (5852744) @ Episode 7608/10000, loss: 0.0052739186212420467\n",
      "Episode Reward: 13.0\n",
      "Step 992 (5853736) @ Episode 7609/10000, loss: 0.0029210061766207226\n",
      "Episode Reward: 21.0\n",
      "Step 431 (5854167) @ Episode 7610/10000, loss: 0.0063213170506060125\n",
      "Episode Reward: 5.0\n",
      "Step 703 (5854870) @ Episode 7611/10000, loss: 0.0052068531513214116\n",
      "Episode Reward: 12.0\n",
      "Step 1204 (5856074) @ Episode 7612/10000, loss: 0.0048733451403677464\n",
      "Episode Reward: 23.0\n",
      "Step 747 (5856821) @ Episode 7613/10000, loss: 0.0030661444179713726\n",
      "Episode Reward: 10.0\n",
      "Step 563 (5857384) @ Episode 7614/10000, loss: 0.0046813748776912695\n",
      "Episode Reward: 8.0\n",
      "Step 651 (5858035) @ Episode 7615/10000, loss: 0.0107321664690971374\n",
      "Episode Reward: 13.0\n",
      "Step 770 (5858805) @ Episode 7616/10000, loss: 0.0051344605162739757\n",
      "Episode Reward: 15.0\n",
      "Step 510 (5859315) @ Episode 7617/10000, loss: 0.0042223399505019198\n",
      "Episode Reward: 5.0\n",
      "Step 587 (5859902) @ Episode 7618/10000, loss: 0.0043174973689019684\n",
      "Episode Reward: 10.0\n",
      "Step 97 (5859999) @ Episode 7619/10000, loss: 0.0020386781543493274\n",
      " Copied model parameters to target network\n",
      "Step 652 (5860554) @ Episode 7619/10000, loss: 0.0164288599044084557\n",
      "Episode Reward: 12.0\n",
      "Step 589 (5861143) @ Episode 7620/10000, loss: 0.0024163895286619663\n",
      "Episode Reward: 9.0\n",
      "Step 932 (5862075) @ Episode 7621/10000, loss: 0.0026708962395787244\n",
      "Episode Reward: 14.0\n",
      "Step 847 (5862922) @ Episode 7622/10000, loss: 0.0120846070349216467\n",
      "Episode Reward: 18.0\n",
      "Step 1323 (5864245) @ Episode 7623/10000, loss: 0.0226393770426511763\n",
      "Episode Reward: 28.0\n",
      "Step 979 (5865224) @ Episode 7624/10000, loss: 0.0021293181926012045\n",
      "Episode Reward: 25.0\n",
      "Step 1032 (5866256) @ Episode 7625/10000, loss: 0.0033233866561204195\n",
      "Episode Reward: 19.0\n",
      "Step 928 (5867184) @ Episode 7626/10000, loss: 0.0014995890669524674\n",
      "Episode Reward: 16.0\n",
      "Step 795 (5867979) @ Episode 7627/10000, loss: 0.0050983484834432695\n",
      "Episode Reward: 10.0\n",
      "Step 726 (5868705) @ Episode 7628/10000, loss: 0.0023943383712321523\n",
      "Episode Reward: 15.0\n",
      "Step 675 (5869380) @ Episode 7629/10000, loss: 0.0028816987760365013\n",
      "Episode Reward: 9.0\n",
      "Step 619 (5869999) @ Episode 7630/10000, loss: 0.0058668572455644615\n",
      " Copied model parameters to target network\n",
      "Step 1302 (5870682) @ Episode 7630/10000, loss: 0.0028012865222990513\n",
      "Episode Reward: 27.0\n",
      "Step 646 (5871328) @ Episode 7631/10000, loss: 0.0114050731062889108\n",
      "Episode Reward: 10.0\n",
      "Step 948 (5872276) @ Episode 7632/10000, loss: 0.0025145597755908966\n",
      "Episode Reward: 18.0\n",
      "Step 738 (5873014) @ Episode 7633/10000, loss: 0.0086267348378896712\n",
      "Episode Reward: 18.0\n",
      "Step 755 (5873769) @ Episode 7634/10000, loss: 0.0077016265131533153\n",
      "Episode Reward: 11.0\n",
      "Step 1502 (5875271) @ Episode 7635/10000, loss: 0.0020239681471139193\n",
      "Episode Reward: 27.0\n",
      "Step 1076 (5876347) @ Episode 7636/10000, loss: 0.0068132407031953335\n",
      "Episode Reward: 21.0\n",
      "Step 614 (5876961) @ Episode 7637/10000, loss: 0.0046539525501430035\n",
      "Episode Reward: 11.0\n",
      "Step 998 (5877959) @ Episode 7638/10000, loss: 0.0120216514915227895\n",
      "Episode Reward: 21.0\n",
      "Step 788 (5878747) @ Episode 7639/10000, loss: 0.0073440899141132837\n",
      "Episode Reward: 12.0\n",
      "Step 1067 (5879814) @ Episode 7640/10000, loss: 0.0058893836103379735\n",
      "Episode Reward: 19.0\n",
      "Step 185 (5879999) @ Episode 7641/10000, loss: 0.0066590150818228727\n",
      " Copied model parameters to target network\n",
      "Step 984 (5880798) @ Episode 7641/10000, loss: 0.0030619450844824314\n",
      "Episode Reward: 16.0\n",
      "Step 784 (5881582) @ Episode 7642/10000, loss: 0.0022134338505566124\n",
      "Episode Reward: 17.0\n",
      "Step 798 (5882380) @ Episode 7643/10000, loss: 0.0035065286792814736\n",
      "Episode Reward: 16.0\n",
      "Step 561 (5882941) @ Episode 7644/10000, loss: 0.0127929644659161575\n",
      "Episode Reward: 9.0\n",
      "Step 856 (5883797) @ Episode 7645/10000, loss: 0.0024467362090945244\n",
      "Episode Reward: 12.0\n",
      "Step 545 (5884342) @ Episode 7646/10000, loss: 0.0048859170638024815\n",
      "Episode Reward: 9.0\n",
      "Step 1157 (5885499) @ Episode 7647/10000, loss: 0.0043967720121145255\n",
      "Episode Reward: 25.0\n",
      "Step 868 (5886367) @ Episode 7648/10000, loss: 0.0028407447971403687\n",
      "Episode Reward: 23.0\n",
      "Step 620 (5886987) @ Episode 7649/10000, loss: 0.0168962068855762486\n",
      "Episode Reward: 9.0\n",
      "Step 632 (5887619) @ Episode 7650/10000, loss: 0.0017776977038010955\n",
      "Episode Reward: 10.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 07:44:47,630] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video007650.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 579 (5888198) @ Episode 7651/10000, loss: 0.0038013362791389227\n",
      "Episode Reward: 8.0\n",
      "Step 1016 (5889214) @ Episode 7652/10000, loss: 0.0037613175809383392\n",
      "Episode Reward: 20.0\n",
      "Step 445 (5889659) @ Episode 7653/10000, loss: 0.0027771899476647377\n",
      "Episode Reward: 5.0\n",
      "Step 340 (5889999) @ Episode 7654/10000, loss: 0.0039238194003701213\n",
      " Copied model parameters to target network\n",
      "Step 709 (5890368) @ Episode 7654/10000, loss: 0.0083632422611117365\n",
      "Episode Reward: 10.0\n",
      "Step 1343 (5891711) @ Episode 7655/10000, loss: 0.0033751549199223523\n",
      "Episode Reward: 29.0\n",
      "Step 850 (5892561) @ Episode 7656/10000, loss: 0.0027355377096682787\n",
      "Episode Reward: 13.0\n",
      "Step 618 (5893179) @ Episode 7657/10000, loss: 0.0052708587609231474\n",
      "Episode Reward: 10.0\n",
      "Step 1015 (5894194) @ Episode 7658/10000, loss: 0.0052810176275670538\n",
      "Episode Reward: 18.0\n",
      "Step 659 (5894853) @ Episode 7659/10000, loss: 0.0051826392300426962\n",
      "Episode Reward: 11.0\n",
      "Step 679 (5895532) @ Episode 7660/10000, loss: 0.0041043274104595186\n",
      "Episode Reward: 12.0\n",
      "Step 952 (5896484) @ Episode 7661/10000, loss: 0.0014449240406975157\n",
      "Episode Reward: 18.0\n",
      "Step 802 (5897286) @ Episode 7662/10000, loss: 0.0045278323814272882\n",
      "Episode Reward: 14.0\n",
      "Step 840 (5898126) @ Episode 7663/10000, loss: 0.0027328305877745153\n",
      "Episode Reward: 12.0\n",
      "Step 865 (5898991) @ Episode 7664/10000, loss: 0.0046969102695584363\n",
      "Episode Reward: 12.0\n",
      "Step 1008 (5899999) @ Episode 7665/10000, loss: 0.0026103667914867484\n",
      " Copied model parameters to target network\n",
      "Step 1016 (5900007) @ Episode 7665/10000, loss: 0.0017205539625138044\n",
      "Episode Reward: 19.0\n",
      "Step 1252 (5901259) @ Episode 7666/10000, loss: 0.0045158076100051425\n",
      "Episode Reward: 20.0\n",
      "Step 968 (5902227) @ Episode 7667/10000, loss: 0.0027403743006289005\n",
      "Episode Reward: 19.0\n",
      "Step 779 (5903006) @ Episode 7668/10000, loss: 0.0101576270535588264\n",
      "Episode Reward: 13.0\n",
      "Step 784 (5903790) @ Episode 7669/10000, loss: 0.0021488680504262447\n",
      "Episode Reward: 12.0\n",
      "Step 932 (5904722) @ Episode 7670/10000, loss: 0.0039841905236244235\n",
      "Episode Reward: 18.0\n",
      "Step 845 (5905567) @ Episode 7671/10000, loss: 0.1142404675483703616\n",
      "Episode Reward: 16.0\n",
      "Step 785 (5906352) @ Episode 7672/10000, loss: 0.0014939139364287257\n",
      "Episode Reward: 19.0\n",
      "Step 671 (5907023) @ Episode 7673/10000, loss: 0.0032389569096267223\n",
      "Episode Reward: 11.0\n",
      "Step 881 (5907904) @ Episode 7674/10000, loss: 0.0111968005076050765\n",
      "Episode Reward: 15.0\n",
      "Step 743 (5908647) @ Episode 7675/10000, loss: 0.0050080432556569587\n",
      "Episode Reward: 11.0\n",
      "Step 842 (5909489) @ Episode 7676/10000, loss: 0.0035345191136002547\n",
      "Episode Reward: 11.0\n",
      "Step 510 (5909999) @ Episode 7677/10000, loss: 0.0036270455457270145\n",
      " Copied model parameters to target network\n",
      "Step 855 (5910344) @ Episode 7677/10000, loss: 0.0035100451204925776\n",
      "Episode Reward: 12.0\n",
      "Step 989 (5911333) @ Episode 7678/10000, loss: 0.0043782019056379795\n",
      "Episode Reward: 26.0\n",
      "Step 770 (5912103) @ Episode 7679/10000, loss: 0.0049183689989149578\n",
      "Episode Reward: 11.0\n",
      "Step 774 (5912877) @ Episode 7680/10000, loss: 0.0094436975196003916\n",
      "Episode Reward: 15.0\n",
      "Step 781 (5913658) @ Episode 7681/10000, loss: 0.0020423179958015684\n",
      "Episode Reward: 11.0\n",
      "Step 612 (5914270) @ Episode 7682/10000, loss: 0.0074098417535424234\n",
      "Episode Reward: 8.0\n",
      "Step 1020 (5915290) @ Episode 7683/10000, loss: 0.0064080418087542065\n",
      "Episode Reward: 20.0\n",
      "Step 557 (5915847) @ Episode 7684/10000, loss: 0.0022484224755316973\n",
      "Episode Reward: 8.0\n",
      "Step 676 (5916523) @ Episode 7685/10000, loss: 0.0043247132562100897\n",
      "Episode Reward: 9.0\n",
      "Step 749 (5917272) @ Episode 7686/10000, loss: 0.0039179362356662754\n",
      "Episode Reward: 12.0\n",
      "Step 492 (5917764) @ Episode 7687/10000, loss: 0.0044615007936954515\n",
      "Episode Reward: 6.0\n",
      "Step 848 (5918612) @ Episode 7688/10000, loss: 0.0027658790349960327\n",
      "Episode Reward: 16.0\n",
      "Step 745 (5919357) @ Episode 7689/10000, loss: 0.0018208269029855728\n",
      "Episode Reward: 12.0\n",
      "Step 642 (5919999) @ Episode 7690/10000, loss: 0.0091802813112735753\n",
      " Copied model parameters to target network\n",
      "Step 786 (5920143) @ Episode 7690/10000, loss: 0.0029905242845416072\n",
      "Episode Reward: 15.0\n",
      "Step 624 (5920767) @ Episode 7691/10000, loss: 0.0111254211515188226\n",
      "Episode Reward: 9.0\n",
      "Step 675 (5921442) @ Episode 7692/10000, loss: 0.0055040423758327966\n",
      "Episode Reward: 9.0\n",
      "Step 1094 (5922536) @ Episode 7693/10000, loss: 0.0023650391958653927\n",
      "Episode Reward: 18.0\n",
      "Step 495 (5923031) @ Episode 7694/10000, loss: 0.0079620676115155225\n",
      "Episode Reward: 7.0\n",
      "Step 855 (5923886) @ Episode 7695/10000, loss: 0.0118103194981813435\n",
      "Episode Reward: 13.0\n",
      "Step 1112 (5924998) @ Episode 7696/10000, loss: 0.0018443618901073933\n",
      "Episode Reward: 20.0\n",
      "Step 904 (5925902) @ Episode 7697/10000, loss: 0.0060023763217031966\n",
      "Episode Reward: 15.0\n",
      "Step 618 (5926520) @ Episode 7698/10000, loss: 0.0021517090499401093\n",
      "Episode Reward: 12.0\n",
      "Step 929 (5927449) @ Episode 7699/10000, loss: 0.0021350074093788862\n",
      "Episode Reward: 22.0\n",
      "Step 783 (5928232) @ Episode 7700/10000, loss: 0.0029016078915446997\n",
      "Episode Reward: 15.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 07:51:09,185] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video007700.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 694 (5928926) @ Episode 7701/10000, loss: 0.0036260969936847687\n",
      "Episode Reward: 11.0\n",
      "Step 723 (5929649) @ Episode 7702/10000, loss: 0.0063933688215911395\n",
      "Episode Reward: 16.0\n",
      "Step 350 (5929999) @ Episode 7703/10000, loss: 0.0038437421899288893\n",
      " Copied model parameters to target network\n",
      "Step 744 (5930393) @ Episode 7703/10000, loss: 0.0058387573808431625\n",
      "Episode Reward: 13.0\n",
      "Step 670 (5931063) @ Episode 7704/10000, loss: 0.0027750486042350536\n",
      "Episode Reward: 11.0\n",
      "Step 880 (5931943) @ Episode 7705/10000, loss: 0.0063465246930718424\n",
      "Episode Reward: 13.0\n",
      "Step 742 (5932685) @ Episode 7706/10000, loss: 0.0015851957723498344\n",
      "Episode Reward: 12.0\n",
      "Step 900 (5933585) @ Episode 7707/10000, loss: 0.0027558323927223682\n",
      "Episode Reward: 14.0\n",
      "Step 872 (5934457) @ Episode 7708/10000, loss: 0.0013969622086733582\n",
      "Episode Reward: 15.0\n",
      "Step 906 (5935363) @ Episode 7709/10000, loss: 0.0048848711885511875\n",
      "Episode Reward: 16.0\n",
      "Step 857 (5936220) @ Episode 7710/10000, loss: 0.0020647421479225168\n",
      "Episode Reward: 16.0\n",
      "Step 924 (5937144) @ Episode 7711/10000, loss: 0.0026115993969142437\n",
      "Episode Reward: 16.0\n",
      "Step 513 (5937657) @ Episode 7712/10000, loss: 0.0023601180873811245\n",
      "Episode Reward: 8.0\n",
      "Step 1311 (5938968) @ Episode 7713/10000, loss: 0.0040255696512758736\n",
      "Episode Reward: 27.0\n",
      "Step 610 (5939578) @ Episode 7714/10000, loss: 0.0042003141716122636\n",
      "Episode Reward: 9.0\n",
      "Step 421 (5939999) @ Episode 7715/10000, loss: 0.0134421968832612047\n",
      " Copied model parameters to target network\n",
      "Step 921 (5940499) @ Episode 7715/10000, loss: 0.0301605369895696647\n",
      "Episode Reward: 16.0\n",
      "Step 599 (5941098) @ Episode 7716/10000, loss: 0.0050451131537556655\n",
      "Episode Reward: 13.0\n",
      "Step 863 (5941961) @ Episode 7717/10000, loss: 0.0031165329273790125\n",
      "Episode Reward: 19.0\n",
      "Step 927 (5942888) @ Episode 7718/10000, loss: 0.0044091572053730494\n",
      "Episode Reward: 15.0\n",
      "Step 823 (5943711) @ Episode 7719/10000, loss: 0.0010904578957706692\n",
      "Episode Reward: 14.0\n",
      "Step 747 (5944458) @ Episode 7720/10000, loss: 0.0072409803979098847\n",
      "Episode Reward: 14.0\n",
      "Step 1530 (5945988) @ Episode 7721/10000, loss: 0.0042832042090594773\n",
      "Episode Reward: 41.0\n",
      "Step 491 (5946479) @ Episode 7722/10000, loss: 0.0050437659956514835\n",
      "Episode Reward: 7.0\n",
      "Step 773 (5947252) @ Episode 7723/10000, loss: 0.0049534398131072522\n",
      "Episode Reward: 12.0\n",
      "Step 728 (5947980) @ Episode 7724/10000, loss: 0.0610983669757843515\n",
      "Episode Reward: 12.0\n",
      "Step 672 (5948652) @ Episode 7725/10000, loss: 0.0011421194067224863\n",
      "Episode Reward: 9.0\n",
      "Step 1341 (5949993) @ Episode 7726/10000, loss: 0.0016220487887039783\n",
      "Episode Reward: 39.0\n",
      "Step 6 (5949999) @ Episode 7727/10000, loss: 0.0061918883584439754\n",
      " Copied model parameters to target network\n",
      "Step 539 (5950532) @ Episode 7727/10000, loss: 0.0050393119454383853\n",
      "Episode Reward: 8.0\n",
      "Step 516 (5951048) @ Episode 7728/10000, loss: 0.0015307442517951135\n",
      "Episode Reward: 6.0\n",
      "Step 455 (5951503) @ Episode 7729/10000, loss: 0.0112234428524971334\n",
      "Episode Reward: 5.0\n",
      "Step 738 (5952241) @ Episode 7730/10000, loss: 0.0038109046872705223\n",
      "Episode Reward: 13.0\n",
      "Step 584 (5952825) @ Episode 7731/10000, loss: 0.0028775525279343133\n",
      "Episode Reward: 9.0\n",
      "Step 1020 (5953845) @ Episode 7732/10000, loss: 0.0029628467746078975\n",
      "Episode Reward: 17.0\n",
      "Step 1048 (5954893) @ Episode 7733/10000, loss: 0.0038512763567268855\n",
      "Episode Reward: 21.0\n",
      "Step 900 (5955793) @ Episode 7734/10000, loss: 0.0024372944608330727\n",
      "Episode Reward: 19.0\n",
      "Step 841 (5956634) @ Episode 7735/10000, loss: 0.0053912415169179448\n",
      "Episode Reward: 14.0\n",
      "Step 741 (5957375) @ Episode 7736/10000, loss: 0.0038101947866380215\n",
      "Episode Reward: 12.0\n",
      "Step 857 (5958232) @ Episode 7737/10000, loss: 0.0058045531623065477\n",
      "Episode Reward: 13.0\n",
      "Step 430 (5958662) @ Episode 7738/10000, loss: 0.0019719861447811127\n",
      "Episode Reward: 5.0\n",
      "Step 867 (5959529) @ Episode 7739/10000, loss: 0.0016783038154244423\n",
      "Episode Reward: 14.0\n",
      "Step 470 (5959999) @ Episode 7740/10000, loss: 0.0042209234088659293\n",
      " Copied model parameters to target network\n",
      "Step 524 (5960053) @ Episode 7740/10000, loss: 0.0056976652704179295\n",
      "Episode Reward: 7.0\n",
      "Step 1055 (5961108) @ Episode 7741/10000, loss: 0.0036557260900735855\n",
      "Episode Reward: 17.0\n",
      "Step 968 (5962076) @ Episode 7742/10000, loss: 0.0038932922761887314\n",
      "Episode Reward: 22.0\n",
      "Step 823 (5962899) @ Episode 7743/10000, loss: 0.0059635732322931297\n",
      "Episode Reward: 14.0\n",
      "Step 782 (5963681) @ Episode 7744/10000, loss: 0.0067765517160296446\n",
      "Episode Reward: 13.0\n",
      "Step 811 (5964492) @ Episode 7745/10000, loss: 0.0039236545562744144\n",
      "Episode Reward: 13.0\n",
      "Step 1117 (5965609) @ Episode 7746/10000, loss: 0.0016330922953784466\n",
      "Episode Reward: 23.0\n",
      "Step 637 (5966246) @ Episode 7747/10000, loss: 0.0030999924056231976\n",
      "Episode Reward: 9.0\n",
      "Step 926 (5967172) @ Episode 7748/10000, loss: 0.0042219422757625585\n",
      "Episode Reward: 20.0\n",
      "Step 756 (5967928) @ Episode 7749/10000, loss: 0.0024864892475306988\n",
      "Episode Reward: 12.0\n",
      "Step 787 (5968715) @ Episode 7750/10000, loss: 0.0021067105699330577\n",
      "Episode Reward: 12.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 07:57:30,942] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video007750.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1002 (5969717) @ Episode 7751/10000, loss: 0.0058283866383135326\n",
      "Episode Reward: 21.0\n",
      "Step 282 (5969999) @ Episode 7752/10000, loss: 0.0084582408890128144\n",
      " Copied model parameters to target network\n",
      "Step 723 (5970440) @ Episode 7752/10000, loss: 0.0031319726258516315\n",
      "Episode Reward: 10.0\n",
      "Step 837 (5971277) @ Episode 7753/10000, loss: 0.0045013711787760268\n",
      "Episode Reward: 18.0\n",
      "Step 1158 (5972435) @ Episode 7754/10000, loss: 0.0056147798895835885\n",
      "Episode Reward: 21.0\n",
      "Step 743 (5973178) @ Episode 7755/10000, loss: 0.0098569234833121312\n",
      "Episode Reward: 15.0\n",
      "Step 414 (5973592) @ Episode 7756/10000, loss: 0.0036683934740722182\n",
      "Episode Reward: 5.0\n",
      "Step 884 (5974476) @ Episode 7757/10000, loss: 0.0112845506519079295\n",
      "Episode Reward: 17.0\n",
      "Step 642 (5975118) @ Episode 7758/10000, loss: 0.0076657678000628958\n",
      "Episode Reward: 12.0\n",
      "Step 528 (5975646) @ Episode 7759/10000, loss: 0.0057709896937012677\n",
      "Episode Reward: 7.0\n",
      "Step 1067 (5976713) @ Episode 7760/10000, loss: 0.0038169622421264658\n",
      "Episode Reward: 25.0\n",
      "Step 1025 (5977738) @ Episode 7761/10000, loss: 0.0168563332408666635\n",
      "Episode Reward: 23.0\n",
      "Step 875 (5978613) @ Episode 7762/10000, loss: 0.0058831418864429185\n",
      "Episode Reward: 16.0\n",
      "Step 627 (5979240) @ Episode 7763/10000, loss: 0.0028482342604547746\n",
      "Episode Reward: 9.0\n",
      "Step 662 (5979902) @ Episode 7764/10000, loss: 0.0056511349976062775\n",
      "Episode Reward: 13.0\n",
      "Step 97 (5979999) @ Episode 7765/10000, loss: 0.0056416559964418413\n",
      " Copied model parameters to target network\n",
      "Step 1194 (5981096) @ Episode 7765/10000, loss: 0.0042598601430654535\n",
      "Episode Reward: 26.0\n",
      "Step 1347 (5982443) @ Episode 7766/10000, loss: 0.0038155578076839447\n",
      "Episode Reward: 32.0\n",
      "Step 980 (5983423) @ Episode 7767/10000, loss: 0.0045189349912106995\n",
      "Episode Reward: 20.0\n",
      "Step 918 (5984341) @ Episode 7768/10000, loss: 0.0038062429521232843\n",
      "Episode Reward: 16.0\n",
      "Step 1000 (5985341) @ Episode 7769/10000, loss: 0.013571867719292642\n",
      "Episode Reward: 25.0\n",
      "Step 482 (5985823) @ Episode 7770/10000, loss: 0.0021902341395616535\n",
      "Episode Reward: 7.0\n",
      "Step 700 (5986523) @ Episode 7771/10000, loss: 0.0037207619752734944\n",
      "Episode Reward: 10.0\n",
      "Step 1012 (5987535) @ Episode 7772/10000, loss: 0.0028989459387958056\n",
      "Episode Reward: 17.0\n",
      "Step 575 (5988110) @ Episode 7773/10000, loss: 0.0283276550471782744\n",
      "Episode Reward: 9.0\n",
      "Step 741 (5988851) @ Episode 7774/10000, loss: 0.0063303951174020778\n",
      "Episode Reward: 16.0\n",
      "Step 502 (5989353) @ Episode 7775/10000, loss: 0.0064925448969006544\n",
      "Episode Reward: 6.0\n",
      "Step 646 (5989999) @ Episode 7776/10000, loss: 0.0066535575315356255\n",
      " Copied model parameters to target network\n",
      "Step 845 (5990198) @ Episode 7776/10000, loss: 0.0043346723541617395\n",
      "Episode Reward: 21.0\n",
      "Step 840 (5991038) @ Episode 7777/10000, loss: 0.0017560720443725586\n",
      "Episode Reward: 18.0\n",
      "Step 972 (5992010) @ Episode 7778/10000, loss: 0.0071333935484290125\n",
      "Episode Reward: 17.0\n",
      "Step 1593 (5993603) @ Episode 7779/10000, loss: 0.0024100271984934807\n",
      "Episode Reward: 43.0\n",
      "Step 835 (5994438) @ Episode 7780/10000, loss: 0.0046257330104708676\n",
      "Episode Reward: 13.0\n",
      "Step 913 (5995351) @ Episode 7781/10000, loss: 0.0035521038807928565\n",
      "Episode Reward: 22.0\n",
      "Step 643 (5995994) @ Episode 7782/10000, loss: 0.0045079640112817294\n",
      "Episode Reward: 10.0\n",
      "Step 774 (5996768) @ Episode 7783/10000, loss: 0.0050180796533823011\n",
      "Episode Reward: 12.0\n",
      "Step 668 (5997436) @ Episode 7784/10000, loss: 0.0041331313550472265\n",
      "Episode Reward: 10.0\n",
      "Step 891 (5998327) @ Episode 7785/10000, loss: 0.0052559087052941325\n",
      "Episode Reward: 22.0\n",
      "Step 857 (5999184) @ Episode 7786/10000, loss: 0.0030050864443182945\n",
      "Episode Reward: 13.0\n",
      "Step 803 (5999987) @ Episode 7787/10000, loss: 0.0042759226635098464\n",
      "Episode Reward: 15.0\n",
      "Step 12 (5999999) @ Episode 7788/10000, loss: 0.0026116475928574894\n",
      " Copied model parameters to target network\n",
      "Step 634 (6000621) @ Episode 7788/10000, loss: 0.0037934258580207825\n",
      "Episode Reward: 10.0\n",
      "Step 931 (6001552) @ Episode 7789/10000, loss: 0.0040633101016283035\n",
      "Episode Reward: 20.0\n",
      "Step 806 (6002358) @ Episode 7790/10000, loss: 0.0043754330836236486\n",
      "Episode Reward: 14.0\n",
      "Step 726 (6003084) @ Episode 7791/10000, loss: 0.0032598895486444235\n",
      "Episode Reward: 13.0\n",
      "Step 760 (6003844) @ Episode 7792/10000, loss: 0.0017253723926842213\n",
      "Episode Reward: 16.0\n",
      "Step 742 (6004586) @ Episode 7793/10000, loss: 0.0074393246322870255\n",
      "Episode Reward: 12.0\n",
      "Step 993 (6005579) @ Episode 7794/10000, loss: 0.0030287308618426323\n",
      "Episode Reward: 20.0\n",
      "Step 432 (6006011) @ Episode 7795/10000, loss: 0.0035306354984641075\n",
      "Episode Reward: 6.0\n",
      "Step 932 (6006943) @ Episode 7796/10000, loss: 0.0028354779351502657\n",
      "Episode Reward: 16.0\n",
      "Step 837 (6007780) @ Episode 7797/10000, loss: 0.0031383587047457695\n",
      "Episode Reward: 14.0\n",
      "Step 496 (6008276) @ Episode 7798/10000, loss: 0.0052513368427753456\n",
      "Episode Reward: 8.0\n",
      "Step 718 (6008994) @ Episode 7799/10000, loss: 0.0024404283612966537\n",
      "Episode Reward: 7.0\n",
      "Step 1005 (6009999) @ Episode 7800/10000, loss: 0.006374899297952652\n",
      " Copied model parameters to target network\n",
      "Step 1134 (6010128) @ Episode 7800/10000, loss: 0.0083010457456111967\n",
      "Episode Reward: 18.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 08:03:58,473] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video007800.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 660 (6010788) @ Episode 7801/10000, loss: 0.0092030568048357965\n",
      "Episode Reward: 10.0\n",
      "Step 476 (6011264) @ Episode 7802/10000, loss: 0.0021792780607938766\n",
      "Episode Reward: 7.0\n",
      "Step 682 (6011946) @ Episode 7803/10000, loss: 0.0020076476503163576\n",
      "Episode Reward: 9.0\n",
      "Step 770 (6012716) @ Episode 7804/10000, loss: 0.0021175772417336702\n",
      "Episode Reward: 12.0\n",
      "Step 872 (6013588) @ Episode 7805/10000, loss: 0.0061263563111424456\n",
      "Episode Reward: 13.0\n",
      "Step 591 (6014179) @ Episode 7806/10000, loss: 0.0039644287899136547\n",
      "Episode Reward: 7.0\n",
      "Step 756 (6014935) @ Episode 7807/10000, loss: 0.0037340302951633937\n",
      "Episode Reward: 13.0\n",
      "Step 544 (6015479) @ Episode 7808/10000, loss: 0.0035524733830243353\n",
      "Episode Reward: 11.0\n",
      "Step 936 (6016415) @ Episode 7809/10000, loss: 0.0057548312470316895\n",
      "Episode Reward: 17.0\n",
      "Step 718 (6017133) @ Episode 7810/10000, loss: 0.0055836532264947897\n",
      "Episode Reward: 17.0\n",
      "Step 594 (6017727) @ Episode 7811/10000, loss: 0.0072447331622242935\n",
      "Episode Reward: 9.0\n",
      "Step 593 (6018320) @ Episode 7812/10000, loss: 0.0022165304981172085\n",
      "Episode Reward: 13.0\n",
      "Step 908 (6019228) @ Episode 7813/10000, loss: 0.0019501545466482645\n",
      "Episode Reward: 22.0\n",
      "Step 539 (6019767) @ Episode 7814/10000, loss: 0.0066239931620657445\n",
      "Episode Reward: 9.0\n",
      "Step 232 (6019999) @ Episode 7815/10000, loss: 0.0090568941086530695\n",
      " Copied model parameters to target network\n",
      "Step 746 (6020513) @ Episode 7815/10000, loss: 0.0018320798408240084\n",
      "Episode Reward: 12.0\n",
      "Step 1213 (6021726) @ Episode 7816/10000, loss: 0.0030437812674790625\n",
      "Episode Reward: 28.0\n",
      "Step 949 (6022675) @ Episode 7817/10000, loss: 0.0041849277913570493\n",
      "Episode Reward: 16.0\n",
      "Step 875 (6023550) @ Episode 7818/10000, loss: 0.0014974857913330197\n",
      "Episode Reward: 16.0\n",
      "Step 636 (6024186) @ Episode 7819/10000, loss: 0.0042860847897827625\n",
      "Episode Reward: 8.0\n",
      "Step 913 (6025099) @ Episode 7820/10000, loss: 0.0031229758169502027\n",
      "Episode Reward: 25.0\n",
      "Step 797 (6025896) @ Episode 7821/10000, loss: 0.0061126896180212513\n",
      "Episode Reward: 17.0\n",
      "Step 375 (6026271) @ Episode 7822/10000, loss: 0.0036269705742597583\n",
      "Episode Reward: 4.0\n",
      "Step 600 (6026871) @ Episode 7823/10000, loss: 0.0044352635741233834\n",
      "Episode Reward: 9.0\n",
      "Step 722 (6027593) @ Episode 7824/10000, loss: 0.0043364595621824265\n",
      "Episode Reward: 13.0\n",
      "Step 930 (6028523) @ Episode 7825/10000, loss: 0.0018935382831841707\n",
      "Episode Reward: 19.0\n",
      "Step 1080 (6029603) @ Episode 7826/10000, loss: 0.0018214124720543623\n",
      "Episode Reward: 22.0\n",
      "Step 396 (6029999) @ Episode 7827/10000, loss: 0.0037275943905115128\n",
      " Copied model parameters to target network\n",
      "Step 892 (6030495) @ Episode 7827/10000, loss: 0.0053481440991163255\n",
      "Episode Reward: 14.0\n",
      "Step 761 (6031256) @ Episode 7828/10000, loss: 0.0029697227291762838\n",
      "Episode Reward: 13.0\n",
      "Step 620 (6031876) @ Episode 7829/10000, loss: 0.0247000046074390423\n",
      "Episode Reward: 16.0\n",
      "Step 737 (6032613) @ Episode 7830/10000, loss: 0.0029826376121491194\n",
      "Episode Reward: 12.0\n",
      "Step 662 (6033275) @ Episode 7831/10000, loss: 0.0029816608875989914\n",
      "Episode Reward: 11.0\n",
      "Step 1262 (6034537) @ Episode 7832/10000, loss: 0.0080448091030120853\n",
      "Episode Reward: 25.0\n",
      "Step 1484 (6036021) @ Episode 7833/10000, loss: 0.0031385007314383984\n",
      "Episode Reward: 34.0\n",
      "Step 976 (6036997) @ Episode 7834/10000, loss: 0.0036739232018589973\n",
      "Episode Reward: 18.0\n",
      "Step 936 (6037933) @ Episode 7835/10000, loss: 0.0034462506882846355\n",
      "Episode Reward: 18.0\n",
      "Step 857 (6038790) @ Episode 7836/10000, loss: 0.0078476080670952845\n",
      "Episode Reward: 20.0\n",
      "Step 603 (6039393) @ Episode 7837/10000, loss: 0.0022818441502749926\n",
      "Episode Reward: 10.0\n",
      "Step 606 (6039999) @ Episode 7838/10000, loss: 0.0045702839270234114\n",
      " Copied model parameters to target network\n",
      "Step 931 (6040324) @ Episode 7838/10000, loss: 0.0019948554690927267\n",
      "Episode Reward: 13.0\n",
      "Step 864 (6041188) @ Episode 7839/10000, loss: 0.0076651545241475105\n",
      "Episode Reward: 21.0\n",
      "Step 908 (6042096) @ Episode 7840/10000, loss: 0.0045154141262173653\n",
      "Episode Reward: 19.0\n",
      "Step 1376 (6043472) @ Episode 7841/10000, loss: 0.0016338222194463015\n",
      "Episode Reward: 34.0\n",
      "Step 928 (6044400) @ Episode 7842/10000, loss: 0.0036189442034810785\n",
      "Episode Reward: 15.0\n",
      "Step 717 (6045117) @ Episode 7843/10000, loss: 0.0036058761179447174\n",
      "Episode Reward: 11.0\n",
      "Step 374 (6045491) @ Episode 7844/10000, loss: 0.0031981843058019876\n",
      "Episode Reward: 5.0\n",
      "Step 708 (6046199) @ Episode 7845/10000, loss: 0.0179496575146913535\n",
      "Episode Reward: 11.0\n",
      "Step 588 (6046787) @ Episode 7846/10000, loss: 0.0056022442877292633\n",
      "Episode Reward: 9.0\n",
      "Step 564 (6047351) @ Episode 7847/10000, loss: 0.0107316561043262484\n",
      "Episode Reward: 9.0\n",
      "Step 721 (6048072) @ Episode 7848/10000, loss: 0.0024073121603578337\n",
      "Episode Reward: 13.0\n",
      "Step 574 (6048646) @ Episode 7849/10000, loss: 0.0035987878218293194\n",
      "Episode Reward: 12.0\n",
      "Step 618 (6049264) @ Episode 7850/10000, loss: 0.0071612764149904256\n",
      "Episode Reward: 8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 08:10:08,175] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video007850.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 735 (6049999) @ Episode 7851/10000, loss: 0.0037188543938100345\n",
      " Copied model parameters to target network\n",
      "Step 764 (6050028) @ Episode 7851/10000, loss: 0.0032301787286996846\n",
      "Episode Reward: 19.0\n",
      "Step 944 (6050972) @ Episode 7852/10000, loss: 0.0089424727484583856\n",
      "Episode Reward: 18.0\n",
      "Step 721 (6051693) @ Episode 7853/10000, loss: 0.0071255965158343315\n",
      "Episode Reward: 11.0\n",
      "Step 672 (6052365) @ Episode 7854/10000, loss: 0.0070200762711465366\n",
      "Episode Reward: 11.0\n",
      "Step 585 (6052950) @ Episode 7855/10000, loss: 0.0016822674078866847\n",
      "Episode Reward: 16.0\n",
      "Step 546 (6053496) @ Episode 7856/10000, loss: 0.0072374716401100165\n",
      "Episode Reward: 9.0\n",
      "Step 666 (6054162) @ Episode 7857/10000, loss: 0.0016396819846704602\n",
      "Episode Reward: 9.0\n",
      "Step 735 (6054897) @ Episode 7858/10000, loss: 0.0052401730790734292\n",
      "Episode Reward: 11.0\n",
      "Step 820 (6055717) @ Episode 7859/10000, loss: 0.0041356659494340425\n",
      "Episode Reward: 13.0\n",
      "Step 807 (6056524) @ Episode 7860/10000, loss: 0.0014246281934902072\n",
      "Episode Reward: 15.0\n",
      "Step 825 (6057349) @ Episode 7861/10000, loss: 0.0114614609628915796\n",
      "Episode Reward: 11.0\n",
      "Step 282 (6057631) @ Episode 7862/10000, loss: 0.0023729614913463593\n",
      "Episode Reward: 3.0\n",
      "Step 836 (6058467) @ Episode 7863/10000, loss: 0.0017764985095709562\n",
      "Episode Reward: 14.0\n",
      "Step 932 (6059399) @ Episode 7864/10000, loss: 0.0041763414628803733\n",
      "Episode Reward: 23.0\n",
      "Step 600 (6059999) @ Episode 7865/10000, loss: 0.0042354357428848743\n",
      " Copied model parameters to target network\n",
      "Step 649 (6060048) @ Episode 7865/10000, loss: 0.0038473620079457764\n",
      "Episode Reward: 8.0\n",
      "Step 860 (6060908) @ Episode 7866/10000, loss: 0.0023338436149060726\n",
      "Episode Reward: 15.0\n",
      "Step 586 (6061494) @ Episode 7867/10000, loss: 0.0027157040312886247\n",
      "Episode Reward: 8.0\n",
      "Step 719 (6062213) @ Episode 7868/10000, loss: 0.0022742950823158026\n",
      "Episode Reward: 12.0\n",
      "Step 592 (6062805) @ Episode 7869/10000, loss: 0.0080401869490742686\n",
      "Episode Reward: 11.0\n",
      "Step 862 (6063667) @ Episode 7870/10000, loss: 0.0013303917367011309\n",
      "Episode Reward: 14.0\n",
      "Step 645 (6064312) @ Episode 7871/10000, loss: 0.0021768244914710525\n",
      "Episode Reward: 9.0\n",
      "Step 720 (6065032) @ Episode 7872/10000, loss: 0.0067100967280566693\n",
      "Episode Reward: 15.0\n",
      "Step 866 (6065898) @ Episode 7873/10000, loss: 0.0026981448754668236\n",
      "Episode Reward: 19.0\n",
      "Step 860 (6066758) @ Episode 7874/10000, loss: 0.0020095156505703926\n",
      "Episode Reward: 17.0\n",
      "Step 790 (6067548) @ Episode 7875/10000, loss: 0.0039035691879689693\n",
      "Episode Reward: 18.0\n",
      "Step 843 (6068391) @ Episode 7876/10000, loss: 0.0064596207812428474\n",
      "Episode Reward: 14.0\n",
      "Step 704 (6069095) @ Episode 7877/10000, loss: 0.0173278264701366423\n",
      "Episode Reward: 11.0\n",
      "Step 904 (6069999) @ Episode 7878/10000, loss: 0.0026185901369899517\n",
      " Copied model parameters to target network\n",
      "Step 1246 (6070341) @ Episode 7878/10000, loss: 0.0018166931113228202\n",
      "Episode Reward: 26.0\n",
      "Step 692 (6071033) @ Episode 7879/10000, loss: 0.0052686082199215895\n",
      "Episode Reward: 10.0\n",
      "Step 1056 (6072089) @ Episode 7880/10000, loss: 0.0546611249446868983\n",
      "Episode Reward: 26.0\n",
      "Step 898 (6072987) @ Episode 7881/10000, loss: 0.0046036764979362497\n",
      "Episode Reward: 14.0\n",
      "Step 882 (6073869) @ Episode 7882/10000, loss: 0.0050570238381624225\n",
      "Episode Reward: 13.0\n",
      "Step 728 (6074597) @ Episode 7883/10000, loss: 0.0034734143409878016\n",
      "Episode Reward: 12.0\n",
      "Step 782 (6075379) @ Episode 7884/10000, loss: 0.0026514907367527485\n",
      "Episode Reward: 12.0\n",
      "Step 849 (6076228) @ Episode 7885/10000, loss: 0.0064684124663472176\n",
      "Episode Reward: 19.0\n",
      "Step 939 (6077167) @ Episode 7886/10000, loss: 0.0033336943015456285\n",
      "Episode Reward: 16.0\n",
      "Step 609 (6077776) @ Episode 7887/10000, loss: 0.0014150060014799237\n",
      "Episode Reward: 8.0\n",
      "Step 772 (6078548) @ Episode 7888/10000, loss: 0.0097503373399376875\n",
      "Episode Reward: 14.0\n",
      "Step 789 (6079337) @ Episode 7889/10000, loss: 0.0033121809829026464\n",
      "Episode Reward: 14.0\n",
      "Step 662 (6079999) @ Episode 7890/10000, loss: 0.0053672106005251415\n",
      " Copied model parameters to target network\n",
      "Step 791 (6080128) @ Episode 7890/10000, loss: 0.0022435882128775125\n",
      "Episode Reward: 13.0\n",
      "Step 737 (6080865) @ Episode 7891/10000, loss: 0.0059315715916454792\n",
      "Episode Reward: 13.0\n",
      "Step 438 (6081303) @ Episode 7892/10000, loss: 0.0035582755226641893\n",
      "Episode Reward: 5.0\n",
      "Step 693 (6081996) @ Episode 7893/10000, loss: 0.0024166484363377094\n",
      "Episode Reward: 10.0\n",
      "Step 736 (6082732) @ Episode 7894/10000, loss: 0.0051952372305095237\n",
      "Episode Reward: 13.0\n",
      "Step 571 (6083303) @ Episode 7895/10000, loss: 0.0046049603261053564\n",
      "Episode Reward: 10.0\n",
      "Step 630 (6083933) @ Episode 7896/10000, loss: 0.0066981445997953415\n",
      "Episode Reward: 9.0\n",
      "Step 1225 (6085158) @ Episode 7897/10000, loss: 0.0016103913076221943\n",
      "Episode Reward: 34.0\n",
      "Step 563 (6085721) @ Episode 7898/10000, loss: 0.0042662522755563263\n",
      "Episode Reward: 8.0\n",
      "Step 924 (6086645) @ Episode 7899/10000, loss: 0.0391583666205406216\n",
      "Episode Reward: 20.0\n",
      "Step 839 (6087484) @ Episode 7900/10000, loss: 0.0046907300129532816\n",
      "Episode Reward: 14.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 08:16:08,793] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video007900.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 599 (6088083) @ Episode 7901/10000, loss: 0.0018604559591040015\n",
      "Episode Reward: 8.0\n",
      "Step 658 (6088741) @ Episode 7902/10000, loss: 0.0023104115389287476\n",
      "Episode Reward: 10.0\n",
      "Step 991 (6089732) @ Episode 7903/10000, loss: 0.0043145199306309226\n",
      "Episode Reward: 20.0\n",
      "Step 267 (6089999) @ Episode 7904/10000, loss: 0.0109316213056445123\n",
      " Copied model parameters to target network\n",
      "Step 847 (6090579) @ Episode 7904/10000, loss: 0.0073933387175202377\n",
      "Episode Reward: 18.0\n",
      "Step 1034 (6091613) @ Episode 7905/10000, loss: 0.0020725654903799295\n",
      "Episode Reward: 21.0\n",
      "Step 839 (6092452) @ Episode 7906/10000, loss: 0.0054557546973228455\n",
      "Episode Reward: 13.0\n",
      "Step 754 (6093206) @ Episode 7907/10000, loss: 0.0228614564985036855\n",
      "Episode Reward: 15.0\n",
      "Step 591 (6093797) @ Episode 7908/10000, loss: 0.0022288479376584298\n",
      "Episode Reward: 7.0\n",
      "Step 666 (6094463) @ Episode 7909/10000, loss: 0.0040056770667433748\n",
      "Episode Reward: 13.0\n",
      "Step 767 (6095230) @ Episode 7910/10000, loss: 0.0082174343988299373\n",
      "Episode Reward: 12.0\n",
      "Step 1236 (6096466) @ Episode 7911/10000, loss: 0.0070656593888998037\n",
      "Episode Reward: 33.0\n",
      "Step 878 (6097344) @ Episode 7912/10000, loss: 0.0071942070499062545\n",
      "Episode Reward: 17.0\n",
      "Step 753 (6098097) @ Episode 7913/10000, loss: 0.0104709258303046233\n",
      "Episode Reward: 12.0\n",
      "Step 782 (6098879) @ Episode 7914/10000, loss: 0.0074374014511704445\n",
      "Episode Reward: 12.0\n",
      "Step 1120 (6099999) @ Episode 7915/10000, loss: 0.0013753741513937712\n",
      " Copied model parameters to target network\n",
      "Step 1596 (6100475) @ Episode 7915/10000, loss: 0.0159098953008651733\n",
      "Episode Reward: 45.0\n",
      "Step 683 (6101158) @ Episode 7916/10000, loss: 0.0020806209649890667\n",
      "Episode Reward: 10.0\n",
      "Step 989 (6102147) @ Episode 7917/10000, loss: 0.0029944069683551797\n",
      "Episode Reward: 16.0\n",
      "Step 874 (6103021) @ Episode 7918/10000, loss: 0.0064020063728094153\n",
      "Episode Reward: 14.0\n",
      "Step 1097 (6104118) @ Episode 7919/10000, loss: 0.0098478738218545917\n",
      "Episode Reward: 26.0\n",
      "Step 1056 (6105174) @ Episode 7920/10000, loss: 0.0017734845168888569\n",
      "Episode Reward: 17.0\n",
      "Step 421 (6105595) @ Episode 7921/10000, loss: 0.0078868102282285695\n",
      "Episode Reward: 6.0\n",
      "Step 792 (6106387) @ Episode 7922/10000, loss: 0.0084016947075724633\n",
      "Episode Reward: 12.0\n",
      "Step 453 (6106840) @ Episode 7923/10000, loss: 0.0062279417179524933\n",
      "Episode Reward: 7.0\n",
      "Step 680 (6107520) @ Episode 7924/10000, loss: 0.0175097193568944932\n",
      "Episode Reward: 10.0\n",
      "Step 621 (6108141) @ Episode 7925/10000, loss: 0.0057123331353068353\n",
      "Episode Reward: 8.0\n",
      "Step 766 (6108907) @ Episode 7926/10000, loss: 0.0060264649800956252\n",
      "Episode Reward: 14.0\n",
      "Step 726 (6109633) @ Episode 7927/10000, loss: 0.0030664186924695976\n",
      "Episode Reward: 11.0\n",
      "Step 366 (6109999) @ Episode 7928/10000, loss: 0.0176529306918382646\n",
      " Copied model parameters to target network\n",
      "Step 902 (6110535) @ Episode 7928/10000, loss: 0.0046424739994108684\n",
      "Episode Reward: 15.0\n",
      "Step 453 (6110988) @ Episode 7929/10000, loss: 0.0100433155894279485\n",
      "Episode Reward: 6.0\n",
      "Step 965 (6111953) @ Episode 7930/10000, loss: 0.0055351648479700095\n",
      "Episode Reward: 19.0\n",
      "Step 762 (6112715) @ Episode 7931/10000, loss: 0.0016381207387894392\n",
      "Episode Reward: 16.0\n",
      "Step 791 (6113506) @ Episode 7932/10000, loss: 0.0039269425906240946\n",
      "Episode Reward: 12.0\n",
      "Step 1045 (6114551) @ Episode 7933/10000, loss: 0.0063016004860401157\n",
      "Episode Reward: 19.0\n",
      "Step 1065 (6115616) @ Episode 7934/10000, loss: 0.0044869957491755486\n",
      "Episode Reward: 20.0\n",
      "Step 840 (6116456) @ Episode 7935/10000, loss: 0.0052412273362278948\n",
      "Episode Reward: 14.0\n",
      "Step 757 (6117213) @ Episode 7936/10000, loss: 0.0034671705216169357\n",
      "Episode Reward: 12.0\n",
      "Step 567 (6117780) @ Episode 7937/10000, loss: 0.0190715417265892038\n",
      "Episode Reward: 9.0\n",
      "Step 719 (6118499) @ Episode 7938/10000, loss: 0.0061313146725296976\n",
      "Episode Reward: 12.0\n",
      "Step 564 (6119063) @ Episode 7939/10000, loss: 0.0053750579245388515\n",
      "Episode Reward: 10.0\n",
      "Step 756 (6119819) @ Episode 7940/10000, loss: 0.0020331097766757013\n",
      "Episode Reward: 13.0\n",
      "Step 180 (6119999) @ Episode 7941/10000, loss: 0.0055542853660881524\n",
      " Copied model parameters to target network\n",
      "Step 557 (6120376) @ Episode 7941/10000, loss: 0.0027660769410431385\n",
      "Episode Reward: 7.0\n",
      "Step 962 (6121338) @ Episode 7942/10000, loss: 0.0032800845801830296\n",
      "Episode Reward: 18.0\n",
      "Step 689 (6122027) @ Episode 7943/10000, loss: 0.0023194078821688895\n",
      "Episode Reward: 9.0\n",
      "Step 930 (6122957) @ Episode 7944/10000, loss: 0.0129397632554173477\n",
      "Episode Reward: 15.0\n",
      "Step 1093 (6124050) @ Episode 7945/10000, loss: 0.0064721703529357912\n",
      "Episode Reward: 24.0\n",
      "Step 961 (6125011) @ Episode 7946/10000, loss: 0.0042849970050156122\n",
      "Episode Reward: 16.0\n",
      "Step 876 (6125887) @ Episode 7947/10000, loss: 0.0057149785570800304\n",
      "Episode Reward: 15.0\n",
      "Step 638 (6126525) @ Episode 7948/10000, loss: 0.0056471601128578197\n",
      "Episode Reward: 9.0\n",
      "Step 813 (6127338) @ Episode 7949/10000, loss: 0.0037403306923806667\n",
      "Episode Reward: 14.0\n",
      "Step 962 (6128300) @ Episode 7950/10000, loss: 0.0060759261250495914\n",
      "Episode Reward: 17.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 08:22:32,336] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video007950.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 836 (6129136) @ Episode 7951/10000, loss: 0.0116313882172107776\n",
      "Episode Reward: 18.0\n",
      "Step 740 (6129876) @ Episode 7952/10000, loss: 0.0071949055418372154\n",
      "Episode Reward: 11.0\n",
      "Step 123 (6129999) @ Episode 7953/10000, loss: 0.0118092615157365895\n",
      " Copied model parameters to target network\n",
      "Step 764 (6130640) @ Episode 7953/10000, loss: 0.0050926711410284042\n",
      "Episode Reward: 17.0\n",
      "Step 599 (6131239) @ Episode 7954/10000, loss: 0.0025667408481240273\n",
      "Episode Reward: 13.0\n",
      "Step 855 (6132094) @ Episode 7955/10000, loss: 0.0103839654475450525\n",
      "Episode Reward: 15.0\n",
      "Step 1011 (6133105) @ Episode 7956/10000, loss: 0.0107214218005537998\n",
      "Episode Reward: 21.0\n",
      "Step 740 (6133845) @ Episode 7957/10000, loss: 0.0103705264627933569\n",
      "Episode Reward: 10.0\n",
      "Step 493 (6134338) @ Episode 7958/10000, loss: 0.0046659051440656185\n",
      "Episode Reward: 8.0\n",
      "Step 823 (6135161) @ Episode 7959/10000, loss: 0.0035426761023700237\n",
      "Episode Reward: 14.0\n",
      "Step 725 (6135886) @ Episode 7960/10000, loss: 0.0021995718125253916\n",
      "Episode Reward: 13.0\n",
      "Step 1013 (6136899) @ Episode 7961/10000, loss: 0.0014688684605062008\n",
      "Episode Reward: 19.0\n",
      "Step 864 (6137763) @ Episode 7962/10000, loss: 0.0028135823085904125\n",
      "Episode Reward: 16.0\n",
      "Step 602 (6138365) @ Episode 7963/10000, loss: 0.0130790825933218122\n",
      "Episode Reward: 9.0\n",
      "Step 888 (6139253) @ Episode 7964/10000, loss: 0.0025464640930294995\n",
      "Episode Reward: 21.0\n",
      "Step 746 (6139999) @ Episode 7965/10000, loss: 0.0047158170491456985\n",
      " Copied model parameters to target network\n",
      "Step 865 (6140118) @ Episode 7965/10000, loss: 0.0007389187812805176\n",
      "Episode Reward: 21.0\n",
      "Step 673 (6140791) @ Episode 7966/10000, loss: 0.0034978222101926804\n",
      "Episode Reward: 13.0\n",
      "Step 658 (6141449) @ Episode 7967/10000, loss: 0.0024512168020009995\n",
      "Episode Reward: 11.0\n",
      "Step 710 (6142159) @ Episode 7968/10000, loss: 0.0078922687098383945\n",
      "Episode Reward: 11.0\n",
      "Step 710 (6142869) @ Episode 7969/10000, loss: 0.0062205409631133086\n",
      "Episode Reward: 11.0\n",
      "Step 1063 (6143932) @ Episode 7970/10000, loss: 0.0045461067929863935\n",
      "Episode Reward: 21.0\n",
      "Step 899 (6144831) @ Episode 7971/10000, loss: 0.0012748313602060087\n",
      "Episode Reward: 14.0\n",
      "Step 564 (6145395) @ Episode 7972/10000, loss: 0.0080715026706457143\n",
      "Episode Reward: 14.0\n",
      "Step 1125 (6146520) @ Episode 7973/10000, loss: 0.0020520242396742105\n",
      "Episode Reward: 27.0\n",
      "Step 706 (6147226) @ Episode 7974/10000, loss: 0.0063624735921621324\n",
      "Episode Reward: 12.0\n",
      "Step 567 (6147793) @ Episode 7975/10000, loss: 0.0024914825335144997\n",
      "Episode Reward: 10.0\n",
      "Step 1000 (6148793) @ Episode 7976/10000, loss: 0.0018346668221056461\n",
      "Episode Reward: 17.0\n",
      "Step 1038 (6149831) @ Episode 7977/10000, loss: 0.0044037755578756336\n",
      "Episode Reward: 24.0\n",
      "Step 168 (6149999) @ Episode 7978/10000, loss: 0.0051273107528686522\n",
      " Copied model parameters to target network\n",
      "Step 986 (6150817) @ Episode 7978/10000, loss: 0.0030406052246689796\n",
      "Episode Reward: 18.0\n",
      "Step 1052 (6151869) @ Episode 7979/10000, loss: 0.0095444936305284516\n",
      "Episode Reward: 25.0\n",
      "Step 517 (6152386) @ Episode 7980/10000, loss: 0.0098789418116211897\n",
      "Episode Reward: 6.0\n",
      "Step 885 (6153271) @ Episode 7981/10000, loss: 0.0025032516568899155\n",
      "Episode Reward: 16.0\n",
      "Step 752 (6154023) @ Episode 7982/10000, loss: 0.0045922878198325634\n",
      "Episode Reward: 12.0\n",
      "Step 749 (6154772) @ Episode 7983/10000, loss: 0.0058534876443445683\n",
      "Episode Reward: 16.0\n",
      "Step 792 (6155564) @ Episode 7984/10000, loss: 0.0025151793379336596\n",
      "Episode Reward: 13.0\n",
      "Step 1205 (6156769) @ Episode 7985/10000, loss: 0.0036593652330338955\n",
      "Episode Reward: 34.0\n",
      "Step 899 (6157668) @ Episode 7986/10000, loss: 0.0018731013406068087\n",
      "Episode Reward: 17.0\n",
      "Step 1043 (6158711) @ Episode 7987/10000, loss: 0.0057830028235912324\n",
      "Episode Reward: 17.0\n",
      "Step 657 (6159368) @ Episode 7988/10000, loss: 0.0071690911427140248\n",
      "Episode Reward: 10.0\n",
      "Step 631 (6159999) @ Episode 7989/10000, loss: 0.0020045756828039885\n",
      " Copied model parameters to target network\n",
      "Step 1022 (6160390) @ Episode 7989/10000, loss: 0.0040363948792219169\n",
      "Episode Reward: 23.0\n",
      "Step 507 (6160897) @ Episode 7990/10000, loss: 0.0068784062750637535\n",
      "Episode Reward: 7.0\n",
      "Step 672 (6161569) @ Episode 7991/10000, loss: 0.0026442441157996655\n",
      "Episode Reward: 9.0\n",
      "Step 1106 (6162675) @ Episode 7992/10000, loss: 0.0017677249852567911\n",
      "Episode Reward: 22.0\n",
      "Step 494 (6163169) @ Episode 7993/10000, loss: 0.0030055921524763107\n",
      "Episode Reward: 6.0\n",
      "Step 859 (6164028) @ Episode 7994/10000, loss: 0.0098642539232969287\n",
      "Episode Reward: 18.0\n",
      "Step 1099 (6165127) @ Episode 7995/10000, loss: 0.0034534435253590345\n",
      "Episode Reward: 25.0\n",
      "Step 643 (6165770) @ Episode 7996/10000, loss: 0.0097684888169169435\n",
      "Episode Reward: 11.0\n",
      "Step 1086 (6166856) @ Episode 7997/10000, loss: 0.0039967945776879794\n",
      "Episode Reward: 28.0\n",
      "Step 749 (6167605) @ Episode 7998/10000, loss: 0.0030416955705732107\n",
      "Episode Reward: 12.0\n",
      "Step 1216 (6168821) @ Episode 7999/10000, loss: 0.0025081960484385493\n",
      "Episode Reward: 28.0\n",
      "Step 922 (6169743) @ Episode 8000/10000, loss: 0.0052485964260995396\n",
      "Episode Reward: 22.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 08:29:03,111] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video008000.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 256 (6169999) @ Episode 8001/10000, loss: 0.0031227488070726395\n",
      " Copied model parameters to target network\n",
      "Step 687 (6170430) @ Episode 8001/10000, loss: 0.0023622021544724703\n",
      "Episode Reward: 13.0\n",
      "Step 848 (6171278) @ Episode 8002/10000, loss: 0.0075707342475652695\n",
      "Episode Reward: 16.0\n",
      "Step 817 (6172095) @ Episode 8003/10000, loss: 0.0035010357387363915\n",
      "Episode Reward: 11.0\n",
      "Step 802 (6172897) @ Episode 8004/10000, loss: 0.0024077603593468666\n",
      "Episode Reward: 11.0\n",
      "Step 1120 (6174017) @ Episode 8005/10000, loss: 0.0076529602520167835\n",
      "Episode Reward: 17.0\n",
      "Step 965 (6174982) @ Episode 8006/10000, loss: 0.0442792810499668185\n",
      "Episode Reward: 19.0\n",
      "Step 800 (6175782) @ Episode 8007/10000, loss: 0.0277003087103366852\n",
      "Episode Reward: 11.0\n",
      "Step 761 (6176543) @ Episode 8008/10000, loss: 0.0070260707288980485\n",
      "Episode Reward: 10.0\n",
      "Step 491 (6177034) @ Episode 8009/10000, loss: 0.0054056160151958466\n",
      "Episode Reward: 6.0\n",
      "Step 746 (6177780) @ Episode 8010/10000, loss: 0.0022906525991857056\n",
      "Episode Reward: 14.0\n",
      "Step 1087 (6178867) @ Episode 8011/10000, loss: 0.0100286956876516345\n",
      "Episode Reward: 18.0\n",
      "Step 570 (6179437) @ Episode 8012/10000, loss: 0.0041401861235499385\n",
      "Episode Reward: 7.0\n",
      "Step 528 (6179965) @ Episode 8013/10000, loss: 0.0023169978521764287\n",
      "Episode Reward: 8.0\n",
      "Step 34 (6179999) @ Episode 8014/10000, loss: 0.0028860983438789845\n",
      " Copied model parameters to target network\n",
      "Step 538 (6180503) @ Episode 8014/10000, loss: 0.1036558970808982857\n",
      "Episode Reward: 8.0\n",
      "Step 628 (6181131) @ Episode 8015/10000, loss: 0.0066133122891187676\n",
      "Episode Reward: 10.0\n",
      "Step 655 (6181786) @ Episode 8016/10000, loss: 0.0102707017213106168\n",
      "Episode Reward: 9.0\n",
      "Step 798 (6182584) @ Episode 8017/10000, loss: 0.0035798326134681765\n",
      "Episode Reward: 12.0\n",
      "Step 980 (6183564) @ Episode 8018/10000, loss: 0.0345096960663795553\n",
      "Episode Reward: 20.0\n",
      "Step 1012 (6184576) @ Episode 8019/10000, loss: 0.0028956066817045215\n",
      "Episode Reward: 24.0\n",
      "Step 652 (6185228) @ Episode 8020/10000, loss: 0.0058895852416753776\n",
      "Episode Reward: 9.0\n",
      "Step 777 (6186005) @ Episode 8021/10000, loss: 0.0032292581163346767\n",
      "Episode Reward: 12.0\n",
      "Step 804 (6186809) @ Episode 8022/10000, loss: 0.0055619189515709888\n",
      "Episode Reward: 13.0\n",
      "Step 446 (6187255) @ Episode 8023/10000, loss: 0.0037880989257246256\n",
      "Episode Reward: 5.0\n",
      "Step 1148 (6188403) @ Episode 8024/10000, loss: 0.0043030781671404844\n",
      "Episode Reward: 27.0\n",
      "Step 785 (6189188) @ Episode 8025/10000, loss: 0.0097181200981140142\n",
      "Episode Reward: 11.0\n",
      "Step 811 (6189999) @ Episode 8026/10000, loss: 0.0054202382452785974\n",
      " Copied model parameters to target network\n",
      "Step 884 (6190072) @ Episode 8026/10000, loss: 0.0027288410346955065\n",
      "Episode Reward: 15.0\n",
      "Step 792 (6190864) @ Episode 8027/10000, loss: 0.0039180736057460315\n",
      "Episode Reward: 24.0\n",
      "Step 1039 (6191903) @ Episode 8028/10000, loss: 0.0020188107155263424\n",
      "Episode Reward: 19.0\n",
      "Step 687 (6192590) @ Episode 8029/10000, loss: 0.0020146416500210766\n",
      "Episode Reward: 8.0\n",
      "Step 682 (6193272) @ Episode 8030/10000, loss: 0.0041464604437351235\n",
      "Episode Reward: 10.0\n",
      "Step 826 (6194098) @ Episode 8031/10000, loss: 0.0038836849853396416\n",
      "Episode Reward: 13.0\n",
      "Step 519 (6194617) @ Episode 8032/10000, loss: 0.0018413617508485913\n",
      "Episode Reward: 8.0\n",
      "Step 960 (6195577) @ Episode 8033/10000, loss: 0.0026826199609786276\n",
      "Episode Reward: 23.0\n",
      "Step 648 (6196225) @ Episode 8034/10000, loss: 0.1825745254755020165\n",
      "Episode Reward: 9.0\n",
      "Step 977 (6197202) @ Episode 8035/10000, loss: 0.0013917882461100817\n",
      "Episode Reward: 17.0\n",
      "Step 583 (6197785) @ Episode 8036/10000, loss: 0.0058736186474561695\n",
      "Episode Reward: 9.0\n",
      "Step 1145 (6198930) @ Episode 8037/10000, loss: 0.0035580596886575226\n",
      "Episode Reward: 18.0\n",
      "Step 616 (6199546) @ Episode 8038/10000, loss: 0.0071430052630603313\n",
      "Episode Reward: 13.0\n",
      "Step 453 (6199999) @ Episode 8039/10000, loss: 0.0033162927720695734\n",
      " Copied model parameters to target network\n",
      "Step 775 (6200321) @ Episode 8039/10000, loss: 0.0016396600985899568\n",
      "Episode Reward: 12.0\n",
      "Step 848 (6201169) @ Episode 8040/10000, loss: 0.0021180780604481697\n",
      "Episode Reward: 14.0\n",
      "Step 997 (6202166) @ Episode 8041/10000, loss: 0.0016013665590435266\n",
      "Episode Reward: 17.0\n",
      "Step 969 (6203135) @ Episode 8042/10000, loss: 0.0063302647322416306\n",
      "Episode Reward: 19.0\n",
      "Step 866 (6204001) @ Episode 8043/10000, loss: 0.0017274835845455527\n",
      "Episode Reward: 17.0\n",
      "Step 1003 (6205004) @ Episode 8044/10000, loss: 0.004673662595450878\n",
      "Episode Reward: 21.0\n",
      "Step 658 (6205662) @ Episode 8045/10000, loss: 0.0039657852612435823\n",
      "Episode Reward: 10.0\n",
      "Step 706 (6206368) @ Episode 8046/10000, loss: 0.0014740447513759136\n",
      "Episode Reward: 11.0\n",
      "Step 506 (6206874) @ Episode 8047/10000, loss: 0.0035123080015182495\n",
      "Episode Reward: 7.0\n",
      "Step 1045 (6207919) @ Episode 8048/10000, loss: 0.0086503960192203526\n",
      "Episode Reward: 16.0\n",
      "Step 1152 (6209071) @ Episode 8049/10000, loss: 0.0040654605254530915\n",
      "Episode Reward: 24.0\n",
      "Step 703 (6209774) @ Episode 8050/10000, loss: 0.0029128519818186762\n",
      "Episode Reward: 11.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 08:35:20,838] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video008050.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 225 (6209999) @ Episode 8051/10000, loss: 0.0019209617748856544\n",
      " Copied model parameters to target network\n",
      "Step 532 (6210306) @ Episode 8051/10000, loss: 0.0111553696915507322\n",
      "Episode Reward: 7.0\n",
      "Step 1135 (6211441) @ Episode 8052/10000, loss: 0.0045624002814292918\n",
      "Episode Reward: 18.0\n",
      "Step 706 (6212147) @ Episode 8053/10000, loss: 0.0050193476490676467\n",
      "Episode Reward: 9.0\n",
      "Step 582 (6212729) @ Episode 8054/10000, loss: 0.0043258303776383463\n",
      "Episode Reward: 8.0\n",
      "Step 962 (6213691) @ Episode 8055/10000, loss: 0.0078104343265295035\n",
      "Episode Reward: 20.0\n",
      "Step 796 (6214487) @ Episode 8056/10000, loss: 0.0048897638916969346\n",
      "Episode Reward: 26.0\n",
      "Step 866 (6215353) @ Episode 8057/10000, loss: 0.0080569889396429067\n",
      "Episode Reward: 17.0\n",
      "Step 787 (6216140) @ Episode 8058/10000, loss: 0.0391631647944450427\n",
      "Episode Reward: 12.0\n",
      "Step 656 (6216796) @ Episode 8059/10000, loss: 0.0071643684059381485\n",
      "Episode Reward: 10.0\n",
      "Step 1035 (6217831) @ Episode 8060/10000, loss: 0.0040986626408994255\n",
      "Episode Reward: 23.0\n",
      "Step 888 (6218719) @ Episode 8061/10000, loss: 0.0022441525943577296\n",
      "Episode Reward: 14.0\n",
      "Step 570 (6219289) @ Episode 8062/10000, loss: 0.0017716498114168644\n",
      "Episode Reward: 7.0\n",
      "Step 710 (6219999) @ Episode 8063/10000, loss: 0.0026688312646001577\n",
      " Copied model parameters to target network\n",
      "Step 765 (6220054) @ Episode 8063/10000, loss: 0.0459448210895061565\n",
      "Episode Reward: 13.0\n",
      "Step 1187 (6221241) @ Episode 8064/10000, loss: 0.0024018131662160167\n",
      "Episode Reward: 19.0\n",
      "Step 740 (6221981) @ Episode 8065/10000, loss: 0.0034935991279780865\n",
      "Episode Reward: 12.0\n",
      "Step 929 (6222910) @ Episode 8066/10000, loss: 0.0030449130572378635\n",
      "Episode Reward: 26.0\n",
      "Step 513 (6223423) @ Episode 8067/10000, loss: 0.0021558327134698635\n",
      "Episode Reward: 8.0\n",
      "Step 1067 (6224490) @ Episode 8068/10000, loss: 0.0039630341343581685\n",
      "Episode Reward: 22.0\n",
      "Step 667 (6225157) @ Episode 8069/10000, loss: 0.0040630884468555451\n",
      "Episode Reward: 11.0\n",
      "Step 1150 (6226307) @ Episode 8070/10000, loss: 0.0145543804392218595\n",
      "Episode Reward: 23.0\n",
      "Step 755 (6227062) @ Episode 8071/10000, loss: 0.0039031214546412234\n",
      "Episode Reward: 18.0\n",
      "Step 853 (6227915) @ Episode 8072/10000, loss: 0.0186297353357076647\n",
      "Episode Reward: 14.0\n",
      "Step 900 (6228815) @ Episode 8073/10000, loss: 0.0030543073080480175\n",
      "Episode Reward: 17.0\n",
      "Step 1080 (6229895) @ Episode 8074/10000, loss: 0.0024921754375100136\n",
      "Episode Reward: 23.0\n",
      "Step 104 (6229999) @ Episode 8075/10000, loss: 0.0074905478395521648\n",
      " Copied model parameters to target network\n",
      "Step 624 (6230519) @ Episode 8075/10000, loss: 0.0119827752932906155\n",
      "Episode Reward: 9.0\n",
      "Step 1080 (6231599) @ Episode 8076/10000, loss: 0.0075814025476574944\n",
      "Episode Reward: 18.0\n",
      "Step 852 (6232451) @ Episode 8077/10000, loss: 0.0099451784044504177\n",
      "Episode Reward: 15.0\n",
      "Step 799 (6233250) @ Episode 8078/10000, loss: 0.0067272926680743695\n",
      "Episode Reward: 16.0\n",
      "Step 868 (6234118) @ Episode 8079/10000, loss: 0.0061954837292432785\n",
      "Episode Reward: 17.0\n",
      "Step 636 (6234754) @ Episode 8080/10000, loss: 0.0033678787294775248\n",
      "Episode Reward: 10.0\n",
      "Step 920 (6235674) @ Episode 8081/10000, loss: 0.0067158043384552467\n",
      "Episode Reward: 23.0\n",
      "Step 858 (6236532) @ Episode 8082/10000, loss: 0.0062940865755081186\n",
      "Episode Reward: 25.0\n",
      "Step 1029 (6237561) @ Episode 8083/10000, loss: 0.0025297845713794234\n",
      "Episode Reward: 20.0\n",
      "Step 838 (6238399) @ Episode 8084/10000, loss: 0.0056054955348372464\n",
      "Episode Reward: 14.0\n",
      "Step 825 (6239224) @ Episode 8085/10000, loss: 0.0054667638614773754\n",
      "Episode Reward: 15.0\n",
      "Step 775 (6239999) @ Episode 8086/10000, loss: 0.0037966975942254066\n",
      " Copied model parameters to target network\n",
      "Step 965 (6240189) @ Episode 8086/10000, loss: 0.0031744046136736875\n",
      "Episode Reward: 19.0\n",
      "Step 944 (6241133) @ Episode 8087/10000, loss: 0.0109163718298077583\n",
      "Episode Reward: 17.0\n",
      "Step 705 (6241838) @ Episode 8088/10000, loss: 0.0038678538985550404\n",
      "Episode Reward: 12.0\n",
      "Step 899 (6242737) @ Episode 8089/10000, loss: 0.0021196100860834125\n",
      "Episode Reward: 16.0\n",
      "Step 1024 (6243761) @ Episode 8090/10000, loss: 0.0041675041429698476\n",
      "Episode Reward: 19.0\n",
      "Step 780 (6244541) @ Episode 8091/10000, loss: 0.0148635748773813254\n",
      "Episode Reward: 12.0\n",
      "Step 1012 (6245553) @ Episode 8092/10000, loss: 0.0083137992769479755\n",
      "Episode Reward: 20.0\n",
      "Step 798 (6246351) @ Episode 8093/10000, loss: 0.0038842824287712574\n",
      "Episode Reward: 16.0\n",
      "Step 801 (6247152) @ Episode 8094/10000, loss: 0.0035139215178787716\n",
      "Episode Reward: 11.0\n",
      "Step 739 (6247891) @ Episode 8095/10000, loss: 0.0028912047855556015\n",
      "Episode Reward: 11.0\n",
      "Step 624 (6248515) @ Episode 8096/10000, loss: 0.0062130959704518322\n",
      "Episode Reward: 11.0\n",
      "Step 1284 (6249799) @ Episode 8097/10000, loss: 0.0072324890643358236\n",
      "Episode Reward: 32.0\n",
      "Step 200 (6249999) @ Episode 8098/10000, loss: 0.0083038667216897016\n",
      " Copied model parameters to target network\n",
      "Step 969 (6250768) @ Episode 8098/10000, loss: 0.0028410626109689474\n",
      "Episode Reward: 19.0\n",
      "Step 960 (6251728) @ Episode 8099/10000, loss: 0.0037031266838312155\n",
      "Episode Reward: 18.0\n",
      "Step 724 (6252452) @ Episode 8100/10000, loss: 0.0027079973369836807\n",
      "Episode Reward: 14.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 08:42:04,131] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video008100.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 860 (6253312) @ Episode 8101/10000, loss: 0.0052424804307520395\n",
      "Episode Reward: 12.0\n",
      "Step 583 (6253895) @ Episode 8102/10000, loss: 0.0047844676300883293\n",
      "Episode Reward: 12.0\n",
      "Step 763 (6254658) @ Episode 8103/10000, loss: 0.0026594770606607243\n",
      "Episode Reward: 14.0\n",
      "Step 1047 (6255705) @ Episode 8104/10000, loss: 0.0041062384843826293\n",
      "Episode Reward: 18.0\n",
      "Step 781 (6256486) @ Episode 8105/10000, loss: 0.0078311329707503326\n",
      "Episode Reward: 11.0\n",
      "Step 1264 (6257750) @ Episode 8106/10000, loss: 0.0044493596069514756\n",
      "Episode Reward: 25.0\n",
      "Step 935 (6258685) @ Episode 8107/10000, loss: 0.0067126899957656866\n",
      "Episode Reward: 17.0\n",
      "Step 1034 (6259719) @ Episode 8108/10000, loss: 0.0023985386360436681\n",
      "Episode Reward: 17.0\n",
      "Step 280 (6259999) @ Episode 8109/10000, loss: 0.0039563239552080633\n",
      " Copied model parameters to target network\n",
      "Step 443 (6260162) @ Episode 8109/10000, loss: 0.0069935745559632787\n",
      "Episode Reward: 7.0\n",
      "Step 630 (6260792) @ Episode 8110/10000, loss: 0.0055156713351607325\n",
      "Episode Reward: 9.0\n",
      "Step 712 (6261504) @ Episode 8111/10000, loss: 0.0017277349252253774\n",
      "Episode Reward: 11.0\n",
      "Step 857 (6262361) @ Episode 8112/10000, loss: 0.0018729425501078367\n",
      "Episode Reward: 20.0\n",
      "Step 1068 (6263429) @ Episode 8113/10000, loss: 0.0041087134741246735\n",
      "Episode Reward: 23.0\n",
      "Step 770 (6264199) @ Episode 8114/10000, loss: 0.0036746284458786257\n",
      "Episode Reward: 12.0\n",
      "Step 1030 (6265229) @ Episode 8115/10000, loss: 0.0052533829584717753\n",
      "Episode Reward: 15.0\n",
      "Step 754 (6265983) @ Episode 8116/10000, loss: 0.0037907932419329885\n",
      "Episode Reward: 15.0\n",
      "Step 743 (6266726) @ Episode 8117/10000, loss: 0.0023030873853713274\n",
      "Episode Reward: 14.0\n",
      "Step 879 (6267605) @ Episode 8118/10000, loss: 0.0074976333416998394\n",
      "Episode Reward: 16.0\n",
      "Step 675 (6268280) @ Episode 8119/10000, loss: 0.0044943974353373056\n",
      "Episode Reward: 12.0\n",
      "Step 1308 (6269588) @ Episode 8120/10000, loss: 0.0091384975239634514\n",
      "Episode Reward: 25.0\n",
      "Step 399 (6269987) @ Episode 8121/10000, loss: 0.0687770694494247468\n",
      "Episode Reward: 5.0\n",
      "Step 12 (6269999) @ Episode 8122/10000, loss: 0.0044402312487363815\n",
      " Copied model parameters to target network\n",
      "Step 846 (6270833) @ Episode 8122/10000, loss: 0.0015773819759488106\n",
      "Episode Reward: 14.0\n",
      "Step 871 (6271704) @ Episode 8123/10000, loss: 0.0023949909955263138\n",
      "Episode Reward: 12.0\n",
      "Step 1029 (6272733) @ Episode 8124/10000, loss: 0.0027432539500296116\n",
      "Episode Reward: 18.0\n",
      "Step 821 (6273554) @ Episode 8125/10000, loss: 0.0038421645294874907\n",
      "Episode Reward: 14.0\n",
      "Step 800 (6274354) @ Episode 8126/10000, loss: 0.0194958560168743137\n",
      "Episode Reward: 12.0\n",
      "Step 685 (6275039) @ Episode 8127/10000, loss: 0.0084655340760946272\n",
      "Episode Reward: 10.0\n",
      "Step 1405 (6276444) @ Episode 8128/10000, loss: 0.0036420542746782303\n",
      "Episode Reward: 34.0\n",
      "Step 1169 (6277613) @ Episode 8129/10000, loss: 0.0025309729389846325\n",
      "Episode Reward: 27.0\n",
      "Step 634 (6278247) @ Episode 8130/10000, loss: 0.0048882854171097282\n",
      "Episode Reward: 9.0\n",
      "Step 817 (6279064) @ Episode 8131/10000, loss: 0.0028563076630234725\n",
      "Episode Reward: 14.0\n",
      "Step 416 (6279480) @ Episode 8132/10000, loss: 0.0035041091032326224\n",
      "Episode Reward: 5.0\n",
      "Step 519 (6279999) @ Episode 8133/10000, loss: 0.0028868610970675945\n",
      " Copied model parameters to target network\n",
      "Step 812 (6280292) @ Episode 8133/10000, loss: 0.0024074795655906237\n",
      "Episode Reward: 14.0\n",
      "Step 670 (6280962) @ Episode 8134/10000, loss: 0.0044547175057232387\n",
      "Episode Reward: 10.0\n",
      "Step 819 (6281781) @ Episode 8135/10000, loss: 0.0013100360520184046\n",
      "Episode Reward: 13.0\n",
      "Step 777 (6282558) @ Episode 8136/10000, loss: 0.0115911671891808514\n",
      "Episode Reward: 13.0\n",
      "Step 868 (6283426) @ Episode 8137/10000, loss: 0.0058421967551112175\n",
      "Episode Reward: 19.0\n",
      "Step 754 (6284180) @ Episode 8138/10000, loss: 0.0076276473701000214\n",
      "Episode Reward: 12.0\n",
      "Step 427 (6284607) @ Episode 8139/10000, loss: 0.0052082384936511526\n",
      "Episode Reward: 5.0\n",
      "Step 997 (6285604) @ Episode 8140/10000, loss: 0.0043120034970343115\n",
      "Episode Reward: 23.0\n",
      "Step 800 (6286404) @ Episode 8141/10000, loss: 0.0034867594949901104\n",
      "Episode Reward: 12.0\n",
      "Step 564 (6286968) @ Episode 8142/10000, loss: 0.0091823097318410874\n",
      "Episode Reward: 10.0\n",
      "Step 1170 (6288138) @ Episode 8143/10000, loss: 0.0030136662535369396\n",
      "Episode Reward: 36.0\n",
      "Step 1012 (6289150) @ Episode 8144/10000, loss: 0.0025531803257763386\n",
      "Episode Reward: 16.0\n",
      "Step 754 (6289904) @ Episode 8145/10000, loss: 0.0027884475421160466\n",
      "Episode Reward: 12.0\n",
      "Step 95 (6289999) @ Episode 8146/10000, loss: 0.0017398273339495063\n",
      " Copied model parameters to target network\n",
      "Step 895 (6290799) @ Episode 8146/10000, loss: 0.0032014460302889347\n",
      "Episode Reward: 16.0\n",
      "Step 626 (6291425) @ Episode 8147/10000, loss: 0.0082641402259469034\n",
      "Episode Reward: 17.0\n",
      "Step 962 (6292387) @ Episode 8148/10000, loss: 0.0060500921681523324\n",
      "Episode Reward: 23.0\n",
      "Step 1145 (6293532) @ Episode 8149/10000, loss: 0.0048830746673047546\n",
      "Episode Reward: 23.0\n",
      "Step 875 (6294407) @ Episode 8150/10000, loss: 0.0021691790316253926\n",
      "Episode Reward: 12.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 08:48:40,656] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video008150.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 910 (6295317) @ Episode 8151/10000, loss: 0.0073548643849790194\n",
      "Episode Reward: 18.0\n",
      "Step 815 (6296132) @ Episode 8152/10000, loss: 0.0021416035015136003\n",
      "Episode Reward: 12.0\n",
      "Step 848 (6296980) @ Episode 8153/10000, loss: 0.0079712867736816437\n",
      "Episode Reward: 15.0\n",
      "Step 661 (6297641) @ Episode 8154/10000, loss: 0.0019042438361793756\n",
      "Episode Reward: 10.0\n",
      "Step 1134 (6298775) @ Episode 8155/10000, loss: 0.0108580328524112783\n",
      "Episode Reward: 27.0\n",
      "Step 1170 (6299945) @ Episode 8156/10000, loss: 0.0020515059586614373\n",
      "Episode Reward: 26.0\n",
      "Step 54 (6299999) @ Episode 8157/10000, loss: 0.0054547684267163284\n",
      " Copied model parameters to target network\n",
      "Step 875 (6300820) @ Episode 8157/10000, loss: 0.0016975096659734845\n",
      "Episode Reward: 18.0\n",
      "Step 836 (6301656) @ Episode 8158/10000, loss: 0.0058202715590596234\n",
      "Episode Reward: 14.0\n",
      "Step 561 (6302217) @ Episode 8159/10000, loss: 0.0017203465104103088\n",
      "Episode Reward: 7.0\n",
      "Step 934 (6303151) @ Episode 8160/10000, loss: 0.0027443449944257736\n",
      "Episode Reward: 16.0\n",
      "Step 902 (6304053) @ Episode 8161/10000, loss: 0.0018661767244338998\n",
      "Episode Reward: 15.0\n",
      "Step 970 (6305023) @ Episode 8162/10000, loss: 0.0050704320892691615\n",
      "Episode Reward: 18.0\n",
      "Step 403 (6305426) @ Episode 8163/10000, loss: 0.0018989113159477713\n",
      "Episode Reward: 6.0\n",
      "Step 555 (6305981) @ Episode 8164/10000, loss: 0.0064188418909907346\n",
      "Episode Reward: 9.0\n",
      "Step 557 (6306538) @ Episode 8165/10000, loss: 0.0043010385707020765\n",
      "Episode Reward: 8.0\n",
      "Step 811 (6307349) @ Episode 8166/10000, loss: 0.0027064299210906037\n",
      "Episode Reward: 14.0\n",
      "Step 668 (6308017) @ Episode 8167/10000, loss: 0.0216331332921981876\n",
      "Episode Reward: 10.0\n",
      "Step 606 (6308623) @ Episode 8168/10000, loss: 0.0018186287488788366\n",
      "Episode Reward: 8.0\n",
      "Step 1174 (6309797) @ Episode 8169/10000, loss: 0.0076745650731027135\n",
      "Episode Reward: 26.0\n",
      "Step 202 (6309999) @ Episode 8170/10000, loss: 0.0051192296668887146\n",
      " Copied model parameters to target network\n",
      "Step 907 (6310704) @ Episode 8170/10000, loss: 0.0048614921979606157\n",
      "Episode Reward: 18.0\n",
      "Step 934 (6311638) @ Episode 8171/10000, loss: 0.0043621370568871524\n",
      "Episode Reward: 22.0\n",
      "Step 1037 (6312675) @ Episode 8172/10000, loss: 0.0041569173336029055\n",
      "Episode Reward: 27.0\n",
      "Step 855 (6313530) @ Episode 8173/10000, loss: 0.0069660912267863753\n",
      "Episode Reward: 15.0\n",
      "Step 1074 (6314604) @ Episode 8174/10000, loss: 0.0063968952745199256\n",
      "Episode Reward: 21.0\n",
      "Step 879 (6315483) @ Episode 8175/10000, loss: 0.0408740155398845727\n",
      "Episode Reward: 15.0\n",
      "Step 903 (6316386) @ Episode 8176/10000, loss: 0.0061894990503787994\n",
      "Episode Reward: 16.0\n",
      "Step 882 (6317268) @ Episode 8177/10000, loss: 0.0035850089043378837\n",
      "Episode Reward: 15.0\n",
      "Step 854 (6318122) @ Episode 8178/10000, loss: 0.0137281389907002455\n",
      "Episode Reward: 13.0\n",
      "Step 699 (6318821) @ Episode 8179/10000, loss: 0.0018654583254829057\n",
      "Episode Reward: 11.0\n",
      "Step 596 (6319417) @ Episode 8180/10000, loss: 0.0024020485579967564\n",
      "Episode Reward: 9.0\n",
      "Step 582 (6319999) @ Episode 8181/10000, loss: 0.0036656758747994955\n",
      " Copied model parameters to target network\n",
      "Step 893 (6320310) @ Episode 8181/10000, loss: 0.0032519772648811345\n",
      "Episode Reward: 17.0\n",
      "Step 936 (6321246) @ Episode 8182/10000, loss: 0.0015463950112462044\n",
      "Episode Reward: 20.0\n",
      "Step 843 (6322089) @ Episode 8183/10000, loss: 0.0064057805575430395\n",
      "Episode Reward: 15.0\n",
      "Step 1171 (6323260) @ Episode 8184/10000, loss: 0.0029789814725518227\n",
      "Episode Reward: 26.0\n",
      "Step 1054 (6324314) @ Episode 8185/10000, loss: 0.0016748291673138738\n",
      "Episode Reward: 24.0\n",
      "Step 702 (6325016) @ Episode 8186/10000, loss: 0.0097179580479860353\n",
      "Episode Reward: 13.0\n",
      "Step 796 (6325812) @ Episode 8187/10000, loss: 0.0101250279694795612\n",
      "Episode Reward: 13.0\n",
      "Step 929 (6326741) @ Episode 8188/10000, loss: 0.0070684673264622696\n",
      "Episode Reward: 22.0\n",
      "Step 396 (6327137) @ Episode 8189/10000, loss: 0.0074398671276867395\n",
      "Episode Reward: 5.0\n",
      "Step 884 (6328021) @ Episode 8190/10000, loss: 0.0040218932554125794\n",
      "Episode Reward: 17.0\n",
      "Step 790 (6328811) @ Episode 8191/10000, loss: 0.0037217633798718452\n",
      "Episode Reward: 13.0\n",
      "Step 565 (6329376) @ Episode 8192/10000, loss: 0.0014119967818260193\n",
      "Episode Reward: 9.0\n",
      "Step 623 (6329999) @ Episode 8193/10000, loss: 0.0057991081848740587\n",
      " Copied model parameters to target network\n",
      "Step 817 (6330193) @ Episode 8193/10000, loss: 0.0015886644832789898\n",
      "Episode Reward: 22.0\n",
      "Step 1111 (6331304) @ Episode 8194/10000, loss: 0.0064680702053010468\n",
      "Episode Reward: 18.0\n",
      "Step 673 (6331977) @ Episode 8195/10000, loss: 0.0100890565663576135\n",
      "Episode Reward: 11.0\n",
      "Step 1005 (6332982) @ Episode 8196/10000, loss: 0.0031418662983924155\n",
      "Episode Reward: 20.0\n",
      "Step 841 (6333823) @ Episode 8197/10000, loss: 0.0063641965389251715\n",
      "Episode Reward: 15.0\n",
      "Step 1009 (6334832) @ Episode 8198/10000, loss: 0.0077765453606843954\n",
      "Episode Reward: 24.0\n",
      "Step 695 (6335527) @ Episode 8199/10000, loss: 0.0028806407935917377\n",
      "Episode Reward: 14.0\n",
      "Step 747 (6336274) @ Episode 8200/10000, loss: 0.0066229277290403847\n",
      "Episode Reward: 12.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 08:55:12,546] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video008200.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 934 (6337208) @ Episode 8201/10000, loss: 0.0034996806643903255\n",
      "Episode Reward: 20.0\n",
      "Step 1136 (6338344) @ Episode 8202/10000, loss: 0.0053048417903482918\n",
      "Episode Reward: 23.0\n",
      "Step 909 (6339253) @ Episode 8203/10000, loss: 0.0086394976824522027\n",
      "Episode Reward: 19.0\n",
      "Step 705 (6339958) @ Episode 8204/10000, loss: 0.0030094212852418423\n",
      "Episode Reward: 11.0\n",
      "Step 41 (6339999) @ Episode 8205/10000, loss: 0.0037744201254099607\n",
      " Copied model parameters to target network\n",
      "Step 643 (6340601) @ Episode 8205/10000, loss: 0.0052365954034030446\n",
      "Episode Reward: 11.0\n",
      "Step 773 (6341374) @ Episode 8206/10000, loss: 0.0444676317274570474\n",
      "Episode Reward: 11.0\n",
      "Step 580 (6341954) @ Episode 8207/10000, loss: 0.0083939014002680786\n",
      "Episode Reward: 9.0\n",
      "Step 685 (6342639) @ Episode 8208/10000, loss: 0.0019976529292762284\n",
      "Episode Reward: 10.0\n",
      "Step 648 (6343287) @ Episode 8209/10000, loss: 0.0027920512948185205\n",
      "Episode Reward: 10.0\n",
      "Step 456 (6343743) @ Episode 8210/10000, loss: 0.0021038164850324392\n",
      "Episode Reward: 6.0\n",
      "Step 719 (6344462) @ Episode 8211/10000, loss: 0.0101583870127797137\n",
      "Episode Reward: 11.0\n",
      "Step 666 (6345128) @ Episode 8212/10000, loss: 0.0066742021590471275\n",
      "Episode Reward: 13.0\n",
      "Step 727 (6345855) @ Episode 8213/10000, loss: 0.0017972737550735474\n",
      "Episode Reward: 12.0\n",
      "Step 940 (6346795) @ Episode 8214/10000, loss: 0.0025760133285075426\n",
      "Episode Reward: 18.0\n",
      "Step 599 (6347394) @ Episode 8215/10000, loss: 0.0039546773768961435\n",
      "Episode Reward: 11.0\n",
      "Step 631 (6348025) @ Episode 8216/10000, loss: 0.0193445999175310135\n",
      "Episode Reward: 10.0\n",
      "Step 893 (6348918) @ Episode 8217/10000, loss: 0.0064136725850403315\n",
      "Episode Reward: 16.0\n",
      "Step 642 (6349560) @ Episode 8218/10000, loss: 0.0027108232025057077\n",
      "Episode Reward: 10.0\n",
      "Step 439 (6349999) @ Episode 8219/10000, loss: 0.0134938713163137444\n",
      " Copied model parameters to target network\n",
      "Step 866 (6350426) @ Episode 8219/10000, loss: 0.0093659330159425745\n",
      "Episode Reward: 15.0\n",
      "Step 796 (6351222) @ Episode 8220/10000, loss: 0.0143440598621964457\n",
      "Episode Reward: 12.0\n",
      "Step 1129 (6352351) @ Episode 8221/10000, loss: 0.0032931179739534855\n",
      "Episode Reward: 20.0\n",
      "Step 796 (6353147) @ Episode 8222/10000, loss: 0.0036631668917834767\n",
      "Episode Reward: 13.0\n",
      "Step 996 (6354143) @ Episode 8223/10000, loss: 0.0045567154884338385\n",
      "Episode Reward: 16.0\n",
      "Step 448 (6354591) @ Episode 8224/10000, loss: 0.0038862465880811214\n",
      "Episode Reward: 10.0\n",
      "Step 945 (6355536) @ Episode 8225/10000, loss: 0.0034165596589446068\n",
      "Episode Reward: 23.0\n",
      "Step 474 (6356010) @ Episode 8226/10000, loss: 0.0095201805233955384\n",
      "Episode Reward: 7.0\n",
      "Step 1235 (6357245) @ Episode 8227/10000, loss: 0.0019904228392988443\n",
      "Episode Reward: 24.0\n",
      "Step 586 (6357831) @ Episode 8228/10000, loss: 0.0074935564771294595\n",
      "Episode Reward: 9.0\n",
      "Step 917 (6358748) @ Episode 8229/10000, loss: 0.0073405914008617475\n",
      "Episode Reward: 20.0\n",
      "Step 705 (6359453) @ Episode 8230/10000, loss: 0.0060966257005929954\n",
      "Episode Reward: 10.0\n",
      "Step 546 (6359999) @ Episode 8231/10000, loss: 0.0036848960444331173\n",
      " Copied model parameters to target network\n",
      "Step 914 (6360367) @ Episode 8231/10000, loss: 0.0015609865076839924\n",
      "Episode Reward: 14.0\n",
      "Step 901 (6361268) @ Episode 8232/10000, loss: 0.0037812704686075456\n",
      "Episode Reward: 16.0\n",
      "Step 550 (6361818) @ Episode 8233/10000, loss: 0.0033148899674415598\n",
      "Episode Reward: 11.0\n",
      "Step 924 (6362742) @ Episode 8234/10000, loss: 0.0114254700019955648\n",
      "Episode Reward: 17.0\n",
      "Step 946 (6363688) @ Episode 8235/10000, loss: 0.0046401862055063254\n",
      "Episode Reward: 18.0\n",
      "Step 693 (6364381) @ Episode 8236/10000, loss: 0.0085278125479817395\n",
      "Episode Reward: 9.0\n",
      "Step 562 (6364943) @ Episode 8237/10000, loss: 0.0097630564123392185\n",
      "Episode Reward: 8.0\n",
      "Step 768 (6365711) @ Episode 8238/10000, loss: 0.0023193263914436143\n",
      "Episode Reward: 11.0\n",
      "Step 875 (6366586) @ Episode 8239/10000, loss: 0.0018849039915949106\n",
      "Episode Reward: 13.0\n",
      "Step 795 (6367381) @ Episode 8240/10000, loss: 0.0053120525553822526\n",
      "Episode Reward: 15.0\n",
      "Step 796 (6368177) @ Episode 8241/10000, loss: 0.0108481962233781814\n",
      "Episode Reward: 14.0\n",
      "Step 1061 (6369238) @ Episode 8242/10000, loss: 0.0022949909325689077\n",
      "Episode Reward: 19.0\n",
      "Step 761 (6369999) @ Episode 8243/10000, loss: 0.0093317963182926186\n",
      " Copied model parameters to target network\n",
      "Step 1058 (6370296) @ Episode 8243/10000, loss: 0.0128985587507486345\n",
      "Episode Reward: 21.0\n",
      "Step 652 (6370948) @ Episode 8244/10000, loss: 0.0171457268297672277\n",
      "Episode Reward: 10.0\n",
      "Step 634 (6371582) @ Episode 8245/10000, loss: 0.0035813176073133945\n",
      "Episode Reward: 8.0\n",
      "Step 819 (6372401) @ Episode 8246/10000, loss: 0.0013284110464155674\n",
      "Episode Reward: 14.0\n",
      "Step 693 (6373094) @ Episode 8247/10000, loss: 0.0051550129428505904\n",
      "Episode Reward: 11.0\n",
      "Step 1032 (6374126) @ Episode 8248/10000, loss: 0.0028671873733401333\n",
      "Episode Reward: 30.0\n",
      "Step 876 (6375002) @ Episode 8249/10000, loss: 0.0125608034431934365\n",
      "Episode Reward: 19.0\n",
      "Step 893 (6375895) @ Episode 8250/10000, loss: 0.0035835581365972757\n",
      "Episode Reward: 15.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 09:01:26,901] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video008250.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 834 (6376729) @ Episode 8251/10000, loss: 0.0128618646413087843\n",
      "Episode Reward: 14.0\n",
      "Step 889 (6377618) @ Episode 8252/10000, loss: 0.0045402529649436473\n",
      "Episode Reward: 14.0\n",
      "Step 842 (6378460) @ Episode 8253/10000, loss: 0.0050842976197600365\n",
      "Episode Reward: 18.0\n",
      "Step 737 (6379197) @ Episode 8254/10000, loss: 0.0030984154436737335\n",
      "Episode Reward: 14.0\n",
      "Step 593 (6379790) @ Episode 8255/10000, loss: 0.0051497453823685656\n",
      "Episode Reward: 13.0\n",
      "Step 209 (6379999) @ Episode 8256/10000, loss: 0.0040699057281017393\n",
      " Copied model parameters to target network\n",
      "Step 881 (6380671) @ Episode 8256/10000, loss: 0.0026703849434852687\n",
      "Episode Reward: 22.0\n",
      "Step 641 (6381312) @ Episode 8257/10000, loss: 0.0073895249515771874\n",
      "Episode Reward: 11.0\n",
      "Step 944 (6382256) @ Episode 8258/10000, loss: 0.0044690105132758622\n",
      "Episode Reward: 20.0\n",
      "Step 478 (6382734) @ Episode 8259/10000, loss: 0.0076592275872826587\n",
      "Episode Reward: 7.0\n",
      "Step 1172 (6383906) @ Episode 8260/10000, loss: 0.0117784468457102784\n",
      "Episode Reward: 24.0\n",
      "Step 705 (6384611) @ Episode 8261/10000, loss: 0.0044262362644076357\n",
      "Episode Reward: 16.0\n",
      "Step 756 (6385367) @ Episode 8262/10000, loss: 0.0095174442976713186\n",
      "Episode Reward: 14.0\n",
      "Step 1279 (6386646) @ Episode 8263/10000, loss: 0.0067806374281644823\n",
      "Episode Reward: 34.0\n",
      "Step 1265 (6387911) @ Episode 8264/10000, loss: 0.0047384360805153855\n",
      "Episode Reward: 23.0\n",
      "Step 839 (6388750) @ Episode 8265/10000, loss: 0.0018106915522366762\n",
      "Episode Reward: 14.0\n",
      "Step 648 (6389398) @ Episode 8266/10000, loss: 0.0047326423227787028\n",
      "Episode Reward: 14.0\n",
      "Step 601 (6389999) @ Episode 8267/10000, loss: 0.0076558957807719717\n",
      " Copied model parameters to target network\n",
      "Step 945 (6390343) @ Episode 8267/10000, loss: 0.0017498978413641453\n",
      "Episode Reward: 15.0\n",
      "Step 615 (6390958) @ Episode 8268/10000, loss: 0.0022178795188665395\n",
      "Episode Reward: 9.0\n",
      "Step 803 (6391761) @ Episode 8269/10000, loss: 0.0033269156701862815\n",
      "Episode Reward: 12.0\n",
      "Step 690 (6392451) @ Episode 8270/10000, loss: 0.0117851300165057187\n",
      "Episode Reward: 11.0\n",
      "Step 825 (6393276) @ Episode 8271/10000, loss: 0.0022951583378016957\n",
      "Episode Reward: 13.0\n",
      "Step 1002 (6394278) @ Episode 8272/10000, loss: 0.0022827091161161665\n",
      "Episode Reward: 18.0\n",
      "Step 1356 (6395634) @ Episode 8273/10000, loss: 0.0119676850736141235\n",
      "Episode Reward: 29.0\n",
      "Step 851 (6396485) @ Episode 8274/10000, loss: 0.0063934652134776115\n",
      "Episode Reward: 14.0\n",
      "Step 972 (6397457) @ Episode 8275/10000, loss: 0.0030166334472596645\n",
      "Episode Reward: 22.0\n",
      "Step 795 (6398252) @ Episode 8276/10000, loss: 0.0088126454502344136\n",
      "Episode Reward: 14.0\n",
      "Step 759 (6399011) @ Episode 8277/10000, loss: 0.0056310174986720085\n",
      "Episode Reward: 21.0\n",
      "Step 556 (6399567) @ Episode 8278/10000, loss: 0.0157023761421442035\n",
      "Episode Reward: 9.0\n",
      "Step 432 (6399999) @ Episode 8279/10000, loss: 0.0042942930012941367\n",
      " Copied model parameters to target network\n",
      "Step 607 (6400174) @ Episode 8279/10000, loss: 0.0049754763022065165\n",
      "Episode Reward: 10.0\n",
      "Step 851 (6401025) @ Episode 8280/10000, loss: 0.0025414144620299345\n",
      "Episode Reward: 13.0\n",
      "Step 994 (6402019) @ Episode 8281/10000, loss: 0.0060245967470109466\n",
      "Episode Reward: 17.0\n",
      "Step 1015 (6403034) @ Episode 8282/10000, loss: 0.0025053552817553287\n",
      "Episode Reward: 20.0\n",
      "Step 1175 (6404209) @ Episode 8283/10000, loss: 0.0085261166095733645\n",
      "Episode Reward: 20.0\n",
      "Step 1391 (6405600) @ Episode 8284/10000, loss: 0.0040805418975651263\n",
      "Episode Reward: 27.0\n",
      "Step 654 (6406254) @ Episode 8285/10000, loss: 0.0027470989152789116\n",
      "Episode Reward: 11.0\n",
      "Step 1300 (6407554) @ Episode 8286/10000, loss: 0.0023941805120557547\n",
      "Episode Reward: 24.0\n",
      "Step 1001 (6408555) @ Episode 8287/10000, loss: 0.016141971573233604\n",
      "Episode Reward: 21.0\n",
      "Step 1107 (6409662) @ Episode 8288/10000, loss: 0.0024384078569710255\n",
      "Episode Reward: 25.0\n",
      "Step 337 (6409999) @ Episode 8289/10000, loss: 0.0028467378579080105\n",
      " Copied model parameters to target network\n",
      "Step 924 (6410586) @ Episode 8289/10000, loss: 0.0026134492363780737\n",
      "Episode Reward: 15.0\n",
      "Step 1030 (6411616) @ Episode 8290/10000, loss: 0.0035963556729257107\n",
      "Episode Reward: 20.0\n",
      "Step 691 (6412307) @ Episode 8291/10000, loss: 0.0037266425788402557\n",
      "Episode Reward: 9.0\n",
      "Step 606 (6412913) @ Episode 8292/10000, loss: 0.0030471235513687134\n",
      "Episode Reward: 14.0\n",
      "Step 883 (6413796) @ Episode 8293/10000, loss: 0.0047727450728416446\n",
      "Episode Reward: 13.0\n",
      "Step 876 (6414672) @ Episode 8294/10000, loss: 0.0019484352087602028\n",
      "Episode Reward: 20.0\n",
      "Step 1266 (6415938) @ Episode 8295/10000, loss: 0.0056314822286367425\n",
      "Episode Reward: 27.0\n",
      "Step 1190 (6417128) @ Episode 8296/10000, loss: 0.0026275690179318193\n",
      "Episode Reward: 26.0\n",
      "Step 816 (6417944) @ Episode 8297/10000, loss: 0.0142379682511091231\n",
      "Episode Reward: 13.0\n",
      "Step 559 (6418503) @ Episode 8298/10000, loss: 0.0036585526540875435\n",
      "Episode Reward: 8.0\n",
      "Step 1145 (6419648) @ Episode 8299/10000, loss: 0.0030113516841083765\n",
      "Episode Reward: 28.0\n",
      "Step 351 (6419999) @ Episode 8300/10000, loss: 0.0101386448368430143\n",
      " Copied model parameters to target network\n",
      "Step 897 (6420545) @ Episode 8300/10000, loss: 0.0037190676666796207\n",
      "Episode Reward: 21.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 09:08:21,990] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video008300.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1117 (6421662) @ Episode 8301/10000, loss: 0.0045604407787323045\n",
      "Episode Reward: 21.0\n",
      "Step 733 (6422395) @ Episode 8302/10000, loss: 0.0018018826376646757\n",
      "Episode Reward: 11.0\n",
      "Step 770 (6423165) @ Episode 8303/10000, loss: 0.0017766456585377455\n",
      "Episode Reward: 15.0\n",
      "Step 640 (6423805) @ Episode 8304/10000, loss: 0.0147628551349043853\n",
      "Episode Reward: 9.0\n",
      "Step 791 (6424596) @ Episode 8305/10000, loss: 0.0076724067330360413\n",
      "Episode Reward: 16.0\n",
      "Step 1551 (6426147) @ Episode 8306/10000, loss: 0.0030287809204310185\n",
      "Episode Reward: 34.0\n",
      "Step 775 (6426922) @ Episode 8307/10000, loss: 0.0044774869456887245\n",
      "Episode Reward: 12.0\n",
      "Step 852 (6427774) @ Episode 8308/10000, loss: 0.0073535898700356485\n",
      "Episode Reward: 13.0\n",
      "Step 914 (6428688) @ Episode 8309/10000, loss: 0.0091256862506270447\n",
      "Episode Reward: 14.0\n",
      "Step 815 (6429503) @ Episode 8310/10000, loss: 0.0031372611410915853\n",
      "Episode Reward: 15.0\n",
      "Step 496 (6429999) @ Episode 8311/10000, loss: 0.0033933129161596394\n",
      " Copied model parameters to target network\n",
      "Step 831 (6430334) @ Episode 8311/10000, loss: 0.0085181295871734627\n",
      "Episode Reward: 14.0\n",
      "Step 868 (6431202) @ Episode 8312/10000, loss: 0.0032203642185777426\n",
      "Episode Reward: 15.0\n",
      "Step 712 (6431914) @ Episode 8313/10000, loss: 0.0035422551445662975\n",
      "Episode Reward: 12.0\n",
      "Step 1162 (6433076) @ Episode 8314/10000, loss: 0.0035334818530827766\n",
      "Episode Reward: 28.0\n",
      "Step 754 (6433830) @ Episode 8315/10000, loss: 0.0096389632672071467\n",
      "Episode Reward: 12.0\n",
      "Step 809 (6434639) @ Episode 8316/10000, loss: 0.0060923062264919285\n",
      "Episode Reward: 17.0\n",
      "Step 736 (6435375) @ Episode 8317/10000, loss: 0.0028333212248981956\n",
      "Episode Reward: 12.0\n",
      "Step 1163 (6436538) @ Episode 8318/10000, loss: 0.0092857843264937497\n",
      "Episode Reward: 32.0\n",
      "Step 747 (6437285) @ Episode 8319/10000, loss: 0.0044980528764426715\n",
      "Episode Reward: 20.0\n",
      "Step 1158 (6438443) @ Episode 8320/10000, loss: 0.0053961593657732015\n",
      "Episode Reward: 34.0\n",
      "Step 386 (6438829) @ Episode 8321/10000, loss: 0.0051285373046994217\n",
      "Episode Reward: 4.0\n",
      "Step 704 (6439533) @ Episode 8322/10000, loss: 0.0040429453365504746\n",
      "Episode Reward: 11.0\n",
      "Step 466 (6439999) @ Episode 8323/10000, loss: 0.0040822993032634266\n",
      " Copied model parameters to target network\n",
      "Step 880 (6440413) @ Episode 8323/10000, loss: 0.0019596223719418051\n",
      "Episode Reward: 20.0\n",
      "Step 989 (6441402) @ Episode 8324/10000, loss: 0.0078783091157674796\n",
      "Episode Reward: 21.0\n",
      "Step 768 (6442170) @ Episode 8325/10000, loss: 0.0032511912286281586\n",
      "Episode Reward: 13.0\n",
      "Step 718 (6442888) @ Episode 8326/10000, loss: 0.0042868861928582195\n",
      "Episode Reward: 10.0\n",
      "Step 610 (6443498) @ Episode 8327/10000, loss: 0.0021391236223280437\n",
      "Episode Reward: 9.0\n",
      "Step 1022 (6444520) @ Episode 8328/10000, loss: 0.0050199413672089586\n",
      "Episode Reward: 18.0\n",
      "Step 1031 (6445551) @ Episode 8329/10000, loss: 0.0116804763674736025\n",
      "Episode Reward: 24.0\n",
      "Step 1302 (6446853) @ Episode 8330/10000, loss: 0.0048681665211915976\n",
      "Episode Reward: 30.0\n",
      "Step 844 (6447697) @ Episode 8331/10000, loss: 0.0033578334841877226\n",
      "Episode Reward: 13.0\n",
      "Step 1100 (6448797) @ Episode 8332/10000, loss: 0.0028305340092629194\n",
      "Episode Reward: 20.0\n",
      "Step 962 (6449759) @ Episode 8333/10000, loss: 0.0109636299312114726\n",
      "Episode Reward: 15.0\n",
      "Step 240 (6449999) @ Episode 8334/10000, loss: 0.0051574981771409515\n",
      " Copied model parameters to target network\n",
      "Step 1001 (6450760) @ Episode 8334/10000, loss: 0.0068448772653937347\n",
      "Episode Reward: 17.0\n",
      "Step 804 (6451564) @ Episode 8335/10000, loss: 0.0046868259087204934\n",
      "Episode Reward: 14.0\n",
      "Step 721 (6452285) @ Episode 8336/10000, loss: 0.0066282702609896667\n",
      "Episode Reward: 12.0\n",
      "Step 801 (6453086) @ Episode 8337/10000, loss: 0.0032395939342677593\n",
      "Episode Reward: 12.0\n",
      "Step 821 (6453907) @ Episode 8338/10000, loss: 0.0065021621994674218\n",
      "Episode Reward: 13.0\n",
      "Step 767 (6454674) @ Episode 8339/10000, loss: 0.0084770470857620244\n",
      "Episode Reward: 13.0\n",
      "Step 751 (6455425) @ Episode 8340/10000, loss: 0.0022505987435579386\n",
      "Episode Reward: 12.0\n",
      "Step 575 (6456000) @ Episode 8341/10000, loss: 0.0036608881782740355\n",
      "Episode Reward: 9.0\n",
      "Step 666 (6456666) @ Episode 8342/10000, loss: 0.0032582101412117484\n",
      "Episode Reward: 10.0\n",
      "Step 775 (6457441) @ Episode 8343/10000, loss: 0.0055854129604995257\n",
      "Episode Reward: 13.0\n",
      "Step 882 (6458323) @ Episode 8344/10000, loss: 0.0037745111621916294\n",
      "Episode Reward: 16.0\n",
      "Step 781 (6459104) @ Episode 8345/10000, loss: 0.0095459772273898128\n",
      "Episode Reward: 16.0\n",
      "Step 852 (6459956) @ Episode 8346/10000, loss: 0.0023404941894114017\n",
      "Episode Reward: 18.0\n",
      "Step 43 (6459999) @ Episode 8347/10000, loss: 0.0020496123470366645\n",
      " Copied model parameters to target network\n",
      "Step 974 (6460930) @ Episode 8347/10000, loss: 0.0105740698054432873\n",
      "Episode Reward: 21.0\n",
      "Step 968 (6461898) @ Episode 8348/10000, loss: 0.0070612621493637568\n",
      "Episode Reward: 17.0\n",
      "Step 782 (6462680) @ Episode 8349/10000, loss: 0.0018119555898010735\n",
      "Episode Reward: 14.0\n",
      "Step 656 (6463336) @ Episode 8350/10000, loss: 0.0029533971101045613\n",
      "Episode Reward: 11.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 09:15:03,432] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video008350.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 923 (6464259) @ Episode 8351/10000, loss: 0.0066905752755701548\n",
      "Episode Reward: 14.0\n",
      "Step 638 (6464897) @ Episode 8352/10000, loss: 0.0039010774344205856\n",
      "Episode Reward: 18.0\n",
      "Step 777 (6465674) @ Episode 8353/10000, loss: 0.0025072975549846888\n",
      "Episode Reward: 12.0\n",
      "Step 805 (6466479) @ Episode 8354/10000, loss: 0.0050370828248560435\n",
      "Episode Reward: 14.0\n",
      "Step 638 (6467117) @ Episode 8355/10000, loss: 0.0026954400818794966\n",
      "Episode Reward: 10.0\n",
      "Step 1027 (6468144) @ Episode 8356/10000, loss: 0.0018772617913782597\n",
      "Episode Reward: 20.0\n",
      "Step 883 (6469027) @ Episode 8357/10000, loss: 0.0395727492868900394\n",
      "Episode Reward: 15.0\n",
      "Step 972 (6469999) @ Episode 8358/10000, loss: 0.0059431903064250955\n",
      " Copied model parameters to target network\n",
      "Step 992 (6470019) @ Episode 8358/10000, loss: 0.0071728252805769446\n",
      "Episode Reward: 24.0\n",
      "Step 754 (6470773) @ Episode 8359/10000, loss: 0.0340932123363018046\n",
      "Episode Reward: 12.0\n",
      "Step 912 (6471685) @ Episode 8360/10000, loss: 0.0031431084498763084\n",
      "Episode Reward: 18.0\n",
      "Step 1059 (6472744) @ Episode 8361/10000, loss: 0.0037559359334409237\n",
      "Episode Reward: 19.0\n",
      "Step 1203 (6473947) @ Episode 8362/10000, loss: 0.0241416972130537036\n",
      "Episode Reward: 33.0\n",
      "Step 664 (6474611) @ Episode 8363/10000, loss: 0.0134628443047404295\n",
      "Episode Reward: 11.0\n",
      "Step 796 (6475407) @ Episode 8364/10000, loss: 0.0026254898402839928\n",
      "Episode Reward: 16.0\n",
      "Step 1038 (6476445) @ Episode 8365/10000, loss: 0.0022376889828592546\n",
      "Episode Reward: 21.0\n",
      "Step 1152 (6477597) @ Episode 8366/10000, loss: 0.0023538670502603054\n",
      "Episode Reward: 25.0\n",
      "Step 839 (6478436) @ Episode 8367/10000, loss: 0.0028738030232489117\n",
      "Episode Reward: 20.0\n",
      "Step 1457 (6479893) @ Episode 8368/10000, loss: 0.0042232219129800847\n",
      "Episode Reward: 28.0\n",
      "Step 106 (6479999) @ Episode 8369/10000, loss: 0.0060330242849886424\n",
      " Copied model parameters to target network\n",
      "Step 900 (6480793) @ Episode 8369/10000, loss: 0.0861460715532302967\n",
      "Episode Reward: 15.0\n",
      "Step 764 (6481557) @ Episode 8370/10000, loss: 0.0036698458716273308\n",
      "Episode Reward: 13.0\n",
      "Step 1126 (6482683) @ Episode 8371/10000, loss: 0.0019540339708328247\n",
      "Episode Reward: 23.0\n",
      "Step 924 (6483607) @ Episode 8372/10000, loss: 0.0040847007185220727\n",
      "Episode Reward: 16.0\n",
      "Step 1209 (6484816) @ Episode 8373/10000, loss: 0.0019653770141303545\n",
      "Episode Reward: 28.0\n",
      "Step 924 (6485740) @ Episode 8374/10000, loss: 0.0035894243046641356\n",
      "Episode Reward: 12.0\n",
      "Step 857 (6486597) @ Episode 8375/10000, loss: 0.0027628024108707905\n",
      "Episode Reward: 17.0\n",
      "Step 744 (6487341) @ Episode 8376/10000, loss: 0.0030506365001201637\n",
      "Episode Reward: 15.0\n",
      "Step 915 (6488256) @ Episode 8377/10000, loss: 0.0057288431562483313\n",
      "Episode Reward: 16.0\n",
      "Step 1393 (6489649) @ Episode 8378/10000, loss: 0.0010923366062343123\n",
      "Episode Reward: 34.0\n",
      "Step 350 (6489999) @ Episode 8379/10000, loss: 0.0024670378770679235\n",
      " Copied model parameters to target network\n",
      "Step 1213 (6490862) @ Episode 8379/10000, loss: 0.0155159570276737213\n",
      "Episode Reward: 28.0\n",
      "Step 809 (6491671) @ Episode 8380/10000, loss: 0.0059944447129964837\n",
      "Episode Reward: 13.0\n",
      "Step 761 (6492432) @ Episode 8381/10000, loss: 0.0045496318489313126\n",
      "Episode Reward: 14.0\n",
      "Step 566 (6492998) @ Episode 8382/10000, loss: 0.0026207454502582556\n",
      "Episode Reward: 8.0\n",
      "Step 1014 (6494012) @ Episode 8383/10000, loss: 0.0102851456031203277\n",
      "Episode Reward: 24.0\n",
      "Step 919 (6494931) @ Episode 8384/10000, loss: 0.0047445632517337873\n",
      "Episode Reward: 20.0\n",
      "Step 1330 (6496261) @ Episode 8385/10000, loss: 0.0024890140630304813\n",
      "Episode Reward: 25.0\n",
      "Step 755 (6497016) @ Episode 8386/10000, loss: 0.0041807261295616637\n",
      "Episode Reward: 13.0\n",
      "Step 905 (6497921) @ Episode 8387/10000, loss: 0.0039310976862907414\n",
      "Episode Reward: 16.0\n",
      "Step 863 (6498784) @ Episode 8388/10000, loss: 0.0031300666742026806\n",
      "Episode Reward: 17.0\n",
      "Step 774 (6499558) @ Episode 8389/10000, loss: 0.0042934734374284748\n",
      "Episode Reward: 12.0\n",
      "Step 441 (6499999) @ Episode 8390/10000, loss: 0.0058161229826509955\n",
      " Copied model parameters to target network\n",
      "Step 989 (6500547) @ Episode 8390/10000, loss: 0.0067903748713433748\n",
      "Episode Reward: 19.0\n",
      "Step 961 (6501508) @ Episode 8391/10000, loss: 0.0048982761800289152\n",
      "Episode Reward: 21.0\n",
      "Step 717 (6502225) @ Episode 8392/10000, loss: 0.0157819595187902456\n",
      "Episode Reward: 11.0\n",
      "Step 475 (6502700) @ Episode 8393/10000, loss: 0.0038804034702479844\n",
      "Episode Reward: 6.0\n",
      "Step 782 (6503482) @ Episode 8394/10000, loss: 0.0056482325308024887\n",
      "Episode Reward: 13.0\n",
      "Step 985 (6504467) @ Episode 8395/10000, loss: 0.0062291519716382035\n",
      "Episode Reward: 23.0\n",
      "Step 1245 (6505712) @ Episode 8396/10000, loss: 0.0019434031564742327\n",
      "Episode Reward: 37.0\n",
      "Step 504 (6506216) @ Episode 8397/10000, loss: 0.0069269877858459955\n",
      "Episode Reward: 6.0\n",
      "Step 550 (6506766) @ Episode 8398/10000, loss: 0.0324124731123447498\n",
      "Episode Reward: 9.0\n",
      "Step 1190 (6507956) @ Episode 8399/10000, loss: 0.0031617826316505674\n",
      "Episode Reward: 24.0\n",
      "Step 1146 (6509102) @ Episode 8400/10000, loss: 0.0034508355893194675\n",
      "Episode Reward: 18.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 09:22:12,912] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video008400.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 666 (6509768) @ Episode 8401/10000, loss: 0.0073794159106910235\n",
      "Episode Reward: 12.0\n",
      "Step 231 (6509999) @ Episode 8402/10000, loss: 0.0028963922522962093\n",
      " Copied model parameters to target network\n",
      "Step 630 (6510398) @ Episode 8402/10000, loss: 0.0014938854146748781\n",
      "Episode Reward: 9.0\n",
      "Step 1231 (6511629) @ Episode 8403/10000, loss: 0.0039234384894371035\n",
      "Episode Reward: 26.0\n",
      "Step 776 (6512405) @ Episode 8404/10000, loss: 0.0043806242756545543\n",
      "Episode Reward: 16.0\n",
      "Step 962 (6513367) @ Episode 8405/10000, loss: 0.0032904986292123795\n",
      "Episode Reward: 17.0\n",
      "Step 967 (6514334) @ Episode 8406/10000, loss: 0.0033162857871502646\n",
      "Episode Reward: 20.0\n",
      "Step 1202 (6515536) @ Episode 8407/10000, loss: 0.0015840985579416156\n",
      "Episode Reward: 22.0\n",
      "Step 917 (6516453) @ Episode 8408/10000, loss: 0.0031903812196105726\n",
      "Episode Reward: 14.0\n",
      "Step 742 (6517195) @ Episode 8409/10000, loss: 0.0021319836378097534\n",
      "Episode Reward: 11.0\n",
      "Step 1007 (6518202) @ Episode 8410/10000, loss: 0.0054600196890532975\n",
      "Episode Reward: 17.0\n",
      "Step 988 (6519190) @ Episode 8411/10000, loss: 0.0050387429073452953\n",
      "Episode Reward: 24.0\n",
      "Step 567 (6519757) @ Episode 8412/10000, loss: 0.0037458667065948256\n",
      "Episode Reward: 8.0\n",
      "Step 242 (6519999) @ Episode 8413/10000, loss: 0.0076059754937887193\n",
      " Copied model parameters to target network\n",
      "Step 1153 (6520910) @ Episode 8413/10000, loss: 0.0038981023244559765\n",
      "Episode Reward: 19.0\n",
      "Step 882 (6521792) @ Episode 8414/10000, loss: 0.0058755157515406614\n",
      "Episode Reward: 16.0\n",
      "Step 733 (6522525) @ Episode 8415/10000, loss: 0.0021690041758120066\n",
      "Episode Reward: 12.0\n",
      "Step 738 (6523263) @ Episode 8416/10000, loss: 0.0032914020121097565\n",
      "Episode Reward: 12.0\n",
      "Step 1246 (6524509) @ Episode 8417/10000, loss: 0.0089847017079591756\n",
      "Episode Reward: 29.0\n",
      "Step 873 (6525382) @ Episode 8418/10000, loss: 0.0052079632878303532\n",
      "Episode Reward: 15.0\n",
      "Step 1101 (6526483) @ Episode 8419/10000, loss: 0.0139066958799958235\n",
      "Episode Reward: 25.0\n",
      "Step 729 (6527212) @ Episode 8420/10000, loss: 0.0077325608581304554\n",
      "Episode Reward: 12.0\n",
      "Step 1120 (6528332) @ Episode 8421/10000, loss: 0.0045782784000039185\n",
      "Episode Reward: 25.0\n",
      "Step 1047 (6529379) @ Episode 8422/10000, loss: 0.0041824216023087556\n",
      "Episode Reward: 17.0\n",
      "Step 620 (6529999) @ Episode 8423/10000, loss: 0.0044662444852292546\n",
      " Copied model parameters to target network\n",
      "Step 840 (6530219) @ Episode 8423/10000, loss: 0.0063673821277916437\n",
      "Episode Reward: 15.0\n",
      "Step 1098 (6531317) @ Episode 8424/10000, loss: 0.0050039798952639116\n",
      "Episode Reward: 17.0\n",
      "Step 1402 (6532719) @ Episode 8425/10000, loss: 0.0082848379388451584\n",
      "Episode Reward: 39.0\n",
      "Step 690 (6533409) @ Episode 8426/10000, loss: 0.0072156707756221294\n",
      "Episode Reward: 11.0\n",
      "Step 883 (6534292) @ Episode 8427/10000, loss: 0.0034337188117206097\n",
      "Episode Reward: 14.0\n",
      "Step 1209 (6535501) @ Episode 8428/10000, loss: 0.0036687382962554693\n",
      "Episode Reward: 22.0\n",
      "Step 880 (6536381) @ Episode 8429/10000, loss: 0.0060286619700491435\n",
      "Episode Reward: 17.0\n",
      "Step 1063 (6537444) @ Episode 8430/10000, loss: 0.0055499784648418438\n",
      "Episode Reward: 23.0\n",
      "Step 1037 (6538481) @ Episode 8431/10000, loss: 0.0065967505797743886\n",
      "Episode Reward: 21.0\n",
      "Step 845 (6539326) @ Episode 8432/10000, loss: 0.0111140860244631776\n",
      "Episode Reward: 15.0\n",
      "Step 673 (6539999) @ Episode 8433/10000, loss: 0.0081875184550881395\n",
      " Copied model parameters to target network\n",
      "Step 841 (6540167) @ Episode 8433/10000, loss: 0.0042809592559933664\n",
      "Episode Reward: 21.0\n",
      "Step 878 (6541045) @ Episode 8434/10000, loss: 0.0014660938177257776\n",
      "Episode Reward: 12.0\n",
      "Step 1045 (6542090) @ Episode 8435/10000, loss: 0.0104871168732643134\n",
      "Episode Reward: 18.0\n",
      "Step 956 (6543046) @ Episode 8436/10000, loss: 0.0077114515006542213\n",
      "Episode Reward: 16.0\n",
      "Step 1084 (6544130) @ Episode 8437/10000, loss: 0.0052462820895016195\n",
      "Episode Reward: 17.0\n",
      "Step 474 (6544604) @ Episode 8438/10000, loss: 0.0096662454307079323\n",
      "Episode Reward: 10.0\n",
      "Step 875 (6545479) @ Episode 8439/10000, loss: 0.0058786035515367985\n",
      "Episode Reward: 21.0\n",
      "Step 699 (6546178) @ Episode 8440/10000, loss: 0.0034852875396609306\n",
      "Episode Reward: 12.0\n",
      "Step 799 (6546977) @ Episode 8441/10000, loss: 0.0055852397345006475\n",
      "Episode Reward: 20.0\n",
      "Step 1022 (6547999) @ Episode 8442/10000, loss: 0.0028789679054170847\n",
      "Episode Reward: 20.0\n",
      "Step 573 (6548572) @ Episode 8443/10000, loss: 0.0032766554504632957\n",
      "Episode Reward: 10.0\n",
      "Step 851 (6549423) @ Episode 8444/10000, loss: 0.0062351375818252563\n",
      "Episode Reward: 20.0\n",
      "Step 569 (6549992) @ Episode 8445/10000, loss: 0.0025749674532562494\n",
      "Episode Reward: 9.0\n",
      "Step 7 (6549999) @ Episode 8446/10000, loss: 0.0022812169045209885\n",
      " Copied model parameters to target network\n",
      "Step 679 (6550671) @ Episode 8446/10000, loss: 0.0042351377196609973\n",
      "Episode Reward: 10.0\n",
      "Step 1185 (6551856) @ Episode 8447/10000, loss: 0.0022022388875484467\n",
      "Episode Reward: 23.0\n",
      "Step 497 (6552353) @ Episode 8448/10000, loss: 0.0055761742405593395\n",
      "Episode Reward: 6.0\n",
      "Step 824 (6553177) @ Episode 8449/10000, loss: 0.0040665827691555023\n",
      "Episode Reward: 17.0\n",
      "Step 660 (6553837) @ Episode 8450/10000, loss: 0.0055854758247733125\n",
      "Episode Reward: 11.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 09:29:10,937] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video008450.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 797 (6554634) @ Episode 8451/10000, loss: 0.0034703738056123257\n",
      "Episode Reward: 12.0\n",
      "Step 1082 (6555716) @ Episode 8452/10000, loss: 0.0025338458362966776\n",
      "Episode Reward: 28.0\n",
      "Step 783 (6556499) @ Episode 8453/10000, loss: 0.0040515232831239765\n",
      "Episode Reward: 13.0\n",
      "Step 813 (6557312) @ Episode 8454/10000, loss: 0.0062633613124489787\n",
      "Episode Reward: 21.0\n",
      "Step 894 (6558206) @ Episode 8455/10000, loss: 0.0048744129016995437\n",
      "Episode Reward: 17.0\n",
      "Step 762 (6558968) @ Episode 8456/10000, loss: 0.0381305925548076645\n",
      "Episode Reward: 16.0\n",
      "Step 1031 (6559999) @ Episode 8457/10000, loss: 0.0030575008131563663\n",
      " Copied model parameters to target network\n",
      "Step 1144 (6560112) @ Episode 8457/10000, loss: 0.0232162252068519695\n",
      "Episode Reward: 24.0\n",
      "Step 848 (6560960) @ Episode 8458/10000, loss: 0.0022613196633756167\n",
      "Episode Reward: 19.0\n",
      "Step 912 (6561872) @ Episode 8459/10000, loss: 0.0034331576898694045\n",
      "Episode Reward: 15.0\n",
      "Step 887 (6562759) @ Episode 8460/10000, loss: 0.0057905400171875955\n",
      "Episode Reward: 16.0\n",
      "Step 714 (6563473) @ Episode 8461/10000, loss: 0.0121736954897642145\n",
      "Episode Reward: 14.0\n",
      "Step 656 (6564129) @ Episode 8462/10000, loss: 0.0030345965642482042\n",
      "Episode Reward: 9.0\n",
      "Step 591 (6564720) @ Episode 8463/10000, loss: 0.0291704386472702035\n",
      "Episode Reward: 8.0\n",
      "Step 826 (6565546) @ Episode 8464/10000, loss: 0.0073102181777358055\n",
      "Episode Reward: 14.0\n",
      "Step 439 (6565985) @ Episode 8465/10000, loss: 0.0034672643523663282\n",
      "Episode Reward: 5.0\n",
      "Step 1023 (6567008) @ Episode 8466/10000, loss: 0.0163026992231607443\n",
      "Episode Reward: 17.0\n",
      "Step 615 (6567623) @ Episode 8467/10000, loss: 0.0079265078529715548\n",
      "Episode Reward: 10.0\n",
      "Step 559 (6568182) @ Episode 8468/10000, loss: 0.0039744568057358265\n",
      "Episode Reward: 9.0\n",
      "Step 787 (6568969) @ Episode 8469/10000, loss: 0.0031115817837417126\n",
      "Episode Reward: 13.0\n",
      "Step 662 (6569631) @ Episode 8470/10000, loss: 0.0038007702678442603\n",
      "Episode Reward: 9.0\n",
      "Step 368 (6569999) @ Episode 8471/10000, loss: 0.0034248651936650276\n",
      " Copied model parameters to target network\n",
      "Step 1053 (6570684) @ Episode 8471/10000, loss: 0.0048749120905995378\n",
      "Episode Reward: 24.0\n",
      "Step 687 (6571371) @ Episode 8472/10000, loss: 0.0019947893451899295\n",
      "Episode Reward: 15.0\n",
      "Step 831 (6572202) @ Episode 8473/10000, loss: 0.0022353290114551783\n",
      "Episode Reward: 13.0\n",
      "Step 670 (6572872) @ Episode 8474/10000, loss: 0.0180568248033523565\n",
      "Episode Reward: 10.0\n",
      "Step 584 (6573456) @ Episode 8475/10000, loss: 0.0118781691417098056\n",
      "Episode Reward: 9.0\n",
      "Step 740 (6574196) @ Episode 8476/10000, loss: 0.0022240467369556427\n",
      "Episode Reward: 13.0\n",
      "Step 660 (6574856) @ Episode 8477/10000, loss: 0.0048090526834130295\n",
      "Episode Reward: 11.0\n",
      "Step 785 (6575641) @ Episode 8478/10000, loss: 0.0030167696531862025\n",
      "Episode Reward: 12.0\n",
      "Step 856 (6576497) @ Episode 8479/10000, loss: 0.0082694273442029955\n",
      "Episode Reward: 14.0\n",
      "Step 1325 (6577822) @ Episode 8480/10000, loss: 0.0026118564419448376\n",
      "Episode Reward: 33.0\n",
      "Step 1055 (6578877) @ Episode 8481/10000, loss: 0.0026460362132638693\n",
      "Episode Reward: 20.0\n",
      "Step 563 (6579440) @ Episode 8482/10000, loss: 0.0038507117424160245\n",
      "Episode Reward: 15.0\n",
      "Step 559 (6579999) @ Episode 8483/10000, loss: 0.0066356691531836994\n",
      " Copied model parameters to target network\n",
      "Step 921 (6580361) @ Episode 8483/10000, loss: 0.0134556861594319343\n",
      "Episode Reward: 14.0\n",
      "Step 777 (6581138) @ Episode 8484/10000, loss: 0.0017923129489645362\n",
      "Episode Reward: 13.0\n",
      "Step 1080 (6582218) @ Episode 8485/10000, loss: 0.0035287532955408096\n",
      "Episode Reward: 25.0\n",
      "Step 974 (6583192) @ Episode 8486/10000, loss: 0.0174769386649131775\n",
      "Episode Reward: 15.0\n",
      "Step 811 (6584003) @ Episode 8487/10000, loss: 0.0056019714102149015\n",
      "Episode Reward: 12.0\n",
      "Step 649 (6584652) @ Episode 8488/10000, loss: 0.0044844551011919975\n",
      "Episode Reward: 10.0\n",
      "Step 1191 (6585843) @ Episode 8489/10000, loss: 0.0026655308902263645\n",
      "Episode Reward: 29.0\n",
      "Step 501 (6586344) @ Episode 8490/10000, loss: 0.0135366851463913926\n",
      "Episode Reward: 7.0\n",
      "Step 1226 (6587570) @ Episode 8491/10000, loss: 0.0573812089860439393\n",
      "Episode Reward: 24.0\n",
      "Step 398 (6587968) @ Episode 8492/10000, loss: 0.0032717057038098574\n",
      "Episode Reward: 5.0\n",
      "Step 736 (6588704) @ Episode 8493/10000, loss: 0.0023451140150427824\n",
      "Episode Reward: 10.0\n",
      "Step 775 (6589479) @ Episode 8494/10000, loss: 0.0111555028706789028\n",
      "Episode Reward: 11.0\n",
      "Step 520 (6589999) @ Episode 8495/10000, loss: 0.0063699781894683845\n",
      " Copied model parameters to target network\n",
      "Step 659 (6590138) @ Episode 8495/10000, loss: 0.0019600815139710903\n",
      "Episode Reward: 10.0\n",
      "Step 811 (6590949) @ Episode 8496/10000, loss: 0.0170119293034076793\n",
      "Episode Reward: 12.0\n",
      "Step 978 (6591927) @ Episode 8497/10000, loss: 0.0226755067706108167\n",
      "Episode Reward: 18.0\n",
      "Step 829 (6592756) @ Episode 8498/10000, loss: 0.0044246027246117594\n",
      "Episode Reward: 19.0\n",
      "Step 789 (6593545) @ Episode 8499/10000, loss: 0.0068253674544394025\n",
      "Episode Reward: 12.0\n",
      "Step 674 (6594219) @ Episode 8500/10000, loss: 0.0052241468802094468\n",
      "Episode Reward: 8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 09:35:32,115] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video008500.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 732 (6594951) @ Episode 8501/10000, loss: 0.0031373538076877594\n",
      "Episode Reward: 11.0\n",
      "Step 1144 (6596095) @ Episode 8502/10000, loss: 0.0025509889237582684\n",
      "Episode Reward: 24.0\n",
      "Step 471 (6596566) @ Episode 8503/10000, loss: 0.0027292380109429365\n",
      "Episode Reward: 6.0\n",
      "Step 653 (6597219) @ Episode 8504/10000, loss: 0.0021360213868319996\n",
      "Episode Reward: 10.0\n",
      "Step 746 (6597965) @ Episode 8505/10000, loss: 0.0026479812804609537\n",
      "Episode Reward: 11.0\n",
      "Step 598 (6598563) @ Episode 8506/10000, loss: 0.0038890657015144825\n",
      "Episode Reward: 8.0\n",
      "Step 912 (6599475) @ Episode 8507/10000, loss: 0.0953869894146919326\n",
      "Episode Reward: 15.0\n",
      "Step 524 (6599999) @ Episode 8508/10000, loss: 0.0040047909133136277\n",
      " Copied model parameters to target network\n",
      "Step 935 (6600410) @ Episode 8508/10000, loss: 0.0037663802504539496\n",
      "Episode Reward: 16.0\n",
      "Step 630 (6601040) @ Episode 8509/10000, loss: 0.0022881920449435715\n",
      "Episode Reward: 11.0\n",
      "Step 642 (6601682) @ Episode 8510/10000, loss: 0.0123326051980257036\n",
      "Episode Reward: 11.0\n",
      "Step 791 (6602473) @ Episode 8511/10000, loss: 0.0087786139920353894\n",
      "Episode Reward: 13.0\n",
      "Step 803 (6603276) @ Episode 8512/10000, loss: 0.0080986190587282188\n",
      "Episode Reward: 15.0\n",
      "Step 1203 (6604479) @ Episode 8513/10000, loss: 0.0037325813900679354\n",
      "Episode Reward: 19.0\n",
      "Step 582 (6605061) @ Episode 8514/10000, loss: 0.0111211519688367845\n",
      "Episode Reward: 9.0\n",
      "Step 813 (6605874) @ Episode 8515/10000, loss: 0.0021592236589640388\n",
      "Episode Reward: 14.0\n",
      "Step 896 (6606770) @ Episode 8516/10000, loss: 0.0073157064616680145\n",
      "Episode Reward: 15.0\n",
      "Step 503 (6607273) @ Episode 8517/10000, loss: 0.0075589562766253954\n",
      "Episode Reward: 7.0\n",
      "Step 895 (6608168) @ Episode 8518/10000, loss: 0.0023742350749671468\n",
      "Episode Reward: 19.0\n",
      "Step 1023 (6609191) @ Episode 8519/10000, loss: 0.0033034421503543854\n",
      "Episode Reward: 16.0\n",
      "Step 808 (6609999) @ Episode 8520/10000, loss: 0.0043999915942549706\n",
      " Copied model parameters to target network\n",
      "Step 1071 (6610262) @ Episode 8520/10000, loss: 0.0100827710703015337\n",
      "Episode Reward: 24.0\n",
      "Step 668 (6610930) @ Episode 8521/10000, loss: 0.0120459804311394727\n",
      "Episode Reward: 9.0\n",
      "Step 584 (6611514) @ Episode 8522/10000, loss: 0.0053409636020660466\n",
      "Episode Reward: 8.0\n",
      "Step 793 (6612307) @ Episode 8523/10000, loss: 0.0040123937651515014\n",
      "Episode Reward: 14.0\n",
      "Step 692 (6612999) @ Episode 8524/10000, loss: 0.0017960977274924517\n",
      "Episode Reward: 10.0\n",
      "Step 1182 (6614181) @ Episode 8525/10000, loss: 0.0071139628998935222\n",
      "Episode Reward: 22.0\n",
      "Step 476 (6614657) @ Episode 8526/10000, loss: 0.0061460677534341815\n",
      "Episode Reward: 6.0\n",
      "Step 766 (6615423) @ Episode 8527/10000, loss: 0.0078508788719773335\n",
      "Episode Reward: 13.0\n",
      "Step 563 (6615986) @ Episode 8528/10000, loss: 0.0021890816278755665\n",
      "Episode Reward: 10.0\n",
      "Step 801 (6616787) @ Episode 8529/10000, loss: 0.0038906056433916095\n",
      "Episode Reward: 14.0\n",
      "Step 1036 (6617823) @ Episode 8530/10000, loss: 0.0064127650111913683\n",
      "Episode Reward: 13.0\n",
      "Step 923 (6618746) @ Episode 8531/10000, loss: 0.0055359639227390294\n",
      "Episode Reward: 15.0\n",
      "Step 847 (6619593) @ Episode 8532/10000, loss: 0.0052683651447296146\n",
      "Episode Reward: 14.0\n",
      "Step 406 (6619999) @ Episode 8533/10000, loss: 0.0043020159937441356\n",
      " Copied model parameters to target network\n",
      "Step 1174 (6620767) @ Episode 8533/10000, loss: 0.0081991543993353844\n",
      "Episode Reward: 32.0\n",
      "Step 689 (6621456) @ Episode 8534/10000, loss: 0.0033009150065481663\n",
      "Episode Reward: 9.0\n",
      "Step 915 (6622371) @ Episode 8535/10000, loss: 0.0092874756082892426\n",
      "Episode Reward: 15.0\n",
      "Step 606 (6622977) @ Episode 8536/10000, loss: 0.0072974497452378278\n",
      "Episode Reward: 8.0\n",
      "Step 617 (6623594) @ Episode 8537/10000, loss: 0.0023099556565284738\n",
      "Episode Reward: 10.0\n",
      "Step 928 (6624522) @ Episode 8538/10000, loss: 0.0076271165162324905\n",
      "Episode Reward: 18.0\n",
      "Step 918 (6625440) @ Episode 8539/10000, loss: 0.0085967993363738067\n",
      "Episode Reward: 18.0\n",
      "Step 747 (6626187) @ Episode 8540/10000, loss: 0.0055495351552963266\n",
      "Episode Reward: 12.0\n",
      "Step 1024 (6627211) @ Episode 8541/10000, loss: 0.0110681010410189636\n",
      "Episode Reward: 19.0\n",
      "Step 1268 (6628479) @ Episode 8542/10000, loss: 0.0171351525932550439\n",
      "Episode Reward: 29.0\n",
      "Step 891 (6629370) @ Episode 8543/10000, loss: 0.0060900570824742324\n",
      "Episode Reward: 14.0\n",
      "Step 629 (6629999) @ Episode 8544/10000, loss: 0.0027715829201042653\n",
      " Copied model parameters to target network\n",
      "Step 823 (6630193) @ Episode 8544/10000, loss: 0.0037837529089301825\n",
      "Episode Reward: 17.0\n",
      "Step 643 (6630836) @ Episode 8545/10000, loss: 0.0022820634767413141\n",
      "Episode Reward: 10.0\n",
      "Step 564 (6631400) @ Episode 8546/10000, loss: 0.0281946603208780345\n",
      "Episode Reward: 8.0\n",
      "Step 822 (6632222) @ Episode 8547/10000, loss: 0.0096451789140701305\n",
      "Episode Reward: 15.0\n",
      "Step 725 (6632947) @ Episode 8548/10000, loss: 0.0073874713853001595\n",
      "Episode Reward: 12.0\n",
      "Step 803 (6633750) @ Episode 8549/10000, loss: 0.0042685912922024734\n",
      "Episode Reward: 14.0\n",
      "Step 889 (6634639) @ Episode 8550/10000, loss: 0.0041445042006671437\n",
      "Episode Reward: 17.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 09:41:56,468] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video008550.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 857 (6635496) @ Episode 8551/10000, loss: 0.0250106323510408485\n",
      "Episode Reward: 22.0\n",
      "Step 517 (6636013) @ Episode 8552/10000, loss: 0.0026669565122574568\n",
      "Episode Reward: 8.0\n",
      "Step 960 (6636973) @ Episode 8553/10000, loss: 0.0133950654417276382\n",
      "Episode Reward: 19.0\n",
      "Step 664 (6637637) @ Episode 8554/10000, loss: 0.0335354469716548914\n",
      "Episode Reward: 10.0\n",
      "Step 549 (6638186) @ Episode 8555/10000, loss: 0.0122375702485442166\n",
      "Episode Reward: 8.0\n",
      "Step 949 (6639135) @ Episode 8556/10000, loss: 0.0097055006772279746\n",
      "Episode Reward: 19.0\n",
      "Step 864 (6639999) @ Episode 8557/10000, loss: 0.0071316547691822056\n",
      " Copied model parameters to target network\n",
      "Step 937 (6640072) @ Episode 8557/10000, loss: 0.0048715127632021975\n",
      "Episode Reward: 19.0\n",
      "Step 1133 (6641205) @ Episode 8558/10000, loss: 0.0042739850468933584\n",
      "Episode Reward: 33.0\n",
      "Step 813 (6642018) @ Episode 8559/10000, loss: 0.0036263684742152695\n",
      "Episode Reward: 12.0\n",
      "Step 666 (6642684) @ Episode 8560/10000, loss: 0.0038334566634148365\n",
      "Episode Reward: 14.0\n",
      "Step 966 (6643650) @ Episode 8561/10000, loss: 0.0045411540195345886\n",
      "Episode Reward: 22.0\n",
      "Step 1186 (6644836) @ Episode 8562/10000, loss: 0.0036343263927847147\n",
      "Episode Reward: 22.0\n",
      "Step 749 (6645585) @ Episode 8563/10000, loss: 0.0137123959138989456\n",
      "Episode Reward: 11.0\n",
      "Step 954 (6646539) @ Episode 8564/10000, loss: 0.0038763750344514847\n",
      "Episode Reward: 22.0\n",
      "Step 843 (6647382) @ Episode 8565/10000, loss: 0.0032432817388325934\n",
      "Episode Reward: 16.0\n",
      "Step 1114 (6648496) @ Episode 8566/10000, loss: 0.0027108136564493185\n",
      "Episode Reward: 19.0\n",
      "Step 663 (6649159) @ Episode 8567/10000, loss: 0.0089443195611238482\n",
      "Episode Reward: 10.0\n",
      "Step 771 (6649930) @ Episode 8568/10000, loss: 0.0106273945420980455\n",
      "Episode Reward: 12.0\n",
      "Step 69 (6649999) @ Episode 8569/10000, loss: 0.0023279907181859016\n",
      " Copied model parameters to target network\n",
      "Step 791 (6650721) @ Episode 8569/10000, loss: 0.0101962592452764518\n",
      "Episode Reward: 13.0\n",
      "Step 573 (6651294) @ Episode 8570/10000, loss: 0.0055626509711146355\n",
      "Episode Reward: 9.0\n",
      "Step 1125 (6652419) @ Episode 8571/10000, loss: 0.0025406847707927227\n",
      "Episode Reward: 22.0\n",
      "Step 646 (6653065) @ Episode 8572/10000, loss: 0.0034287823364138603\n",
      "Episode Reward: 21.0\n",
      "Step 586 (6653651) @ Episode 8573/10000, loss: 0.0042452341876924043\n",
      "Episode Reward: 8.0\n",
      "Step 1074 (6654725) @ Episode 8574/10000, loss: 0.0033080345019698143\n",
      "Episode Reward: 17.0\n",
      "Step 774 (6655499) @ Episode 8575/10000, loss: 0.0129261445254087452\n",
      "Episode Reward: 10.0\n",
      "Step 783 (6656282) @ Episode 8576/10000, loss: 0.0191573742777109156\n",
      "Episode Reward: 13.0\n",
      "Step 1067 (6657349) @ Episode 8577/10000, loss: 0.0095275240018963814\n",
      "Episode Reward: 27.0\n",
      "Step 723 (6658072) @ Episode 8578/10000, loss: 0.0024113142862915993\n",
      "Episode Reward: 11.0\n",
      "Step 863 (6658935) @ Episode 8579/10000, loss: 0.0167576540261507039\n",
      "Episode Reward: 16.0\n",
      "Step 277 (6659212) @ Episode 8580/10000, loss: 0.0054479455575346955\n",
      "Episode Reward: 3.0\n",
      "Step 787 (6659999) @ Episode 8581/10000, loss: 0.0027204938232898717\n",
      " Copied model parameters to target network\n",
      "Step 977 (6660189) @ Episode 8581/10000, loss: 0.0025382721796631813\n",
      "Episode Reward: 16.0\n",
      "Step 1144 (6661333) @ Episode 8582/10000, loss: 0.0019172596512362364\n",
      "Episode Reward: 21.0\n",
      "Step 1350 (6662683) @ Episode 8583/10000, loss: 0.0062625268474221236\n",
      "Episode Reward: 30.0\n",
      "Step 933 (6663616) @ Episode 8584/10000, loss: 0.0014200913719832897\n",
      "Episode Reward: 17.0\n",
      "Step 528 (6664144) @ Episode 8585/10000, loss: 0.0043006213381886483\n",
      "Episode Reward: 7.0\n",
      "Step 624 (6664768) @ Episode 8586/10000, loss: 0.0533101856708526682\n",
      "Episode Reward: 8.0\n",
      "Step 778 (6665546) @ Episode 8587/10000, loss: 0.0022077325265854597\n",
      "Episode Reward: 13.0\n",
      "Step 846 (6666392) @ Episode 8588/10000, loss: 0.0131999906152486863\n",
      "Episode Reward: 15.0\n",
      "Step 714 (6667106) @ Episode 8589/10000, loss: 0.0121885994449257855\n",
      "Episode Reward: 11.0\n",
      "Step 538 (6667644) @ Episode 8590/10000, loss: 0.0177198369055986437\n",
      "Episode Reward: 11.0\n",
      "Step 898 (6668542) @ Episode 8591/10000, loss: 0.0040049459785223016\n",
      "Episode Reward: 20.0\n",
      "Step 756 (6669298) @ Episode 8592/10000, loss: 0.0024155024439096455\n",
      "Episode Reward: 12.0\n",
      "Step 701 (6669999) @ Episode 8593/10000, loss: 0.0082127116620540626\n",
      " Copied model parameters to target network\n",
      "Step 1163 (6670461) @ Episode 8593/10000, loss: 0.0025914353318512445\n",
      "Episode Reward: 22.0\n",
      "Step 941 (6671402) @ Episode 8594/10000, loss: 0.0033822474069893365\n",
      "Episode Reward: 17.0\n",
      "Step 835 (6672237) @ Episode 8595/10000, loss: 0.0063972054049372678\n",
      "Episode Reward: 12.0\n",
      "Step 934 (6673171) @ Episode 8596/10000, loss: 0.0060449782758951193\n",
      "Episode Reward: 17.0\n",
      "Step 529 (6673700) @ Episode 8597/10000, loss: 0.0033521642908453943\n",
      "Episode Reward: 8.0\n",
      "Step 589 (6674289) @ Episode 8598/10000, loss: 0.0042255171574652195\n",
      "Episode Reward: 9.0\n",
      "Step 670 (6674959) @ Episode 8599/10000, loss: 0.0047126626595854763\n",
      "Episode Reward: 11.0\n",
      "Step 688 (6675647) @ Episode 8600/10000, loss: 0.0030421977862715727\n",
      "Episode Reward: 10.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 09:48:23,601] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video008600.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 951 (6676598) @ Episode 8601/10000, loss: 0.0035199425183236643\n",
      "Episode Reward: 15.0\n",
      "Step 699 (6677297) @ Episode 8602/10000, loss: 0.0050020609050989154\n",
      "Episode Reward: 14.0\n",
      "Step 866 (6678163) @ Episode 8603/10000, loss: 0.0062651205807924273\n",
      "Episode Reward: 15.0\n",
      "Step 943 (6679106) @ Episode 8604/10000, loss: 0.0051416032947599895\n",
      "Episode Reward: 15.0\n",
      "Step 893 (6679999) @ Episode 8605/10000, loss: 0.0115736899897456172\n",
      " Copied model parameters to target network\n",
      "Step 1062 (6680168) @ Episode 8605/10000, loss: 0.0031417279969900846\n",
      "Episode Reward: 22.0\n",
      "Step 1088 (6681256) @ Episode 8606/10000, loss: 0.0066554653458297257\n",
      "Episode Reward: 17.0\n",
      "Step 875 (6682131) @ Episode 8607/10000, loss: 0.0037984582595527175\n",
      "Episode Reward: 13.0\n",
      "Step 544 (6682675) @ Episode 8608/10000, loss: 0.0056136325001716616\n",
      "Episode Reward: 7.0\n",
      "Step 721 (6683396) @ Episode 8609/10000, loss: 0.0033213144633919514\n",
      "Episode Reward: 11.0\n",
      "Step 603 (6683999) @ Episode 8610/10000, loss: 0.0086193578317761425\n",
      "Episode Reward: 10.0\n",
      "Step 1204 (6685203) @ Episode 8611/10000, loss: 0.0019412706606090069\n",
      "Episode Reward: 23.0\n",
      "Step 686 (6685889) @ Episode 8612/10000, loss: 0.0037379050627350807\n",
      "Episode Reward: 10.0\n",
      "Step 820 (6686709) @ Episode 8613/10000, loss: 0.0018474539974704385\n",
      "Episode Reward: 17.0\n",
      "Step 712 (6687421) @ Episode 8614/10000, loss: 0.0074863461777567866\n",
      "Episode Reward: 13.0\n",
      "Step 674 (6688095) @ Episode 8615/10000, loss: 0.0046575916931033134\n",
      "Episode Reward: 12.0\n",
      "Step 627 (6688722) @ Episode 8616/10000, loss: 0.0028644055128097534\n",
      "Episode Reward: 9.0\n",
      "Step 640 (6689362) @ Episode 8617/10000, loss: 0.0043159951455891134\n",
      "Episode Reward: 10.0\n",
      "Step 637 (6689999) @ Episode 8618/10000, loss: 0.0085447952151298526\n",
      " Copied model parameters to target network\n",
      "Step 790 (6690152) @ Episode 8618/10000, loss: 0.0036799353547394276\n",
      "Episode Reward: 13.0\n",
      "Step 771 (6690923) @ Episode 8619/10000, loss: 0.0041418136097490794\n",
      "Episode Reward: 14.0\n",
      "Step 688 (6691611) @ Episode 8620/10000, loss: 0.0301697719842195555\n",
      "Episode Reward: 10.0\n",
      "Step 659 (6692270) @ Episode 8621/10000, loss: 0.0238809660077095033\n",
      "Episode Reward: 10.0\n",
      "Step 657 (6692927) @ Episode 8622/10000, loss: 0.0024466426111757755\n",
      "Episode Reward: 11.0\n",
      "Step 840 (6693767) @ Episode 8623/10000, loss: 0.0056695411913096905\n",
      "Episode Reward: 14.0\n",
      "Step 1388 (6695155) @ Episode 8624/10000, loss: 0.0027853543870151043\n",
      "Episode Reward: 33.0\n",
      "Step 796 (6695951) @ Episode 8625/10000, loss: 0.0021355052012950186\n",
      "Episode Reward: 15.0\n",
      "Step 846 (6696797) @ Episode 8626/10000, loss: 0.0012293285690248013\n",
      "Episode Reward: 17.0\n",
      "Step 865 (6697662) @ Episode 8627/10000, loss: 0.0346991084516048407\n",
      "Episode Reward: 12.0\n",
      "Step 949 (6698611) @ Episode 8628/10000, loss: 0.0041090603917837146\n",
      "Episode Reward: 24.0\n",
      "Step 649 (6699260) @ Episode 8629/10000, loss: 0.0023440988734364519\n",
      "Episode Reward: 10.0\n",
      "Step 739 (6699999) @ Episode 8630/10000, loss: 0.0065201995894312864\n",
      " Copied model parameters to target network\n",
      "Step 789 (6700049) @ Episode 8630/10000, loss: 0.0019912680145353085\n",
      "Episode Reward: 14.0\n",
      "Step 1294 (6701343) @ Episode 8631/10000, loss: 0.0025665368884801865\n",
      "Episode Reward: 29.0\n",
      "Step 954 (6702297) @ Episode 8632/10000, loss: 0.0034425477497279644\n",
      "Episode Reward: 17.0\n",
      "Step 418 (6702715) @ Episode 8633/10000, loss: 0.0023714280687272555\n",
      "Episode Reward: 5.0\n",
      "Step 1106 (6703821) @ Episode 8634/10000, loss: 0.0051934588700532915\n",
      "Episode Reward: 26.0\n",
      "Step 820 (6704641) @ Episode 8635/10000, loss: 0.0019062338396906853\n",
      "Episode Reward: 16.0\n",
      "Step 522 (6705163) @ Episode 8636/10000, loss: 0.0038821503985673193\n",
      "Episode Reward: 8.0\n",
      "Step 818 (6705981) @ Episode 8637/10000, loss: 0.0029599827248603106\n",
      "Episode Reward: 17.0\n",
      "Step 1123 (6707104) @ Episode 8638/10000, loss: 0.0052502392791211605\n",
      "Episode Reward: 17.0\n",
      "Step 713 (6707817) @ Episode 8639/10000, loss: 0.0054828952997922983\n",
      "Episode Reward: 10.0\n",
      "Step 705 (6708522) @ Episode 8640/10000, loss: 0.0048311143182218075\n",
      "Episode Reward: 12.0\n",
      "Step 752 (6709274) @ Episode 8641/10000, loss: 0.0032221304718405013\n",
      "Episode Reward: 12.0\n",
      "Step 725 (6709999) @ Episode 8642/10000, loss: 0.0028265998698771663\n",
      " Copied model parameters to target network\n",
      "Step 948 (6710222) @ Episode 8642/10000, loss: 0.0069440677762031555\n",
      "Episode Reward: 19.0\n",
      "Step 892 (6711114) @ Episode 8643/10000, loss: 0.0032111024484038353\n",
      "Episode Reward: 17.0\n",
      "Step 1618 (6712732) @ Episode 8644/10000, loss: 0.0039252778515219695\n",
      "Episode Reward: 45.0\n",
      "Step 283 (6713015) @ Episode 8645/10000, loss: 0.0076464386656880384\n",
      "Episode Reward: 3.0\n",
      "Step 1193 (6714208) @ Episode 8646/10000, loss: 0.0088039487600326545\n",
      "Episode Reward: 22.0\n",
      "Step 802 (6715010) @ Episode 8647/10000, loss: 0.0029731234535574913\n",
      "Episode Reward: 13.0\n",
      "Step 915 (6715925) @ Episode 8648/10000, loss: 0.0025473427958786488\n",
      "Episode Reward: 15.0\n",
      "Step 739 (6716664) @ Episode 8649/10000, loss: 0.0083811189979314873\n",
      "Episode Reward: 12.0\n",
      "Step 574 (6717238) @ Episode 8650/10000, loss: 0.0053119249641895293\n",
      "Episode Reward: 8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 09:54:55,773] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video008650.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 775 (6718013) @ Episode 8651/10000, loss: 0.0688816234469413805\n",
      "Episode Reward: 13.0\n",
      "Step 1101 (6719114) @ Episode 8652/10000, loss: 0.0077992146834731175\n",
      "Episode Reward: 18.0\n",
      "Step 733 (6719847) @ Episode 8653/10000, loss: 0.0032043880783021453\n",
      "Episode Reward: 11.0\n",
      "Step 152 (6719999) @ Episode 8654/10000, loss: 0.0031908154487609863\n",
      " Copied model parameters to target network\n",
      "Step 1121 (6720968) @ Episode 8654/10000, loss: 0.0075191175565123563\n",
      "Episode Reward: 29.0\n",
      "Step 839 (6721807) @ Episode 8655/10000, loss: 0.0099180135875940325\n",
      "Episode Reward: 14.0\n",
      "Step 929 (6722736) @ Episode 8656/10000, loss: 0.0044146319851279266\n",
      "Episode Reward: 15.0\n",
      "Step 939 (6723675) @ Episode 8657/10000, loss: 0.0078165009617805485\n",
      "Episode Reward: 20.0\n",
      "Step 833 (6724508) @ Episode 8658/10000, loss: 0.0109657496213912965\n",
      "Episode Reward: 15.0\n",
      "Step 529 (6725037) @ Episode 8659/10000, loss: 0.0037170327268540866\n",
      "Episode Reward: 8.0\n",
      "Step 900 (6725937) @ Episode 8660/10000, loss: 0.0112964212894439742\n",
      "Episode Reward: 15.0\n",
      "Step 958 (6726895) @ Episode 8661/10000, loss: 0.0197310671210289785\n",
      "Episode Reward: 19.0\n",
      "Step 644 (6727539) @ Episode 8662/10000, loss: 0.0048742545768618585\n",
      "Episode Reward: 10.0\n",
      "Step 726 (6728265) @ Episode 8663/10000, loss: 0.0032165753655135633\n",
      "Episode Reward: 12.0\n",
      "Step 758 (6729023) @ Episode 8664/10000, loss: 0.0013995117042213678\n",
      "Episode Reward: 13.0\n",
      "Step 748 (6729771) @ Episode 8665/10000, loss: 0.0060773170553147796\n",
      "Episode Reward: 15.0\n",
      "Step 228 (6729999) @ Episode 8666/10000, loss: 0.0124302599579095847\n",
      " Copied model parameters to target network\n",
      "Step 1113 (6730884) @ Episode 8666/10000, loss: 0.0061403857544064527\n",
      "Episode Reward: 21.0\n",
      "Step 551 (6731435) @ Episode 8667/10000, loss: 0.0033284574747085575\n",
      "Episode Reward: 7.0\n",
      "Step 913 (6732348) @ Episode 8668/10000, loss: 0.0037543906364589933\n",
      "Episode Reward: 14.0\n",
      "Step 724 (6733072) @ Episode 8669/10000, loss: 0.0047521800734102734\n",
      "Episode Reward: 16.0\n",
      "Step 702 (6733774) @ Episode 8670/10000, loss: 0.0066805868409574033\n",
      "Episode Reward: 13.0\n",
      "Step 1186 (6734960) @ Episode 8671/10000, loss: 0.0024505972396582365\n",
      "Episode Reward: 26.0\n",
      "Step 1120 (6736080) @ Episode 8672/10000, loss: 0.0057958783581852914\n",
      "Episode Reward: 27.0\n",
      "Step 692 (6736772) @ Episode 8673/10000, loss: 0.0081401010975241664\n",
      "Episode Reward: 12.0\n",
      "Step 728 (6737500) @ Episode 8674/10000, loss: 0.0118351494893431665\n",
      "Episode Reward: 10.0\n",
      "Step 722 (6738222) @ Episode 8675/10000, loss: 0.0023302678018808365\n",
      "Episode Reward: 10.0\n",
      "Step 666 (6738888) @ Episode 8676/10000, loss: 0.0024090195074677467\n",
      "Episode Reward: 9.0\n",
      "Step 819 (6739707) @ Episode 8677/10000, loss: 0.0027057221159338956\n",
      "Episode Reward: 19.0\n",
      "Step 292 (6739999) @ Episode 8678/10000, loss: 0.0036851954646408565\n",
      " Copied model parameters to target network\n",
      "Step 421 (6740128) @ Episode 8678/10000, loss: 0.0053812214173376564\n",
      "Episode Reward: 5.0\n",
      "Step 1043 (6741171) @ Episode 8679/10000, loss: 0.0123938396573066718\n",
      "Episode Reward: 20.0\n",
      "Step 662 (6741833) @ Episode 8680/10000, loss: 0.0034660750534385443\n",
      "Episode Reward: 16.0\n",
      "Step 520 (6742353) @ Episode 8681/10000, loss: 0.0020213194657117135\n",
      "Episode Reward: 7.0\n",
      "Step 529 (6742882) @ Episode 8682/10000, loss: 0.0047235195524990565\n",
      "Episode Reward: 8.0\n",
      "Step 437 (6743319) @ Episode 8683/10000, loss: 0.0029742259066551924\n",
      "Episode Reward: 3.0\n",
      "Step 907 (6744226) @ Episode 8684/10000, loss: 0.0046285027638077746\n",
      "Episode Reward: 14.0\n",
      "Step 922 (6745148) @ Episode 8685/10000, loss: 0.0113314427435398145\n",
      "Episode Reward: 22.0\n",
      "Step 937 (6746085) @ Episode 8686/10000, loss: 0.0038411607965826994\n",
      "Episode Reward: 15.0\n",
      "Step 812 (6746897) @ Episode 8687/10000, loss: 0.0157227087765932194\n",
      "Episode Reward: 12.0\n",
      "Step 778 (6747675) @ Episode 8688/10000, loss: 0.0037367609329521656\n",
      "Episode Reward: 12.0\n",
      "Step 903 (6748578) @ Episode 8689/10000, loss: 0.0035487546119838953\n",
      "Episode Reward: 18.0\n",
      "Step 624 (6749202) @ Episode 8690/10000, loss: 0.0020024285186082125\n",
      "Episode Reward: 9.0\n",
      "Step 797 (6749999) @ Episode 8691/10000, loss: 0.0030532225500792265\n",
      " Copied model parameters to target network\n",
      "Step 840 (6750042) @ Episode 8691/10000, loss: 0.0022768769413232803\n",
      "Episode Reward: 14.0\n",
      "Step 720 (6750762) @ Episode 8692/10000, loss: 0.0012794670183211565\n",
      "Episode Reward: 11.0\n",
      "Step 990 (6751752) @ Episode 8693/10000, loss: 0.0019986238330602646\n",
      "Episode Reward: 17.0\n",
      "Step 658 (6752410) @ Episode 8694/10000, loss: 0.0051038367673754698\n",
      "Episode Reward: 8.0\n",
      "Step 676 (6753086) @ Episode 8695/10000, loss: 0.0022675732616335154\n",
      "Episode Reward: 10.0\n",
      "Step 838 (6753924) @ Episode 8696/10000, loss: 0.0041705854237079625\n",
      "Episode Reward: 19.0\n",
      "Step 1377 (6755301) @ Episode 8697/10000, loss: 0.0028964844532310963\n",
      "Episode Reward: 37.0\n",
      "Step 706 (6756007) @ Episode 8698/10000, loss: 0.0054564969614148144\n",
      "Episode Reward: 11.0\n",
      "Step 778 (6756785) @ Episode 8699/10000, loss: 0.0033477512188255787\n",
      "Episode Reward: 17.0\n",
      "Step 551 (6757336) @ Episode 8700/10000, loss: 0.0041178651154041295\n",
      "Episode Reward: 8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 10:01:13,388] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video008700.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 311 (6757647) @ Episode 8701/10000, loss: 0.0033066580072045326\n",
      "Episode Reward: 3.0\n",
      "Step 862 (6758509) @ Episode 8702/10000, loss: 0.0464316271245479686\n",
      "Episode Reward: 14.0\n",
      "Step 956 (6759465) @ Episode 8703/10000, loss: 0.0062826913781464134\n",
      "Episode Reward: 16.0\n",
      "Step 534 (6759999) @ Episode 8704/10000, loss: 0.0023920228704810143\n",
      " Copied model parameters to target network\n",
      "Step 707 (6760172) @ Episode 8704/10000, loss: 0.0070788208395242695\n",
      "Episode Reward: 15.0\n",
      "Step 1066 (6761238) @ Episode 8705/10000, loss: 0.0028316820971667767\n",
      "Episode Reward: 18.0\n",
      "Step 605 (6761843) @ Episode 8706/10000, loss: 0.0021459180861711556\n",
      "Episode Reward: 10.0\n",
      "Step 736 (6762579) @ Episode 8707/10000, loss: 0.0074316360987722874\n",
      "Episode Reward: 11.0\n",
      "Step 841 (6763420) @ Episode 8708/10000, loss: 0.0082784481346607276\n",
      "Episode Reward: 14.0\n",
      "Step 457 (6763877) @ Episode 8709/10000, loss: 0.0099923685193061833\n",
      "Episode Reward: 5.0\n",
      "Step 686 (6764563) @ Episode 8710/10000, loss: 0.0401785783469677435\n",
      "Episode Reward: 14.0\n",
      "Step 744 (6765307) @ Episode 8711/10000, loss: 0.0095197660848498343\n",
      "Episode Reward: 12.0\n",
      "Step 854 (6766161) @ Episode 8712/10000, loss: 0.0053479350171983247\n",
      "Episode Reward: 19.0\n",
      "Step 538 (6766699) @ Episode 8713/10000, loss: 0.0036908648908138275\n",
      "Episode Reward: 7.0\n",
      "Step 1005 (6767704) @ Episode 8714/10000, loss: 0.0069937952794134625\n",
      "Episode Reward: 19.0\n",
      "Step 1339 (6769043) @ Episode 8715/10000, loss: 0.0030907322652637963\n",
      "Episode Reward: 25.0\n",
      "Step 805 (6769848) @ Episode 8716/10000, loss: 0.0159863326698541648\n",
      "Episode Reward: 13.0\n",
      "Step 151 (6769999) @ Episode 8717/10000, loss: 0.1319905221462249875\n",
      " Copied model parameters to target network\n",
      "Step 715 (6770563) @ Episode 8717/10000, loss: 0.0031954576261341574\n",
      "Episode Reward: 9.0\n",
      "Step 861 (6771424) @ Episode 8718/10000, loss: 0.0038604838773608208\n",
      "Episode Reward: 13.0\n",
      "Step 1214 (6772638) @ Episode 8719/10000, loss: 0.0040567745454609393\n",
      "Episode Reward: 24.0\n",
      "Step 799 (6773437) @ Episode 8720/10000, loss: 0.0067713242024183274\n",
      "Episode Reward: 15.0\n",
      "Step 855 (6774292) @ Episode 8721/10000, loss: 0.0062786936759948735\n",
      "Episode Reward: 14.0\n",
      "Step 1082 (6775374) @ Episode 8722/10000, loss: 0.0050532985478639632\n",
      "Episode Reward: 27.0\n",
      "Step 1098 (6776472) @ Episode 8723/10000, loss: 0.0024679803755134344\n",
      "Episode Reward: 16.0\n",
      "Step 1050 (6777522) @ Episode 8724/10000, loss: 0.0012906376505270637\n",
      "Episode Reward: 19.0\n",
      "Step 859 (6778381) @ Episode 8725/10000, loss: 0.0064084138721227653\n",
      "Episode Reward: 18.0\n",
      "Step 568 (6778949) @ Episode 8726/10000, loss: 0.0016285502351820469\n",
      "Episode Reward: 9.0\n",
      "Step 934 (6779883) @ Episode 8727/10000, loss: 0.0085925124585628514\n",
      "Episode Reward: 19.0\n",
      "Step 116 (6779999) @ Episode 8728/10000, loss: 0.0075497995130717754\n",
      " Copied model parameters to target network\n",
      "Step 1045 (6780928) @ Episode 8728/10000, loss: 0.0017060000682249665\n",
      "Episode Reward: 24.0\n",
      "Step 1447 (6782375) @ Episode 8729/10000, loss: 0.0047631245106458663\n",
      "Episode Reward: 25.0\n",
      "Step 1276 (6783651) @ Episode 8730/10000, loss: 0.0067500071600079547\n",
      "Episode Reward: 28.0\n",
      "Step 694 (6784345) @ Episode 8731/10000, loss: 0.0026541799306869507\n",
      "Episode Reward: 11.0\n",
      "Step 1071 (6785416) @ Episode 8732/10000, loss: 0.0028531611897051334\n",
      "Episode Reward: 23.0\n",
      "Step 769 (6786185) @ Episode 8733/10000, loss: 0.0021080267615616323\n",
      "Episode Reward: 12.0\n",
      "Step 780 (6786965) @ Episode 8734/10000, loss: 0.0040039448067545897\n",
      "Episode Reward: 11.0\n",
      "Step 1014 (6787979) @ Episode 8735/10000, loss: 0.0053576007485389713\n",
      "Episode Reward: 23.0\n",
      "Step 952 (6788931) @ Episode 8736/10000, loss: 0.0056686229072511206\n",
      "Episode Reward: 14.0\n",
      "Step 803 (6789734) @ Episode 8737/10000, loss: 0.0081061013042926796\n",
      "Episode Reward: 17.0\n",
      "Step 265 (6789999) @ Episode 8738/10000, loss: 0.0015033965464681387\n",
      " Copied model parameters to target network\n",
      "Step 583 (6790317) @ Episode 8738/10000, loss: 0.0135093256831169136\n",
      "Episode Reward: 13.0\n",
      "Step 785 (6791102) @ Episode 8739/10000, loss: 0.0026427796110510826\n",
      "Episode Reward: 13.0\n",
      "Step 764 (6791866) @ Episode 8740/10000, loss: 0.0036298551131039862\n",
      "Episode Reward: 15.0\n",
      "Step 545 (6792411) @ Episode 8741/10000, loss: 0.0114562660455703745\n",
      "Episode Reward: 11.0\n",
      "Step 830 (6793241) @ Episode 8742/10000, loss: 0.0275866817682981512\n",
      "Episode Reward: 12.0\n",
      "Step 832 (6794073) @ Episode 8743/10000, loss: 0.0038887970149517063\n",
      "Episode Reward: 15.0\n",
      "Step 1125 (6795198) @ Episode 8744/10000, loss: 0.0127179119735956277\n",
      "Episode Reward: 19.0\n",
      "Step 1239 (6796437) @ Episode 8745/10000, loss: 0.0052365721203386784\n",
      "Episode Reward: 27.0\n",
      "Step 626 (6797063) @ Episode 8746/10000, loss: 0.0621024556457996445\n",
      "Episode Reward: 8.0\n",
      "Step 701 (6797764) @ Episode 8747/10000, loss: 0.0051876590587198735\n",
      "Episode Reward: 10.0\n",
      "Step 838 (6798602) @ Episode 8748/10000, loss: 0.0036304616369307043\n",
      "Episode Reward: 12.0\n",
      "Step 528 (6799130) @ Episode 8749/10000, loss: 0.0043814601376652725\n",
      "Episode Reward: 7.0\n",
      "Step 869 (6799999) @ Episode 8750/10000, loss: 0.0078526856377720837\n",
      " Copied model parameters to target network\n",
      "Step 978 (6800108) @ Episode 8750/10000, loss: 0.0088906288146972667\n",
      "Episode Reward: 15.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 10:07:59,706] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video008750.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 704 (6800812) @ Episode 8751/10000, loss: 0.0040105152875185015\n",
      "Episode Reward: 12.0\n",
      "Step 1224 (6802036) @ Episode 8752/10000, loss: 0.0030635572038590913\n",
      "Episode Reward: 26.0\n",
      "Step 677 (6802713) @ Episode 8753/10000, loss: 0.0062320576980710035\n",
      "Episode Reward: 10.0\n",
      "Step 1194 (6803907) @ Episode 8754/10000, loss: 0.0026095041539520025\n",
      "Episode Reward: 28.0\n",
      "Step 549 (6804456) @ Episode 8755/10000, loss: 0.0032550951000303032\n",
      "Episode Reward: 7.0\n",
      "Step 922 (6805378) @ Episode 8756/10000, loss: 0.0210239794105291376\n",
      "Episode Reward: 14.0\n",
      "Step 845 (6806223) @ Episode 8757/10000, loss: 0.0076720486395061027\n",
      "Episode Reward: 17.0\n",
      "Step 632 (6806855) @ Episode 8758/10000, loss: 0.0037727812305092817\n",
      "Episode Reward: 10.0\n",
      "Step 1174 (6808029) @ Episode 8759/10000, loss: 0.0059339171275496484\n",
      "Episode Reward: 25.0\n",
      "Step 929 (6808958) @ Episode 8760/10000, loss: 0.0018465227913111448\n",
      "Episode Reward: 14.0\n",
      "Step 678 (6809636) @ Episode 8761/10000, loss: 0.0062027294188737875\n",
      "Episode Reward: 8.0\n",
      "Step 363 (6809999) @ Episode 8762/10000, loss: 0.0041369982063770292\n",
      " Copied model parameters to target network\n",
      "Step 934 (6810570) @ Episode 8762/10000, loss: 0.0822184085845947388\n",
      "Episode Reward: 15.0\n",
      "Step 801 (6811371) @ Episode 8763/10000, loss: 0.0014884599950164557\n",
      "Episode Reward: 13.0\n",
      "Step 978 (6812349) @ Episode 8764/10000, loss: 0.0145449005067348488\n",
      "Episode Reward: 17.0\n",
      "Step 1180 (6813529) @ Episode 8765/10000, loss: 0.0061085848137736328\n",
      "Episode Reward: 26.0\n",
      "Step 742 (6814271) @ Episode 8766/10000, loss: 0.0017131950007751584\n",
      "Episode Reward: 13.0\n",
      "Step 668 (6814939) @ Episode 8767/10000, loss: 0.0042990762740373615\n",
      "Episode Reward: 9.0\n",
      "Step 659 (6815598) @ Episode 8768/10000, loss: 0.0062898509204387665\n",
      "Episode Reward: 10.0\n",
      "Step 633 (6816231) @ Episode 8769/10000, loss: 0.0068587022833526134\n",
      "Episode Reward: 10.0\n",
      "Step 898 (6817129) @ Episode 8770/10000, loss: 0.0135369701310992244\n",
      "Episode Reward: 19.0\n",
      "Step 860 (6817989) @ Episode 8771/10000, loss: 0.0030125982593744993\n",
      "Episode Reward: 18.0\n",
      "Step 832 (6818821) @ Episode 8772/10000, loss: 0.0040478524751961232\n",
      "Episode Reward: 17.0\n",
      "Step 822 (6819643) @ Episode 8773/10000, loss: 0.0078812409192323687\n",
      "Episode Reward: 17.0\n",
      "Step 356 (6819999) @ Episode 8774/10000, loss: 0.0115792332217097285\n",
      " Copied model parameters to target network\n",
      "Step 800 (6820443) @ Episode 8774/10000, loss: 0.0081127202138304715\n",
      "Episode Reward: 12.0\n",
      "Step 1045 (6821488) @ Episode 8775/10000, loss: 0.0070347543805837636\n",
      "Episode Reward: 20.0\n",
      "Step 963 (6822451) @ Episode 8776/10000, loss: 0.0026707488577812915\n",
      "Episode Reward: 19.0\n",
      "Step 752 (6823203) @ Episode 8777/10000, loss: 0.0054017612710595135\n",
      "Episode Reward: 10.0\n",
      "Step 1364 (6824567) @ Episode 8778/10000, loss: 0.0050503285601735115\n",
      "Episode Reward: 27.0\n",
      "Step 882 (6825449) @ Episode 8779/10000, loss: 0.0040245428681373664\n",
      "Episode Reward: 21.0\n",
      "Step 459 (6825908) @ Episode 8780/10000, loss: 0.0043837423436343675\n",
      "Episode Reward: 10.0\n",
      "Step 865 (6826773) @ Episode 8781/10000, loss: 0.0076250294223427775\n",
      "Episode Reward: 18.0\n",
      "Step 609 (6827382) @ Episode 8782/10000, loss: 0.0031892785336822275\n",
      "Episode Reward: 16.0\n",
      "Step 850 (6828232) @ Episode 8783/10000, loss: 0.0072689871303737165\n",
      "Episode Reward: 19.0\n",
      "Step 824 (6829056) @ Episode 8784/10000, loss: 0.0034839909058064222\n",
      "Episode Reward: 13.0\n",
      "Step 725 (6829781) @ Episode 8785/10000, loss: 0.0109090991318225866\n",
      "Episode Reward: 12.0\n",
      "Step 218 (6829999) @ Episode 8786/10000, loss: 0.0062218192033469684\n",
      " Copied model parameters to target network\n",
      "Step 803 (6830584) @ Episode 8786/10000, loss: 0.0014158705016598105\n",
      "Episode Reward: 13.0\n",
      "Step 628 (6831212) @ Episode 8787/10000, loss: 0.0064457482658326635\n",
      "Episode Reward: 9.0\n",
      "Step 884 (6832096) @ Episode 8788/10000, loss: 0.0050784386694431305\n",
      "Episode Reward: 18.0\n",
      "Step 953 (6833049) @ Episode 8789/10000, loss: 0.0053522260859608657\n",
      "Episode Reward: 16.0\n",
      "Step 803 (6833852) @ Episode 8790/10000, loss: 0.0064443135634064674\n",
      "Episode Reward: 15.0\n",
      "Step 1026 (6834878) @ Episode 8791/10000, loss: 0.0029595997184515343\n",
      "Episode Reward: 13.0\n",
      "Step 653 (6835531) @ Episode 8792/10000, loss: 0.0104129230603575768\n",
      "Episode Reward: 10.0\n",
      "Step 642 (6836173) @ Episode 8793/10000, loss: 0.0018230238929390907\n",
      "Episode Reward: 8.0\n",
      "Step 631 (6836804) @ Episode 8794/10000, loss: 0.0059925606474280367\n",
      "Episode Reward: 9.0\n",
      "Step 770 (6837574) @ Episode 8795/10000, loss: 0.0041448837146162995\n",
      "Episode Reward: 12.0\n",
      "Step 732 (6838306) @ Episode 8796/10000, loss: 0.0081258937716484078\n",
      "Episode Reward: 11.0\n",
      "Step 1129 (6839435) @ Episode 8797/10000, loss: 0.0072717289440333847\n",
      "Episode Reward: 25.0\n",
      "Step 564 (6839999) @ Episode 8798/10000, loss: 0.0045713102445006377\n",
      " Copied model parameters to target network\n",
      "Step 1068 (6840503) @ Episode 8798/10000, loss: 0.0028203511610627174\n",
      "Episode Reward: 20.0\n",
      "Step 654 (6841157) @ Episode 8799/10000, loss: 0.0054427031427621845\n",
      "Episode Reward: 10.0\n",
      "Step 495 (6841652) @ Episode 8800/10000, loss: 0.0064162183552980425\n",
      "Episode Reward: 7.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 10:14:33,278] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video008800.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 691 (6842343) @ Episode 8801/10000, loss: 0.0037407034542411566\n",
      "Episode Reward: 11.0\n",
      "Step 854 (6843197) @ Episode 8802/10000, loss: 0.0059966035187244415\n",
      "Episode Reward: 14.0\n",
      "Step 541 (6843738) @ Episode 8803/10000, loss: 0.0057846056297421455\n",
      "Episode Reward: 8.0\n",
      "Step 1294 (6845032) @ Episode 8804/10000, loss: 0.0047765150666236887\n",
      "Episode Reward: 24.0\n",
      "Step 1200 (6846232) @ Episode 8805/10000, loss: 0.0060789650306105614\n",
      "Episode Reward: 20.0\n",
      "Step 665 (6846897) @ Episode 8806/10000, loss: 0.0096635008230805415\n",
      "Episode Reward: 10.0\n",
      "Step 939 (6847836) @ Episode 8807/10000, loss: 0.0090805171057581965\n",
      "Episode Reward: 15.0\n",
      "Step 744 (6848580) @ Episode 8808/10000, loss: 0.0048956647515296946\n",
      "Episode Reward: 11.0\n",
      "Step 767 (6849347) @ Episode 8809/10000, loss: 0.0047883391380310065\n",
      "Episode Reward: 15.0\n",
      "Step 652 (6849999) @ Episode 8810/10000, loss: 0.0131097547709941867\n",
      " Copied model parameters to target network\n",
      "Step 758 (6850105) @ Episode 8810/10000, loss: 0.0054589710198342855\n",
      "Episode Reward: 15.0\n",
      "Step 874 (6850979) @ Episode 8811/10000, loss: 0.0112578878179192547\n",
      "Episode Reward: 17.0\n",
      "Step 690 (6851669) @ Episode 8812/10000, loss: 0.0012557437876239424\n",
      "Episode Reward: 17.0\n",
      "Step 662 (6852331) @ Episode 8813/10000, loss: 0.0038489112630486493\n",
      "Episode Reward: 11.0\n",
      "Step 713 (6853044) @ Episode 8814/10000, loss: 0.0041264891624450685\n",
      "Episode Reward: 16.0\n",
      "Step 697 (6853741) @ Episode 8815/10000, loss: 0.0023540994152426725\n",
      "Episode Reward: 11.0\n",
      "Step 911 (6854652) @ Episode 8816/10000, loss: 0.0024381475523114204\n",
      "Episode Reward: 15.0\n",
      "Step 777 (6855429) @ Episode 8817/10000, loss: 0.0047303680330514917\n",
      "Episode Reward: 12.0\n",
      "Step 1166 (6856595) @ Episode 8818/10000, loss: 0.0011511518387123942\n",
      "Episode Reward: 25.0\n",
      "Step 476 (6857071) @ Episode 8819/10000, loss: 0.0040523922070860865\n",
      "Episode Reward: 5.0\n",
      "Step 745 (6857816) @ Episode 8820/10000, loss: 0.0014422860695049167\n",
      "Episode Reward: 15.0\n",
      "Step 565 (6858381) @ Episode 8821/10000, loss: 0.0068051256239414215\n",
      "Episode Reward: 8.0\n",
      "Step 927 (6859308) @ Episode 8822/10000, loss: 0.0082813119515776634\n",
      "Episode Reward: 19.0\n",
      "Step 691 (6859999) @ Episode 8823/10000, loss: 0.0071965996176004413\n",
      " Copied model parameters to target network\n",
      "Step 745 (6860053) @ Episode 8823/10000, loss: 0.0065356791019439754\n",
      "Episode Reward: 13.0\n",
      "Step 1056 (6861109) @ Episode 8824/10000, loss: 0.0009764123242348433\n",
      "Episode Reward: 21.0\n",
      "Step 651 (6861760) @ Episode 8825/10000, loss: 0.0060287415981292725\n",
      "Episode Reward: 9.0\n",
      "Step 875 (6862635) @ Episode 8826/10000, loss: 0.0082094417884945878\n",
      "Episode Reward: 15.0\n",
      "Step 863 (6863498) @ Episode 8827/10000, loss: 0.0016065058298408985\n",
      "Episode Reward: 14.0\n",
      "Step 544 (6864042) @ Episode 8828/10000, loss: 0.0033753414172679186\n",
      "Episode Reward: 8.0\n",
      "Step 739 (6864781) @ Episode 8829/10000, loss: 0.0045666284859180455\n",
      "Episode Reward: 16.0\n",
      "Step 692 (6865473) @ Episode 8830/10000, loss: 0.0064028124324977413\n",
      "Episode Reward: 9.0\n",
      "Step 796 (6866269) @ Episode 8831/10000, loss: 0.0034874193370342255\n",
      "Episode Reward: 17.0\n",
      "Step 756 (6867025) @ Episode 8832/10000, loss: 0.0084901107475161555\n",
      "Episode Reward: 19.0\n",
      "Step 1130 (6868155) @ Episode 8833/10000, loss: 0.0024703075177967554\n",
      "Episode Reward: 22.0\n",
      "Step 747 (6868902) @ Episode 8834/10000, loss: 0.0053469594568014145\n",
      "Episode Reward: 12.0\n",
      "Step 867 (6869769) @ Episode 8835/10000, loss: 0.0027966336347162724\n",
      "Episode Reward: 16.0\n",
      "Step 230 (6869999) @ Episode 8836/10000, loss: 0.0032246890477836137\n",
      " Copied model parameters to target network\n",
      "Step 954 (6870723) @ Episode 8836/10000, loss: 0.0039875800721347334\n",
      "Episode Reward: 17.0\n",
      "Step 1176 (6871899) @ Episode 8837/10000, loss: 0.0049246815033257014\n",
      "Episode Reward: 21.0\n",
      "Step 578 (6872477) @ Episode 8838/10000, loss: 0.0040867105126380925\n",
      "Episode Reward: 9.0\n",
      "Step 506 (6872983) @ Episode 8839/10000, loss: 0.0035845749080181126\n",
      "Episode Reward: 6.0\n",
      "Step 1108 (6874091) @ Episode 8840/10000, loss: 0.0027512954548001295\n",
      "Episode Reward: 19.0\n",
      "Step 776 (6874867) @ Episode 8841/10000, loss: 0.0017001321539282799\n",
      "Episode Reward: 17.0\n",
      "Step 645 (6875512) @ Episode 8842/10000, loss: 0.0034578863997012377\n",
      "Episode Reward: 13.0\n",
      "Step 672 (6876184) @ Episode 8843/10000, loss: 0.0031414069235324863\n",
      "Episode Reward: 10.0\n",
      "Step 828 (6877012) @ Episode 8844/10000, loss: 0.0040984158404171478\n",
      "Episode Reward: 11.0\n",
      "Step 1015 (6878027) @ Episode 8845/10000, loss: 0.0033928295597434044\n",
      "Episode Reward: 17.0\n",
      "Step 549 (6878576) @ Episode 8846/10000, loss: 0.0045194048434495935\n",
      "Episode Reward: 8.0\n",
      "Step 653 (6879229) @ Episode 8847/10000, loss: 0.0017488609300926328\n",
      "Episode Reward: 14.0\n",
      "Step 770 (6879999) @ Episode 8848/10000, loss: 0.0023675817064940936\n",
      " Copied model parameters to target network\n",
      "Step 887 (6880116) @ Episode 8848/10000, loss: 0.0015592901036143303\n",
      "Episode Reward: 25.0\n",
      "Step 975 (6881091) @ Episode 8849/10000, loss: 0.0028085100930184126\n",
      "Episode Reward: 19.0\n",
      "Step 1067 (6882158) @ Episode 8850/10000, loss: 0.0021197842434048653\n",
      "Episode Reward: 17.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 10:21:01,174] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video008850.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 580 (6882738) @ Episode 8851/10000, loss: 0.0036378807853907347\n",
      "Episode Reward: 9.0\n",
      "Step 1113 (6883851) @ Episode 8852/10000, loss: 0.0030317546334117655\n",
      "Episode Reward: 25.0\n",
      "Step 1012 (6884863) @ Episode 8853/10000, loss: 0.0059122331440448765\n",
      "Episode Reward: 21.0\n",
      "Step 1212 (6886075) @ Episode 8854/10000, loss: 0.0069749541580677035\n",
      "Episode Reward: 19.0\n",
      "Step 681 (6886756) @ Episode 8855/10000, loss: 0.0095963124185800558\n",
      "Episode Reward: 9.0\n",
      "Step 808 (6887564) @ Episode 8856/10000, loss: 0.0044650896452367317\n",
      "Episode Reward: 11.0\n",
      "Step 1023 (6888587) @ Episode 8857/10000, loss: 0.0040461653843522073\n",
      "Episode Reward: 17.0\n",
      "Step 869 (6889456) @ Episode 8858/10000, loss: 0.0019844858907163143\n",
      "Episode Reward: 15.0\n",
      "Step 543 (6889999) @ Episode 8859/10000, loss: 0.0038031945005059242\n",
      " Copied model parameters to target network\n",
      "Step 970 (6890426) @ Episode 8859/10000, loss: 0.0025201193057000637\n",
      "Episode Reward: 24.0\n",
      "Step 699 (6891125) @ Episode 8860/10000, loss: 0.0048189950175583367\n",
      "Episode Reward: 10.0\n",
      "Step 472 (6891597) @ Episode 8861/10000, loss: 0.0066590495407581333\n",
      "Episode Reward: 6.0\n",
      "Step 578 (6892175) @ Episode 8862/10000, loss: 0.0126407844945788386\n",
      "Episode Reward: 10.0\n",
      "Step 1288 (6893463) @ Episode 8863/10000, loss: 0.0036792699247598654\n",
      "Episode Reward: 27.0\n",
      "Step 631 (6894094) @ Episode 8864/10000, loss: 0.0037155929021537304\n",
      "Episode Reward: 10.0\n",
      "Step 636 (6894730) @ Episode 8865/10000, loss: 0.0145188700407743453\n",
      "Episode Reward: 10.0\n",
      "Step 1002 (6895732) @ Episode 8866/10000, loss: 0.0049206409603357315\n",
      "Episode Reward: 21.0\n",
      "Step 866 (6896598) @ Episode 8867/10000, loss: 0.0045899292454123594\n",
      "Episode Reward: 21.0\n",
      "Step 447 (6897045) @ Episode 8868/10000, loss: 0.0246948394924402242\n",
      "Episode Reward: 8.0\n",
      "Step 730 (6897775) @ Episode 8869/10000, loss: 0.0040678968653082857\n",
      "Episode Reward: 12.0\n",
      "Step 968 (6898743) @ Episode 8870/10000, loss: 0.0033712345175445086\n",
      "Episode Reward: 17.0\n",
      "Step 939 (6899682) @ Episode 8871/10000, loss: 0.0100541552528738985\n",
      "Episode Reward: 20.0\n",
      "Step 317 (6899999) @ Episode 8872/10000, loss: 0.0018438386032357812\n",
      " Copied model parameters to target network\n",
      "Step 670 (6900352) @ Episode 8872/10000, loss: 0.0053326776251196864\n",
      "Episode Reward: 11.0\n",
      "Step 805 (6901157) @ Episode 8873/10000, loss: 0.0037719996180385356\n",
      "Episode Reward: 12.0\n",
      "Step 552 (6901709) @ Episode 8874/10000, loss: 0.0149584859609603884\n",
      "Episode Reward: 8.0\n",
      "Step 1037 (6902746) @ Episode 8875/10000, loss: 0.0016466384986415505\n",
      "Episode Reward: 16.0\n",
      "Step 482 (6903228) @ Episode 8876/10000, loss: 0.0030247974209487444\n",
      "Episode Reward: 5.0\n",
      "Step 810 (6904038) @ Episode 8877/10000, loss: 0.0064812926575541553\n",
      "Episode Reward: 18.0\n",
      "Step 905 (6904943) @ Episode 8878/10000, loss: 0.0074838334694504743\n",
      "Episode Reward: 15.0\n",
      "Step 921 (6905864) @ Episode 8879/10000, loss: 0.0073695397004485135\n",
      "Episode Reward: 18.0\n",
      "Step 726 (6906590) @ Episode 8880/10000, loss: 0.0082275941967964175\n",
      "Episode Reward: 13.0\n",
      "Step 815 (6907405) @ Episode 8881/10000, loss: 0.0042292410507798195\n",
      "Episode Reward: 14.0\n",
      "Step 1077 (6908482) @ Episode 8882/10000, loss: 0.0044180457480251794\n",
      "Episode Reward: 23.0\n",
      "Step 910 (6909392) @ Episode 8883/10000, loss: 0.0055172378197312355\n",
      "Episode Reward: 14.0\n",
      "Step 607 (6909999) @ Episode 8884/10000, loss: 0.0544540248811244966\n",
      " Copied model parameters to target network\n",
      "Step 1071 (6910463) @ Episode 8884/10000, loss: 0.0027124607004225254\n",
      "Episode Reward: 18.0\n",
      "Step 1113 (6911576) @ Episode 8885/10000, loss: 0.0070910253562033185\n",
      "Episode Reward: 18.0\n",
      "Step 687 (6912263) @ Episode 8886/10000, loss: 0.0033945632167160513\n",
      "Episode Reward: 11.0\n",
      "Step 600 (6912863) @ Episode 8887/10000, loss: 0.0028119611088186502\n",
      "Episode Reward: 12.0\n",
      "Step 1064 (6913927) @ Episode 8888/10000, loss: 0.0037211906164884567\n",
      "Episode Reward: 23.0\n",
      "Step 806 (6914733) @ Episode 8889/10000, loss: 0.0063337208703160293\n",
      "Episode Reward: 17.0\n",
      "Step 650 (6915383) @ Episode 8890/10000, loss: 0.0209272727370262156\n",
      "Episode Reward: 15.0\n",
      "Step 928 (6916311) @ Episode 8891/10000, loss: 0.0036915969103574753\n",
      "Episode Reward: 14.0\n",
      "Step 1096 (6917407) @ Episode 8892/10000, loss: 0.0155514460057020193\n",
      "Episode Reward: 18.0\n",
      "Step 786 (6918193) @ Episode 8893/10000, loss: 0.0020259369630366564\n",
      "Episode Reward: 12.0\n",
      "Step 1001 (6919194) @ Episode 8894/10000, loss: 0.0025829109363257885\n",
      "Episode Reward: 22.0\n",
      "Step 696 (6919890) @ Episode 8895/10000, loss: 0.0052879946306347856\n",
      "Episode Reward: 14.0\n",
      "Step 109 (6919999) @ Episode 8896/10000, loss: 0.0135150691494345664\n",
      " Copied model parameters to target network\n",
      "Step 851 (6920741) @ Episode 8896/10000, loss: 0.0045729046687483792\n",
      "Episode Reward: 13.0\n",
      "Step 836 (6921577) @ Episode 8897/10000, loss: 0.0033737574703991413\n",
      "Episode Reward: 12.0\n",
      "Step 495 (6922072) @ Episode 8898/10000, loss: 0.0032570720650255685\n",
      "Episode Reward: 8.0\n",
      "Step 621 (6922693) @ Episode 8899/10000, loss: 0.0064281728118658074\n",
      "Episode Reward: 13.0\n",
      "Step 1101 (6923794) @ Episode 8900/10000, loss: 0.0135190058499574669\n",
      "Episode Reward: 36.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 10:27:34,721] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video008900.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 371 (6924165) @ Episode 8901/10000, loss: 0.0099784471094608347\n",
      "Episode Reward: 4.0\n",
      "Step 681 (6924846) @ Episode 8902/10000, loss: 0.0021880231797695166\n",
      "Episode Reward: 11.0\n",
      "Step 613 (6925459) @ Episode 8903/10000, loss: 0.0029902525711804638\n",
      "Episode Reward: 9.0\n",
      "Step 991 (6926450) @ Episode 8904/10000, loss: 0.0017112388741225004\n",
      "Episode Reward: 21.0\n",
      "Step 848 (6927298) @ Episode 8905/10000, loss: 0.0062711113132536414\n",
      "Episode Reward: 15.0\n",
      "Step 942 (6928240) @ Episode 8906/10000, loss: 0.0022221165709197526\n",
      "Episode Reward: 17.0\n",
      "Step 879 (6929119) @ Episode 8907/10000, loss: 0.0052445381879806523\n",
      "Episode Reward: 17.0\n",
      "Step 558 (6929677) @ Episode 8908/10000, loss: 0.0058629140257835395\n",
      "Episode Reward: 7.0\n",
      "Step 322 (6929999) @ Episode 8909/10000, loss: 0.0034281481057405475\n",
      " Copied model parameters to target network\n",
      "Step 593 (6930270) @ Episode 8909/10000, loss: 0.0039901277050375944\n",
      "Episode Reward: 8.0\n",
      "Step 831 (6931101) @ Episode 8910/10000, loss: 0.0022007275838404894\n",
      "Episode Reward: 14.0\n",
      "Step 704 (6931805) @ Episode 8911/10000, loss: 0.0042666308581829075\n",
      "Episode Reward: 10.0\n",
      "Step 824 (6932629) @ Episode 8912/10000, loss: 0.0064138565212488174\n",
      "Episode Reward: 16.0\n",
      "Step 733 (6933362) @ Episode 8913/10000, loss: 0.0102633675560355196\n",
      "Episode Reward: 15.0\n",
      "Step 1006 (6934368) @ Episode 8914/10000, loss: 0.0067041944712400447\n",
      "Episode Reward: 17.0\n",
      "Step 994 (6935362) @ Episode 8915/10000, loss: 0.0010554047767072916\n",
      "Episode Reward: 21.0\n",
      "Step 527 (6935889) @ Episode 8916/10000, loss: 0.0084969457238912583\n",
      "Episode Reward: 6.0\n",
      "Step 956 (6936845) @ Episode 8917/10000, loss: 0.0020402837544679643\n",
      "Episode Reward: 15.0\n",
      "Step 1340 (6938185) @ Episode 8918/10000, loss: 0.0042287684045732023\n",
      "Episode Reward: 29.0\n",
      "Step 810 (6938995) @ Episode 8919/10000, loss: 0.0078039243817329415\n",
      "Episode Reward: 14.0\n",
      "Step 441 (6939436) @ Episode 8920/10000, loss: 0.0073038409464061263\n",
      "Episode Reward: 6.0\n",
      "Step 563 (6939999) @ Episode 8921/10000, loss: 0.0058995666913688184\n",
      " Copied model parameters to target network\n",
      "Step 843 (6940279) @ Episode 8921/10000, loss: 0.0045520514249801644\n",
      "Episode Reward: 18.0\n",
      "Step 1051 (6941330) @ Episode 8922/10000, loss: 0.0034494253341108565\n",
      "Episode Reward: 18.0\n",
      "Step 437 (6941767) @ Episode 8923/10000, loss: 0.0087922886013984683\n",
      "Episode Reward: 7.0\n",
      "Step 821 (6942588) @ Episode 8924/10000, loss: 0.0167583636939525627\n",
      "Episode Reward: 12.0\n",
      "Step 799 (6943387) @ Episode 8925/10000, loss: 0.0104675181210041053\n",
      "Episode Reward: 14.0\n",
      "Step 841 (6944228) @ Episode 8926/10000, loss: 0.0029784624930471183\n",
      "Episode Reward: 14.0\n",
      "Step 502 (6944730) @ Episode 8927/10000, loss: 0.0035449007991701365\n",
      "Episode Reward: 8.0\n",
      "Step 619 (6945349) @ Episode 8928/10000, loss: 0.0019044891232624653\n",
      "Episode Reward: 10.0\n",
      "Step 1121 (6946470) @ Episode 8929/10000, loss: 0.0028903263155370955\n",
      "Episode Reward: 21.0\n",
      "Step 901 (6947371) @ Episode 8930/10000, loss: 0.0036048814654350288\n",
      "Episode Reward: 17.0\n",
      "Step 708 (6948079) @ Episode 8931/10000, loss: 0.0026181330904364586\n",
      "Episode Reward: 12.0\n",
      "Step 671 (6948750) @ Episode 8932/10000, loss: 0.0026927883736789227\n",
      "Episode Reward: 11.0\n",
      "Step 685 (6949435) @ Episode 8933/10000, loss: 0.0023054718039929867\n",
      "Episode Reward: 9.0\n",
      "Step 564 (6949999) @ Episode 8934/10000, loss: 0.0047489842399954865\n",
      " Copied model parameters to target network\n",
      "Step 753 (6950188) @ Episode 8934/10000, loss: 0.0030904375016689375\n",
      "Episode Reward: 12.0\n",
      "Step 670 (6950858) @ Episode 8935/10000, loss: 0.0022957948967814445\n",
      "Episode Reward: 10.0\n",
      "Step 335 (6951193) @ Episode 8936/10000, loss: 0.0079581271857023242\n",
      "Episode Reward: 3.0\n",
      "Step 873 (6952066) @ Episode 8937/10000, loss: 0.0036798887886106975\n",
      "Episode Reward: 14.0\n",
      "Step 571 (6952637) @ Episode 8938/10000, loss: 0.0089131090790033344\n",
      "Episode Reward: 6.0\n",
      "Step 892 (6953529) @ Episode 8939/10000, loss: 0.0022047827951610097\n",
      "Episode Reward: 20.0\n",
      "Step 664 (6954193) @ Episode 8940/10000, loss: 0.0023677481804043055\n",
      "Episode Reward: 9.0\n",
      "Step 759 (6954952) @ Episode 8941/10000, loss: 0.0070501305162906657\n",
      "Episode Reward: 11.0\n",
      "Step 862 (6955814) @ Episode 8942/10000, loss: 0.0024920590221881866\n",
      "Episode Reward: 15.0\n",
      "Step 708 (6956522) @ Episode 8943/10000, loss: 0.0028837432619184256\n",
      "Episode Reward: 12.0\n",
      "Step 488 (6957010) @ Episode 8944/10000, loss: 0.0120525034144520766\n",
      "Episode Reward: 7.0\n",
      "Step 1070 (6958080) @ Episode 8945/10000, loss: 0.0050622378475964071\n",
      "Episode Reward: 17.0\n",
      "Step 976 (6959056) @ Episode 8946/10000, loss: 0.0019541457295417786\n",
      "Episode Reward: 22.0\n",
      "Step 779 (6959835) @ Episode 8947/10000, loss: 0.0025072435382753613\n",
      "Episode Reward: 13.0\n",
      "Step 164 (6959999) @ Episode 8948/10000, loss: 0.0023356955498456955\n",
      " Copied model parameters to target network\n",
      "Step 643 (6960478) @ Episode 8948/10000, loss: 0.0098138833418488526\n",
      "Episode Reward: 13.0\n",
      "Step 922 (6961400) @ Episode 8949/10000, loss: 0.0030666808597743514\n",
      "Episode Reward: 15.0\n",
      "Step 1013 (6962413) @ Episode 8950/10000, loss: 0.0041896644979715354\n",
      "Episode Reward: 18.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 10:33:43,392] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video008950.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1010 (6963423) @ Episode 8951/10000, loss: 0.0032652635127305984\n",
      "Episode Reward: 21.0\n",
      "Step 1027 (6964450) @ Episode 8952/10000, loss: 0.0045926054008305076\n",
      "Episode Reward: 20.0\n",
      "Step 786 (6965236) @ Episode 8953/10000, loss: 0.0033386498689651494\n",
      "Episode Reward: 16.0\n",
      "Step 590 (6965826) @ Episode 8954/10000, loss: 0.0083384327590465556\n",
      "Episode Reward: 10.0\n",
      "Step 611 (6966437) @ Episode 8955/10000, loss: 0.0192292630672454835\n",
      "Episode Reward: 6.0\n",
      "Step 672 (6967109) @ Episode 8956/10000, loss: 0.0017973716603592038\n",
      "Episode Reward: 10.0\n",
      "Step 1030 (6968139) @ Episode 8957/10000, loss: 0.0045876335352659225\n",
      "Episode Reward: 30.0\n",
      "Step 899 (6969038) @ Episode 8958/10000, loss: 0.0062123807147145275\n",
      "Episode Reward: 18.0\n",
      "Step 952 (6969990) @ Episode 8959/10000, loss: 0.0034697677474468946\n",
      "Episode Reward: 17.0\n",
      "Step 9 (6969999) @ Episode 8960/10000, loss: 0.0057066129520535474\n",
      " Copied model parameters to target network\n",
      "Step 959 (6970949) @ Episode 8960/10000, loss: 0.0079785864800214777\n",
      "Episode Reward: 18.0\n",
      "Step 635 (6971584) @ Episode 8961/10000, loss: 0.0051827356219291695\n",
      "Episode Reward: 10.0\n",
      "Step 885 (6972469) @ Episode 8962/10000, loss: 0.0058886627666652295\n",
      "Episode Reward: 16.0\n",
      "Step 904 (6973373) @ Episode 8963/10000, loss: 0.0090968701988458635\n",
      "Episode Reward: 19.0\n",
      "Step 811 (6974184) @ Episode 8964/10000, loss: 0.0048775579780340195\n",
      "Episode Reward: 17.0\n",
      "Step 759 (6974943) @ Episode 8965/10000, loss: 0.0067728273570537577\n",
      "Episode Reward: 12.0\n",
      "Step 801 (6975744) @ Episode 8966/10000, loss: 0.0025662581901997328\n",
      "Episode Reward: 12.0\n",
      "Step 784 (6976528) @ Episode 8967/10000, loss: 0.0120026944205164915\n",
      "Episode Reward: 13.0\n",
      "Step 731 (6977259) @ Episode 8968/10000, loss: 0.0024719252251088622\n",
      "Episode Reward: 8.0\n",
      "Step 1023 (6978282) @ Episode 8969/10000, loss: 0.0047699688002467155\n",
      "Episode Reward: 19.0\n",
      "Step 845 (6979127) @ Episode 8970/10000, loss: 0.0053523704409599316\n",
      "Episode Reward: 15.0\n",
      "Step 808 (6979935) @ Episode 8971/10000, loss: 0.0031373901292681694\n",
      "Episode Reward: 16.0\n",
      "Step 64 (6979999) @ Episode 8972/10000, loss: 0.0132780112326145175\n",
      " Copied model parameters to target network\n",
      "Step 599 (6980534) @ Episode 8972/10000, loss: 0.0021384581923484802\n",
      "Episode Reward: 8.0\n",
      "Step 596 (6981130) @ Episode 8973/10000, loss: 0.0030461852438747883\n",
      "Episode Reward: 8.0\n",
      "Step 764 (6981894) @ Episode 8974/10000, loss: 0.0068534864112734795\n",
      "Episode Reward: 13.0\n",
      "Step 839 (6982733) @ Episode 8975/10000, loss: 0.0027926093898713593\n",
      "Episode Reward: 19.0\n",
      "Step 751 (6983484) @ Episode 8976/10000, loss: 0.0009985849028453238\n",
      "Episode Reward: 16.0\n",
      "Step 543 (6984027) @ Episode 8977/10000, loss: 0.0634072348475456219\n",
      "Episode Reward: 7.0\n",
      "Step 368 (6984395) @ Episode 8978/10000, loss: 0.0617945343255996736\n",
      "Episode Reward: 4.0\n",
      "Step 685 (6985080) @ Episode 8979/10000, loss: 0.0053087864071130757\n",
      "Episode Reward: 11.0\n",
      "Step 1095 (6986175) @ Episode 8980/10000, loss: 0.0096575384959578515\n",
      "Episode Reward: 18.0\n",
      "Step 739 (6986914) @ Episode 8981/10000, loss: 0.0035287146456539635\n",
      "Episode Reward: 13.0\n",
      "Step 920 (6987834) @ Episode 8982/10000, loss: 0.0047672973014414313\n",
      "Episode Reward: 11.0\n",
      "Step 717 (6988551) @ Episode 8983/10000, loss: 0.0033398000523447993\n",
      "Episode Reward: 12.0\n",
      "Step 465 (6989016) @ Episode 8984/10000, loss: 0.0025933338329195976\n",
      "Episode Reward: 7.0\n",
      "Step 983 (6989999) @ Episode 8985/10000, loss: 0.0064317798241972927\n",
      " Copied model parameters to target network\n",
      "Step 1025 (6990041) @ Episode 8985/10000, loss: 0.0018761639948934317\n",
      "Episode Reward: 26.0\n",
      "Step 648 (6990689) @ Episode 8986/10000, loss: 0.0040118796750903138\n",
      "Episode Reward: 10.0\n",
      "Step 693 (6991382) @ Episode 8987/10000, loss: 0.0084974970668554344\n",
      "Episode Reward: 10.0\n",
      "Step 1159 (6992541) @ Episode 8988/10000, loss: 0.0032303836196660995\n",
      "Episode Reward: 22.0\n",
      "Step 572 (6993113) @ Episode 8989/10000, loss: 0.0079929549247026446\n",
      "Episode Reward: 12.0\n",
      "Step 828 (6993941) @ Episode 8990/10000, loss: 0.0057953754439949997\n",
      "Episode Reward: 16.0\n",
      "Step 726 (6994667) @ Episode 8991/10000, loss: 0.0015919108409434557\n",
      "Episode Reward: 14.0\n",
      "Step 542 (6995209) @ Episode 8992/10000, loss: 0.0042735338211059575\n",
      "Episode Reward: 8.0\n",
      "Step 1041 (6996250) @ Episode 8993/10000, loss: 0.0067255697213113313\n",
      "Episode Reward: 23.0\n",
      "Step 1041 (6997291) @ Episode 8994/10000, loss: 0.0035626981407403946\n",
      "Episode Reward: 18.0\n",
      "Step 824 (6998115) @ Episode 8995/10000, loss: 0.0022806124761700633\n",
      "Episode Reward: 13.0\n",
      "Step 317 (6998432) @ Episode 8996/10000, loss: 0.0029033245518803596\n",
      "Episode Reward: 4.0\n",
      "Step 882 (6999314) @ Episode 8997/10000, loss: 0.0023446779232472182\n",
      "Episode Reward: 16.0\n",
      "Step 685 (6999999) @ Episode 8998/10000, loss: 0.0049495780840516096\n",
      " Copied model parameters to target network\n",
      "Step 780 (7000094) @ Episode 8998/10000, loss: 0.0109816780313849452\n",
      "Episode Reward: 12.0\n",
      "Step 293 (7000387) @ Episode 8999/10000, loss: 0.0032682763412594795\n",
      "Episode Reward: 2.0\n",
      "Step 494 (7000881) @ Episode 9000/10000, loss: 0.0028002739418298006\n",
      "Episode Reward: 7.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 10:39:49,698] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video009000.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 792 (7001673) @ Episode 9001/10000, loss: 0.0014591910876333714\n",
      "Episode Reward: 13.0\n",
      "Step 775 (7002448) @ Episode 9002/10000, loss: 0.0020706148352473974\n",
      "Episode Reward: 9.0\n",
      "Step 861 (7003309) @ Episode 9003/10000, loss: 0.0056273378431797035\n",
      "Episode Reward: 12.0\n",
      "Step 737 (7004046) @ Episode 9004/10000, loss: 0.0091101173311471945\n",
      "Episode Reward: 12.0\n",
      "Step 851 (7004897) @ Episode 9005/10000, loss: 0.0026165833696722984\n",
      "Episode Reward: 12.0\n",
      "Step 675 (7005572) @ Episode 9006/10000, loss: 0.0023312612902373075\n",
      "Episode Reward: 8.0\n",
      "Step 771 (7006343) @ Episode 9007/10000, loss: 0.0046516633592545993\n",
      "Episode Reward: 10.0\n",
      "Step 708 (7007051) @ Episode 9008/10000, loss: 0.0027314904145896435\n",
      "Episode Reward: 9.0\n",
      "Step 793 (7007844) @ Episode 9009/10000, loss: 0.0052925748750567445\n",
      "Episode Reward: 12.0\n",
      "Step 751 (7008595) @ Episode 9010/10000, loss: 0.0018517841817811131\n",
      "Episode Reward: 11.0\n",
      "Step 628 (7009223) @ Episode 9011/10000, loss: 0.0090574342757463463\n",
      "Episode Reward: 12.0\n",
      "Step 515 (7009738) @ Episode 9012/10000, loss: 0.0046296515502035628\n",
      "Episode Reward: 10.0\n",
      "Step 261 (7009999) @ Episode 9013/10000, loss: 0.0057528866454958924\n",
      " Copied model parameters to target network\n",
      "Step 807 (7010545) @ Episode 9013/10000, loss: 0.0023034876212477684\n",
      "Episode Reward: 17.0\n",
      "Step 659 (7011204) @ Episode 9014/10000, loss: 0.0027200863696634776\n",
      "Episode Reward: 11.0\n",
      "Step 528 (7011732) @ Episode 9015/10000, loss: 0.0024471259675920017\n",
      "Episode Reward: 8.0\n",
      "Step 540 (7012272) @ Episode 9016/10000, loss: 0.0060210940428078175\n",
      "Episode Reward: 8.0\n",
      "Step 676 (7012948) @ Episode 9017/10000, loss: 0.0058700614608824256\n",
      "Episode Reward: 11.0\n",
      "Step 695 (7013643) @ Episode 9018/10000, loss: 0.0019763740710914135\n",
      "Episode Reward: 11.0\n",
      "Step 534 (7014177) @ Episode 9019/10000, loss: 0.0068023768253624446\n",
      "Episode Reward: 8.0\n",
      "Step 903 (7015080) @ Episode 9020/10000, loss: 0.0057543679140508175\n",
      "Episode Reward: 17.0\n",
      "Step 837 (7015917) @ Episode 9021/10000, loss: 0.0433392152190208448\n",
      "Episode Reward: 14.0\n",
      "Step 1133 (7017050) @ Episode 9022/10000, loss: 0.0015408121980726719\n",
      "Episode Reward: 19.0\n",
      "Step 736 (7017786) @ Episode 9023/10000, loss: 0.0029280916787683964\n",
      "Episode Reward: 11.0\n",
      "Step 559 (7018345) @ Episode 9024/10000, loss: 0.0029891761951148517\n",
      "Episode Reward: 8.0\n",
      "Step 835 (7019180) @ Episode 9025/10000, loss: 0.0022302251309156425\n",
      "Episode Reward: 17.0\n",
      "Step 766 (7019946) @ Episode 9026/10000, loss: 0.0025832531973719597\n",
      "Episode Reward: 9.0\n",
      "Step 53 (7019999) @ Episode 9027/10000, loss: 0.0040430887602269655\n",
      " Copied model parameters to target network\n",
      "Step 990 (7020936) @ Episode 9027/10000, loss: 0.0214436799287796029\n",
      "Episode Reward: 16.0\n",
      "Step 1002 (7021938) @ Episode 9028/10000, loss: 0.005478601902723312\n",
      "Episode Reward: 20.0\n",
      "Step 635 (7022573) @ Episode 9029/10000, loss: 0.0038753445260226727\n",
      "Episode Reward: 12.0\n",
      "Step 1020 (7023593) @ Episode 9030/10000, loss: 0.0021784747950732716\n",
      "Episode Reward: 21.0\n",
      "Step 601 (7024194) @ Episode 9031/10000, loss: 0.0056275790557265285\n",
      "Episode Reward: 9.0\n",
      "Step 980 (7025174) @ Episode 9032/10000, loss: 0.0053346697241067896\n",
      "Episode Reward: 16.0\n",
      "Step 692 (7025866) @ Episode 9033/10000, loss: 0.0049929413944482844\n",
      "Episode Reward: 11.0\n",
      "Step 1078 (7026944) @ Episode 9034/10000, loss: 0.0205057077109813784\n",
      "Episode Reward: 25.0\n",
      "Step 971 (7027915) @ Episode 9035/10000, loss: 0.0041718329302966595\n",
      "Episode Reward: 20.0\n",
      "Step 991 (7028906) @ Episode 9036/10000, loss: 0.0760099291801452686\n",
      "Episode Reward: 20.0\n",
      "Step 574 (7029480) @ Episode 9037/10000, loss: 0.0052513414993882183\n",
      "Episode Reward: 11.0\n",
      "Step 519 (7029999) @ Episode 9038/10000, loss: 0.0029510438907891514\n",
      " Copied model parameters to target network\n",
      "Step 1122 (7030602) @ Episode 9038/10000, loss: 0.0346179045736789755\n",
      "Episode Reward: 18.0\n",
      "Step 404 (7031006) @ Episode 9039/10000, loss: 0.0039725583046674735\n",
      "Episode Reward: 5.0\n",
      "Step 650 (7031656) @ Episode 9040/10000, loss: 0.0015185482334345583\n",
      "Episode Reward: 13.0\n",
      "Step 1072 (7032728) @ Episode 9041/10000, loss: 0.0011382641969248652\n",
      "Episode Reward: 30.0\n",
      "Step 543 (7033271) @ Episode 9042/10000, loss: 0.0049395626410841944\n",
      "Episode Reward: 8.0\n",
      "Step 453 (7033724) @ Episode 9043/10000, loss: 0.0025169146247208128\n",
      "Episode Reward: 6.0\n",
      "Step 662 (7034386) @ Episode 9044/10000, loss: 0.0024960632435977465\n",
      "Episode Reward: 11.0\n",
      "Step 861 (7035247) @ Episode 9045/10000, loss: 0.0055231889709830288\n",
      "Episode Reward: 15.0\n",
      "Step 918 (7036165) @ Episode 9046/10000, loss: 0.0030796793289482594\n",
      "Episode Reward: 13.0\n",
      "Step 766 (7036931) @ Episode 9047/10000, loss: 0.0279125403612852104\n",
      "Episode Reward: 11.0\n",
      "Step 781 (7037712) @ Episode 9048/10000, loss: 0.0018211986171081662\n",
      "Episode Reward: 15.0\n",
      "Step 830 (7038542) @ Episode 9049/10000, loss: 0.0063720988109707837\n",
      "Episode Reward: 16.0\n",
      "Step 675 (7039217) @ Episode 9050/10000, loss: 0.0055989231914281845\n",
      "Episode Reward: 11.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 10:45:55,762] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video009050.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 540 (7039757) @ Episode 9051/10000, loss: 0.0038408231921494007\n",
      "Episode Reward: 7.0\n",
      "Step 242 (7039999) @ Episode 9052/10000, loss: 0.0028620916418731213\n",
      " Copied model parameters to target network\n",
      "Step 767 (7040524) @ Episode 9052/10000, loss: 0.0028262482956051826\n",
      "Episode Reward: 19.0\n",
      "Step 659 (7041183) @ Episode 9053/10000, loss: 0.0017732643755152822\n",
      "Episode Reward: 10.0\n",
      "Step 861 (7042044) @ Episode 9054/10000, loss: 0.0050445380620658446\n",
      "Episode Reward: 11.0\n",
      "Step 648 (7042692) @ Episode 9055/10000, loss: 0.0036368980072438717\n",
      "Episode Reward: 9.0\n",
      "Step 949 (7043641) @ Episode 9056/10000, loss: 0.0038218735717236996\n",
      "Episode Reward: 19.0\n",
      "Step 608 (7044249) @ Episode 9057/10000, loss: 0.0032880427315831184\n",
      "Episode Reward: 8.0\n",
      "Step 682 (7044931) @ Episode 9058/10000, loss: 0.0043562981300055986\n",
      "Episode Reward: 11.0\n",
      "Step 475 (7045406) @ Episode 9059/10000, loss: 0.0026437831111252316\n",
      "Episode Reward: 6.0\n",
      "Step 1091 (7046497) @ Episode 9060/10000, loss: 0.0023915821220725775\n",
      "Episode Reward: 20.0\n",
      "Step 1120 (7047617) @ Episode 9061/10000, loss: 0.0046745436266064647\n",
      "Episode Reward: 22.0\n",
      "Step 456 (7048073) @ Episode 9062/10000, loss: 0.0042100474238395691\n",
      "Episode Reward: 6.0\n",
      "Step 652 (7048725) @ Episode 9063/10000, loss: 0.0029147355817258366\n",
      "Episode Reward: 13.0\n",
      "Step 1065 (7049790) @ Episode 9064/10000, loss: 0.0032074814662337303\n",
      "Episode Reward: 22.0\n",
      "Step 209 (7049999) @ Episode 9065/10000, loss: 0.0035972562618553645\n",
      " Copied model parameters to target network\n",
      "Step 534 (7050324) @ Episode 9065/10000, loss: 0.0040417080745100975\n",
      "Episode Reward: 7.0\n",
      "Step 674 (7050998) @ Episode 9066/10000, loss: 0.0080579174682497985\n",
      "Episode Reward: 10.0\n",
      "Step 1011 (7052009) @ Episode 9067/10000, loss: 0.0022572265006601817\n",
      "Episode Reward: 20.0\n",
      "Step 657 (7052666) @ Episode 9068/10000, loss: 0.0018762100953608751\n",
      "Episode Reward: 10.0\n",
      "Step 982 (7053648) @ Episode 9069/10000, loss: 0.0021738002542406325\n",
      "Episode Reward: 17.0\n",
      "Step 850 (7054498) @ Episode 9070/10000, loss: 0.0010524042882025242\n",
      "Episode Reward: 15.0\n",
      "Step 882 (7055380) @ Episode 9071/10000, loss: 0.0036183616612106565\n",
      "Episode Reward: 15.0\n",
      "Step 774 (7056154) @ Episode 9072/10000, loss: 0.0032861651852726936\n",
      "Episode Reward: 17.0\n",
      "Step 684 (7056838) @ Episode 9073/10000, loss: 0.0098974844440817834\n",
      "Episode Reward: 11.0\n",
      "Step 859 (7057697) @ Episode 9074/10000, loss: 0.0016152129974216223\n",
      "Episode Reward: 13.0\n",
      "Step 794 (7058491) @ Episode 9075/10000, loss: 0.0045056799426674847\n",
      "Episode Reward: 17.0\n",
      "Step 578 (7059069) @ Episode 9076/10000, loss: 0.0022713947109878063\n",
      "Episode Reward: 9.0\n",
      "Step 653 (7059722) @ Episode 9077/10000, loss: 0.0879049524664878859\n",
      "Episode Reward: 11.0\n",
      "Step 277 (7059999) @ Episode 9078/10000, loss: 0.0053440816700458535\n",
      " Copied model parameters to target network\n",
      "Step 1177 (7060899) @ Episode 9078/10000, loss: 0.0023242691531777388\n",
      "Episode Reward: 31.0\n",
      "Step 671 (7061570) @ Episode 9079/10000, loss: 0.0023812744766473776\n",
      "Episode Reward: 9.0\n",
      "Step 544 (7062114) @ Episode 9080/10000, loss: 0.0030588130466639996\n",
      "Episode Reward: 11.0\n",
      "Step 494 (7062608) @ Episode 9081/10000, loss: 0.0052767829038202765\n",
      "Episode Reward: 9.0\n",
      "Step 608 (7063216) @ Episode 9082/10000, loss: 0.0064957225695252425\n",
      "Episode Reward: 8.0\n",
      "Step 694 (7063910) @ Episode 9083/10000, loss: 0.0017851772718131542\n",
      "Episode Reward: 15.0\n",
      "Step 576 (7064486) @ Episode 9084/10000, loss: 0.0029348558746278286\n",
      "Episode Reward: 10.0\n",
      "Step 482 (7064968) @ Episode 9085/10000, loss: 0.0064451163634657865\n",
      "Episode Reward: 6.0\n",
      "Step 620 (7065588) @ Episode 9086/10000, loss: 0.0059950933791697025\n",
      "Episode Reward: 8.0\n",
      "Step 939 (7066527) @ Episode 9087/10000, loss: 0.0018158687744289637\n",
      "Episode Reward: 15.0\n",
      "Step 949 (7067476) @ Episode 9088/10000, loss: 0.0060743917711079123\n",
      "Episode Reward: 15.0\n",
      "Step 797 (7068273) @ Episode 9089/10000, loss: 0.0008984886226244271\n",
      "Episode Reward: 13.0\n",
      "Step 990 (7069263) @ Episode 9090/10000, loss: 0.0006731775356456637\n",
      "Episode Reward: 18.0\n",
      "Step 711 (7069974) @ Episode 9091/10000, loss: 0.0053696073591709148\n",
      "Episode Reward: 12.0\n",
      "Step 25 (7069999) @ Episode 9092/10000, loss: 0.0023807007819414147\n",
      " Copied model parameters to target network\n",
      "Step 777 (7070751) @ Episode 9092/10000, loss: 0.0044490108266472822\n",
      "Episode Reward: 13.0\n",
      "Step 516 (7071267) @ Episode 9093/10000, loss: 0.0039855828508734776\n",
      "Episode Reward: 7.0\n",
      "Step 1297 (7072564) @ Episode 9094/10000, loss: 0.0029228732455521823\n",
      "Episode Reward: 32.0\n",
      "Step 413 (7072977) @ Episode 9095/10000, loss: 0.0051299426704645167\n",
      "Episode Reward: 4.0\n",
      "Step 665 (7073642) @ Episode 9096/10000, loss: 0.0026782248169183733\n",
      "Episode Reward: 13.0\n",
      "Step 634 (7074276) @ Episode 9097/10000, loss: 0.0031794407404959282\n",
      "Episode Reward: 10.0\n",
      "Step 1082 (7075358) @ Episode 9098/10000, loss: 0.0062000132165849218\n",
      "Episode Reward: 25.0\n",
      "Step 657 (7076015) @ Episode 9099/10000, loss: 0.0027990161906927824\n",
      "Episode Reward: 11.0\n",
      "Step 486 (7076501) @ Episode 9100/10000, loss: 0.0035069580189883717\n",
      "Episode Reward: 7.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 10:51:51,768] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video009100.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 592 (7077093) @ Episode 9101/10000, loss: 0.0028978395275771626\n",
      "Episode Reward: 10.0\n",
      "Step 402 (7077495) @ Episode 9102/10000, loss: 0.0034391803201287985\n",
      "Episode Reward: 8.0\n",
      "Step 724 (7078219) @ Episode 9103/10000, loss: 0.0045364778488874435\n",
      "Episode Reward: 12.0\n",
      "Step 776 (7078995) @ Episode 9104/10000, loss: 0.0075981570407748226\n",
      "Episode Reward: 12.0\n",
      "Step 607 (7079602) @ Episode 9105/10000, loss: 0.0012562009505927563\n",
      "Episode Reward: 11.0\n",
      "Step 397 (7079999) @ Episode 9106/10000, loss: 0.0036030332557857037\n",
      " Copied model parameters to target network\n",
      "Step 780 (7080382) @ Episode 9106/10000, loss: 0.0072436323389410978\n",
      "Episode Reward: 13.0\n",
      "Step 884 (7081266) @ Episode 9107/10000, loss: 0.0126529969274997717\n",
      "Episode Reward: 22.0\n",
      "Step 1258 (7082524) @ Episode 9108/10000, loss: 0.0018170236144214869\n",
      "Episode Reward: 27.0\n",
      "Step 1024 (7083548) @ Episode 9109/10000, loss: 0.0026574505027383566\n",
      "Episode Reward: 28.0\n",
      "Step 748 (7084296) @ Episode 9110/10000, loss: 0.0008400479564443231\n",
      "Episode Reward: 14.0\n",
      "Step 1174 (7085470) @ Episode 9111/10000, loss: 0.0018965834751725197\n",
      "Episode Reward: 19.0\n",
      "Step 664 (7086134) @ Episode 9112/10000, loss: 0.0026667970232665545\n",
      "Episode Reward: 9.0\n",
      "Step 1099 (7087233) @ Episode 9113/10000, loss: 0.0109911356121301655\n",
      "Episode Reward: 23.0\n",
      "Step 1077 (7088310) @ Episode 9114/10000, loss: 0.0082197887822985653\n",
      "Episode Reward: 35.0\n",
      "Step 585 (7088895) @ Episode 9115/10000, loss: 0.0058391727507114416\n",
      "Episode Reward: 8.0\n",
      "Step 563 (7089458) @ Episode 9116/10000, loss: 0.0028180589433759455\n",
      "Episode Reward: 9.0\n",
      "Step 541 (7089999) @ Episode 9117/10000, loss: 0.0026688352227211885\n",
      " Copied model parameters to target network\n",
      "Step 1145 (7090603) @ Episode 9117/10000, loss: 0.0025278653483837843\n",
      "Episode Reward: 20.0\n",
      "Step 825 (7091428) @ Episode 9118/10000, loss: 0.0035312781110405925\n",
      "Episode Reward: 20.0\n",
      "Step 755 (7092183) @ Episode 9119/10000, loss: 0.0036395424976944923\n",
      "Episode Reward: 12.0\n",
      "Step 573 (7092756) @ Episode 9120/10000, loss: 0.0039268787950277333\n",
      "Episode Reward: 8.0\n",
      "Step 297 (7093053) @ Episode 9121/10000, loss: 0.0052246488630771646\n",
      "Episode Reward: 3.0\n",
      "Step 308 (7093361) @ Episode 9122/10000, loss: 0.0014896313659846783\n",
      "Episode Reward: 3.0\n",
      "Step 572 (7093933) @ Episode 9123/10000, loss: 0.0107800494879484184\n",
      "Episode Reward: 9.0\n",
      "Step 750 (7094683) @ Episode 9124/10000, loss: 0.0021657641045749187\n",
      "Episode Reward: 13.0\n",
      "Step 707 (7095390) @ Episode 9125/10000, loss: 0.0073317708447575577\n",
      "Episode Reward: 12.0\n",
      "Step 827 (7096217) @ Episode 9126/10000, loss: 0.0013314720708876848\n",
      "Episode Reward: 17.0\n",
      "Step 910 (7097127) @ Episode 9127/10000, loss: 0.0078062629327178224\n",
      "Episode Reward: 15.0\n",
      "Step 401 (7097528) @ Episode 9128/10000, loss: 0.0032951724715530872\n",
      "Episode Reward: 5.0\n",
      "Step 554 (7098082) @ Episode 9129/10000, loss: 0.0073222839273512365\n",
      "Episode Reward: 7.0\n",
      "Step 886 (7098968) @ Episode 9130/10000, loss: 0.0016589122824370863\n",
      "Episode Reward: 14.0\n",
      "Step 979 (7099947) @ Episode 9131/10000, loss: 0.0039068381302058743\n",
      "Episode Reward: 18.0\n",
      "Step 52 (7099999) @ Episode 9132/10000, loss: 0.0032517204526811845\n",
      " Copied model parameters to target network\n",
      "Step 1028 (7100975) @ Episode 9132/10000, loss: 0.0078134732320904733\n",
      "Episode Reward: 17.0\n",
      "Step 807 (7101782) @ Episode 9133/10000, loss: 0.0017625975888222456\n",
      "Episode Reward: 14.0\n",
      "Step 650 (7102432) @ Episode 9134/10000, loss: 0.0010522184893488884\n",
      "Episode Reward: 9.0\n",
      "Step 815 (7103247) @ Episode 9135/10000, loss: 0.0060903872363269339\n",
      "Episode Reward: 17.0\n",
      "Step 493 (7103740) @ Episode 9136/10000, loss: 0.0021390912588685755\n",
      "Episode Reward: 7.0\n",
      "Step 563 (7104303) @ Episode 9137/10000, loss: 0.0050773550756275654\n",
      "Episode Reward: 9.0\n",
      "Step 902 (7105205) @ Episode 9138/10000, loss: 0.0027561567258089783\n",
      "Episode Reward: 13.0\n",
      "Step 395 (7105600) @ Episode 9139/10000, loss: 0.0018092629034072168\n",
      "Episode Reward: 4.0\n",
      "Step 911 (7106511) @ Episode 9140/10000, loss: 0.0053318808786571037\n",
      "Episode Reward: 15.0\n",
      "Step 1538 (7108049) @ Episode 9141/10000, loss: 0.0033629210665822032\n",
      "Episode Reward: 48.0\n",
      "Step 786 (7108835) @ Episode 9142/10000, loss: 0.0031991950236260893\n",
      "Episode Reward: 12.0\n",
      "Step 780 (7109615) @ Episode 9143/10000, loss: 0.0075690979138016787\n",
      "Episode Reward: 12.0\n",
      "Step 384 (7109999) @ Episode 9144/10000, loss: 0.0512630604207515753\n",
      " Copied model parameters to target network\n",
      "Step 870 (7110485) @ Episode 9144/10000, loss: 0.0022224129643291235\n",
      "Episode Reward: 15.0\n",
      "Step 770 (7111255) @ Episode 9145/10000, loss: 0.0041151428595185288\n",
      "Episode Reward: 13.0\n",
      "Step 1286 (7112541) @ Episode 9146/10000, loss: 0.0028957077302038671\n",
      "Episode Reward: 28.0\n",
      "Step 396 (7112937) @ Episode 9147/10000, loss: 0.0088617652654647834\n",
      "Episode Reward: 5.0\n",
      "Step 593 (7113530) @ Episode 9148/10000, loss: 0.0064571299590170385\n",
      "Episode Reward: 9.0\n",
      "Step 954 (7114484) @ Episode 9149/10000, loss: 0.0057216840796172624\n",
      "Episode Reward: 17.0\n",
      "Step 950 (7115434) @ Episode 9150/10000, loss: 0.0013847248628735542\n",
      "Episode Reward: 23.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 10:58:02,400] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video009150.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 947 (7116381) @ Episode 9151/10000, loss: 0.0040894076228141785\n",
      "Episode Reward: 22.0\n",
      "Step 728 (7117109) @ Episode 9152/10000, loss: 0.0048096673563122756\n",
      "Episode Reward: 10.0\n",
      "Step 1119 (7118228) @ Episode 9153/10000, loss: 0.0046961307525634766\n",
      "Episode Reward: 24.0\n",
      "Step 938 (7119166) @ Episode 9154/10000, loss: 0.0066555729135870933\n",
      "Episode Reward: 16.0\n",
      "Step 496 (7119662) @ Episode 9155/10000, loss: 0.0034707365557551384\n",
      "Episode Reward: 8.0\n",
      "Step 337 (7119999) @ Episode 9156/10000, loss: 0.0036760871298611164\n",
      " Copied model parameters to target network\n",
      "Step 984 (7120646) @ Episode 9156/10000, loss: 0.0036979170981794596\n",
      "Episode Reward: 19.0\n",
      "Step 958 (7121604) @ Episode 9157/10000, loss: 0.0055660922080278453\n",
      "Episode Reward: 20.0\n",
      "Step 804 (7122408) @ Episode 9158/10000, loss: 0.0054816962219774728\n",
      "Episode Reward: 13.0\n",
      "Step 745 (7123153) @ Episode 9159/10000, loss: 0.0177128762006759643\n",
      "Episode Reward: 11.0\n",
      "Step 684 (7123837) @ Episode 9160/10000, loss: 0.0043398630805313595\n",
      "Episode Reward: 11.0\n",
      "Step 1123 (7124960) @ Episode 9161/10000, loss: 0.0040572686120867734\n",
      "Episode Reward: 21.0\n",
      "Step 942 (7125902) @ Episode 9162/10000, loss: 0.0052889059297740466\n",
      "Episode Reward: 19.0\n",
      "Step 749 (7126651) @ Episode 9163/10000, loss: 0.0061757853254675865\n",
      "Episode Reward: 15.0\n",
      "Step 526 (7127177) @ Episode 9164/10000, loss: 0.0012419582344591618\n",
      "Episode Reward: 9.0\n",
      "Step 422 (7127599) @ Episode 9165/10000, loss: 0.0165785066783428217\n",
      "Episode Reward: 6.0\n",
      "Step 769 (7128368) @ Episode 9166/10000, loss: 0.0172636099159717566\n",
      "Episode Reward: 13.0\n",
      "Step 656 (7129024) @ Episode 9167/10000, loss: 0.0062605021521449097\n",
      "Episode Reward: 13.0\n",
      "Step 805 (7129829) @ Episode 9168/10000, loss: 0.0030823568813502793\n",
      "Episode Reward: 16.0\n",
      "Step 170 (7129999) @ Episode 9169/10000, loss: 0.0041233254596591515\n",
      " Copied model parameters to target network\n",
      "Step 968 (7130797) @ Episode 9169/10000, loss: 0.0052854269742965753\n",
      "Episode Reward: 22.0\n",
      "Step 717 (7131514) @ Episode 9170/10000, loss: 0.0024133205879479647\n",
      "Episode Reward: 15.0\n",
      "Step 1037 (7132551) @ Episode 9171/10000, loss: 0.0018985539209097624\n",
      "Episode Reward: 17.0\n",
      "Step 783 (7133334) @ Episode 9172/10000, loss: 0.0017787568503990776\n",
      "Episode Reward: 11.0\n",
      "Step 902 (7134236) @ Episode 9173/10000, loss: 0.0032603142317384484\n",
      "Episode Reward: 21.0\n",
      "Step 752 (7134988) @ Episode 9174/10000, loss: 0.0024512028321623802\n",
      "Episode Reward: 11.0\n",
      "Step 1301 (7136289) @ Episode 9175/10000, loss: 0.0038393894210457847\n",
      "Episode Reward: 33.0\n",
      "Step 1009 (7137298) @ Episode 9176/10000, loss: 0.0100404946133494385\n",
      "Episode Reward: 23.0\n",
      "Step 954 (7138252) @ Episode 9177/10000, loss: 0.0124149648472666745\n",
      "Episode Reward: 17.0\n",
      "Step 800 (7139052) @ Episode 9178/10000, loss: 0.0044010453857481487\n",
      "Episode Reward: 16.0\n",
      "Step 947 (7139999) @ Episode 9179/10000, loss: 0.0076507041230797777\n",
      " Copied model parameters to target network\n",
      "Step 1043 (7140095) @ Episode 9179/10000, loss: 0.0222591273486614232\n",
      "Episode Reward: 21.0\n",
      "Step 596 (7140691) @ Episode 9180/10000, loss: 0.0036539002321660527\n",
      "Episode Reward: 8.0\n",
      "Step 1097 (7141788) @ Episode 9181/10000, loss: 0.0018393365899100974\n",
      "Episode Reward: 27.0\n",
      "Step 1005 (7142793) @ Episode 9182/10000, loss: 0.0057124877348542218\n",
      "Episode Reward: 21.0\n",
      "Step 1057 (7143850) @ Episode 9183/10000, loss: 0.0053496975451707847\n",
      "Episode Reward: 17.0\n",
      "Step 920 (7144770) @ Episode 9184/10000, loss: 0.0124455504119396215\n",
      "Episode Reward: 15.0\n",
      "Step 786 (7145556) @ Episode 9185/10000, loss: 0.0037550276611000325\n",
      "Episode Reward: 13.0\n",
      "Step 648 (7146204) @ Episode 9186/10000, loss: 0.0054840212687856755\n",
      "Episode Reward: 10.0\n",
      "Step 740 (7146944) @ Episode 9187/10000, loss: 0.0083149205893278125\n",
      "Episode Reward: 12.0\n",
      "Step 721 (7147665) @ Episode 9188/10000, loss: 0.0024058078415691853\n",
      "Episode Reward: 10.0\n",
      "Step 1006 (7148671) @ Episode 9189/10000, loss: 0.0040741181001067162\n",
      "Episode Reward: 17.0\n",
      "Step 870 (7149541) @ Episode 9190/10000, loss: 0.0045422436669468887\n",
      "Episode Reward: 15.0\n",
      "Step 458 (7149999) @ Episode 9191/10000, loss: 0.0193243604153394776\n",
      " Copied model parameters to target network\n",
      "Step 1099 (7150640) @ Episode 9191/10000, loss: 0.0059057949110865595\n",
      "Episode Reward: 19.0\n",
      "Step 750 (7151390) @ Episode 9192/10000, loss: 0.0044449903070926677\n",
      "Episode Reward: 13.0\n",
      "Step 892 (7152282) @ Episode 9193/10000, loss: 0.00652235280722379747\n",
      "Episode Reward: 16.0\n",
      "Step 753 (7153035) @ Episode 9194/10000, loss: 0.0034116413444280624\n",
      "Episode Reward: 12.0\n",
      "Step 1024 (7154059) @ Episode 9195/10000, loss: 0.0086135603487491631\n",
      "Episode Reward: 19.0\n",
      "Step 802 (7154861) @ Episode 9196/10000, loss: 0.0039261421188712125\n",
      "Episode Reward: 14.0\n",
      "Step 574 (7155435) @ Episode 9197/10000, loss: 0.0041200830601155763\n",
      "Episode Reward: 8.0\n",
      "Step 1010 (7156445) @ Episode 9198/10000, loss: 0.0065326588228344925\n",
      "Episode Reward: 36.0\n",
      "Step 1063 (7157508) @ Episode 9199/10000, loss: 0.0089777512475848203\n",
      "Episode Reward: 21.0\n",
      "Step 800 (7158308) @ Episode 9200/10000, loss: 0.0019620251841843135\n",
      "Episode Reward: 14.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 11:04:46,972] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video009200.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 601 (7158909) @ Episode 9201/10000, loss: 0.0073744547553360465\n",
      "Episode Reward: 9.0\n",
      "Step 984 (7159893) @ Episode 9202/10000, loss: 0.1674875319004058846\n",
      "Episode Reward: 17.0\n",
      "Step 106 (7159999) @ Episode 9203/10000, loss: 0.0055146394297480588\n",
      " Copied model parameters to target network\n",
      "Step 521 (7160414) @ Episode 9203/10000, loss: 0.0039751157164573673\n",
      "Episode Reward: 7.0\n",
      "Step 1038 (7161452) @ Episode 9204/10000, loss: 0.0081593198701739315\n",
      "Episode Reward: 18.0\n",
      "Step 604 (7162056) @ Episode 9205/10000, loss: 0.0044246576726436615\n",
      "Episode Reward: 9.0\n",
      "Step 642 (7162698) @ Episode 9206/10000, loss: 0.0096474802121520044\n",
      "Episode Reward: 10.0\n",
      "Step 607 (7163305) @ Episode 9207/10000, loss: 0.0051629664376378062\n",
      "Episode Reward: 15.0\n",
      "Step 1087 (7164392) @ Episode 9208/10000, loss: 0.0075859930366277695\n",
      "Episode Reward: 22.0\n",
      "Step 733 (7165125) @ Episode 9209/10000, loss: 0.0047555663622915745\n",
      "Episode Reward: 11.0\n",
      "Step 939 (7166064) @ Episode 9210/10000, loss: 0.0184939932078123142\n",
      "Episode Reward: 15.0\n",
      "Step 644 (7166708) @ Episode 9211/10000, loss: 0.0111797507852315983\n",
      "Episode Reward: 11.0\n",
      "Step 1024 (7167732) @ Episode 9212/10000, loss: 0.0859318971633911174\n",
      "Episode Reward: 17.0\n",
      "Step 696 (7168428) @ Episode 9213/10000, loss: 0.0051772659644484524\n",
      "Episode Reward: 11.0\n",
      "Step 1118 (7169546) @ Episode 9214/10000, loss: 0.0042504477314651016\n",
      "Episode Reward: 24.0\n",
      "Step 453 (7169999) @ Episode 9215/10000, loss: 0.0025729942135512836\n",
      " Copied model parameters to target network\n",
      "Step 950 (7170496) @ Episode 9215/10000, loss: 0.0033371427562087774\n",
      "Episode Reward: 18.0\n",
      "Step 440 (7170936) @ Episode 9216/10000, loss: 0.0476054958999156953\n",
      "Episode Reward: 6.0\n",
      "Step 496 (7171432) @ Episode 9217/10000, loss: 0.0009994636056944728\n",
      "Episode Reward: 8.0\n",
      "Step 908 (7172340) @ Episode 9218/10000, loss: 0.0022843950428068648\n",
      "Episode Reward: 15.0\n",
      "Step 818 (7173158) @ Episode 9219/10000, loss: 0.0063750622794032153\n",
      "Episode Reward: 14.0\n",
      "Step 1219 (7174377) @ Episode 9220/10000, loss: 0.0019883983768522747\n",
      "Episode Reward: 27.0\n",
      "Step 992 (7175369) @ Episode 9221/10000, loss: 0.0039252298884093766\n",
      "Episode Reward: 18.0\n",
      "Step 747 (7176116) @ Episode 9222/10000, loss: 0.0185722857713699343\n",
      "Episode Reward: 11.0\n",
      "Step 628 (7176744) @ Episode 9223/10000, loss: 0.0032724465709179647\n",
      "Episode Reward: 10.0\n",
      "Step 694 (7177438) @ Episode 9224/10000, loss: 0.0026461165398359328\n",
      "Episode Reward: 11.0\n",
      "Step 901 (7178339) @ Episode 9225/10000, loss: 0.0036641918122768444\n",
      "Episode Reward: 14.0\n",
      "Step 559 (7178898) @ Episode 9226/10000, loss: 0.0024157571606338024\n",
      "Episode Reward: 9.0\n",
      "Step 926 (7179824) @ Episode 9227/10000, loss: 0.0124916452914476477\n",
      "Episode Reward: 18.0\n",
      "Step 175 (7179999) @ Episode 9228/10000, loss: 0.0038742311298847246\n",
      " Copied model parameters to target network\n",
      "Step 881 (7180705) @ Episode 9228/10000, loss: 0.0035750353708863266\n",
      "Episode Reward: 18.0\n",
      "Step 861 (7181566) @ Episode 9229/10000, loss: 0.0032651568762958053\n",
      "Episode Reward: 16.0\n",
      "Step 550 (7182116) @ Episode 9230/10000, loss: 0.0049958745948970326\n",
      "Episode Reward: 8.0\n",
      "Step 870 (7182986) @ Episode 9231/10000, loss: 0.0016188635490834713\n",
      "Episode Reward: 14.0\n",
      "Step 602 (7183588) @ Episode 9232/10000, loss: 0.0057133939117193223\n",
      "Episode Reward: 9.0\n",
      "Step 695 (7184283) @ Episode 9233/10000, loss: 0.0033913452643901116\n",
      "Episode Reward: 10.0\n",
      "Step 739 (7185022) @ Episode 9234/10000, loss: 0.0017721801996231087\n",
      "Episode Reward: 12.0\n",
      "Step 712 (7185734) @ Episode 9235/10000, loss: 0.0077688777819275865\n",
      "Episode Reward: 10.0\n",
      "Step 1276 (7187010) @ Episode 9236/10000, loss: 0.0067021963186562067\n",
      "Episode Reward: 29.0\n",
      "Step 668 (7187678) @ Episode 9237/10000, loss: 0.0022969688288867474\n",
      "Episode Reward: 14.0\n",
      "Step 972 (7188650) @ Episode 9238/10000, loss: 0.0067718215286731727\n",
      "Episode Reward: 19.0\n",
      "Step 1136 (7189786) @ Episode 9239/10000, loss: 0.0083733834326267244\n",
      "Episode Reward: 26.0\n",
      "Step 213 (7189999) @ Episode 9240/10000, loss: 0.0101886969059705735\n",
      " Copied model parameters to target network\n",
      "Step 903 (7190689) @ Episode 9240/10000, loss: 0.0102562122046947485\n",
      "Episode Reward: 14.0\n",
      "Step 753 (7191442) @ Episode 9241/10000, loss: 0.0033688941039144993\n",
      "Episode Reward: 13.0\n",
      "Step 1213 (7192655) @ Episode 9242/10000, loss: 0.0011239044833928347\n",
      "Episode Reward: 25.0\n",
      "Step 578 (7193233) @ Episode 9243/10000, loss: 0.0040822289884090427\n",
      "Episode Reward: 9.0\n",
      "Step 492 (7193725) @ Episode 9244/10000, loss: 0.0042482172138988973\n",
      "Episode Reward: 7.0\n",
      "Step 630 (7194355) @ Episode 9245/10000, loss: 0.3333553969860077323\n",
      "Episode Reward: 8.0\n",
      "Step 913 (7195268) @ Episode 9246/10000, loss: 0.0033980954904109244\n",
      "Episode Reward: 18.0\n",
      "Step 741 (7196009) @ Episode 9247/10000, loss: 0.0033799570519477134\n",
      "Episode Reward: 11.0\n",
      "Step 1025 (7197034) @ Episode 9248/10000, loss: 0.0013577260542660952\n",
      "Episode Reward: 18.0\n",
      "Step 833 (7197867) @ Episode 9249/10000, loss: 0.0069243661127984525\n",
      "Episode Reward: 18.0\n",
      "Step 611 (7198478) @ Episode 9250/10000, loss: 0.0069646569900214675\n",
      "Episode Reward: 8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 11:11:08,808] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video009250.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 741 (7199219) @ Episode 9251/10000, loss: 0.0055038174614310265\n",
      "Episode Reward: 11.0\n",
      "Step 780 (7199999) @ Episode 9252/10000, loss: 0.0027440637350082397\n",
      " Copied model parameters to target network\n",
      "Step 944 (7200163) @ Episode 9252/10000, loss: 0.0022937580943107605\n",
      "Episode Reward: 16.0\n",
      "Step 1009 (7201172) @ Episode 9253/10000, loss: 0.0040626316331326964\n",
      "Episode Reward: 17.0\n",
      "Step 834 (7202006) @ Episode 9254/10000, loss: 0.0048664794303476813\n",
      "Episode Reward: 14.0\n",
      "Step 1177 (7203183) @ Episode 9255/10000, loss: 0.0036406465806066997\n",
      "Episode Reward: 18.0\n",
      "Step 962 (7204145) @ Episode 9256/10000, loss: 0.0022380249574780464\n",
      "Episode Reward: 25.0\n",
      "Step 910 (7205055) @ Episode 9257/10000, loss: 0.0208278745412826545\n",
      "Episode Reward: 16.0\n",
      "Step 968 (7206023) @ Episode 9258/10000, loss: 0.0049507152289152145\n",
      "Episode Reward: 17.0\n",
      "Step 806 (7206829) @ Episode 9259/10000, loss: 0.0023332904092967515\n",
      "Episode Reward: 21.0\n",
      "Step 633 (7207462) @ Episode 9260/10000, loss: 0.0045548714697360998\n",
      "Episode Reward: 10.0\n",
      "Step 1000 (7208462) @ Episode 9261/10000, loss: 0.0012972070835530758\n",
      "Episode Reward: 24.0\n",
      "Step 646 (7209108) @ Episode 9262/10000, loss: 0.0091598229482769974\n",
      "Episode Reward: 10.0\n",
      "Step 766 (7209874) @ Episode 9263/10000, loss: 0.0080151865258812968\n",
      "Episode Reward: 14.0\n",
      "Step 125 (7209999) @ Episode 9264/10000, loss: 0.0041321017779409885\n",
      " Copied model parameters to target network\n",
      "Step 753 (7210627) @ Episode 9264/10000, loss: 0.0034569012932479384\n",
      "Episode Reward: 12.0\n",
      "Step 653 (7211280) @ Episode 9265/10000, loss: 0.0037798159755766395\n",
      "Episode Reward: 10.0\n",
      "Step 779 (7212059) @ Episode 9266/10000, loss: 0.0026907112915068865\n",
      "Episode Reward: 13.0\n",
      "Step 590 (7212649) @ Episode 9267/10000, loss: 0.0030887802131474027\n",
      "Episode Reward: 9.0\n",
      "Step 748 (7213397) @ Episode 9268/10000, loss: 0.0070522809401154525\n",
      "Episode Reward: 13.0\n",
      "Step 702 (7214099) @ Episode 9269/10000, loss: 0.0019630712922662497\n",
      "Episode Reward: 12.0\n",
      "Step 526 (7214625) @ Episode 9270/10000, loss: 0.0047435979358851913\n",
      "Episode Reward: 8.0\n",
      "Step 1266 (7215891) @ Episode 9271/10000, loss: 0.0015751111786812544\n",
      "Episode Reward: 29.0\n",
      "Step 702 (7216593) @ Episode 9272/10000, loss: 0.0025411685928702354\n",
      "Episode Reward: 12.0\n",
      "Step 1089 (7217682) @ Episode 9273/10000, loss: 0.0048223780468106276\n",
      "Episode Reward: 24.0\n",
      "Step 1031 (7218713) @ Episode 9274/10000, loss: 0.0133986789733171465\n",
      "Episode Reward: 17.0\n",
      "Step 872 (7219585) @ Episode 9275/10000, loss: 0.0028147574048489332\n",
      "Episode Reward: 19.0\n",
      "Step 414 (7219999) @ Episode 9276/10000, loss: 0.0410299189388752704\n",
      " Copied model parameters to target network\n",
      "Step 946 (7220531) @ Episode 9276/10000, loss: 0.0032045291736721992\n",
      "Episode Reward: 15.0\n",
      "Step 750 (7221281) @ Episode 9277/10000, loss: 0.0017085236031562097\n",
      "Episode Reward: 14.0\n",
      "Step 892 (7222173) @ Episode 9278/10000, loss: 0.0155465919524431238\n",
      "Episode Reward: 17.0\n",
      "Step 897 (7223070) @ Episode 9279/10000, loss: 0.0033224073704332113\n",
      "Episode Reward: 13.0\n",
      "Step 803 (7223873) @ Episode 9280/10000, loss: 0.0050234636291861532\n",
      "Episode Reward: 15.0\n",
      "Step 743 (7224616) @ Episode 9281/10000, loss: 0.0125791635364294052\n",
      "Episode Reward: 14.0\n",
      "Step 567 (7225183) @ Episode 9282/10000, loss: 0.0039721052162349225\n",
      "Episode Reward: 8.0\n",
      "Step 624 (7225807) @ Episode 9283/10000, loss: 0.0020925702992826714\n",
      "Episode Reward: 12.0\n",
      "Step 971 (7226778) @ Episode 9284/10000, loss: 0.0020064001437276615\n",
      "Episode Reward: 16.0\n",
      "Step 596 (7227374) @ Episode 9285/10000, loss: 0.0200743991881608965\n",
      "Episode Reward: 9.0\n",
      "Step 762 (7228136) @ Episode 9286/10000, loss: 0.0046296883374452596\n",
      "Episode Reward: 13.0\n",
      "Step 762 (7228898) @ Episode 9287/10000, loss: 0.0062953657470643523\n",
      "Episode Reward: 12.0\n",
      "Step 814 (7229712) @ Episode 9288/10000, loss: 0.0021376337390393026\n",
      "Episode Reward: 18.0\n",
      "Step 287 (7229999) @ Episode 9289/10000, loss: 0.0021615540608763695\n",
      " Copied model parameters to target network\n",
      "Step 738 (7230450) @ Episode 9289/10000, loss: 0.0049408250488340855\n",
      "Episode Reward: 11.0\n",
      "Step 1206 (7231656) @ Episode 9290/10000, loss: 0.0043002218008041384\n",
      "Episode Reward: 24.0\n",
      "Step 614 (7232270) @ Episode 9291/10000, loss: 0.0044270958751440056\n",
      "Episode Reward: 9.0\n",
      "Step 679 (7232949) @ Episode 9292/10000, loss: 0.0015378630487248302\n",
      "Episode Reward: 11.0\n",
      "Step 961 (7233910) @ Episode 9293/10000, loss: 0.0055714966729283334\n",
      "Episode Reward: 18.0\n",
      "Step 1132 (7235042) @ Episode 9294/10000, loss: 0.0024087280035018924\n",
      "Episode Reward: 23.0\n",
      "Step 660 (7235702) @ Episode 9295/10000, loss: 0.0048664733767509465\n",
      "Episode Reward: 9.0\n",
      "Step 1130 (7236832) @ Episode 9296/10000, loss: 0.0025526983663439753\n",
      "Episode Reward: 23.0\n",
      "Step 614 (7237446) @ Episode 9297/10000, loss: 0.0098826494067907337\n",
      "Episode Reward: 9.0\n",
      "Step 571 (7238017) @ Episode 9298/10000, loss: 0.0021153565030544996\n",
      "Episode Reward: 8.0\n",
      "Step 819 (7238836) @ Episode 9299/10000, loss: 0.0066865477710962296\n",
      "Episode Reward: 18.0\n",
      "Step 581 (7239417) @ Episode 9300/10000, loss: 0.0029321545735001564\n",
      "Episode Reward: 8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 11:17:36,819] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video009300.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 582 (7239999) @ Episode 9301/10000, loss: 0.0040617701597511774\n",
      " Copied model parameters to target network\n",
      "Step 1383 (7240800) @ Episode 9301/10000, loss: 0.0018274032045155764\n",
      "Episode Reward: 28.0\n",
      "Step 914 (7241714) @ Episode 9302/10000, loss: 0.0056873476132750518\n",
      "Episode Reward: 15.0\n",
      "Step 1204 (7242918) @ Episode 9303/10000, loss: 0.0039437939412891865\n",
      "Episode Reward: 32.0\n",
      "Step 948 (7243866) @ Episode 9304/10000, loss: 0.0150764565914869376\n",
      "Episode Reward: 17.0\n",
      "Step 750 (7244616) @ Episode 9305/10000, loss: 0.0054957969114184385\n",
      "Episode Reward: 11.0\n",
      "Step 979 (7245595) @ Episode 9306/10000, loss: 0.0036785430274903774\n",
      "Episode Reward: 23.0\n",
      "Step 967 (7246562) @ Episode 9307/10000, loss: 0.0060701207257807255\n",
      "Episode Reward: 13.0\n",
      "Step 938 (7247500) @ Episode 9308/10000, loss: 0.0283583607524633472\n",
      "Episode Reward: 15.0\n",
      "Step 867 (7248367) @ Episode 9309/10000, loss: 0.0045471293851733214\n",
      "Episode Reward: 17.0\n",
      "Step 760 (7249127) @ Episode 9310/10000, loss: 0.0084251984953880313\n",
      "Episode Reward: 12.0\n",
      "Step 860 (7249987) @ Episode 9311/10000, loss: 0.0028825362678617244\n",
      "Episode Reward: 15.0\n",
      "Step 12 (7249999) @ Episode 9312/10000, loss: 0.002635571174323559\n",
      " Copied model parameters to target network\n",
      "Step 618 (7250605) @ Episode 9312/10000, loss: 0.0028080926276743413\n",
      "Episode Reward: 9.0\n",
      "Step 649 (7251254) @ Episode 9313/10000, loss: 0.0042699389159679417\n",
      "Episode Reward: 10.0\n",
      "Step 658 (7251912) @ Episode 9314/10000, loss: 0.0034072366543114185\n",
      "Episode Reward: 10.0\n",
      "Step 640 (7252552) @ Episode 9315/10000, loss: 0.0077193449251353743\n",
      "Episode Reward: 12.0\n",
      "Step 1223 (7253775) @ Episode 9316/10000, loss: 0.0022670156322419643\n",
      "Episode Reward: 27.0\n",
      "Step 929 (7254704) @ Episode 9317/10000, loss: 0.0029744089115411043\n",
      "Episode Reward: 15.0\n",
      "Step 912 (7255616) @ Episode 9318/10000, loss: 0.0048530339263379573\n",
      "Episode Reward: 15.0\n",
      "Step 1005 (7256621) @ Episode 9319/10000, loss: 0.0234541296958923346\n",
      "Episode Reward: 15.0\n",
      "Step 1078 (7257699) @ Episode 9320/10000, loss: 0.0054690320976078515\n",
      "Episode Reward: 25.0\n",
      "Step 824 (7258523) @ Episode 9321/10000, loss: 0.0027519655413925648\n",
      "Episode Reward: 14.0\n",
      "Step 728 (7259251) @ Episode 9322/10000, loss: 0.0062292180955411785\n",
      "Episode Reward: 12.0\n",
      "Step 686 (7259937) @ Episode 9323/10000, loss: 0.0056024244986474516\n",
      "Episode Reward: 10.0\n",
      "Step 62 (7259999) @ Episode 9324/10000, loss: 0.0048455703072249899\n",
      " Copied model parameters to target network\n",
      "Step 656 (7260593) @ Episode 9324/10000, loss: 0.0023638939019292593\n",
      "Episode Reward: 10.0\n",
      "Step 439 (7261032) @ Episode 9325/10000, loss: 0.0031142167281359434\n",
      "Episode Reward: 6.0\n",
      "Step 1185 (7262217) @ Episode 9326/10000, loss: 0.0055675399489700797\n",
      "Episode Reward: 19.0\n",
      "Step 1143 (7263360) @ Episode 9327/10000, loss: 0.0037602474913001068\n",
      "Episode Reward: 20.0\n",
      "Step 929 (7264289) @ Episode 9328/10000, loss: 0.0067624873481690883\n",
      "Episode Reward: 14.0\n",
      "Step 824 (7265113) @ Episode 9329/10000, loss: 0.0026602661237120631\n",
      "Episode Reward: 17.0\n",
      "Step 726 (7265839) @ Episode 9330/10000, loss: 0.0045889285393059257\n",
      "Episode Reward: 13.0\n",
      "Step 904 (7266743) @ Episode 9331/10000, loss: 0.0022032738197594884\n",
      "Episode Reward: 16.0\n",
      "Step 991 (7267734) @ Episode 9332/10000, loss: 0.0096232239156961442\n",
      "Episode Reward: 17.0\n",
      "Step 1104 (7268838) @ Episode 9333/10000, loss: 0.0020977561362087727\n",
      "Episode Reward: 28.0\n",
      "Step 674 (7269512) @ Episode 9334/10000, loss: 0.0029209163039922714\n",
      "Episode Reward: 13.0\n",
      "Step 487 (7269999) @ Episode 9335/10000, loss: 0.0064420402050018314\n",
      " Copied model parameters to target network\n",
      "Step 1225 (7270737) @ Episode 9335/10000, loss: 0.0039251134730875493\n",
      "Episode Reward: 29.0\n",
      "Step 684 (7271421) @ Episode 9336/10000, loss: 0.0026929397135972977\n",
      "Episode Reward: 9.0\n",
      "Step 946 (7272367) @ Episode 9337/10000, loss: 0.0027148020453751087\n",
      "Episode Reward: 15.0\n",
      "Step 681 (7273048) @ Episode 9338/10000, loss: 0.0039553251117467886\n",
      "Episode Reward: 12.0\n",
      "Step 684 (7273732) @ Episode 9339/10000, loss: 0.0021789253223687413\n",
      "Episode Reward: 10.0\n",
      "Step 749 (7274481) @ Episode 9340/10000, loss: 0.0030059630516916513\n",
      "Episode Reward: 11.0\n",
      "Step 724 (7275205) @ Episode 9341/10000, loss: 0.0014375915052369237\n",
      "Episode Reward: 12.0\n",
      "Step 947 (7276152) @ Episode 9342/10000, loss: 0.0084314178675413132\n",
      "Episode Reward: 17.0\n",
      "Step 1350 (7277502) @ Episode 9343/10000, loss: 0.0365390256047248843\n",
      "Episode Reward: 33.0\n",
      "Step 880 (7278382) @ Episode 9344/10000, loss: 0.0068949870765209247\n",
      "Episode Reward: 14.0\n",
      "Step 1224 (7279606) @ Episode 9345/10000, loss: 0.0037498618476092815\n",
      "Episode Reward: 28.0\n",
      "Step 393 (7279999) @ Episode 9346/10000, loss: 0.0118024097755551345\n",
      " Copied model parameters to target network\n",
      "Step 557 (7280163) @ Episode 9346/10000, loss: 0.0030083993915468454\n",
      "Episode Reward: 8.0\n",
      "Step 587 (7280750) @ Episode 9347/10000, loss: 0.0073004830628633518\n",
      "Episode Reward: 14.0\n",
      "Step 977 (7281727) @ Episode 9348/10000, loss: 0.0289626382291317215\n",
      "Episode Reward: 20.0\n",
      "Step 936 (7282663) @ Episode 9349/10000, loss: 0.0031457617878913884\n",
      "Episode Reward: 17.0\n",
      "Step 940 (7283603) @ Episode 9350/10000, loss: 0.0071589518338441855\n",
      "Episode Reward: 19.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 11:24:35,113] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video009350.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 750 (7284353) @ Episode 9351/10000, loss: 0.0020066751167178154\n",
      "Episode Reward: 17.0\n",
      "Step 783 (7285136) @ Episode 9352/10000, loss: 0.0036129143554717302\n",
      "Episode Reward: 11.0\n",
      "Step 850 (7285986) @ Episode 9353/10000, loss: 0.0051187630742788315\n",
      "Episode Reward: 18.0\n",
      "Step 986 (7286972) @ Episode 9354/10000, loss: 0.0047786510549485684\n",
      "Episode Reward: 16.0\n",
      "Step 639 (7287611) @ Episode 9355/10000, loss: 0.0051736366003751755\n",
      "Episode Reward: 9.0\n",
      "Step 920 (7288531) @ Episode 9356/10000, loss: 0.0044082533568143845\n",
      "Episode Reward: 21.0\n",
      "Step 583 (7289114) @ Episode 9357/10000, loss: 0.0093538602814078335\n",
      "Episode Reward: 8.0\n",
      "Step 696 (7289810) @ Episode 9358/10000, loss: 0.0120202787220478067\n",
      "Episode Reward: 15.0\n",
      "Step 189 (7289999) @ Episode 9359/10000, loss: 0.0030981868039816626\n",
      " Copied model parameters to target network\n",
      "Step 957 (7290767) @ Episode 9359/10000, loss: 0.0086089754477143297\n",
      "Episode Reward: 24.0\n",
      "Step 593 (7291360) @ Episode 9360/10000, loss: 0.0042590429075062275\n",
      "Episode Reward: 13.0\n",
      "Step 727 (7292087) @ Episode 9361/10000, loss: 0.0271340943872928622\n",
      "Episode Reward: 8.0\n",
      "Step 820 (7292907) @ Episode 9362/10000, loss: 0.0023823049850761894\n",
      "Episode Reward: 18.0\n",
      "Step 701 (7293608) @ Episode 9363/10000, loss: 0.0028509167023003133\n",
      "Episode Reward: 13.0\n",
      "Step 697 (7294305) @ Episode 9364/10000, loss: 0.0101162642240524365\n",
      "Episode Reward: 10.0\n",
      "Step 1071 (7295376) @ Episode 9365/10000, loss: 0.0020530906040221453\n",
      "Episode Reward: 24.0\n",
      "Step 632 (7296008) @ Episode 9366/10000, loss: 0.0072668925859034066\n",
      "Episode Reward: 8.0\n",
      "Step 912 (7296920) @ Episode 9367/10000, loss: 0.0050544310361146935\n",
      "Episode Reward: 21.0\n",
      "Step 894 (7297814) @ Episode 9368/10000, loss: 0.0079444143921136862\n",
      "Episode Reward: 19.0\n",
      "Step 977 (7298791) @ Episode 9369/10000, loss: 0.0013548674760386348\n",
      "Episode Reward: 18.0\n",
      "Step 624 (7299415) @ Episode 9370/10000, loss: 0.0075491322204470634\n",
      "Episode Reward: 9.0\n",
      "Step 584 (7299999) @ Episode 9371/10000, loss: 0.0053865923546254635\n",
      " Copied model parameters to target network\n",
      "Step 961 (7300376) @ Episode 9371/10000, loss: 0.0023794455919414763\n",
      "Episode Reward: 19.0\n",
      "Step 908 (7301284) @ Episode 9372/10000, loss: 0.2748840153217315744\n",
      "Episode Reward: 15.0\n",
      "Step 766 (7302050) @ Episode 9373/10000, loss: 0.0149579290300607684\n",
      "Episode Reward: 13.0\n",
      "Step 581 (7302631) @ Episode 9374/10000, loss: 0.0045392010360956194\n",
      "Episode Reward: 12.0\n",
      "Step 923 (7303554) @ Episode 9375/10000, loss: 0.0171119235455989847\n",
      "Episode Reward: 20.0\n",
      "Step 693 (7304247) @ Episode 9376/10000, loss: 0.0024053931701928377\n",
      "Episode Reward: 11.0\n",
      "Step 633 (7304880) @ Episode 9377/10000, loss: 0.0130025399848818787\n",
      "Episode Reward: 10.0\n",
      "Step 857 (7305737) @ Episode 9378/10000, loss: 0.0043776142410933973\n",
      "Episode Reward: 17.0\n",
      "Step 776 (7306513) @ Episode 9379/10000, loss: 0.0073424102738499644\n",
      "Episode Reward: 13.0\n",
      "Step 976 (7307489) @ Episode 9380/10000, loss: 0.0035091743338853126\n",
      "Episode Reward: 16.0\n",
      "Step 690 (7308179) @ Episode 9381/10000, loss: 0.0154046984389424326\n",
      "Episode Reward: 10.0\n",
      "Step 630 (7308809) @ Episode 9382/10000, loss: 0.0027512423694133764\n",
      "Episode Reward: 10.0\n",
      "Step 999 (7309808) @ Episode 9383/10000, loss: 0.0292505137622356447\n",
      "Episode Reward: 25.0\n",
      "Step 191 (7309999) @ Episode 9384/10000, loss: 0.0063571846112608915\n",
      " Copied model parameters to target network\n",
      "Step 922 (7310730) @ Episode 9384/10000, loss: 0.0107133360579609877\n",
      "Episode Reward: 14.0\n",
      "Step 1167 (7311897) @ Episode 9385/10000, loss: 0.0046174665912985857\n",
      "Episode Reward: 24.0\n",
      "Step 590 (7312487) @ Episode 9386/10000, loss: 0.0044245673343539245\n",
      "Episode Reward: 10.0\n",
      "Step 739 (7313226) @ Episode 9387/10000, loss: 0.0033197994343936443\n",
      "Episode Reward: 16.0\n",
      "Step 617 (7313843) @ Episode 9388/10000, loss: 0.0020683254115283496\n",
      "Episode Reward: 10.0\n",
      "Step 767 (7314610) @ Episode 9389/10000, loss: 0.0052435491234064176\n",
      "Episode Reward: 13.0\n",
      "Step 868 (7315478) @ Episode 9390/10000, loss: 0.0122754108160734187\n",
      "Episode Reward: 21.0\n",
      "Step 615 (7316093) @ Episode 9391/10000, loss: 0.0045508872717618945\n",
      "Episode Reward: 9.0\n",
      "Step 844 (7316937) @ Episode 9392/10000, loss: 0.0031890461686998606\n",
      "Episode Reward: 14.0\n",
      "Step 770 (7317707) @ Episode 9393/10000, loss: 0.0025157844647765166\n",
      "Episode Reward: 12.0\n",
      "Step 1188 (7318895) @ Episode 9394/10000, loss: 0.0027728024870157245\n",
      "Episode Reward: 27.0\n",
      "Step 706 (7319601) @ Episode 9395/10000, loss: 0.0020000943914055824\n",
      "Episode Reward: 19.0\n",
      "Step 398 (7319999) @ Episode 9396/10000, loss: 0.0028023007325828075\n",
      " Copied model parameters to target network\n",
      "Step 829 (7320430) @ Episode 9396/10000, loss: 0.0023035106714814985\n",
      "Episode Reward: 17.0\n",
      "Step 930 (7321360) @ Episode 9397/10000, loss: 0.0019821517635136843\n",
      "Episode Reward: 18.0\n",
      "Step 783 (7322143) @ Episode 9398/10000, loss: 0.0056799449957907291\n",
      "Episode Reward: 16.0\n",
      "Step 831 (7322974) @ Episode 9399/10000, loss: 0.0017274983692914248\n",
      "Episode Reward: 17.0\n",
      "Step 696 (7323670) @ Episode 9400/10000, loss: 0.0033580577000975614\n",
      "Episode Reward: 14.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-11-05 11:30:54,277] Starting new video recorder writing to /home/mark/projects/reinforcement-learning/experiments/Breakout-v0/monitor/openaigym.video.0.14354.video009400.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 721 (7324391) @ Episode 9401/10000, loss: 0.0066166231408715254\n",
      "Episode Reward: 10.0\n",
      "Step 1381 (7325772) @ Episode 9402/10000, loss: 0.0023492448963224894\n",
      "Episode Reward: 29.0\n",
      "Step 661 (7326433) @ Episode 9403/10000, loss: 0.0066148564219474798\n",
      "Episode Reward: 10.0\n",
      "Step 743 (7327176) @ Episode 9404/10000, loss: 0.0023949537426233298\n",
      "Episode Reward: 12.0\n",
      "Step 857 (7328033) @ Episode 9405/10000, loss: 0.0084447320550680165\n",
      "Episode Reward: 17.0\n",
      "Step 676 (7328709) @ Episode 9406/10000, loss: 0.0095829935744404834\n",
      "Episode Reward: 10.0\n",
      "Step 820 (7329529) @ Episode 9407/10000, loss: 0.0048130019567906866\n",
      "Episode Reward: 13.0\n",
      "Step 470 (7329999) @ Episode 9408/10000, loss: 0.0065483115613460545\n",
      " Copied model parameters to target network\n",
      "Step 982 (7330511) @ Episode 9408/10000, loss: 0.0022894281428307295\n",
      "Episode Reward: 16.0\n",
      "Step 796 (7331307) @ Episode 9409/10000, loss: 0.0481149181723594726\n",
      "Episode Reward: 9.0\n",
      "Step 981 (7332288) @ Episode 9410/10000, loss: 0.0054785697720944881\n",
      "Episode Reward: 17.0\n",
      "Step 1015 (7333303) @ Episode 9411/10000, loss: 0.0078357225283980378\n",
      "Episode Reward: 20.0\n",
      "Step 1024 (7334327) @ Episode 9412/10000, loss: 0.0059493528679013252\n",
      "Episode Reward: 18.0\n",
      "Step 878 (7335205) @ Episode 9413/10000, loss: 0.0038838940672576427\n",
      "Episode Reward: 15.0\n",
      "Step 628 (7335833) @ Episode 9414/10000, loss: 0.0102299656718969354\n",
      "Episode Reward: 11.0\n",
      "Step 947 (7336780) @ Episode 9415/10000, loss: 0.0174465328454971354\n",
      "Episode Reward: 24.0\n",
      "Step 1353 (7338133) @ Episode 9416/10000, loss: 0.0071962508372962475\n",
      "Episode Reward: 39.0\n",
      "Step 845 (7338978) @ Episode 9417/10000, loss: 0.0018515038536861539\n",
      "Episode Reward: 12.0\n",
      "Step 926 (7339904) @ Episode 9418/10000, loss: 0.0057129273191094444\n",
      "Episode Reward: 15.0\n",
      "Step 95 (7339999) @ Episode 9419/10000, loss: 0.0358454808592796347\n",
      " Copied model parameters to target network\n",
      "Step 794 (7340698) @ Episode 9419/10000, loss: 0.0041659316048026085\n",
      "Episode Reward: 18.0\n",
      "Step 794 (7341492) @ Episode 9420/10000, loss: 0.0239967051893472678\n",
      "Episode Reward: 13.0\n",
      "Step 963 (7342455) @ Episode 9421/10000, loss: 0.0061395699158310897\n",
      "Episode Reward: 24.0\n",
      "Step 1293 (7343748) @ Episode 9422/10000, loss: 0.0089597087353467942\n",
      "Episode Reward: 23.0\n",
      "Step 826 (7344574) @ Episode 9423/10000, loss: 0.0113717839121818543\n",
      "Episode Reward: 14.0\n",
      "Step 755 (7345329) @ Episode 9424/10000, loss: 0.0172394607216119773"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "experiments_dir = os.path.abspath('./experiments/{}'.format(env.spec.id))\n",
    "# create global step variable\n",
    "global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "# estimators\n",
    "q_estimator = Estimator(scope='q', summaries_dir=experiments_dir)\n",
    "target_estimator = Estimator(scope='target_q')\n",
    "# state processor\n",
    "state_processor = StateProcessor()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for t, stats in deep_q_learning(sess,\n",
    "                                    env,\n",
    "                                    q_estimator=q_estimator,\n",
    "                                    target_estimator=target_estimator,\n",
    "                                    state_processor=state_processor,\n",
    "                                    n_episodes=10000,\n",
    "                                    experiments_dir=experiments_dir,\n",
    "                                    replay_mem_size=500000,\n",
    "                                    replay_mem_init_size=50000,\n",
    "                                    estimator_update_steps=10000,\n",
    "                                    discount_factor=0.99,\n",
    "                                    epsilon_start=1.0,\n",
    "                                    epsilon_end=0.1,\n",
    "                                    epsilon_decay_steps=500000,\n",
    "                                    batch_size=32):\n",
    "        \n",
    "        print('\\nEpisode Reward: {}'.format(stats.episode_rewards[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
